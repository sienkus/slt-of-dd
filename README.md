This is the code for the Singular Learning Theory of Double Descent


This project aims to resolve the open problem of double descent within the framework of singular learning theory (SLT) and developmental interpretability. In particular, this means:

* Operationalizing the “effective model complexity” proposed by Nakkiran et al. (2021) as an explanation of DD, via the local learning coefficient (LLC) from Lau et al. (2023).
  
* Clarifying whether epoch-wise and model-wise double descent have common or diverging causes, through developmental and mechanistic interpretability.
  
*Situating DD in the context of the “universal learning process” from SLT (Hoogland et al., forthcoming).

Making substantial theoretical progress on DD and resolving some of the open disagreements in the literature would advance our understanding of inductive biases in neural networks and thus may eventually contribute to our understanding of key problems in technical AI safety, such as instrumental convergence and mesa-optimization. 
