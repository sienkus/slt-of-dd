{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./devinterp\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: einops>=0.6.1 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from devinterp==0.2.0) (0.6.1)\n",
      "Collecting matplotlib>=3.8.0 (from devinterp==0.2.0)\n",
      "  Using cached matplotlib-3.8.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from devinterp==0.2.0) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.5.3 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from devinterp==0.2.0) (2.2.1)\n",
      "Collecting scipy>=1.11.3 (from devinterp==0.2.0)\n",
      "  Using cached scipy-1.12.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: torch>=2.0.1 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from devinterp==0.2.0) (2.0.1)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from devinterp==0.2.0) (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (6.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from pandas>=1.5.3->devinterp==0.2.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from pandas>=1.5.3->devinterp==0.2.0) (2024.1)\n",
      "Requirement already satisfied: filelock in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from torch>=2.0.1->devinterp==0.2.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from torch>=2.0.1->devinterp==0.2.0) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from torch>=2.0.1->devinterp==0.2.0) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from torch>=2.0.1->devinterp==0.2.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from torch>=2.0.1->devinterp==0.2.0) (3.1.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.8.0->devinterp==0.2.0) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->devinterp==0.2.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from jinja2->torch>=2.0.1->devinterp==0.2.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from sympy->torch>=2.0.1->devinterp==0.2.0) (1.3.0)\n",
      "Using cached matplotlib-3.8.3-cp39-cp39-macosx_11_0_arm64.whl (7.5 MB)\n",
      "Using cached scipy-1.12.0-cp39-cp39-macosx_12_0_arm64.whl (31.4 MB)\n",
      "Building wheels for collected packages: devinterp\n",
      "  Building wheel for devinterp (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for devinterp: filename=devinterp-0.2.0-py3-none-any.whl size=32207 sha256=bd7537713dbe2adff76641fbd69f6816d00ab45363f29480b23e278d61a10a6c\n",
      "  Stored in directory: /private/var/folders/z1/4ncpvz_901x1gm_4cv8jlcwr0000gn/T/pip-ephem-wheel-cache-eq4_vcz2/wheels/d1/77/c6/79d956127053bf417b2be69c96cf13206452a78ec4d772f07c\n",
      "Successfully built devinterp\n",
      "Installing collected packages: scipy, matplotlib, devinterp\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.4\n",
      "    Uninstalling matplotlib-3.7.4:\n",
      "      Successfully uninstalled matplotlib-3.7.4\n",
      "  Attempting uninstall: devinterp\n",
      "    Found existing installation: devinterp 0.1.0\n",
      "    Uninstalling devinterp-0.1.0:\n",
      "      Successfully uninstalled devinterp-0.1.0\n",
      "Successfully installed devinterp-0.2.0 matplotlib-3.8.3 scipy-1.12.0\n"
     ]
    }
   ],
   "source": [
    "import pip\n",
    "! python -m pip install /Users/sienkadounia/lab/ai-futures/Project/devinterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import devinterp\n",
    "from devinterp.slt import estimate_learning_coeff, estimate_learning_coeff_with_summary\n",
    "from devinterp.slt import llc\n",
    "from devinterp.slt.mala import MalaAcceptanceRate\n",
    "from devinterp.optim.sgld import SGLD\n",
    "from devinterp.utils import plot_trace, optimal_temperature\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, Subset, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "device = 'mps' # 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = '/Users/sienkadounia/lab/ai-futures/Project/ewdd/'\n",
    "label_noise_path = '/Users/sienkadounia/lab/ai-futures/Project/label_noise/'\n",
    "rlcts_path = '/Users/sienkadounia/lab/checkpoints/rlcts/ewdd/'\n",
    "mwdd_path = '/Users/sienkadounia/lab/ai-futures/Project/mwdd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "epochs = 400\n",
    "num_classes = 10\n",
    "lr = 0.002\n",
    "use_label_noise =False\n",
    "augmented = False\n",
    "use_adam_op = False\n",
    "input_size = 28 * 28  # MNIST images are 28x28\n",
    "output_size = 10  # 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "mnist_train = datasets.MNIST('data/',\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=transform)\n",
    "mnist_test = datasets.MNIST('data/',\n",
    "                            train=False,\n",
    "                            download=True,\n",
    "                            transform=transform)\n",
    "\n",
    "# Randomly select 40k samples from the training set\n",
    "indices = torch.randperm(len(mnist_train))[:40000]\n",
    "train_data = torch.utils.data.Subset(mnist_train, indices)\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(mnist_test,\n",
    "                        batch_size = batch_size,\n",
    "                        shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, input_size) \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "hidden_sizes = [2, 4, 8, 16, 32 ,64, 128]\n",
    "for k in range (len(hidden_sizes)):\n",
    "    hidden_size = hidden_sizes[k]\n",
    "    model = FCNN(input_size, hidden_size, output_size).to(device)\n",
    "    model.load_state_dict(torch.load(mwdd_path + 'fccnn_'+str(hidden_size)+'_fixed.pth'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MALA calibration for FCNN Model with 1600\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.7287842035293579\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.5614064931869507\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.43637627363204956\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.8354129195213318\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.7710245847702026\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.4292408227920532\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.899661123752594\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.8479490876197815\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.5761594176292419\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.9113941788673401\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.8834526538848877\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.8621942400932312\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.9060407280921936\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.8934714794158936\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.8846835494041443\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.9006694555282593\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.899359941482544\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.894490122795105\n",
      "Running MALA calibration for FCNN Model with 3190\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.6756241917610168\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.4026646018028259\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.36480724811553955\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.8349125981330872\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.6585123538970947\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.3046875\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.8656055331230164\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.8137378692626953\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.3729232847690582\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.9064733386039734\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.8801850080490112\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.8222407102584839\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.904525876045227\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.9128607511520386\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.8892495632171631\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.9081498980522156\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.9006252288818359\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.9087761640548706\n",
      "Running MALA calibration for FCNN Model with 6370\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.5170938372612\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.3996245265007019\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.3331521451473236\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.5184937715530396\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.4893363416194916\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.2688739597797394\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.5139486789703369\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.5442326664924622\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.38184523582458496\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.5564374327659607\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.5679206252098083\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.5284686088562012\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.5548192262649536\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.5674022436141968\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.5246544480323792\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.5542673468589783\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.557211697101593\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.5498247742652893\n",
      "Running MALA calibration for FCNN Model with 12730\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.5244458913803101\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.27764201164245605\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.31021445989608765\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.518045961856842\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.4344407320022583\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.12141180783510208\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.6066039800643921\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.5512232184410095\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.22711221873760223\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.5815739631652832\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.5396888256072998\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.5158652067184448\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.5519378185272217\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.5658354759216309\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.5854284167289734\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.599022388458252\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.5788835883140564\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.5775966048240662\n",
      "Running MALA calibration for FCNN Model with 25450\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.5200234055519104\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.16511417925357819\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.2572088837623596\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.5358158946037292\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.3371734321117401\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.05948924273252487\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.5565557479858398\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.47468301653862\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.08555642515420914\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.572136640548706\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.5583520531654358\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.5034305453300476\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.6073129177093506\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.567939817905426\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.598388671875\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.5756756663322449\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.5700817704200745\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.5722277164459229\n",
      "Running MALA calibration for FCNN Model with 50890\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.4806358218193054\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.11587197333574295\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.22536052763462067\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.501561164855957\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.29384589195251465\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.04394073411822319\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.5543370246887207\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.46418288350105286\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.08931360393762589\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.48923859000205994\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.5429036617279053\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.4847102463245392\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.5609560012817383\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.5228310227394104\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.49452298879623413\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.5131886601448059\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.47279489040374756\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.5440284013748169\n",
      "Running MALA calibration for FCNN Model with 101770\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.3906921446323395\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.018498821184039116\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.1898045688867569\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.4938895106315613\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.1727977991104126\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.005027054343372583\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.5545948147773743\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.3954106867313385\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.014825993217527866\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.5108584761619568\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.49777117371559143\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.38547027111053467\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.5127857327461243\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.5619058012962341\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.5236049294471741\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.5049905776977539\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.5586370229721069\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.5107626914978027\n"
     ]
    }
   ],
   "source": [
    "all_calib_results = []\n",
    "for i in range(len(hidden_sizes)):\n",
    "    EPSILONS = [1e-4, 3e-5, 1e-5, 1e-6, 1e-7, 1e-8]\n",
    "    GAMMAS = [1.0, 10.0, 100.0]\n",
    "    NUM_CHAINS = 1\n",
    "    NUM_DRAWS = 500\n",
    "    calib_results = {}\n",
    "\n",
    "    model = models[i]\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "\n",
    "    print(f'Running MALA calibration for FCNN Model with {count_parameters(model)}')\n",
    "\n",
    "    def estimate_mala_sweeper(model):\n",
    "        for epsilon in EPSILONS:\n",
    "            for gamma in GAMMAS:\n",
    "                mala_estimator = MalaAcceptanceRate(\n",
    "                    num_chains=NUM_CHAINS,\n",
    "                    num_draws=NUM_DRAWS,\n",
    "                    temperature=optimal_temperature(train_loader),\n",
    "                    learning_rate=epsilon,\n",
    "                    device=device,\n",
    "                )\n",
    "\n",
    "                result = estimate_learning_coeff_with_summary(\n",
    "                    model,\n",
    "                    train_loader,\n",
    "                    criterion=criterion,\n",
    "                    optimizer_kwargs=dict(\n",
    "                        lr=epsilon, localization=gamma, temperature=optimal_temperature(train_loader)\n",
    "                    ),\n",
    "                    sampling_method=SGLD,\n",
    "                    num_chains=NUM_CHAINS,\n",
    "                    num_draws=NUM_DRAWS,\n",
    "                    callbacks=[mala_estimator],\n",
    "                    verbose=False,\n",
    "                    online=True,\n",
    "                )\n",
    "                mala_acceptance_rate_mean = mala_estimator.sample()[\"mala_accept/mean\"]\n",
    "                calib_results[(epsilon, gamma)] = result\n",
    "                print(\n",
    "                    f\"epsilon {epsilon}, gamma {gamma}, mala rate: {mala_acceptance_rate_mean}\"\n",
    "                )\n",
    "\n",
    "    estimate_mala_sweeper(model)\n",
    "\n",
    "    torch.save(calib_results, rlcts_path + 'calib_results.pt')\n",
    "    all_calib_results.append(calib_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_llcs_sweeper(model, epsilons, gammas):\n",
    "    results = {}\n",
    "    for epsilon in epsilons:\n",
    "        for gamma in gammas:\n",
    "            optim_kwargs = dict(lr=epsilon, noise_level=1.0, localization=gamma)\n",
    "            pair = (epsilon, gamma)\n",
    "            results[pair] = estimate_learning_coeff_with_summary(\n",
    "                model=model,\n",
    "                loader=train_loader,\n",
    "                criterion=criterion,\n",
    "                sampling_method=SGLD,\n",
    "                optimizer_kwargs=optim_kwargs,\n",
    "                num_chains=NUM_CHAINS,\n",
    "                num_draws=NUM_DRAWS,\n",
    "                device=device,\n",
    "                online=True,\n",
    "            )\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_single_graph(result, title=\"\"):\n",
    "    llc_color = \"teal\"\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    # plot loss traces\n",
    "    loss_traces = result[\"loss/trace\"]\n",
    "    for trace in loss_traces:\n",
    "        init_loss = trace[0]\n",
    "        zeroed_trace = trace - init_loss\n",
    "        sgld_steps = list(range(len(trace)))\n",
    "        axs.plot(sgld_steps, zeroed_trace)\n",
    "\n",
    "    # plot llcs\n",
    "    means = result[\"llc/means\"]\n",
    "    stds = result[\"llc/stds\"]\n",
    "    sgld_steps = list(range(len(means)))\n",
    "    axs2 = axs.twinx()\n",
    "    axs2.plot(\n",
    "        sgld_steps,\n",
    "        means,\n",
    "        color=llc_color,\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        label=f\"llc\",\n",
    "        zorder=3,\n",
    "    )\n",
    "    axs2.fill_between(\n",
    "        sgld_steps, means - stds, means + stds, color=llc_color, alpha=0.3, zorder=2\n",
    "    )\n",
    "\n",
    "    # center zero, assume zero is in the range of both y axes already\n",
    "    y1_min, y1_max = axs.get_ylim()\n",
    "    y2_min, y2_max = axs2.get_ylim()\n",
    "    y1_zero_ratio = abs(y1_min) / (abs(y1_min) + abs(y1_max))\n",
    "    y2_zero_ratio = abs(y2_min) / (abs(y2_min) + abs(y2_max))\n",
    "    percent_to_add = abs(y1_zero_ratio - y2_zero_ratio)\n",
    "    y1_amt_to_add = (y1_max - y1_min) * percent_to_add\n",
    "    y2_amt_to_add = (y2_max - y2_min) * percent_to_add\n",
    "    if y1_zero_ratio < y2_zero_ratio:\n",
    "        # add to bottom of y1 and top of y2\n",
    "        y1_min -= y1_amt_to_add\n",
    "        y2_max += y2_amt_to_add\n",
    "    elif y2_zero_ratio < y1_zero_ratio:\n",
    "        # add to bottom of y2 and top of y1\n",
    "        y2_min -= y2_amt_to_add\n",
    "        y1_max += y1_amt_to_add\n",
    "    axs.set_ylim(y1_min, y1_max)\n",
    "    axs2.set_ylim(y2_min, y2_max)\n",
    "    axs.set_xlabel(\"SGLD time step\")\n",
    "    axs.set_ylabel(\"loss\")\n",
    "    axs2.set_ylabel(\"llc\", color=llc_color)\n",
    "    axs2.tick_params(axis=\"y\", labelcolor=llc_color)\n",
    "    axs.axhline(color=\"black\", linestyle=\":\")\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sweep_single_model(results, epsilons, gammas, **kwargs):\n",
    "    llc_color = \"teal\"\n",
    "    fig, axs = plt.subplots(len(epsilons), len(gammas))\n",
    "\n",
    "    for i, epsilon in enumerate(epsilons):\n",
    "        for j, gamma in enumerate(gammas):\n",
    "            result = results[(epsilon, gamma)]\n",
    "            # plot loss traces\n",
    "            loss_traces = result[\"loss/trace\"]\n",
    "            for trace in loss_traces:\n",
    "                init_loss = trace[0]\n",
    "                zeroed_trace = trace - init_loss\n",
    "                sgld_steps = list(range(len(trace)))\n",
    "                axs[i, j].plot(sgld_steps, zeroed_trace)\n",
    "\n",
    "            # plot llcs\n",
    "            means = result[\"llc/means\"]\n",
    "            stds = result[\"llc/stds\"]\n",
    "            sgld_steps = list(range(len(means)))\n",
    "            axs2 = axs[i, j].twinx()\n",
    "            axs2.plot(\n",
    "                sgld_steps,\n",
    "                means,\n",
    "                color=llc_color,\n",
    "                linestyle=\"--\",\n",
    "                linewidth=2,\n",
    "                label=f\"llc\",\n",
    "                zorder=3,\n",
    "            )\n",
    "            axs2.fill_between(\n",
    "                sgld_steps,\n",
    "                means - stds,\n",
    "                means + stds,\n",
    "                color=llc_color,\n",
    "                alpha=0.3,\n",
    "                zorder=2,\n",
    "            )\n",
    "\n",
    "            # center zero, assume zero is in the range of both y axes already\n",
    "            y1_min, y1_max = axs[i, j].get_ylim()\n",
    "            y2_min, y2_max = axs2.get_ylim()\n",
    "            y1_zero_ratio = abs(y1_min) / (abs(y1_min) + abs(y1_max))\n",
    "            y2_zero_ratio = abs(y2_min) / (abs(y2_min) + abs(y2_max))\n",
    "            percent_to_add = abs(y1_zero_ratio - y2_zero_ratio)\n",
    "            y1_amt_to_add = (y1_max - y1_min) * percent_to_add\n",
    "            y2_amt_to_add = (y2_max - y2_min) * percent_to_add\n",
    "            if y1_zero_ratio < y2_zero_ratio:\n",
    "                # add to bottom of y1 and top of y2\n",
    "                y1_min -= y1_amt_to_add\n",
    "                y2_max += y2_amt_to_add\n",
    "            elif y2_zero_ratio < y1_zero_ratio:\n",
    "                # add to bottom of y2 and top of y1\n",
    "                y2_min -= y2_amt_to_add\n",
    "                y1_max += y1_amt_to_add\n",
    "            axs[i, j].set_ylim(y1_min, y1_max)\n",
    "            axs2.set_ylim(y2_min, y2_max)\n",
    "\n",
    "            axs[i, j].set_title(f\"$\\epsilon$ = {epsilon} : $\\gamma$ = {gamma}, batch_size = {batch_size}, epochs = {epochs}, lr = {lr}, model_size= {count_parameters(model)}\")\n",
    "            # only show x axis label on last row\n",
    "            if i == len(epsilons) - 1:\n",
    "                axs[i, j].set_xlabel(\"SGLD time step\")\n",
    "            axs[i, j].set_ylabel(\"loss\")\n",
    "            axs2.set_ylabel(\"llc\", color=llc_color)\n",
    "            axs2.tick_params(axis=\"y\", labelcolor=llc_color)\n",
    "    if kwargs[\"title\"]:\n",
    "        fig.suptitle(kwargs[\"title\"], fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for calib_results in all_calib_results:\n",
    "    plt.rcParams[\"figure.figsize\"] = (50, 40)\n",
    "    plot_sweep_single_model(\n",
    "    calib_results,\n",
    "    EPSILONS,\n",
    "    GAMMAS,\n",
    "    title=\"Calibration sweep of FCNN on the MNIST data for lr ($\\\\epsilon$) and localization ($\\\\gamma$)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MALA calibration for FCNN Model with 1600\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.7221306562423706\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.5785762071609497\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.5192403197288513\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.7795318365097046\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.7116860747337341\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.5127459168434143\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.8193890452384949\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.8260107636451721\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.6092385053634644\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.8819879293441772\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.8583958148956299\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.8476064205169678\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.8763826489448547\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.8824042677879333\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.8720222115516663\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.880465030670166\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.8679876923561096\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.8719168305397034\n",
      "Running MALA calibration for FCNN Model with 3190\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.665574312210083\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.46641284227371216\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.4725419878959656\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.7595174312591553\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.6345522999763489\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.4104759097099304\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.8366745710372925\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.7860448360443115\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.4577580988407135\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.8845769762992859\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.8685486316680908\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.7968737483024597\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.8708682060241699\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.8799179792404175\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.8772559762001038\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.8722015023231506\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.8742296695709229\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.8834484815597534\n",
      "Running MALA calibration for FCNN Model with 6370\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.5393244624137878\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.45248499512672424\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.44761744141578674\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.5497764945030212\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.49195945262908936\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.42951926589012146\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.5555539727210999\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.5357252955436707\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.437313973903656\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.5305073857307434\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.558409571647644\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.5177852511405945\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.5422910451889038\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.5521397590637207\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.5585125088691711\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.5879876613616943\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.5189096331596375\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.5546529293060303\n",
      "Running MALA calibration for FCNN Model with 12730\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.5309738516807556\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.36256012320518494\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.414052814245224\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.5600817799568176\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.4593474268913269\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.3063621520996094\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.5256308317184448\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.5133429169654846\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.335744172334671\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.5690690875053406\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.5487520098686218\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.5317598581314087\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.5582950711250305\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.5669242739677429\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.5307480096817017\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.561205267906189\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.566724956035614\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.5475857257843018\n",
      "Running MALA calibration for FCNN Model with 25450\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.4825606346130371\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.2548530399799347\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.3766801357269287\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.5103577971458435\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.3785410523414612\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.23044712841510773\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.5318694710731506\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.4908214807510376\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.1791469007730484\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.5601367950439453\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.5743848085403442\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.47772058844566345\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.5586025714874268\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.567131519317627\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.5681638717651367\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.5777691602706909\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.5710973739624023\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.5644189119338989\n",
      "Running MALA calibration for FCNN Model with 50890\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.46230044960975647\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.24298585951328278\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.3568877577781677\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.510211169719696\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.37294578552246094\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.20809505879878998\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.5185410976409912\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.45343655347824097\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.2004462480545044\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.5453019738197327\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.5272805094718933\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.43485838174819946\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.5200421214103699\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.4911341071128845\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.5126876831054688\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.5190931558609009\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.5013335347175598\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.5039438605308533\n",
      "Running MALA calibration for FCNN Model with 101770\n",
      "epsilon 0.0001, gamma 1.0, mala rate: 0.4343116581439972\n",
      "epsilon 0.0001, gamma 10.0, mala rate: 0.12805213034152985\n",
      "epsilon 0.0001, gamma 100.0, mala rate: 0.3440767824649811\n",
      "epsilon 3e-05, gamma 1.0, mala rate: 0.48656004667282104\n",
      "epsilon 3e-05, gamma 10.0, mala rate: 0.25603535771369934\n",
      "epsilon 3e-05, gamma 100.0, mala rate: 0.13637763261795044\n",
      "epsilon 1e-05, gamma 1.0, mala rate: 0.5082730054855347\n",
      "epsilon 1e-05, gamma 10.0, mala rate: 0.41334038972854614\n",
      "epsilon 1e-05, gamma 100.0, mala rate: 0.07083141058683395\n",
      "epsilon 1e-06, gamma 1.0, mala rate: 0.5262508392333984\n",
      "epsilon 1e-06, gamma 10.0, mala rate: 0.5569930076599121\n",
      "epsilon 1e-06, gamma 100.0, mala rate: 0.41710251569747925\n",
      "epsilon 1e-07, gamma 1.0, mala rate: 0.5485178232192993\n",
      "epsilon 1e-07, gamma 10.0, mala rate: 0.491232305765152\n",
      "epsilon 1e-07, gamma 100.0, mala rate: 0.5130473971366882\n",
      "epsilon 1e-08, gamma 1.0, mala rate: 0.5162519216537476\n",
      "epsilon 1e-08, gamma 10.0, mala rate: 0.5473316311836243\n",
      "epsilon 1e-08, gamma 100.0, mala rate: 0.5069552659988403\n"
     ]
    }
   ],
   "source": [
    "more_chains_all_calib_results = []\n",
    "all_mala_acc_rates = []\n",
    "for i in range(len(hidden_sizes)):\n",
    "    EPSILONS = [1e-4, 3e-5, 1e-5, 1e-6, 1e-7, 1e-8]\n",
    "    GAMMAS = [1.0, 10.0, 100.0]\n",
    "    NUM_CHAINS = 5\n",
    "    NUM_DRAWS = 1000\n",
    "    calib_results = {}\n",
    "    mala_acc_rates = []\n",
    "\n",
    "    model = models[i]\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "\n",
    "    print(f'Running MALA calibration for FCNN Model with {count_parameters(model)}')\n",
    "\n",
    "    def estimate_mala_sweeper(model):\n",
    "        for epsilon in EPSILONS:\n",
    "            for gamma in GAMMAS:\n",
    "                mala_estimator = MalaAcceptanceRate(\n",
    "                    num_chains=NUM_CHAINS,\n",
    "                    num_draws=NUM_DRAWS,\n",
    "                    temperature=optimal_temperature(train_loader),\n",
    "                    learning_rate=epsilon,\n",
    "                    device=device,\n",
    "                )\n",
    "\n",
    "                result = estimate_learning_coeff_with_summary(\n",
    "                    model,\n",
    "                    train_loader,\n",
    "                    criterion=criterion,\n",
    "                    optimizer_kwargs=dict(\n",
    "                        lr=epsilon, localization=gamma, temperature=optimal_temperature(train_loader)\n",
    "                    ),\n",
    "                    sampling_method=SGLD,\n",
    "                    num_chains=NUM_CHAINS,\n",
    "                    num_draws=NUM_DRAWS,\n",
    "                    callbacks=[mala_estimator],\n",
    "                    verbose=False,\n",
    "                    online=True,\n",
    "                )\n",
    "                mala_acceptance_rate_mean = mala_estimator.sample()[\"mala_accept/mean\"]\n",
    "                mala_acc_rates.append(mala_acceptance_rate_mean)\n",
    "                calib_results[(epsilon, gamma)] = result\n",
    "                print(\n",
    "                    f\"epsilon {epsilon}, gamma {gamma}, mala rate: {mala_acceptance_rate_mean}\"\n",
    "                )\n",
    "\n",
    "    estimate_mala_sweeper(model)\n",
    "\n",
    "    torch.save(calib_results, rlcts_path + '10_chains_calib_results.pt')\n",
    "    more_chains_all_calib_results.append(calib_results)\n",
    "    all_mala_acc_rates.append(mala_acc_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for calib_results in more_chains_all_calib_results:\n",
    "   \n",
    "    model = models[i]\n",
    "    plt.rcParams[\"figure.figsize\"] = (60, 40)\n",
    "    plot_sweep_single_model(\n",
    "    calib_results,\n",
    "    EPSILONS,\n",
    "    GAMMAS,\n",
    "    title=\"Calibration sweep of FCNN model on MNIST for lr ($\\\\epsilon$) and localization ($\\\\gamma$)\",\n",
    ")\n",
    "    i=i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
