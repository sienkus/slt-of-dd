{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import yaml\n",
    "import sklearn\n",
    "#import devinterp\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "device = 'mps' # 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define all the hyperparameters\n",
    "use_adam_op = True\n",
    "augmented = True\n",
    "use_label_noise = True\n",
    "pytorch_default_resnet = False\n",
    "on_colab = False\n",
    "model_width = 64\n",
    "num_classes = 10\n",
    "noise_levels = [0.10, 0.15, 0.20]\n",
    "batch_size = 500\n",
    "lr = 0.0001\n",
    "epochs = 2000\n",
    "model_seed = 42\n",
    "data_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ResNet18 for CIFAR\n",
    "## Based on: https://gitlab.com/harvard-machine-learning/double-descent/-/blob/master/models/resnet18k.py\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, **kwargs):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                          nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes, init_channels):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = init_channels\n",
    "        c = init_channels\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, c, kernel_size=7,\n",
    "                               stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(c)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "        self.layer1 = self._make_layer(block, c, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 2*c, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 4*c, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 8*c, num_blocks[3], stride=2)\n",
    "        self.avpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.linear = nn.Linear(8*c*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        # eg: [2, 1, 1, ..., 1]. Only the first one downsamples.\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def make_resnet18k(k, num_classes) -> PreActResNet:\n",
    "    ''' Returns a ResNet18 with width parameter k. (k=64 is standard ResNet18)'''\n",
    "    return PreActResNet(PreActBlock, [2, 2, 2, 2], num_classes=num_classes, init_channels=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Let's import the CIFAR10 dataset from torchvision\n",
    "transform = transforms.Compose([transforms.ToTensor()]) if not augmented else transforms.Compose([transforms.ToTensor(), transforms.RandomCrop(32, padding=4), transforms.RandomHorizontalFlip(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "if data_seed is not None:\n",
    "    torch.manual_seed(data_seed)\n",
    "\n",
    "train_set = datasets.CIFAR10(root='./data',\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=transform)\n",
    "trainloader = DataLoader(train_set,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True\n",
    "                         )\n",
    "\n",
    "test_set = datasets.CIFAR10(root='./data',\n",
    "                            train=False,\n",
    "                            download=True,\n",
    "                            transform=transform)\n",
    "testloader = DataLoader(test_set,\n",
    "                        shuffle=False,\n",
    "                        batch_size=batch_size\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = '/Users/sienkadounia/lab/ai-futures/Project/ewdd/'\n",
    "label_noise_path = '/Users/sienkadounia/lab/ai-futures/Project/label_noise/'\n",
    "rlcts_path = '/Users/sienkadounia/lab/checkpoints/rlcts/ewdd/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_logits = []\n",
    "to_save = list(range(0, 135)) + list(range(130, 1000, 10))+ list(range(1000, 2000, 100)) + [1999]\n",
    "\n",
    "for point in to_save:\n",
    "  logits = []\n",
    "  model = make_resnet18k(model_width, num_classes)\n",
    "  checkpoint= torch.load('ewdd/noise_20' +'checkpoint-with-noise'+str(point)+'.pth', map_location=device)\n",
    "  model.load_state_dict(checkpoint['model_state'])\n",
    "  with torch.no_grad():\n",
    "      for images, labels in testloader:\n",
    "          features = model(images)\n",
    "          logits.extend(features.numpy())\n",
    "  # Apply PCA to reduce dimensionality to 3\n",
    "  pca = PCA(n_components=3)\n",
    "  pca_logit = pca.fit_transform(logits)\n",
    "  pca_logits.append(pca_logit)\n",
    "torch.save(pca_logits, 'ewdd/pca_logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./devinterp\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: einops>=0.6.1 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from devinterp==0.2.0) (0.6.1)\n",
      "Requirement already satisfied: matplotlib>=3.8.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from devinterp==0.2.0) (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from devinterp==0.2.0) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.5.3 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from devinterp==0.2.0) (2.2.1)\n",
      "Requirement already satisfied: scipy>=1.11.3 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from devinterp==0.2.0) (1.12.0)\n",
      "Requirement already satisfied: torch>=2.0.1 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from devinterp==0.2.0) (2.0.1)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from devinterp==0.2.0) (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from matplotlib>=3.8.0->devinterp==0.2.0) (6.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from pandas>=1.5.3->devinterp==0.2.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from pandas>=1.5.3->devinterp==0.2.0) (2024.1)\n",
      "Requirement already satisfied: filelock in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from torch>=2.0.1->devinterp==0.2.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from torch>=2.0.1->devinterp==0.2.0) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from torch>=2.0.1->devinterp==0.2.0) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from torch>=2.0.1->devinterp==0.2.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from torch>=2.0.1->devinterp==0.2.0) (3.1.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.8.0->devinterp==0.2.0) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->devinterp==0.2.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from jinja2->torch>=2.0.1->devinterp==0.2.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages (from sympy->torch>=2.0.1->devinterp==0.2.0) (1.3.0)\n",
      "Building wheels for collected packages: devinterp\n",
      "  Building wheel for devinterp (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for devinterp: filename=devinterp-0.2.0-py3-none-any.whl size=36054 sha256=60214053dd85c3d3a9232489ba2899680a0ccd9af8b36337e87ece2c4012e9cf\n",
      "  Stored in directory: /private/var/folders/z1/4ncpvz_901x1gm_4cv8jlcwr0000gn/T/pip-ephem-wheel-cache-y3aeaz0w/wheels/d1/77/c6/79d956127053bf417b2be69c96cf13206452a78ec4d772f07c\n",
      "Successfully built devinterp\n",
      "Installing collected packages: devinterp\n",
      "  Attempting uninstall: devinterp\n",
      "    Found existing installation: devinterp 0.2.0\n",
      "    Uninstalling devinterp-0.2.0:\n",
      "      Successfully uninstalled devinterp-0.2.0\n",
      "Successfully installed devinterp-0.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install /Users/sienkadounia/lab/ai-futures/Project/devinterp\n",
    "import devinterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devinterp.slt.forms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_logits = torch.load('ewdd/pca_logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pca_logits = np.concatenate(pca_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devinterp.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_helper(z, sigma_early, sigma_late, sigma_interp_end, interp_range=0.2):\n",
    "    sigma_interp_start = interp_range * sigma_interp_end\n",
    "    if z < sigma_interp_start:\n",
    "        return sigma_early\n",
    "    elif z > sigma_interp_end:\n",
    "        return sigma_late\n",
    "    else:\n",
    "        return sigma_early + (sigma_late - sigma_early) / (\n",
    "            sigma_interp_end - sigma_interp_start\n",
    "        ) * (z - sigma_interp_start)\n",
    "\n",
    "def get_smoothed_pcs(\n",
    "    transformed_samples,\n",
    "    num_pca_components,\n",
    "    early_smoothing,\n",
    "    late_smoothing,\n",
    "    late_smoothing_from,\n",
    "):\n",
    "    smoothed_pcs = []\n",
    "    for pca_component_i in range(0, num_pca_components):\n",
    "        print(f\"Processing smoothing for PC{pca_component_i+1}\")\n",
    "        smoothed_pc = np.copy(transformed_samples[:, 0])\n",
    "        for z in range(len(transformed_samples)):\n",
    "            sigma = sigma_helper(\n",
    "                z, early_smoothing, late_smoothing, late_smoothing_from\n",
    "            )\n",
    "            smoothed_pc[z] = gaussian_filter1d(\n",
    "                transformed_samples[:, pca_component_i], sigma\n",
    "            )[z]\n",
    "        smoothed_pcs.append(smoothed_pc)\n",
    "    return smoothed_pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pca_components = 3\n",
    "transformed_samples = cat_pca_logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing smoothing for PC1\n",
      "Processing smoothing for PC2\n",
      "Processing smoothing for PC3\n"
     ]
    }
   ],
   "source": [
    "smoothed_pcs = get_smoothed_pcs(\n",
    "    transformed_samples,\n",
    "    n_pca_components,\n",
    "    early_smoothing=1,\n",
    "    late_smoothing=1,\n",
    "    late_smoothing_from=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_pcs = torch.load('ewdd/smoothed_pcs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSITIONS = [  # TODO automate\n",
    "    (0, 38, \"First Descent\"),\n",
    "    (38, 128, \"Increase\"),\n",
    "    (128, 1_999, \"Second Descent\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(colors) != len(transitions), using rainbow palette.\n",
      "Number of samples: 2330000\n",
      "Plotting PC1 vs PC2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sienkadounia/anaconda3/envs/new/lib/python3.9/site-packages/devinterp/slt/forms.py:109: UserWarning: Can't plot vertex influence when cusp data not provided\n",
      "  warnings.warn(\"Can't plot vertex influence when cusp data not provided\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig = plot_essential_dynamics_grid(\n",
    "    transformed_samples,\n",
    "    smoothed_pcs,\n",
    "    transitions=TRANSITIONS,\n",
    "    marked_cusp_data=[],\n",
    "    num_plotted_pca_comps=n_pca_components,\n",
    "    plot_vertex_influence=True,\n",
    "    plot_caustic=True,\n",
    "    figsize=(8, 8 / 10 * 6),\n",
    "    num_sharp_points=5,\n",
    "    num_vertices=5,\n",
    "    osculate_start=1,\n",
    "    osculate_end_offset=5,\n",
    "    osculate_skip=1,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(smoothed_pcs), \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_pca_components\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "len(smoothed_pcs), len(n_pca_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(colors) != len(transitions), using rainbow palette.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mplot_essential_dynamics_grid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpca_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msmoothed_pcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRANSITIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# marked_cusp_data=marked_cusp_data,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_plotted_pca_comps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_pca_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_vertex_influence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_caustic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_sharp_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_vertices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mosculate_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mosculate_end_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mosculate_skip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/devinterp/lib/python3.9/site-packages/devinterp/slt/forms.py:110\u001b[0m, in \u001b[0;36mplot_essential_dynamics_grid\u001b[0;34m(samples, smoothed_pcs, transitions, colors, marked_cusp_data, num_plotted_pca_comps, plot_caustic, plot_vertex_influence, figsize, num_sharp_points, num_vertices, osculate_start, osculate_end_offset, osculate_skip)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot_vertex_influence \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(marked_cusp_data):\n\u001b[1;32m    109\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt plot vertex influence when cusp data not provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_plotted_pca_comps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msmoothed_pcs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    111\u001b[0m     smoothed_pcs \u001b[38;5;241m=\u001b[39m smoothed_pcs[:num_plotted_pca_comps]\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m  num_plotted_pca_comps \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(smoothed_pcs):\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "fig = plot_essential_dynamics_grid(\n",
    "    transformed_samples,\n",
    "    smoothed_pcs=3,\n",
    "    transitions=TRANSITIONS,\n",
    "    # marked_cusp_data=marked_cusp_data,\n",
    "    num_plotted_pca_comps=n_pca_components,\n",
    "    plot_vertex_influence=True,\n",
    "    plot_caustic=True,\n",
    "    figsize=(8, 8 / 10 * 6),\n",
    "    num_sharp_points=5,\n",
    "    num_vertices=5,\n",
    "    osculate_start=1,\n",
    "    osculate_end_offset=2000,\n",
    "    osculate_skip=8,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_logits[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
