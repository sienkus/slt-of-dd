{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, Subset, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "device = 'mps' # 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = '/Users/sienkadounia/lab/ai-futures/Project/ewdd/'\n",
    "label_noise_path = '/Users/sienkadounia/lab/ai-futures/Project/label_noise/'\n",
    "rlcts_path = '/Users/sienkadounia/lab/checkpoints/rlcts/ewdd/'\n",
    "mwdd_path = '/Users/sienkadounia/lab/ai-futures/Project/mwdd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 2000\n",
    "num_classes = 10\n",
    "lr = 0.1\n",
    "use_label_noise =False\n",
    "augmented = False\n",
    "use_adam_op = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "mnist_train = datasets.MNIST('data/',\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=transform)\n",
    "mnist_test = datasets.MNIST('data/',\n",
    "                            train=False,\n",
    "                            download=True,\n",
    "                            transform=transform)\n",
    "\n",
    "# Randomly select 40k samples from the training set\n",
    "indices = torch.randperm(len(mnist_train))[:40000]\n",
    "train_data = torch.utils.data.Subset(mnist_train, indices)\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(mnist_test,\n",
    "                        batch_size = batch_size,\n",
    "                        shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_weight_reuse(larger_model, smaller_model, additional_hidden_size):\n",
    "    # Copy weights for the first part of the network\n",
    "    larger_model.fc1.weight.data[:smaller_model.fc1.weight.size(0)] = smaller_model.fc1.weight.data\n",
    "    larger_model.fc1.bias.data[:smaller_model.fc1.bias.size(0)] = smaller_model.fc1.bias.data\n",
    "    \n",
    "    # Initialize additional weights normally\n",
    "    nn.init.normal_(larger_model.fc1.weight.data[smaller_model.fc1.weight.size(0):], mean=0, std=0.01)\n",
    "    nn.init.zeros_(larger_model.fc1.bias.data[smaller_model.fc1.bias.size(0):])\n",
    "    \n",
    "    # Initialize output layer weights with Glorot-uniform\n",
    "    nn.init.xavier_uniform_(larger_model.fc2.weight)\n",
    "    nn.init.zeros_(larger_model.fc2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import math\n",
    "def lr_lambda(epoch):\n",
    "    base_lr = 0.1\n",
    "    return base_lr/math.sqrt(epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, train_loader, input_size, hidden_size, output_size):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.95) if not use_adam_op else optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "    wandb.init(project=\"SLT of Double Descent\", \n",
    "    config = {'epochs': epochs,\n",
    "              'classes': num_classes,\n",
    "              'learning_rate': lr,\n",
    "              'use_label_noise': use_label_noise,\n",
    "              'dataset': \"MNIST\",\n",
    "              'architecture': \"FCNN\",\n",
    "              'model_width': count_parameters(model),\n",
    "              'augmented': augmented,\n",
    "              'adam optimizer': use_adam_op})\n",
    "\n",
    "    wandb.watch(model)\n",
    "    config = wandb.config\n",
    "\n",
    "    test_losses = []\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    step = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        for _, data in enumerate(train_loader):\n",
    "            images, labels = data\n",
    "            images = images.view(-1, input_size)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            batch_loss = criterion(outputs, labels)\n",
    "            predictions = outputs.argmax(axis=-1)\n",
    "            train_acc += torch.sum(predictions == labels).item()\n",
    "            train_loss += batch_loss.item()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            step += 1\n",
    "\n",
    "            wandb.log({'batch_loss': batch_loss.item()}, step=step)\n",
    "\n",
    "        # Calculate average training loss for the epoch\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= 40000\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # Validation (or test) loop\n",
    "        model.eval()\n",
    "\n",
    "        test_loss = 0.0\n",
    "        test_acc = 0.0\n",
    "        with torch.no_grad():\n",
    "            for k, test_data in enumerate(test_loader):\n",
    "                test_images, test_labels = test_data\n",
    "                test_images = test_images.view(-1, input_size)\n",
    "                test_images = test_images.to(device)\n",
    "                test_labels = test_labels.to(device)\n",
    "\n",
    "                outputs = model(test_images)\n",
    "                batch_test_loss = criterion(outputs, test_labels)\n",
    "                test_loss += batch_test_loss.item()\n",
    "\n",
    "                predictions = outputs.argmax(axis=-1)\n",
    "                test_acc += torch.sum(predictions == test_labels).item()\n",
    "\n",
    "        # Let's calculate average test loss for the epoch\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc /= len(test_loader.dataset.data)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        torch.save(test_accs, rlcts_path + 'test_accs_'+ str(hidden_size)+'.pt')\n",
    "        torch.save(test_losses, rlcts_path + 'test_losses_'+ str(hidden_size)+'.pt')\n",
    "\n",
    "        wandb.log({'epoch': epoch,\n",
    "                   'loss/train': train_loss,\n",
    "                   'loss/test': test_loss,\n",
    "                   'accuracy/train': train_acc,\n",
    "                   'accuracy/test': test_acc\n",
    "                   }, step=step)\n",
    "\n",
    "        # Print or log the training and test losses for each epoch\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Implement stopping condition based on classification error or epoch limit\n",
    "        # Note: Simplified, as the full stopping condition is not detailed here\n",
    "    wandb.finish()\n",
    "    torch.save(model.state_dict(), mwdd_path + 'fccnn_'+str(hidden_size)+'.pth')\n",
    "    print(f\"Training completed for hidden size: {hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msienka\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240312_170907-o25bw72b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/o25bw72b' target=\"_blank\">divine-water-260</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/o25bw72b' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/o25bw72b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Train Loss: 1.9905, Test Loss: 1.8072\n",
      "Epoch 2/2000, Train Loss: 1.7684, Test Loss: 1.7422\n",
      "Epoch 3/2000, Train Loss: 1.7239, Test Loss: 1.6965\n",
      "Epoch 4/2000, Train Loss: 1.6987, Test Loss: 1.6853\n",
      "Epoch 5/2000, Train Loss: 1.6882, Test Loss: 1.6775\n",
      "Epoch 6/2000, Train Loss: 1.6825, Test Loss: 1.6703\n",
      "Epoch 7/2000, Train Loss: 1.6695, Test Loss: 1.6657\n",
      "Epoch 8/2000, Train Loss: 1.6677, Test Loss: 1.6609\n",
      "Epoch 9/2000, Train Loss: 1.6630, Test Loss: 1.6535\n",
      "Epoch 10/2000, Train Loss: 1.6609, Test Loss: 1.6555\n",
      "Epoch 11/2000, Train Loss: 1.6583, Test Loss: 1.6490\n",
      "Epoch 12/2000, Train Loss: 1.6549, Test Loss: 1.6537\n",
      "Epoch 13/2000, Train Loss: 1.6553, Test Loss: 1.6475\n",
      "Epoch 14/2000, Train Loss: 1.6514, Test Loss: 1.6385\n",
      "Epoch 15/2000, Train Loss: 1.6510, Test Loss: 1.6411\n",
      "Epoch 16/2000, Train Loss: 1.6478, Test Loss: 1.6408\n",
      "Epoch 17/2000, Train Loss: 1.6487, Test Loss: 1.6323\n",
      "Epoch 18/2000, Train Loss: 1.6468, Test Loss: 1.6487\n",
      "Epoch 19/2000, Train Loss: 1.6453, Test Loss: 1.6512\n",
      "Epoch 20/2000, Train Loss: 1.6471, Test Loss: 1.6539\n",
      "Epoch 21/2000, Train Loss: 1.6429, Test Loss: 1.6565\n",
      "Epoch 22/2000, Train Loss: 1.6428, Test Loss: 1.6405\n",
      "Epoch 23/2000, Train Loss: 1.6416, Test Loss: 1.6341\n",
      "Epoch 24/2000, Train Loss: 1.6429, Test Loss: 1.6401\n",
      "Epoch 25/2000, Train Loss: 1.6404, Test Loss: 1.6350\n",
      "Epoch 26/2000, Train Loss: 1.6421, Test Loss: 1.6655\n",
      "Epoch 27/2000, Train Loss: 1.6419, Test Loss: 1.6350\n",
      "Epoch 28/2000, Train Loss: 1.6397, Test Loss: 1.6334\n",
      "Epoch 29/2000, Train Loss: 1.6397, Test Loss: 1.6331\n",
      "Epoch 30/2000, Train Loss: 1.6401, Test Loss: 1.6405\n",
      "Epoch 31/2000, Train Loss: 1.6378, Test Loss: 1.6407\n",
      "Epoch 32/2000, Train Loss: 1.6378, Test Loss: 1.6407\n",
      "Epoch 33/2000, Train Loss: 1.6366, Test Loss: 1.6334\n",
      "Epoch 34/2000, Train Loss: 1.6384, Test Loss: 1.6364\n",
      "Epoch 35/2000, Train Loss: 1.6373, Test Loss: 1.6340\n",
      "Epoch 36/2000, Train Loss: 1.6354, Test Loss: 1.6346\n",
      "Epoch 37/2000, Train Loss: 1.6353, Test Loss: 1.6351\n",
      "Epoch 38/2000, Train Loss: 1.6344, Test Loss: 1.6276\n",
      "Epoch 39/2000, Train Loss: 1.6341, Test Loss: 1.6285\n",
      "Epoch 40/2000, Train Loss: 1.6334, Test Loss: 1.6287\n",
      "Epoch 41/2000, Train Loss: 1.6325, Test Loss: 1.6293\n",
      "Epoch 42/2000, Train Loss: 1.6338, Test Loss: 1.6331\n",
      "Epoch 43/2000, Train Loss: 1.6323, Test Loss: 1.6249\n",
      "Epoch 44/2000, Train Loss: 1.6321, Test Loss: 1.6292\n",
      "Epoch 45/2000, Train Loss: 1.6327, Test Loss: 1.6293\n",
      "Epoch 46/2000, Train Loss: 1.6317, Test Loss: 1.6246\n",
      "Epoch 47/2000, Train Loss: 1.6299, Test Loss: 1.6214\n",
      "Epoch 48/2000, Train Loss: 1.6303, Test Loss: 1.6222\n",
      "Epoch 49/2000, Train Loss: 1.6301, Test Loss: 1.6394\n",
      "Epoch 50/2000, Train Loss: 1.6287, Test Loss: 1.6217\n",
      "Epoch 51/2000, Train Loss: 1.6308, Test Loss: 1.6192\n",
      "Epoch 52/2000, Train Loss: 1.6290, Test Loss: 1.6219\n",
      "Epoch 53/2000, Train Loss: 1.6274, Test Loss: 1.6259\n",
      "Epoch 54/2000, Train Loss: 1.6283, Test Loss: 1.6194\n",
      "Epoch 55/2000, Train Loss: 1.6260, Test Loss: 1.6161\n",
      "Epoch 56/2000, Train Loss: 1.6264, Test Loss: 1.6137\n",
      "Epoch 57/2000, Train Loss: 1.6256, Test Loss: 1.6178\n",
      "Epoch 58/2000, Train Loss: 1.6248, Test Loss: 1.6147\n",
      "Epoch 59/2000, Train Loss: 1.6223, Test Loss: 1.6181\n",
      "Epoch 60/2000, Train Loss: 1.6247, Test Loss: 1.6169\n",
      "Epoch 61/2000, Train Loss: 1.6216, Test Loss: 1.6107\n",
      "Epoch 62/2000, Train Loss: 1.6195, Test Loss: 1.6088\n",
      "Epoch 63/2000, Train Loss: 1.6199, Test Loss: 1.5975\n",
      "Epoch 64/2000, Train Loss: 1.6199, Test Loss: 1.6063\n",
      "Epoch 65/2000, Train Loss: 1.6186, Test Loss: 1.6071\n",
      "Epoch 66/2000, Train Loss: 1.6168, Test Loss: 1.6041\n",
      "Epoch 67/2000, Train Loss: 1.6174, Test Loss: 1.6056\n",
      "Epoch 68/2000, Train Loss: 1.6146, Test Loss: 1.5998\n",
      "Epoch 69/2000, Train Loss: 1.6146, Test Loss: 1.6112\n",
      "Epoch 70/2000, Train Loss: 1.6119, Test Loss: 1.6060\n",
      "Epoch 71/2000, Train Loss: 1.6125, Test Loss: 1.5988\n",
      "Epoch 72/2000, Train Loss: 1.6111, Test Loss: 1.5966\n",
      "Epoch 73/2000, Train Loss: 1.6098, Test Loss: 1.5979\n",
      "Epoch 74/2000, Train Loss: 1.6099, Test Loss: 1.6239\n",
      "Epoch 75/2000, Train Loss: 1.6113, Test Loss: 1.5946\n",
      "Epoch 76/2000, Train Loss: 1.6077, Test Loss: 1.5909\n",
      "Epoch 77/2000, Train Loss: 1.6076, Test Loss: 1.5985\n",
      "Epoch 78/2000, Train Loss: 1.6098, Test Loss: 1.5908\n",
      "Epoch 79/2000, Train Loss: 1.6059, Test Loss: 1.5930\n",
      "Epoch 80/2000, Train Loss: 1.6049, Test Loss: 1.5932\n",
      "Epoch 81/2000, Train Loss: 1.6040, Test Loss: 1.5911\n",
      "Epoch 82/2000, Train Loss: 1.6049, Test Loss: 1.5912\n",
      "Epoch 83/2000, Train Loss: 1.6030, Test Loss: 1.5886\n",
      "Epoch 84/2000, Train Loss: 1.6025, Test Loss: 1.5887\n",
      "Epoch 85/2000, Train Loss: 1.6018, Test Loss: 1.5834\n",
      "Epoch 86/2000, Train Loss: 1.5997, Test Loss: 1.5868\n",
      "Epoch 87/2000, Train Loss: 1.6019, Test Loss: 1.5857\n",
      "Epoch 88/2000, Train Loss: 1.5980, Test Loss: 1.5904\n",
      "Epoch 89/2000, Train Loss: 1.5976, Test Loss: 1.5786\n",
      "Epoch 90/2000, Train Loss: 1.5975, Test Loss: 1.5772\n",
      "Epoch 91/2000, Train Loss: 1.5959, Test Loss: 1.5803\n",
      "Epoch 92/2000, Train Loss: 1.5964, Test Loss: 1.5791\n",
      "Epoch 93/2000, Train Loss: 1.5948, Test Loss: 1.6016\n",
      "Epoch 94/2000, Train Loss: 1.5957, Test Loss: 1.5812\n",
      "Epoch 95/2000, Train Loss: 1.5924, Test Loss: 1.5744\n",
      "Epoch 96/2000, Train Loss: 1.5922, Test Loss: 1.5787\n",
      "Epoch 97/2000, Train Loss: 1.5917, Test Loss: 1.5759\n",
      "Epoch 98/2000, Train Loss: 1.5915, Test Loss: 1.5746\n",
      "Epoch 99/2000, Train Loss: 1.5900, Test Loss: 1.5731\n",
      "Epoch 100/2000, Train Loss: 1.5896, Test Loss: 1.5842\n",
      "Epoch 101/2000, Train Loss: 1.5890, Test Loss: 1.5742\n",
      "Epoch 102/2000, Train Loss: 1.5887, Test Loss: 1.5742\n",
      "Epoch 103/2000, Train Loss: 1.5874, Test Loss: 1.5762\n",
      "Epoch 104/2000, Train Loss: 1.5882, Test Loss: 1.5777\n",
      "Epoch 105/2000, Train Loss: 1.5897, Test Loss: 1.5744\n",
      "Epoch 106/2000, Train Loss: 1.5857, Test Loss: 1.5720\n",
      "Epoch 107/2000, Train Loss: 1.5868, Test Loss: 1.5749\n",
      "Epoch 108/2000, Train Loss: 1.5860, Test Loss: 1.5749\n",
      "Epoch 109/2000, Train Loss: 1.5859, Test Loss: 1.5731\n",
      "Epoch 110/2000, Train Loss: 1.5847, Test Loss: 1.5731\n",
      "Epoch 111/2000, Train Loss: 1.5842, Test Loss: 1.5773\n",
      "Epoch 112/2000, Train Loss: 1.5847, Test Loss: 1.5851\n",
      "Epoch 113/2000, Train Loss: 1.5840, Test Loss: 1.5702\n",
      "Epoch 114/2000, Train Loss: 1.5814, Test Loss: 1.5662\n",
      "Epoch 115/2000, Train Loss: 1.5821, Test Loss: 1.5663\n",
      "Epoch 116/2000, Train Loss: 1.5823, Test Loss: 1.5651\n",
      "Epoch 117/2000, Train Loss: 1.5817, Test Loss: 1.5690\n",
      "Epoch 118/2000, Train Loss: 1.5811, Test Loss: 1.5670\n",
      "Epoch 119/2000, Train Loss: 1.5835, Test Loss: 1.5667\n",
      "Epoch 120/2000, Train Loss: 1.5798, Test Loss: 1.5695\n",
      "Epoch 121/2000, Train Loss: 1.5807, Test Loss: 1.5664\n",
      "Epoch 122/2000, Train Loss: 1.5797, Test Loss: 1.5658\n",
      "Epoch 123/2000, Train Loss: 1.5802, Test Loss: 1.5610\n",
      "Epoch 124/2000, Train Loss: 1.5786, Test Loss: 1.5637\n",
      "Epoch 125/2000, Train Loss: 1.5780, Test Loss: 1.5629\n",
      "Epoch 126/2000, Train Loss: 1.5777, Test Loss: 1.5676\n",
      "Epoch 127/2000, Train Loss: 1.5778, Test Loss: 1.5647\n",
      "Epoch 128/2000, Train Loss: 1.5775, Test Loss: 1.5643\n",
      "Epoch 129/2000, Train Loss: 1.5779, Test Loss: 1.5718\n",
      "Epoch 130/2000, Train Loss: 1.5808, Test Loss: 1.5714\n",
      "Epoch 131/2000, Train Loss: 1.5793, Test Loss: 1.5663\n",
      "Epoch 132/2000, Train Loss: 1.5771, Test Loss: 1.5683\n",
      "Epoch 133/2000, Train Loss: 1.5759, Test Loss: 1.5665\n",
      "Epoch 134/2000, Train Loss: 1.5763, Test Loss: 1.5622\n",
      "Epoch 135/2000, Train Loss: 1.5754, Test Loss: 1.5725\n",
      "Epoch 136/2000, Train Loss: 1.5746, Test Loss: 1.5636\n",
      "Epoch 137/2000, Train Loss: 1.5749, Test Loss: 1.5685\n",
      "Epoch 138/2000, Train Loss: 1.5736, Test Loss: 1.5699\n",
      "Epoch 139/2000, Train Loss: 1.5727, Test Loss: 1.5609\n",
      "Epoch 140/2000, Train Loss: 1.5740, Test Loss: 1.5673\n",
      "Epoch 141/2000, Train Loss: 1.5744, Test Loss: 1.5645\n",
      "Epoch 142/2000, Train Loss: 1.5740, Test Loss: 1.5613\n",
      "Epoch 143/2000, Train Loss: 1.5758, Test Loss: 1.5624\n",
      "Epoch 144/2000, Train Loss: 1.5735, Test Loss: 1.5587\n",
      "Epoch 145/2000, Train Loss: 1.5728, Test Loss: 1.5630\n",
      "Epoch 146/2000, Train Loss: 1.5720, Test Loss: 1.5611\n",
      "Epoch 147/2000, Train Loss: 1.5718, Test Loss: 1.5628\n",
      "Epoch 148/2000, Train Loss: 1.5705, Test Loss: 1.5678\n",
      "Epoch 149/2000, Train Loss: 1.5714, Test Loss: 1.5580\n",
      "Epoch 150/2000, Train Loss: 1.5720, Test Loss: 1.5553\n",
      "Epoch 151/2000, Train Loss: 1.5714, Test Loss: 1.5596\n",
      "Epoch 152/2000, Train Loss: 1.5704, Test Loss: 1.5583\n",
      "Epoch 153/2000, Train Loss: 1.5705, Test Loss: 1.5567\n",
      "Epoch 154/2000, Train Loss: 1.5701, Test Loss: 1.5560\n",
      "Epoch 155/2000, Train Loss: 1.5704, Test Loss: 1.5623\n",
      "Epoch 156/2000, Train Loss: 1.5701, Test Loss: 1.5581\n",
      "Epoch 157/2000, Train Loss: 1.5731, Test Loss: 1.5575\n",
      "Epoch 158/2000, Train Loss: 1.5704, Test Loss: 1.5620\n",
      "Epoch 159/2000, Train Loss: 1.5691, Test Loss: 1.5566\n",
      "Epoch 160/2000, Train Loss: 1.5707, Test Loss: 1.5559\n",
      "Epoch 161/2000, Train Loss: 1.5687, Test Loss: 1.5604\n",
      "Epoch 162/2000, Train Loss: 1.5677, Test Loss: 1.5563\n",
      "Epoch 163/2000, Train Loss: 1.5683, Test Loss: 1.5682\n",
      "Epoch 164/2000, Train Loss: 1.5678, Test Loss: 1.5642\n",
      "Epoch 165/2000, Train Loss: 1.5674, Test Loss: 1.5559\n",
      "Epoch 166/2000, Train Loss: 1.5666, Test Loss: 1.5577\n",
      "Epoch 167/2000, Train Loss: 1.5676, Test Loss: 1.5517\n",
      "Epoch 168/2000, Train Loss: 1.5670, Test Loss: 1.5695\n",
      "Epoch 169/2000, Train Loss: 1.5670, Test Loss: 1.5539\n",
      "Epoch 170/2000, Train Loss: 1.5666, Test Loss: 1.5610\n",
      "Epoch 171/2000, Train Loss: 1.5662, Test Loss: 1.5573\n",
      "Epoch 172/2000, Train Loss: 1.5658, Test Loss: 1.5564\n",
      "Epoch 173/2000, Train Loss: 1.5665, Test Loss: 1.5531\n",
      "Epoch 174/2000, Train Loss: 1.5653, Test Loss: 1.5576\n",
      "Epoch 175/2000, Train Loss: 1.5670, Test Loss: 1.5549\n",
      "Epoch 176/2000, Train Loss: 1.5671, Test Loss: 1.5531\n",
      "Epoch 177/2000, Train Loss: 1.5652, Test Loss: 1.5580\n",
      "Epoch 178/2000, Train Loss: 1.5652, Test Loss: 1.5573\n",
      "Epoch 179/2000, Train Loss: 1.5660, Test Loss: 1.5591\n",
      "Epoch 180/2000, Train Loss: 1.5641, Test Loss: 1.5621\n",
      "Epoch 181/2000, Train Loss: 1.5655, Test Loss: 1.5550\n",
      "Epoch 182/2000, Train Loss: 1.5647, Test Loss: 1.5522\n",
      "Epoch 183/2000, Train Loss: 1.5641, Test Loss: 1.5596\n",
      "Epoch 184/2000, Train Loss: 1.5634, Test Loss: 1.5607\n",
      "Epoch 185/2000, Train Loss: 1.5640, Test Loss: 1.5542\n",
      "Epoch 186/2000, Train Loss: 1.5629, Test Loss: 1.5579\n",
      "Epoch 187/2000, Train Loss: 1.5636, Test Loss: 1.5524\n",
      "Epoch 188/2000, Train Loss: 1.5633, Test Loss: 1.5524\n",
      "Epoch 189/2000, Train Loss: 1.5623, Test Loss: 1.5568\n",
      "Epoch 190/2000, Train Loss: 1.5625, Test Loss: 1.5549\n",
      "Epoch 191/2000, Train Loss: 1.5622, Test Loss: 1.5557\n",
      "Epoch 192/2000, Train Loss: 1.5659, Test Loss: 1.5502\n",
      "Epoch 193/2000, Train Loss: 1.5627, Test Loss: 1.5576\n",
      "Epoch 194/2000, Train Loss: 1.5624, Test Loss: 1.5596\n",
      "Epoch 195/2000, Train Loss: 1.5629, Test Loss: 1.5500\n",
      "Epoch 196/2000, Train Loss: 1.5618, Test Loss: 1.5535\n",
      "Epoch 197/2000, Train Loss: 1.5629, Test Loss: 1.5578\n",
      "Epoch 198/2000, Train Loss: 1.5631, Test Loss: 1.5554\n",
      "Epoch 199/2000, Train Loss: 1.5608, Test Loss: 1.5631\n",
      "Epoch 200/2000, Train Loss: 1.5612, Test Loss: 1.5520\n",
      "Epoch 201/2000, Train Loss: 1.5605, Test Loss: 1.5508\n",
      "Epoch 202/2000, Train Loss: 1.5607, Test Loss: 1.5555\n",
      "Epoch 203/2000, Train Loss: 1.5625, Test Loss: 1.5489\n",
      "Epoch 204/2000, Train Loss: 1.5604, Test Loss: 1.5493\n",
      "Epoch 205/2000, Train Loss: 1.5607, Test Loss: 1.5512\n",
      "Epoch 206/2000, Train Loss: 1.5607, Test Loss: 1.5538\n",
      "Epoch 207/2000, Train Loss: 1.5598, Test Loss: 1.5528\n",
      "Epoch 208/2000, Train Loss: 1.5607, Test Loss: 1.5525\n",
      "Epoch 209/2000, Train Loss: 1.5601, Test Loss: 1.5527\n",
      "Epoch 210/2000, Train Loss: 1.5588, Test Loss: 1.5482\n",
      "Epoch 211/2000, Train Loss: 1.5589, Test Loss: 1.5507\n",
      "Epoch 212/2000, Train Loss: 1.5593, Test Loss: 1.5554\n",
      "Epoch 213/2000, Train Loss: 1.5585, Test Loss: 1.5509\n",
      "Epoch 214/2000, Train Loss: 1.5591, Test Loss: 1.5527\n",
      "Epoch 215/2000, Train Loss: 1.5581, Test Loss: 1.5514\n",
      "Epoch 216/2000, Train Loss: 1.5600, Test Loss: 1.5666\n",
      "Epoch 217/2000, Train Loss: 1.5589, Test Loss: 1.5499\n",
      "Epoch 218/2000, Train Loss: 1.5577, Test Loss: 1.5495\n",
      "Epoch 219/2000, Train Loss: 1.5591, Test Loss: 1.5467\n",
      "Epoch 220/2000, Train Loss: 1.5578, Test Loss: 1.5552\n",
      "Epoch 221/2000, Train Loss: 1.5573, Test Loss: 1.5539\n",
      "Epoch 222/2000, Train Loss: 1.5564, Test Loss: 1.5627\n",
      "Epoch 223/2000, Train Loss: 1.5594, Test Loss: 1.5492\n",
      "Epoch 224/2000, Train Loss: 1.5577, Test Loss: 1.5486\n",
      "Epoch 225/2000, Train Loss: 1.5561, Test Loss: 1.5483\n",
      "Epoch 226/2000, Train Loss: 1.5576, Test Loss: 1.5520\n",
      "Epoch 227/2000, Train Loss: 1.5556, Test Loss: 1.5511\n",
      "Epoch 228/2000, Train Loss: 1.5555, Test Loss: 1.5482\n",
      "Epoch 229/2000, Train Loss: 1.5561, Test Loss: 1.5454\n",
      "Epoch 230/2000, Train Loss: 1.5568, Test Loss: 1.5471\n",
      "Epoch 231/2000, Train Loss: 1.5555, Test Loss: 1.5487\n",
      "Epoch 232/2000, Train Loss: 1.5554, Test Loss: 1.5470\n",
      "Epoch 233/2000, Train Loss: 1.5554, Test Loss: 1.5537\n",
      "Epoch 234/2000, Train Loss: 1.5549, Test Loss: 1.5459\n",
      "Epoch 235/2000, Train Loss: 1.5546, Test Loss: 1.5475\n",
      "Epoch 236/2000, Train Loss: 1.5545, Test Loss: 1.5444\n",
      "Epoch 237/2000, Train Loss: 1.5550, Test Loss: 1.5547\n",
      "Epoch 238/2000, Train Loss: 1.5540, Test Loss: 1.5464\n",
      "Epoch 239/2000, Train Loss: 1.5537, Test Loss: 1.5478\n",
      "Epoch 240/2000, Train Loss: 1.5541, Test Loss: 1.5407\n",
      "Epoch 241/2000, Train Loss: 1.5549, Test Loss: 1.5538\n",
      "Epoch 242/2000, Train Loss: 1.5545, Test Loss: 1.5454\n",
      "Epoch 243/2000, Train Loss: 1.5541, Test Loss: 1.5465\n",
      "Epoch 244/2000, Train Loss: 1.5531, Test Loss: 1.5483\n",
      "Epoch 245/2000, Train Loss: 1.5542, Test Loss: 1.5421\n",
      "Epoch 246/2000, Train Loss: 1.5529, Test Loss: 1.5525\n",
      "Epoch 247/2000, Train Loss: 1.5535, Test Loss: 1.5488\n",
      "Epoch 248/2000, Train Loss: 1.5538, Test Loss: 1.5473\n",
      "Epoch 249/2000, Train Loss: 1.5525, Test Loss: 1.5448\n",
      "Epoch 250/2000, Train Loss: 1.5522, Test Loss: 1.5477\n",
      "Epoch 251/2000, Train Loss: 1.5524, Test Loss: 1.5460\n",
      "Epoch 252/2000, Train Loss: 1.5538, Test Loss: 1.5442\n",
      "Epoch 253/2000, Train Loss: 1.5517, Test Loss: 1.5477\n",
      "Epoch 254/2000, Train Loss: 1.5526, Test Loss: 1.5458\n",
      "Epoch 255/2000, Train Loss: 1.5524, Test Loss: 1.5475\n",
      "Epoch 256/2000, Train Loss: 1.5516, Test Loss: 1.5432\n",
      "Epoch 257/2000, Train Loss: 1.5521, Test Loss: 1.5440\n",
      "Epoch 258/2000, Train Loss: 1.5508, Test Loss: 1.5459\n",
      "Epoch 259/2000, Train Loss: 1.5510, Test Loss: 1.5427\n",
      "Epoch 260/2000, Train Loss: 1.5510, Test Loss: 1.5428\n",
      "Epoch 261/2000, Train Loss: 1.5499, Test Loss: 1.5449\n",
      "Epoch 262/2000, Train Loss: 1.5512, Test Loss: 1.5439\n",
      "Epoch 263/2000, Train Loss: 1.5507, Test Loss: 1.5431\n",
      "Epoch 264/2000, Train Loss: 1.5502, Test Loss: 1.5401\n",
      "Epoch 265/2000, Train Loss: 1.5492, Test Loss: 1.5469\n",
      "Epoch 266/2000, Train Loss: 1.5499, Test Loss: 1.5394\n",
      "Epoch 267/2000, Train Loss: 1.5505, Test Loss: 1.5476\n",
      "Epoch 268/2000, Train Loss: 1.5496, Test Loss: 1.5497\n",
      "Epoch 269/2000, Train Loss: 1.5504, Test Loss: 1.5482\n",
      "Epoch 270/2000, Train Loss: 1.5485, Test Loss: 1.5447\n",
      "Epoch 271/2000, Train Loss: 1.5493, Test Loss: 1.5418\n",
      "Epoch 272/2000, Train Loss: 1.5488, Test Loss: 1.5424\n",
      "Epoch 273/2000, Train Loss: 1.5492, Test Loss: 1.5419\n",
      "Epoch 274/2000, Train Loss: 1.5490, Test Loss: 1.5373\n",
      "Epoch 275/2000, Train Loss: 1.5496, Test Loss: 1.5417\n",
      "Epoch 276/2000, Train Loss: 1.5489, Test Loss: 1.5440\n",
      "Epoch 277/2000, Train Loss: 1.5475, Test Loss: 1.5374\n",
      "Epoch 278/2000, Train Loss: 1.5484, Test Loss: 1.5475\n",
      "Epoch 279/2000, Train Loss: 1.5475, Test Loss: 1.5459\n",
      "Epoch 280/2000, Train Loss: 1.5478, Test Loss: 1.5450\n",
      "Epoch 281/2000, Train Loss: 1.5480, Test Loss: 1.5449\n",
      "Epoch 282/2000, Train Loss: 1.5470, Test Loss: 1.5362\n",
      "Epoch 283/2000, Train Loss: 1.5472, Test Loss: 1.5387\n",
      "Epoch 284/2000, Train Loss: 1.5471, Test Loss: 1.5368\n",
      "Epoch 285/2000, Train Loss: 1.5476, Test Loss: 1.5455\n",
      "Epoch 286/2000, Train Loss: 1.5487, Test Loss: 1.5433\n",
      "Epoch 287/2000, Train Loss: 1.5479, Test Loss: 1.5384\n",
      "Epoch 288/2000, Train Loss: 1.5474, Test Loss: 1.5405\n",
      "Epoch 289/2000, Train Loss: 1.5455, Test Loss: 1.5380\n",
      "Epoch 290/2000, Train Loss: 1.5462, Test Loss: 1.5449\n",
      "Epoch 291/2000, Train Loss: 1.5460, Test Loss: 1.5422\n",
      "Epoch 292/2000, Train Loss: 1.5455, Test Loss: 1.5392\n",
      "Epoch 293/2000, Train Loss: 1.5457, Test Loss: 1.5398\n",
      "Epoch 294/2000, Train Loss: 1.5460, Test Loss: 1.5437\n",
      "Epoch 295/2000, Train Loss: 1.5468, Test Loss: 1.5418\n",
      "Epoch 296/2000, Train Loss: 1.5456, Test Loss: 1.5337\n",
      "Epoch 297/2000, Train Loss: 1.5446, Test Loss: 1.5382\n",
      "Epoch 298/2000, Train Loss: 1.5453, Test Loss: 1.5423\n",
      "Epoch 299/2000, Train Loss: 1.5449, Test Loss: 1.5416\n",
      "Epoch 300/2000, Train Loss: 1.5451, Test Loss: 1.5368\n",
      "Epoch 301/2000, Train Loss: 1.5454, Test Loss: 1.5372\n",
      "Epoch 302/2000, Train Loss: 1.5438, Test Loss: 1.5325\n",
      "Epoch 303/2000, Train Loss: 1.5442, Test Loss: 1.5391\n",
      "Epoch 304/2000, Train Loss: 1.5445, Test Loss: 1.5400\n",
      "Epoch 305/2000, Train Loss: 1.5440, Test Loss: 1.5359\n",
      "Epoch 306/2000, Train Loss: 1.5443, Test Loss: 1.5400\n",
      "Epoch 307/2000, Train Loss: 1.5445, Test Loss: 1.5462\n",
      "Epoch 308/2000, Train Loss: 1.5442, Test Loss: 1.5395\n",
      "Epoch 309/2000, Train Loss: 1.5433, Test Loss: 1.5336\n",
      "Epoch 310/2000, Train Loss: 1.5432, Test Loss: 1.5392\n",
      "Epoch 311/2000, Train Loss: 1.5434, Test Loss: 1.5381\n",
      "Epoch 312/2000, Train Loss: 1.5439, Test Loss: 1.5430\n",
      "Epoch 313/2000, Train Loss: 1.5438, Test Loss: 1.5342\n",
      "Epoch 314/2000, Train Loss: 1.5427, Test Loss: 1.5438\n",
      "Epoch 315/2000, Train Loss: 1.5437, Test Loss: 1.5368\n",
      "Epoch 316/2000, Train Loss: 1.5431, Test Loss: 1.5381\n",
      "Epoch 317/2000, Train Loss: 1.5427, Test Loss: 1.5358\n",
      "Epoch 318/2000, Train Loss: 1.5426, Test Loss: 1.5366\n",
      "Epoch 319/2000, Train Loss: 1.5421, Test Loss: 1.5378\n",
      "Epoch 320/2000, Train Loss: 1.5441, Test Loss: 1.5321\n",
      "Epoch 321/2000, Train Loss: 1.5428, Test Loss: 1.5382\n",
      "Epoch 322/2000, Train Loss: 1.5427, Test Loss: 1.5367\n",
      "Epoch 323/2000, Train Loss: 1.5414, Test Loss: 1.5418\n",
      "Epoch 324/2000, Train Loss: 1.5429, Test Loss: 1.5434\n",
      "Epoch 325/2000, Train Loss: 1.5424, Test Loss: 1.5394\n",
      "Epoch 326/2000, Train Loss: 1.5417, Test Loss: 1.5392\n",
      "Epoch 327/2000, Train Loss: 1.5410, Test Loss: 1.5341\n",
      "Epoch 328/2000, Train Loss: 1.5409, Test Loss: 1.5351\n",
      "Epoch 329/2000, Train Loss: 1.5416, Test Loss: 1.5345\n",
      "Epoch 330/2000, Train Loss: 1.5421, Test Loss: 1.5393\n",
      "Epoch 331/2000, Train Loss: 1.5417, Test Loss: 1.5430\n",
      "Epoch 332/2000, Train Loss: 1.5422, Test Loss: 1.5350\n",
      "Epoch 333/2000, Train Loss: 1.5400, Test Loss: 1.5358\n",
      "Epoch 334/2000, Train Loss: 1.5415, Test Loss: 1.5311\n",
      "Epoch 335/2000, Train Loss: 1.5408, Test Loss: 1.5381\n",
      "Epoch 336/2000, Train Loss: 1.5405, Test Loss: 1.5391\n",
      "Epoch 337/2000, Train Loss: 1.5409, Test Loss: 1.5338\n",
      "Epoch 338/2000, Train Loss: 1.5406, Test Loss: 1.5384\n",
      "Epoch 339/2000, Train Loss: 1.5408, Test Loss: 1.5312\n",
      "Epoch 340/2000, Train Loss: 1.5406, Test Loss: 1.5387\n",
      "Epoch 341/2000, Train Loss: 1.5406, Test Loss: 1.5335\n",
      "Epoch 342/2000, Train Loss: 1.5396, Test Loss: 1.5378\n",
      "Epoch 343/2000, Train Loss: 1.5399, Test Loss: 1.5388\n",
      "Epoch 344/2000, Train Loss: 1.5403, Test Loss: 1.5385\n",
      "Epoch 345/2000, Train Loss: 1.5411, Test Loss: 1.5290\n",
      "Epoch 346/2000, Train Loss: 1.5394, Test Loss: 1.5291\n",
      "Epoch 347/2000, Train Loss: 1.5397, Test Loss: 1.5320\n",
      "Epoch 348/2000, Train Loss: 1.5390, Test Loss: 1.5346\n",
      "Epoch 349/2000, Train Loss: 1.5402, Test Loss: 1.5291\n",
      "Epoch 350/2000, Train Loss: 1.5387, Test Loss: 1.5341\n",
      "Epoch 351/2000, Train Loss: 1.5398, Test Loss: 1.5369\n",
      "Epoch 352/2000, Train Loss: 1.5388, Test Loss: 1.5447\n",
      "Epoch 353/2000, Train Loss: 1.5395, Test Loss: 1.5340\n",
      "Epoch 354/2000, Train Loss: 1.5393, Test Loss: 1.5330\n",
      "Epoch 355/2000, Train Loss: 1.5392, Test Loss: 1.5370\n",
      "Epoch 356/2000, Train Loss: 1.5398, Test Loss: 1.5360\n",
      "Epoch 357/2000, Train Loss: 1.5389, Test Loss: 1.5321\n",
      "Epoch 358/2000, Train Loss: 1.5387, Test Loss: 1.5336\n",
      "Epoch 359/2000, Train Loss: 1.5390, Test Loss: 1.5342\n",
      "Epoch 360/2000, Train Loss: 1.5379, Test Loss: 1.5327\n",
      "Epoch 361/2000, Train Loss: 1.5375, Test Loss: 1.5295\n",
      "Epoch 362/2000, Train Loss: 1.5383, Test Loss: 1.5378\n",
      "Epoch 363/2000, Train Loss: 1.5386, Test Loss: 1.5320\n",
      "Epoch 364/2000, Train Loss: 1.5397, Test Loss: 1.5342\n",
      "Epoch 365/2000, Train Loss: 1.5381, Test Loss: 1.5332\n",
      "Epoch 366/2000, Train Loss: 1.5386, Test Loss: 1.5348\n",
      "Epoch 367/2000, Train Loss: 1.5380, Test Loss: 1.5298\n",
      "Epoch 368/2000, Train Loss: 1.5374, Test Loss: 1.5335\n",
      "Epoch 369/2000, Train Loss: 1.5380, Test Loss: 1.5410\n",
      "Epoch 370/2000, Train Loss: 1.5378, Test Loss: 1.5281\n",
      "Epoch 371/2000, Train Loss: 1.5377, Test Loss: 1.5313\n",
      "Epoch 372/2000, Train Loss: 1.5396, Test Loss: 1.5402\n",
      "Epoch 373/2000, Train Loss: 1.5372, Test Loss: 1.5337\n",
      "Epoch 374/2000, Train Loss: 1.5384, Test Loss: 1.5365\n",
      "Epoch 375/2000, Train Loss: 1.5376, Test Loss: 1.5283\n",
      "Epoch 376/2000, Train Loss: 1.5399, Test Loss: 1.5396\n",
      "Epoch 377/2000, Train Loss: 1.5369, Test Loss: 1.5332\n",
      "Epoch 378/2000, Train Loss: 1.5372, Test Loss: 1.5356\n",
      "Epoch 379/2000, Train Loss: 1.5370, Test Loss: 1.5340\n",
      "Epoch 380/2000, Train Loss: 1.5380, Test Loss: 1.5319\n",
      "Epoch 381/2000, Train Loss: 1.5370, Test Loss: 1.5431\n",
      "Epoch 382/2000, Train Loss: 1.5375, Test Loss: 1.5339\n",
      "Epoch 383/2000, Train Loss: 1.5370, Test Loss: 1.5330\n",
      "Epoch 384/2000, Train Loss: 1.5361, Test Loss: 1.5321\n",
      "Epoch 385/2000, Train Loss: 1.5370, Test Loss: 1.5400\n",
      "Epoch 386/2000, Train Loss: 1.5372, Test Loss: 1.5321\n",
      "Epoch 387/2000, Train Loss: 1.5363, Test Loss: 1.5316\n",
      "Epoch 388/2000, Train Loss: 1.5364, Test Loss: 1.5284\n",
      "Epoch 389/2000, Train Loss: 1.5387, Test Loss: 1.5351\n",
      "Epoch 390/2000, Train Loss: 1.5361, Test Loss: 1.5311\n",
      "Epoch 391/2000, Train Loss: 1.5370, Test Loss: 1.5331\n",
      "Epoch 392/2000, Train Loss: 1.5365, Test Loss: 1.5319\n",
      "Epoch 393/2000, Train Loss: 1.5364, Test Loss: 1.5296\n",
      "Epoch 394/2000, Train Loss: 1.5364, Test Loss: 1.5343\n",
      "Epoch 395/2000, Train Loss: 1.5355, Test Loss: 1.5331\n",
      "Epoch 396/2000, Train Loss: 1.5357, Test Loss: 1.5307\n",
      "Epoch 397/2000, Train Loss: 1.5377, Test Loss: 1.5310\n",
      "Epoch 398/2000, Train Loss: 1.5361, Test Loss: 1.5399\n",
      "Epoch 399/2000, Train Loss: 1.5357, Test Loss: 1.5280\n",
      "Epoch 400/2000, Train Loss: 1.5354, Test Loss: 1.5322\n",
      "Epoch 401/2000, Train Loss: 1.5353, Test Loss: 1.5345\n",
      "Epoch 402/2000, Train Loss: 1.5358, Test Loss: 1.5356\n",
      "Epoch 403/2000, Train Loss: 1.5356, Test Loss: 1.5338\n",
      "Epoch 404/2000, Train Loss: 1.5364, Test Loss: 1.5272\n",
      "Epoch 405/2000, Train Loss: 1.5354, Test Loss: 1.5300\n",
      "Epoch 406/2000, Train Loss: 1.5355, Test Loss: 1.5285\n",
      "Epoch 407/2000, Train Loss: 1.5354, Test Loss: 1.5320\n",
      "Epoch 408/2000, Train Loss: 1.5358, Test Loss: 1.5353\n",
      "Epoch 409/2000, Train Loss: 1.5359, Test Loss: 1.5301\n",
      "Epoch 410/2000, Train Loss: 1.5354, Test Loss: 1.5349\n",
      "Epoch 411/2000, Train Loss: 1.5353, Test Loss: 1.5282\n",
      "Epoch 412/2000, Train Loss: 1.5352, Test Loss: 1.5331\n",
      "Epoch 413/2000, Train Loss: 1.5354, Test Loss: 1.5315\n",
      "Epoch 414/2000, Train Loss: 1.5353, Test Loss: 1.5320\n",
      "Epoch 415/2000, Train Loss: 1.5352, Test Loss: 1.5271\n",
      "Epoch 416/2000, Train Loss: 1.5359, Test Loss: 1.5308\n",
      "Epoch 417/2000, Train Loss: 1.5343, Test Loss: 1.5404\n",
      "Epoch 418/2000, Train Loss: 1.5357, Test Loss: 1.5260\n",
      "Epoch 419/2000, Train Loss: 1.5343, Test Loss: 1.5296\n",
      "Epoch 420/2000, Train Loss: 1.5358, Test Loss: 1.5288\n",
      "Epoch 421/2000, Train Loss: 1.5366, Test Loss: 1.5294\n",
      "Epoch 422/2000, Train Loss: 1.5347, Test Loss: 1.5293\n",
      "Epoch 423/2000, Train Loss: 1.5345, Test Loss: 1.5329\n",
      "Epoch 424/2000, Train Loss: 1.5344, Test Loss: 1.5269\n",
      "Epoch 425/2000, Train Loss: 1.5368, Test Loss: 1.5361\n",
      "Epoch 426/2000, Train Loss: 1.5356, Test Loss: 1.5322\n",
      "Epoch 427/2000, Train Loss: 1.5351, Test Loss: 1.5281\n",
      "Epoch 428/2000, Train Loss: 1.5343, Test Loss: 1.5270\n",
      "Epoch 429/2000, Train Loss: 1.5341, Test Loss: 1.5281\n",
      "Epoch 430/2000, Train Loss: 1.5347, Test Loss: 1.5302\n",
      "Epoch 431/2000, Train Loss: 1.5350, Test Loss: 1.5308\n",
      "Epoch 432/2000, Train Loss: 1.5352, Test Loss: 1.5329\n",
      "Epoch 433/2000, Train Loss: 1.5340, Test Loss: 1.5278\n",
      "Epoch 434/2000, Train Loss: 1.5348, Test Loss: 1.5382\n",
      "Epoch 435/2000, Train Loss: 1.5339, Test Loss: 1.5295\n",
      "Epoch 436/2000, Train Loss: 1.5354, Test Loss: 1.5232\n",
      "Epoch 437/2000, Train Loss: 1.5336, Test Loss: 1.5321\n",
      "Epoch 438/2000, Train Loss: 1.5353, Test Loss: 1.5328\n",
      "Epoch 439/2000, Train Loss: 1.5333, Test Loss: 1.5264\n",
      "Epoch 440/2000, Train Loss: 1.5344, Test Loss: 1.5275\n",
      "Epoch 441/2000, Train Loss: 1.5344, Test Loss: 1.5316\n",
      "Epoch 442/2000, Train Loss: 1.5340, Test Loss: 1.5234\n",
      "Epoch 443/2000, Train Loss: 1.5339, Test Loss: 1.5338\n",
      "Epoch 444/2000, Train Loss: 1.5340, Test Loss: 1.5258\n",
      "Epoch 445/2000, Train Loss: 1.5333, Test Loss: 1.5274\n",
      "Epoch 446/2000, Train Loss: 1.5337, Test Loss: 1.5348\n",
      "Epoch 447/2000, Train Loss: 1.5351, Test Loss: 1.5316\n",
      "Epoch 448/2000, Train Loss: 1.5340, Test Loss: 1.5297\n",
      "Epoch 449/2000, Train Loss: 1.5344, Test Loss: 1.5290\n",
      "Epoch 450/2000, Train Loss: 1.5338, Test Loss: 1.5305\n",
      "Epoch 451/2000, Train Loss: 1.5338, Test Loss: 1.5297\n",
      "Epoch 452/2000, Train Loss: 1.5339, Test Loss: 1.5269\n",
      "Epoch 453/2000, Train Loss: 1.5342, Test Loss: 1.5314\n",
      "Epoch 454/2000, Train Loss: 1.5335, Test Loss: 1.5316\n",
      "Epoch 455/2000, Train Loss: 1.5330, Test Loss: 1.5289\n",
      "Epoch 456/2000, Train Loss: 1.5334, Test Loss: 1.5292\n",
      "Epoch 457/2000, Train Loss: 1.5343, Test Loss: 1.5256\n",
      "Epoch 458/2000, Train Loss: 1.5331, Test Loss: 1.5303\n",
      "Epoch 459/2000, Train Loss: 1.5328, Test Loss: 1.5244\n",
      "Epoch 460/2000, Train Loss: 1.5331, Test Loss: 1.5287\n",
      "Epoch 461/2000, Train Loss: 1.5327, Test Loss: 1.5260\n",
      "Epoch 462/2000, Train Loss: 1.5343, Test Loss: 1.5235\n",
      "Epoch 463/2000, Train Loss: 1.5346, Test Loss: 1.5277\n",
      "Epoch 464/2000, Train Loss: 1.5325, Test Loss: 1.5378\n",
      "Epoch 465/2000, Train Loss: 1.5341, Test Loss: 1.5335\n",
      "Epoch 466/2000, Train Loss: 1.5331, Test Loss: 1.5341\n",
      "Epoch 467/2000, Train Loss: 1.5330, Test Loss: 1.5295\n",
      "Epoch 468/2000, Train Loss: 1.5337, Test Loss: 1.5304\n",
      "Epoch 469/2000, Train Loss: 1.5339, Test Loss: 1.5266\n",
      "Epoch 470/2000, Train Loss: 1.5338, Test Loss: 1.5272\n",
      "Epoch 471/2000, Train Loss: 1.5330, Test Loss: 1.5273\n",
      "Epoch 472/2000, Train Loss: 1.5333, Test Loss: 1.5436\n",
      "Epoch 473/2000, Train Loss: 1.5326, Test Loss: 1.5256\n",
      "Epoch 474/2000, Train Loss: 1.5329, Test Loss: 1.5315\n",
      "Epoch 475/2000, Train Loss: 1.5329, Test Loss: 1.5278\n",
      "Epoch 476/2000, Train Loss: 1.5333, Test Loss: 1.5310\n",
      "Epoch 477/2000, Train Loss: 1.5342, Test Loss: 1.5302\n",
      "Epoch 478/2000, Train Loss: 1.5334, Test Loss: 1.5338\n",
      "Epoch 479/2000, Train Loss: 1.5330, Test Loss: 1.5294\n",
      "Epoch 480/2000, Train Loss: 1.5333, Test Loss: 1.5287\n",
      "Epoch 481/2000, Train Loss: 1.5325, Test Loss: 1.5295\n",
      "Epoch 482/2000, Train Loss: 1.5326, Test Loss: 1.5337\n",
      "Epoch 483/2000, Train Loss: 1.5332, Test Loss: 1.5345\n",
      "Epoch 484/2000, Train Loss: 1.5325, Test Loss: 1.5299\n",
      "Epoch 485/2000, Train Loss: 1.5341, Test Loss: 1.5263\n",
      "Epoch 486/2000, Train Loss: 1.5324, Test Loss: 1.5300\n",
      "Epoch 487/2000, Train Loss: 1.5326, Test Loss: 1.5276\n",
      "Epoch 488/2000, Train Loss: 1.5327, Test Loss: 1.5285\n",
      "Epoch 489/2000, Train Loss: 1.5321, Test Loss: 1.5310\n",
      "Epoch 490/2000, Train Loss: 1.5328, Test Loss: 1.5287\n",
      "Epoch 491/2000, Train Loss: 1.5336, Test Loss: 1.5369\n",
      "Epoch 492/2000, Train Loss: 1.5322, Test Loss: 1.5253\n",
      "Epoch 493/2000, Train Loss: 1.5324, Test Loss: 1.5266\n",
      "Epoch 494/2000, Train Loss: 1.5333, Test Loss: 1.5384\n",
      "Epoch 495/2000, Train Loss: 1.5320, Test Loss: 1.5301\n",
      "Epoch 496/2000, Train Loss: 1.5328, Test Loss: 1.5288\n",
      "Epoch 497/2000, Train Loss: 1.5319, Test Loss: 1.5279\n",
      "Epoch 498/2000, Train Loss: 1.5321, Test Loss: 1.5277\n",
      "Epoch 499/2000, Train Loss: 1.5321, Test Loss: 1.5296\n",
      "Epoch 500/2000, Train Loss: 1.5318, Test Loss: 1.5281\n",
      "Epoch 501/2000, Train Loss: 1.5323, Test Loss: 1.5246\n",
      "Epoch 502/2000, Train Loss: 1.5327, Test Loss: 1.5335\n",
      "Epoch 503/2000, Train Loss: 1.5316, Test Loss: 1.5300\n",
      "Epoch 504/2000, Train Loss: 1.5326, Test Loss: 1.5278\n",
      "Epoch 505/2000, Train Loss: 1.5315, Test Loss: 1.5250\n",
      "Epoch 506/2000, Train Loss: 1.5324, Test Loss: 1.5326\n",
      "Epoch 507/2000, Train Loss: 1.5325, Test Loss: 1.5243\n",
      "Epoch 508/2000, Train Loss: 1.5321, Test Loss: 1.5238\n",
      "Epoch 509/2000, Train Loss: 1.5324, Test Loss: 1.5285\n",
      "Epoch 510/2000, Train Loss: 1.5322, Test Loss: 1.5293\n",
      "Epoch 511/2000, Train Loss: 1.5318, Test Loss: 1.5250\n",
      "Epoch 512/2000, Train Loss: 1.5332, Test Loss: 1.5266\n",
      "Epoch 513/2000, Train Loss: 1.5321, Test Loss: 1.5279\n",
      "Epoch 514/2000, Train Loss: 1.5312, Test Loss: 1.5225\n",
      "Epoch 515/2000, Train Loss: 1.5319, Test Loss: 1.5297\n",
      "Epoch 516/2000, Train Loss: 1.5323, Test Loss: 1.5225\n",
      "Epoch 517/2000, Train Loss: 1.5324, Test Loss: 1.5227\n",
      "Epoch 518/2000, Train Loss: 1.5314, Test Loss: 1.5272\n",
      "Epoch 519/2000, Train Loss: 1.5314, Test Loss: 1.5262\n",
      "Epoch 520/2000, Train Loss: 1.5308, Test Loss: 1.5284\n",
      "Epoch 521/2000, Train Loss: 1.5329, Test Loss: 1.5275\n",
      "Epoch 522/2000, Train Loss: 1.5315, Test Loss: 1.5288\n",
      "Epoch 523/2000, Train Loss: 1.5319, Test Loss: 1.5295\n",
      "Epoch 524/2000, Train Loss: 1.5311, Test Loss: 1.5275\n",
      "Epoch 525/2000, Train Loss: 1.5308, Test Loss: 1.5289\n",
      "Epoch 526/2000, Train Loss: 1.5320, Test Loss: 1.5277\n",
      "Epoch 527/2000, Train Loss: 1.5320, Test Loss: 1.5359\n",
      "Epoch 528/2000, Train Loss: 1.5327, Test Loss: 1.5260\n",
      "Epoch 529/2000, Train Loss: 1.5322, Test Loss: 1.5212\n",
      "Epoch 530/2000, Train Loss: 1.5314, Test Loss: 1.5291\n",
      "Epoch 531/2000, Train Loss: 1.5309, Test Loss: 1.5329\n",
      "Epoch 532/2000, Train Loss: 1.5311, Test Loss: 1.5259\n",
      "Epoch 533/2000, Train Loss: 1.5317, Test Loss: 1.5235\n",
      "Epoch 534/2000, Train Loss: 1.5311, Test Loss: 1.5296\n",
      "Epoch 535/2000, Train Loss: 1.5310, Test Loss: 1.5238\n",
      "Epoch 536/2000, Train Loss: 1.5319, Test Loss: 1.5299\n",
      "Epoch 537/2000, Train Loss: 1.5314, Test Loss: 1.5251\n",
      "Epoch 538/2000, Train Loss: 1.5325, Test Loss: 1.5282\n",
      "Epoch 539/2000, Train Loss: 1.5317, Test Loss: 1.5299\n",
      "Epoch 540/2000, Train Loss: 1.5311, Test Loss: 1.5253\n",
      "Epoch 541/2000, Train Loss: 1.5316, Test Loss: 1.5316\n",
      "Epoch 542/2000, Train Loss: 1.5320, Test Loss: 1.5320\n",
      "Epoch 543/2000, Train Loss: 1.5321, Test Loss: 1.5380\n",
      "Epoch 544/2000, Train Loss: 1.5314, Test Loss: 1.5327\n",
      "Epoch 545/2000, Train Loss: 1.5307, Test Loss: 1.5243\n",
      "Epoch 546/2000, Train Loss: 1.5319, Test Loss: 1.5292\n",
      "Epoch 547/2000, Train Loss: 1.5312, Test Loss: 1.5266\n",
      "Epoch 548/2000, Train Loss: 1.5307, Test Loss: 1.5229\n",
      "Epoch 549/2000, Train Loss: 1.5306, Test Loss: 1.5272\n",
      "Epoch 550/2000, Train Loss: 1.5314, Test Loss: 1.5225\n",
      "Epoch 551/2000, Train Loss: 1.5318, Test Loss: 1.5292\n",
      "Epoch 552/2000, Train Loss: 1.5313, Test Loss: 1.5333\n",
      "Epoch 553/2000, Train Loss: 1.5309, Test Loss: 1.5380\n",
      "Epoch 554/2000, Train Loss: 1.5314, Test Loss: 1.5248\n",
      "Epoch 555/2000, Train Loss: 1.5309, Test Loss: 1.5277\n",
      "Epoch 556/2000, Train Loss: 1.5298, Test Loss: 1.5245\n",
      "Epoch 557/2000, Train Loss: 1.5308, Test Loss: 1.5239\n",
      "Epoch 558/2000, Train Loss: 1.5314, Test Loss: 1.5288\n",
      "Epoch 559/2000, Train Loss: 1.5308, Test Loss: 1.5276\n",
      "Epoch 560/2000, Train Loss: 1.5311, Test Loss: 1.5317\n",
      "Epoch 561/2000, Train Loss: 1.5311, Test Loss: 1.5275\n",
      "Epoch 562/2000, Train Loss: 1.5315, Test Loss: 1.5199\n",
      "Epoch 563/2000, Train Loss: 1.5300, Test Loss: 1.5243\n",
      "Epoch 564/2000, Train Loss: 1.5309, Test Loss: 1.5276\n",
      "Epoch 565/2000, Train Loss: 1.5306, Test Loss: 1.5226\n",
      "Epoch 566/2000, Train Loss: 1.5308, Test Loss: 1.5374\n",
      "Epoch 567/2000, Train Loss: 1.5308, Test Loss: 1.5228\n",
      "Epoch 568/2000, Train Loss: 1.5309, Test Loss: 1.5216\n",
      "Epoch 569/2000, Train Loss: 1.5316, Test Loss: 1.5261\n",
      "Epoch 570/2000, Train Loss: 1.5311, Test Loss: 1.5258\n",
      "Epoch 571/2000, Train Loss: 1.5311, Test Loss: 1.5327\n",
      "Epoch 572/2000, Train Loss: 1.5303, Test Loss: 1.5269\n",
      "Epoch 573/2000, Train Loss: 1.5305, Test Loss: 1.5218\n",
      "Epoch 574/2000, Train Loss: 1.5307, Test Loss: 1.5245\n",
      "Epoch 575/2000, Train Loss: 1.5304, Test Loss: 1.5221\n",
      "Epoch 576/2000, Train Loss: 1.5310, Test Loss: 1.5259\n",
      "Epoch 577/2000, Train Loss: 1.5318, Test Loss: 1.5266\n",
      "Epoch 578/2000, Train Loss: 1.5323, Test Loss: 1.5287\n",
      "Epoch 579/2000, Train Loss: 1.5305, Test Loss: 1.5266\n",
      "Epoch 580/2000, Train Loss: 1.5307, Test Loss: 1.5289\n",
      "Epoch 581/2000, Train Loss: 1.5309, Test Loss: 1.5272\n",
      "Epoch 582/2000, Train Loss: 1.5312, Test Loss: 1.5250\n",
      "Epoch 583/2000, Train Loss: 1.5299, Test Loss: 1.5248\n",
      "Epoch 584/2000, Train Loss: 1.5316, Test Loss: 1.5275\n",
      "Epoch 585/2000, Train Loss: 1.5297, Test Loss: 1.5341\n",
      "Epoch 586/2000, Train Loss: 1.5309, Test Loss: 1.5257\n",
      "Epoch 587/2000, Train Loss: 1.5300, Test Loss: 1.5241\n",
      "Epoch 588/2000, Train Loss: 1.5308, Test Loss: 1.5297\n",
      "Epoch 589/2000, Train Loss: 1.5311, Test Loss: 1.5257\n",
      "Epoch 590/2000, Train Loss: 1.5306, Test Loss: 1.5287\n",
      "Epoch 591/2000, Train Loss: 1.5307, Test Loss: 1.5223\n",
      "Epoch 592/2000, Train Loss: 1.5305, Test Loss: 1.5240\n",
      "Epoch 593/2000, Train Loss: 1.5308, Test Loss: 1.5249\n",
      "Epoch 594/2000, Train Loss: 1.5302, Test Loss: 1.5267\n",
      "Epoch 595/2000, Train Loss: 1.5308, Test Loss: 1.5265\n",
      "Epoch 596/2000, Train Loss: 1.5304, Test Loss: 1.5310\n",
      "Epoch 597/2000, Train Loss: 1.5306, Test Loss: 1.5234\n",
      "Epoch 598/2000, Train Loss: 1.5295, Test Loss: 1.5264\n",
      "Epoch 599/2000, Train Loss: 1.5300, Test Loss: 1.5301\n",
      "Epoch 600/2000, Train Loss: 1.5310, Test Loss: 1.5260\n",
      "Epoch 601/2000, Train Loss: 1.5321, Test Loss: 1.5318\n",
      "Epoch 602/2000, Train Loss: 1.5300, Test Loss: 1.5280\n",
      "Epoch 603/2000, Train Loss: 1.5303, Test Loss: 1.5234\n",
      "Epoch 604/2000, Train Loss: 1.5296, Test Loss: 1.5214\n",
      "Epoch 605/2000, Train Loss: 1.5296, Test Loss: 1.5261\n",
      "Epoch 606/2000, Train Loss: 1.5301, Test Loss: 1.5278\n",
      "Epoch 607/2000, Train Loss: 1.5295, Test Loss: 1.5257\n",
      "Epoch 608/2000, Train Loss: 1.5300, Test Loss: 1.5262\n",
      "Epoch 609/2000, Train Loss: 1.5305, Test Loss: 1.5272\n",
      "Epoch 610/2000, Train Loss: 1.5299, Test Loss: 1.5332\n",
      "Epoch 611/2000, Train Loss: 1.5303, Test Loss: 1.5262\n",
      "Epoch 612/2000, Train Loss: 1.5304, Test Loss: 1.5262\n",
      "Epoch 613/2000, Train Loss: 1.5291, Test Loss: 1.5237\n",
      "Epoch 614/2000, Train Loss: 1.5302, Test Loss: 1.5284\n",
      "Epoch 615/2000, Train Loss: 1.5305, Test Loss: 1.5259\n",
      "Epoch 616/2000, Train Loss: 1.5308, Test Loss: 1.5260\n",
      "Epoch 617/2000, Train Loss: 1.5298, Test Loss: 1.5246\n",
      "Epoch 618/2000, Train Loss: 1.5295, Test Loss: 1.5380\n",
      "Epoch 619/2000, Train Loss: 1.5298, Test Loss: 1.5255\n",
      "Epoch 620/2000, Train Loss: 1.5301, Test Loss: 1.5296\n",
      "Epoch 621/2000, Train Loss: 1.5295, Test Loss: 1.5275\n",
      "Epoch 622/2000, Train Loss: 1.5302, Test Loss: 1.5360\n",
      "Epoch 623/2000, Train Loss: 1.5303, Test Loss: 1.5275\n",
      "Epoch 624/2000, Train Loss: 1.5300, Test Loss: 1.5256\n",
      "Epoch 625/2000, Train Loss: 1.5301, Test Loss: 1.5228\n",
      "Epoch 626/2000, Train Loss: 1.5309, Test Loss: 1.5344\n",
      "Epoch 627/2000, Train Loss: 1.5297, Test Loss: 1.5279\n",
      "Epoch 628/2000, Train Loss: 1.5295, Test Loss: 1.5274\n",
      "Epoch 629/2000, Train Loss: 1.5294, Test Loss: 1.5261\n",
      "Epoch 630/2000, Train Loss: 1.5293, Test Loss: 1.5267\n",
      "Epoch 631/2000, Train Loss: 1.5300, Test Loss: 1.5257\n",
      "Epoch 632/2000, Train Loss: 1.5306, Test Loss: 1.5303\n",
      "Epoch 633/2000, Train Loss: 1.5301, Test Loss: 1.5283\n",
      "Epoch 634/2000, Train Loss: 1.5300, Test Loss: 1.5229\n",
      "Epoch 635/2000, Train Loss: 1.5301, Test Loss: 1.5245\n",
      "Epoch 636/2000, Train Loss: 1.5296, Test Loss: 1.5242\n",
      "Epoch 637/2000, Train Loss: 1.5298, Test Loss: 1.5269\n",
      "Epoch 638/2000, Train Loss: 1.5298, Test Loss: 1.5269\n",
      "Epoch 639/2000, Train Loss: 1.5297, Test Loss: 1.5229\n",
      "Epoch 640/2000, Train Loss: 1.5302, Test Loss: 1.5302\n",
      "Epoch 641/2000, Train Loss: 1.5293, Test Loss: 1.5360\n",
      "Epoch 642/2000, Train Loss: 1.5293, Test Loss: 1.5230\n",
      "Epoch 643/2000, Train Loss: 1.5291, Test Loss: 1.5236\n",
      "Epoch 644/2000, Train Loss: 1.5300, Test Loss: 1.5306\n",
      "Epoch 645/2000, Train Loss: 1.5295, Test Loss: 1.5256\n",
      "Epoch 646/2000, Train Loss: 1.5302, Test Loss: 1.5242\n",
      "Epoch 647/2000, Train Loss: 1.5298, Test Loss: 1.5339\n",
      "Epoch 648/2000, Train Loss: 1.5303, Test Loss: 1.5273\n",
      "Epoch 649/2000, Train Loss: 1.5301, Test Loss: 1.5241\n",
      "Epoch 650/2000, Train Loss: 1.5302, Test Loss: 1.5260\n",
      "Epoch 651/2000, Train Loss: 1.5294, Test Loss: 1.5257\n",
      "Epoch 652/2000, Train Loss: 1.5305, Test Loss: 1.5239\n",
      "Epoch 653/2000, Train Loss: 1.5293, Test Loss: 1.5239\n",
      "Epoch 654/2000, Train Loss: 1.5295, Test Loss: 1.5280\n",
      "Epoch 655/2000, Train Loss: 1.5298, Test Loss: 1.5242\n",
      "Epoch 656/2000, Train Loss: 1.5292, Test Loss: 1.5290\n",
      "Epoch 657/2000, Train Loss: 1.5292, Test Loss: 1.5280\n",
      "Epoch 658/2000, Train Loss: 1.5301, Test Loss: 1.5288\n",
      "Epoch 659/2000, Train Loss: 1.5300, Test Loss: 1.5281\n",
      "Epoch 660/2000, Train Loss: 1.5302, Test Loss: 1.5235\n",
      "Epoch 661/2000, Train Loss: 1.5292, Test Loss: 1.5311\n",
      "Epoch 662/2000, Train Loss: 1.5298, Test Loss: 1.5289\n",
      "Epoch 663/2000, Train Loss: 1.5294, Test Loss: 1.5263\n",
      "Epoch 664/2000, Train Loss: 1.5295, Test Loss: 1.5284\n",
      "Epoch 665/2000, Train Loss: 1.5286, Test Loss: 1.5261\n",
      "Epoch 666/2000, Train Loss: 1.5298, Test Loss: 1.5268\n",
      "Epoch 667/2000, Train Loss: 1.5321, Test Loss: 1.5257\n",
      "Epoch 668/2000, Train Loss: 1.5287, Test Loss: 1.5282\n",
      "Epoch 669/2000, Train Loss: 1.5292, Test Loss: 1.5226\n",
      "Epoch 670/2000, Train Loss: 1.5300, Test Loss: 1.5266\n",
      "Epoch 671/2000, Train Loss: 1.5302, Test Loss: 1.5256\n",
      "Epoch 672/2000, Train Loss: 1.5285, Test Loss: 1.5289\n",
      "Epoch 673/2000, Train Loss: 1.5295, Test Loss: 1.5235\n",
      "Epoch 674/2000, Train Loss: 1.5291, Test Loss: 1.5307\n",
      "Epoch 675/2000, Train Loss: 1.5289, Test Loss: 1.5252\n",
      "Epoch 676/2000, Train Loss: 1.5293, Test Loss: 1.5249\n",
      "Epoch 677/2000, Train Loss: 1.5294, Test Loss: 1.5270\n",
      "Epoch 678/2000, Train Loss: 1.5305, Test Loss: 1.5275\n",
      "Epoch 679/2000, Train Loss: 1.5297, Test Loss: 1.5251\n",
      "Epoch 680/2000, Train Loss: 1.5286, Test Loss: 1.5266\n",
      "Epoch 681/2000, Train Loss: 1.5285, Test Loss: 1.5221\n",
      "Epoch 682/2000, Train Loss: 1.5289, Test Loss: 1.5211\n",
      "Epoch 683/2000, Train Loss: 1.5302, Test Loss: 1.5248\n",
      "Epoch 684/2000, Train Loss: 1.5294, Test Loss: 1.5242\n",
      "Epoch 685/2000, Train Loss: 1.5293, Test Loss: 1.5250\n",
      "Epoch 686/2000, Train Loss: 1.5291, Test Loss: 1.5244\n",
      "Epoch 687/2000, Train Loss: 1.5289, Test Loss: 1.5319\n",
      "Epoch 688/2000, Train Loss: 1.5297, Test Loss: 1.5230\n",
      "Epoch 689/2000, Train Loss: 1.5301, Test Loss: 1.5304\n",
      "Epoch 690/2000, Train Loss: 1.5296, Test Loss: 1.5291\n",
      "Epoch 691/2000, Train Loss: 1.5286, Test Loss: 1.5231\n",
      "Epoch 692/2000, Train Loss: 1.5289, Test Loss: 1.5234\n",
      "Epoch 693/2000, Train Loss: 1.5302, Test Loss: 1.5328\n",
      "Epoch 694/2000, Train Loss: 1.5291, Test Loss: 1.5354\n",
      "Epoch 695/2000, Train Loss: 1.5294, Test Loss: 1.5306\n",
      "Epoch 696/2000, Train Loss: 1.5289, Test Loss: 1.5239\n",
      "Epoch 697/2000, Train Loss: 1.5295, Test Loss: 1.5247\n",
      "Epoch 698/2000, Train Loss: 1.5304, Test Loss: 1.5275\n",
      "Epoch 699/2000, Train Loss: 1.5285, Test Loss: 1.5255\n",
      "Epoch 700/2000, Train Loss: 1.5294, Test Loss: 1.5250\n",
      "Epoch 701/2000, Train Loss: 1.5283, Test Loss: 1.5258\n",
      "Epoch 702/2000, Train Loss: 1.5292, Test Loss: 1.5270\n",
      "Epoch 703/2000, Train Loss: 1.5294, Test Loss: 1.5279\n",
      "Epoch 704/2000, Train Loss: 1.5289, Test Loss: 1.5241\n",
      "Epoch 705/2000, Train Loss: 1.5286, Test Loss: 1.5292\n",
      "Epoch 706/2000, Train Loss: 1.5295, Test Loss: 1.5216\n",
      "Epoch 707/2000, Train Loss: 1.5285, Test Loss: 1.5249\n",
      "Epoch 708/2000, Train Loss: 1.5285, Test Loss: 1.5268\n",
      "Epoch 709/2000, Train Loss: 1.5291, Test Loss: 1.5282\n",
      "Epoch 710/2000, Train Loss: 1.5289, Test Loss: 1.5221\n",
      "Epoch 711/2000, Train Loss: 1.5293, Test Loss: 1.5258\n",
      "Epoch 712/2000, Train Loss: 1.5301, Test Loss: 1.5286\n",
      "Epoch 713/2000, Train Loss: 1.5291, Test Loss: 1.5246\n",
      "Epoch 714/2000, Train Loss: 1.5288, Test Loss: 1.5276\n",
      "Epoch 715/2000, Train Loss: 1.5290, Test Loss: 1.5264\n",
      "Epoch 716/2000, Train Loss: 1.5300, Test Loss: 1.5216\n",
      "Epoch 717/2000, Train Loss: 1.5291, Test Loss: 1.5222\n",
      "Epoch 718/2000, Train Loss: 1.5290, Test Loss: 1.5268\n",
      "Epoch 719/2000, Train Loss: 1.5294, Test Loss: 1.5302\n",
      "Epoch 720/2000, Train Loss: 1.5283, Test Loss: 1.5233\n",
      "Epoch 721/2000, Train Loss: 1.5287, Test Loss: 1.5299\n",
      "Epoch 722/2000, Train Loss: 1.5288, Test Loss: 1.5237\n",
      "Epoch 723/2000, Train Loss: 1.5296, Test Loss: 1.5294\n",
      "Epoch 724/2000, Train Loss: 1.5291, Test Loss: 1.5246\n",
      "Epoch 725/2000, Train Loss: 1.5282, Test Loss: 1.5288\n",
      "Epoch 726/2000, Train Loss: 1.5285, Test Loss: 1.5234\n",
      "Epoch 727/2000, Train Loss: 1.5282, Test Loss: 1.5324\n",
      "Epoch 728/2000, Train Loss: 1.5297, Test Loss: 1.5244\n",
      "Epoch 729/2000, Train Loss: 1.5280, Test Loss: 1.5253\n",
      "Epoch 730/2000, Train Loss: 1.5292, Test Loss: 1.5345\n",
      "Epoch 731/2000, Train Loss: 1.5293, Test Loss: 1.5279\n",
      "Epoch 732/2000, Train Loss: 1.5296, Test Loss: 1.5290\n",
      "Epoch 733/2000, Train Loss: 1.5283, Test Loss: 1.5273\n",
      "Epoch 734/2000, Train Loss: 1.5286, Test Loss: 1.5226\n",
      "Epoch 735/2000, Train Loss: 1.5288, Test Loss: 1.5261\n",
      "Epoch 736/2000, Train Loss: 1.5289, Test Loss: 1.5257\n",
      "Epoch 737/2000, Train Loss: 1.5293, Test Loss: 1.5247\n",
      "Epoch 738/2000, Train Loss: 1.5288, Test Loss: 1.5275\n",
      "Epoch 739/2000, Train Loss: 1.5296, Test Loss: 1.5337\n",
      "Epoch 740/2000, Train Loss: 1.5296, Test Loss: 1.5222\n",
      "Epoch 741/2000, Train Loss: 1.5292, Test Loss: 1.5278\n",
      "Epoch 742/2000, Train Loss: 1.5280, Test Loss: 1.5265\n",
      "Epoch 743/2000, Train Loss: 1.5283, Test Loss: 1.5245\n",
      "Epoch 744/2000, Train Loss: 1.5289, Test Loss: 1.5236\n",
      "Epoch 745/2000, Train Loss: 1.5291, Test Loss: 1.5226\n",
      "Epoch 746/2000, Train Loss: 1.5291, Test Loss: 1.5213\n",
      "Epoch 747/2000, Train Loss: 1.5298, Test Loss: 1.5284\n",
      "Epoch 748/2000, Train Loss: 1.5284, Test Loss: 1.5249\n",
      "Epoch 749/2000, Train Loss: 1.5289, Test Loss: 1.5291\n",
      "Epoch 750/2000, Train Loss: 1.5289, Test Loss: 1.5232\n",
      "Epoch 751/2000, Train Loss: 1.5283, Test Loss: 1.5215\n",
      "Epoch 752/2000, Train Loss: 1.5278, Test Loss: 1.5263\n",
      "Epoch 753/2000, Train Loss: 1.5288, Test Loss: 1.5299\n",
      "Epoch 754/2000, Train Loss: 1.5291, Test Loss: 1.5240\n",
      "Epoch 755/2000, Train Loss: 1.5285, Test Loss: 1.5228\n",
      "Epoch 756/2000, Train Loss: 1.5289, Test Loss: 1.5292\n",
      "Epoch 757/2000, Train Loss: 1.5287, Test Loss: 1.5259\n",
      "Epoch 758/2000, Train Loss: 1.5279, Test Loss: 1.5242\n",
      "Epoch 759/2000, Train Loss: 1.5285, Test Loss: 1.5235\n",
      "Epoch 760/2000, Train Loss: 1.5282, Test Loss: 1.5297\n",
      "Epoch 761/2000, Train Loss: 1.5289, Test Loss: 1.5262\n",
      "Epoch 762/2000, Train Loss: 1.5292, Test Loss: 1.5221\n",
      "Epoch 763/2000, Train Loss: 1.5292, Test Loss: 1.5253\n",
      "Epoch 764/2000, Train Loss: 1.5295, Test Loss: 1.5269\n",
      "Epoch 765/2000, Train Loss: 1.5287, Test Loss: 1.5251\n",
      "Epoch 766/2000, Train Loss: 1.5286, Test Loss: 1.5294\n",
      "Epoch 767/2000, Train Loss: 1.5286, Test Loss: 1.5254\n",
      "Epoch 768/2000, Train Loss: 1.5284, Test Loss: 1.5262\n",
      "Epoch 769/2000, Train Loss: 1.5283, Test Loss: 1.5229\n",
      "Epoch 770/2000, Train Loss: 1.5286, Test Loss: 1.5266\n",
      "Epoch 771/2000, Train Loss: 1.5284, Test Loss: 1.5236\n",
      "Epoch 772/2000, Train Loss: 1.5287, Test Loss: 1.5358\n",
      "Epoch 773/2000, Train Loss: 1.5284, Test Loss: 1.5292\n",
      "Epoch 774/2000, Train Loss: 1.5298, Test Loss: 1.5261\n",
      "Epoch 775/2000, Train Loss: 1.5275, Test Loss: 1.5307\n",
      "Epoch 776/2000, Train Loss: 1.5281, Test Loss: 1.5263\n",
      "Epoch 777/2000, Train Loss: 1.5289, Test Loss: 1.5222\n",
      "Epoch 778/2000, Train Loss: 1.5285, Test Loss: 1.5250\n",
      "Epoch 779/2000, Train Loss: 1.5285, Test Loss: 1.5223\n",
      "Epoch 780/2000, Train Loss: 1.5282, Test Loss: 1.5228\n",
      "Epoch 781/2000, Train Loss: 1.5286, Test Loss: 1.5272\n",
      "Epoch 782/2000, Train Loss: 1.5285, Test Loss: 1.5242\n",
      "Epoch 783/2000, Train Loss: 1.5283, Test Loss: 1.5243\n",
      "Epoch 784/2000, Train Loss: 1.5282, Test Loss: 1.5258\n",
      "Epoch 785/2000, Train Loss: 1.5279, Test Loss: 1.5302\n",
      "Epoch 786/2000, Train Loss: 1.5281, Test Loss: 1.5304\n",
      "Epoch 787/2000, Train Loss: 1.5286, Test Loss: 1.5310\n",
      "Epoch 788/2000, Train Loss: 1.5277, Test Loss: 1.5237\n",
      "Epoch 789/2000, Train Loss: 1.5278, Test Loss: 1.5234\n",
      "Epoch 790/2000, Train Loss: 1.5289, Test Loss: 1.5232\n",
      "Epoch 791/2000, Train Loss: 1.5278, Test Loss: 1.5311\n",
      "Epoch 792/2000, Train Loss: 1.5277, Test Loss: 1.5265\n",
      "Epoch 793/2000, Train Loss: 1.5283, Test Loss: 1.5197\n",
      "Epoch 794/2000, Train Loss: 1.5295, Test Loss: 1.5242\n",
      "Epoch 795/2000, Train Loss: 1.5284, Test Loss: 1.5309\n",
      "Epoch 796/2000, Train Loss: 1.5282, Test Loss: 1.5332\n",
      "Epoch 797/2000, Train Loss: 1.5289, Test Loss: 1.5279\n",
      "Epoch 798/2000, Train Loss: 1.5285, Test Loss: 1.5268\n",
      "Epoch 799/2000, Train Loss: 1.5287, Test Loss: 1.5237\n",
      "Epoch 800/2000, Train Loss: 1.5285, Test Loss: 1.5276\n",
      "Epoch 801/2000, Train Loss: 1.5280, Test Loss: 1.5230\n",
      "Epoch 802/2000, Train Loss: 1.5292, Test Loss: 1.5273\n",
      "Epoch 803/2000, Train Loss: 1.5288, Test Loss: 1.5266\n",
      "Epoch 804/2000, Train Loss: 1.5294, Test Loss: 1.5254\n",
      "Epoch 805/2000, Train Loss: 1.5287, Test Loss: 1.5253\n",
      "Epoch 806/2000, Train Loss: 1.5290, Test Loss: 1.5260\n",
      "Epoch 807/2000, Train Loss: 1.5288, Test Loss: 1.5266\n",
      "Epoch 808/2000, Train Loss: 1.5281, Test Loss: 1.5279\n",
      "Epoch 809/2000, Train Loss: 1.5288, Test Loss: 1.5319\n",
      "Epoch 810/2000, Train Loss: 1.5277, Test Loss: 1.5220\n",
      "Epoch 811/2000, Train Loss: 1.5278, Test Loss: 1.5228\n",
      "Epoch 812/2000, Train Loss: 1.5277, Test Loss: 1.5267\n",
      "Epoch 813/2000, Train Loss: 1.5283, Test Loss: 1.5258\n",
      "Epoch 814/2000, Train Loss: 1.5279, Test Loss: 1.5286\n",
      "Epoch 815/2000, Train Loss: 1.5281, Test Loss: 1.5272\n",
      "Epoch 816/2000, Train Loss: 1.5285, Test Loss: 1.5219\n",
      "Epoch 817/2000, Train Loss: 1.5276, Test Loss: 1.5302\n",
      "Epoch 818/2000, Train Loss: 1.5277, Test Loss: 1.5345\n",
      "Epoch 819/2000, Train Loss: 1.5284, Test Loss: 1.5239\n",
      "Epoch 820/2000, Train Loss: 1.5279, Test Loss: 1.5239\n",
      "Epoch 821/2000, Train Loss: 1.5287, Test Loss: 1.5280\n",
      "Epoch 822/2000, Train Loss: 1.5294, Test Loss: 1.5283\n",
      "Epoch 823/2000, Train Loss: 1.5274, Test Loss: 1.5249\n",
      "Epoch 824/2000, Train Loss: 1.5277, Test Loss: 1.5249\n",
      "Epoch 825/2000, Train Loss: 1.5282, Test Loss: 1.5223\n",
      "Epoch 826/2000, Train Loss: 1.5282, Test Loss: 1.5253\n",
      "Epoch 827/2000, Train Loss: 1.5289, Test Loss: 1.5250\n",
      "Epoch 828/2000, Train Loss: 1.5283, Test Loss: 1.5268\n",
      "Epoch 829/2000, Train Loss: 1.5279, Test Loss: 1.5202\n",
      "Epoch 830/2000, Train Loss: 1.5290, Test Loss: 1.5254\n",
      "Epoch 831/2000, Train Loss: 1.5286, Test Loss: 1.5297\n",
      "Epoch 832/2000, Train Loss: 1.5286, Test Loss: 1.5237\n",
      "Epoch 833/2000, Train Loss: 1.5285, Test Loss: 1.5301\n",
      "Epoch 834/2000, Train Loss: 1.5281, Test Loss: 1.5220\n",
      "Epoch 835/2000, Train Loss: 1.5277, Test Loss: 1.5256\n",
      "Epoch 836/2000, Train Loss: 1.5278, Test Loss: 1.5241\n",
      "Epoch 837/2000, Train Loss: 1.5281, Test Loss: 1.5234\n",
      "Epoch 838/2000, Train Loss: 1.5280, Test Loss: 1.5307\n",
      "Epoch 839/2000, Train Loss: 1.5275, Test Loss: 1.5274\n",
      "Epoch 840/2000, Train Loss: 1.5284, Test Loss: 1.5267\n",
      "Epoch 841/2000, Train Loss: 1.5273, Test Loss: 1.5227\n",
      "Epoch 842/2000, Train Loss: 1.5275, Test Loss: 1.5244\n",
      "Epoch 843/2000, Train Loss: 1.5273, Test Loss: 1.5256\n",
      "Epoch 844/2000, Train Loss: 1.5286, Test Loss: 1.5234\n",
      "Epoch 845/2000, Train Loss: 1.5280, Test Loss: 1.5265\n",
      "Epoch 846/2000, Train Loss: 1.5284, Test Loss: 1.5260\n",
      "Epoch 847/2000, Train Loss: 1.5281, Test Loss: 1.5276\n",
      "Epoch 848/2000, Train Loss: 1.5283, Test Loss: 1.5235\n",
      "Epoch 849/2000, Train Loss: 1.5282, Test Loss: 1.5250\n",
      "Epoch 850/2000, Train Loss: 1.5289, Test Loss: 1.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851/2000, Train Loss: 1.5276, Test Loss: 1.5205\n",
      "Epoch 852/2000, Train Loss: 1.5279, Test Loss: 1.5244\n",
      "Epoch 853/2000, Train Loss: 1.5281, Test Loss: 1.5316\n",
      "Epoch 854/2000, Train Loss: 1.5276, Test Loss: 1.5210\n",
      "Epoch 855/2000, Train Loss: 1.5277, Test Loss: 1.5322\n",
      "Epoch 856/2000, Train Loss: 1.5281, Test Loss: 1.5244\n",
      "Epoch 857/2000, Train Loss: 1.5280, Test Loss: 1.5307\n",
      "Epoch 858/2000, Train Loss: 1.5280, Test Loss: 1.5234\n",
      "Epoch 859/2000, Train Loss: 1.5278, Test Loss: 1.5249\n",
      "Epoch 860/2000, Train Loss: 1.5282, Test Loss: 1.5262\n",
      "Epoch 861/2000, Train Loss: 1.5285, Test Loss: 1.5291\n",
      "Epoch 862/2000, Train Loss: 1.5290, Test Loss: 1.5273\n",
      "Epoch 863/2000, Train Loss: 1.5279, Test Loss: 1.5496\n",
      "Epoch 864/2000, Train Loss: 1.5280, Test Loss: 1.5232\n",
      "Epoch 865/2000, Train Loss: 1.5278, Test Loss: 1.5294\n",
      "Epoch 866/2000, Train Loss: 1.5277, Test Loss: 1.5220\n",
      "Epoch 867/2000, Train Loss: 1.5279, Test Loss: 1.5227\n",
      "Epoch 868/2000, Train Loss: 1.5281, Test Loss: 1.5288\n",
      "Epoch 869/2000, Train Loss: 1.5274, Test Loss: 1.5242\n",
      "Epoch 870/2000, Train Loss: 1.5275, Test Loss: 1.5227\n",
      "Epoch 871/2000, Train Loss: 1.5276, Test Loss: 1.5303\n",
      "Epoch 872/2000, Train Loss: 1.5281, Test Loss: 1.5245\n",
      "Epoch 873/2000, Train Loss: 1.5281, Test Loss: 1.5243\n",
      "Epoch 874/2000, Train Loss: 1.5277, Test Loss: 1.5232\n",
      "Epoch 875/2000, Train Loss: 1.5278, Test Loss: 1.5271\n",
      "Epoch 876/2000, Train Loss: 1.5278, Test Loss: 1.5225\n",
      "Epoch 877/2000, Train Loss: 1.5280, Test Loss: 1.5246\n",
      "Epoch 878/2000, Train Loss: 1.5279, Test Loss: 1.5235\n",
      "Epoch 879/2000, Train Loss: 1.5284, Test Loss: 1.5269\n",
      "Epoch 880/2000, Train Loss: 1.5278, Test Loss: 1.5219\n",
      "Epoch 881/2000, Train Loss: 1.5288, Test Loss: 1.5238\n",
      "Epoch 882/2000, Train Loss: 1.5284, Test Loss: 1.5255\n",
      "Epoch 883/2000, Train Loss: 1.5277, Test Loss: 1.5302\n",
      "Epoch 884/2000, Train Loss: 1.5283, Test Loss: 1.5265\n",
      "Epoch 885/2000, Train Loss: 1.5287, Test Loss: 1.5256\n",
      "Epoch 886/2000, Train Loss: 1.5270, Test Loss: 1.5308\n",
      "Epoch 887/2000, Train Loss: 1.5279, Test Loss: 1.5229\n",
      "Epoch 888/2000, Train Loss: 1.5275, Test Loss: 1.5230\n",
      "Epoch 889/2000, Train Loss: 1.5279, Test Loss: 1.5245\n",
      "Epoch 890/2000, Train Loss: 1.5273, Test Loss: 1.5266\n",
      "Epoch 891/2000, Train Loss: 1.5274, Test Loss: 1.5273\n",
      "Epoch 892/2000, Train Loss: 1.5275, Test Loss: 1.5225\n",
      "Epoch 893/2000, Train Loss: 1.5273, Test Loss: 1.5229\n",
      "Epoch 894/2000, Train Loss: 1.5275, Test Loss: 1.5280\n",
      "Epoch 895/2000, Train Loss: 1.5280, Test Loss: 1.5255\n",
      "Epoch 896/2000, Train Loss: 1.5278, Test Loss: 1.5263\n",
      "Epoch 897/2000, Train Loss: 1.5273, Test Loss: 1.5241\n",
      "Epoch 898/2000, Train Loss: 1.5274, Test Loss: 1.5241\n",
      "Epoch 899/2000, Train Loss: 1.5278, Test Loss: 1.5318\n",
      "Epoch 900/2000, Train Loss: 1.5277, Test Loss: 1.5250\n",
      "Epoch 901/2000, Train Loss: 1.5276, Test Loss: 1.5258\n",
      "Epoch 902/2000, Train Loss: 1.5272, Test Loss: 1.5198\n",
      "Epoch 903/2000, Train Loss: 1.5274, Test Loss: 1.5285\n",
      "Epoch 904/2000, Train Loss: 1.5277, Test Loss: 1.5258\n",
      "Epoch 905/2000, Train Loss: 1.5281, Test Loss: 1.5241\n",
      "Epoch 906/2000, Train Loss: 1.5277, Test Loss: 1.5270\n",
      "Epoch 907/2000, Train Loss: 1.5274, Test Loss: 1.5263\n",
      "Epoch 908/2000, Train Loss: 1.5277, Test Loss: 1.5317\n",
      "Epoch 909/2000, Train Loss: 1.5278, Test Loss: 1.5203\n",
      "Epoch 910/2000, Train Loss: 1.5284, Test Loss: 1.5259\n",
      "Epoch 911/2000, Train Loss: 1.5273, Test Loss: 1.5207\n",
      "Epoch 912/2000, Train Loss: 1.5280, Test Loss: 1.5303\n",
      "Epoch 913/2000, Train Loss: 1.5277, Test Loss: 1.5237\n",
      "Epoch 914/2000, Train Loss: 1.5273, Test Loss: 1.5289\n",
      "Epoch 915/2000, Train Loss: 1.5271, Test Loss: 1.5254\n",
      "Epoch 916/2000, Train Loss: 1.5277, Test Loss: 1.5334\n",
      "Epoch 917/2000, Train Loss: 1.5275, Test Loss: 1.5212\n",
      "Epoch 918/2000, Train Loss: 1.5272, Test Loss: 1.5269\n",
      "Epoch 919/2000, Train Loss: 1.5280, Test Loss: 1.5206\n",
      "Epoch 920/2000, Train Loss: 1.5274, Test Loss: 1.5239\n",
      "Epoch 921/2000, Train Loss: 1.5277, Test Loss: 1.5283\n",
      "Epoch 922/2000, Train Loss: 1.5280, Test Loss: 1.5247\n",
      "Epoch 923/2000, Train Loss: 1.5283, Test Loss: 1.5320\n",
      "Epoch 924/2000, Train Loss: 1.5280, Test Loss: 1.5255\n",
      "Epoch 925/2000, Train Loss: 1.5284, Test Loss: 1.5178\n",
      "Epoch 926/2000, Train Loss: 1.5282, Test Loss: 1.5246\n",
      "Epoch 927/2000, Train Loss: 1.5271, Test Loss: 1.5258\n",
      "Epoch 928/2000, Train Loss: 1.5268, Test Loss: 1.5248\n",
      "Epoch 929/2000, Train Loss: 1.5289, Test Loss: 1.5255\n",
      "Epoch 930/2000, Train Loss: 1.5279, Test Loss: 1.5311\n",
      "Epoch 931/2000, Train Loss: 1.5277, Test Loss: 1.5266\n",
      "Epoch 932/2000, Train Loss: 1.5275, Test Loss: 1.5237\n",
      "Epoch 933/2000, Train Loss: 1.5286, Test Loss: 1.5231\n",
      "Epoch 934/2000, Train Loss: 1.5279, Test Loss: 1.5274\n",
      "Epoch 935/2000, Train Loss: 1.5281, Test Loss: 1.5219\n",
      "Epoch 936/2000, Train Loss: 1.5277, Test Loss: 1.5232\n",
      "Epoch 937/2000, Train Loss: 1.5281, Test Loss: 1.5306\n",
      "Epoch 938/2000, Train Loss: 1.5274, Test Loss: 1.5238\n",
      "Epoch 939/2000, Train Loss: 1.5273, Test Loss: 1.5296\n",
      "Epoch 940/2000, Train Loss: 1.5280, Test Loss: 1.5317\n",
      "Epoch 941/2000, Train Loss: 1.5273, Test Loss: 1.5237\n",
      "Epoch 942/2000, Train Loss: 1.5273, Test Loss: 1.5266\n",
      "Epoch 943/2000, Train Loss: 1.5279, Test Loss: 1.5278\n",
      "Epoch 944/2000, Train Loss: 1.5272, Test Loss: 1.5239\n",
      "Epoch 945/2000, Train Loss: 1.5284, Test Loss: 1.5268\n",
      "Epoch 946/2000, Train Loss: 1.5273, Test Loss: 1.5233\n",
      "Epoch 947/2000, Train Loss: 1.5276, Test Loss: 1.5261\n",
      "Epoch 948/2000, Train Loss: 1.5273, Test Loss: 1.5264\n",
      "Epoch 949/2000, Train Loss: 1.5280, Test Loss: 1.5271\n",
      "Epoch 950/2000, Train Loss: 1.5271, Test Loss: 1.5271\n",
      "Epoch 951/2000, Train Loss: 1.5270, Test Loss: 1.5207\n",
      "Epoch 952/2000, Train Loss: 1.5279, Test Loss: 1.5286\n",
      "Epoch 953/2000, Train Loss: 1.5281, Test Loss: 1.5230\n",
      "Epoch 954/2000, Train Loss: 1.5276, Test Loss: 1.5256\n",
      "Epoch 955/2000, Train Loss: 1.5281, Test Loss: 1.5237\n",
      "Epoch 956/2000, Train Loss: 1.5272, Test Loss: 1.5219\n",
      "Epoch 957/2000, Train Loss: 1.5277, Test Loss: 1.5293\n",
      "Epoch 958/2000, Train Loss: 1.5273, Test Loss: 1.5244\n",
      "Epoch 959/2000, Train Loss: 1.5273, Test Loss: 1.5229\n",
      "Epoch 960/2000, Train Loss: 1.5282, Test Loss: 1.5257\n",
      "Epoch 961/2000, Train Loss: 1.5270, Test Loss: 1.5292\n",
      "Epoch 962/2000, Train Loss: 1.5277, Test Loss: 1.5210\n",
      "Epoch 963/2000, Train Loss: 1.5267, Test Loss: 1.5207\n",
      "Epoch 964/2000, Train Loss: 1.5271, Test Loss: 1.5257\n",
      "Epoch 965/2000, Train Loss: 1.5274, Test Loss: 1.5277\n",
      "Epoch 966/2000, Train Loss: 1.5278, Test Loss: 1.5226\n",
      "Epoch 967/2000, Train Loss: 1.5272, Test Loss: 1.5272\n",
      "Epoch 968/2000, Train Loss: 1.5273, Test Loss: 1.5299\n",
      "Epoch 969/2000, Train Loss: 1.5276, Test Loss: 1.5220\n",
      "Epoch 970/2000, Train Loss: 1.5268, Test Loss: 1.5250\n",
      "Epoch 971/2000, Train Loss: 1.5270, Test Loss: 1.5211\n",
      "Epoch 972/2000, Train Loss: 1.5269, Test Loss: 1.5289\n",
      "Epoch 973/2000, Train Loss: 1.5281, Test Loss: 1.5231\n",
      "Epoch 974/2000, Train Loss: 1.5284, Test Loss: 1.5280\n",
      "Epoch 975/2000, Train Loss: 1.5281, Test Loss: 1.5253\n",
      "Epoch 976/2000, Train Loss: 1.5272, Test Loss: 1.5228\n",
      "Epoch 977/2000, Train Loss: 1.5271, Test Loss: 1.5249\n",
      "Epoch 978/2000, Train Loss: 1.5267, Test Loss: 1.5256\n",
      "Epoch 979/2000, Train Loss: 1.5272, Test Loss: 1.5227\n",
      "Epoch 980/2000, Train Loss: 1.5272, Test Loss: 1.5244\n",
      "Epoch 981/2000, Train Loss: 1.5280, Test Loss: 1.5245\n",
      "Epoch 982/2000, Train Loss: 1.5272, Test Loss: 1.5274\n",
      "Epoch 983/2000, Train Loss: 1.5274, Test Loss: 1.5248\n",
      "Epoch 984/2000, Train Loss: 1.5276, Test Loss: 1.5220\n",
      "Epoch 985/2000, Train Loss: 1.5271, Test Loss: 1.5242\n",
      "Epoch 986/2000, Train Loss: 1.5269, Test Loss: 1.5271\n",
      "Epoch 987/2000, Train Loss: 1.5274, Test Loss: 1.5289\n",
      "Epoch 988/2000, Train Loss: 1.5266, Test Loss: 1.5229\n",
      "Epoch 989/2000, Train Loss: 1.5276, Test Loss: 1.5238\n",
      "Epoch 990/2000, Train Loss: 1.5284, Test Loss: 1.5248\n",
      "Epoch 991/2000, Train Loss: 1.5283, Test Loss: 1.5279\n",
      "Epoch 992/2000, Train Loss: 1.5276, Test Loss: 1.5268\n",
      "Epoch 993/2000, Train Loss: 1.5272, Test Loss: 1.5194\n",
      "Epoch 994/2000, Train Loss: 1.5275, Test Loss: 1.5187\n",
      "Epoch 995/2000, Train Loss: 1.5271, Test Loss: 1.5224\n",
      "Epoch 996/2000, Train Loss: 1.5268, Test Loss: 1.5270\n",
      "Epoch 997/2000, Train Loss: 1.5268, Test Loss: 1.5350\n",
      "Epoch 998/2000, Train Loss: 1.5273, Test Loss: 1.5291\n",
      "Epoch 999/2000, Train Loss: 1.5270, Test Loss: 1.5260\n",
      "Epoch 1000/2000, Train Loss: 1.5271, Test Loss: 1.5215\n",
      "Epoch 1001/2000, Train Loss: 1.5278, Test Loss: 1.5286\n",
      "Epoch 1002/2000, Train Loss: 1.5274, Test Loss: 1.5234\n",
      "Epoch 1003/2000, Train Loss: 1.5272, Test Loss: 1.5286\n",
      "Epoch 1004/2000, Train Loss: 1.5275, Test Loss: 1.5239\n",
      "Epoch 1005/2000, Train Loss: 1.5273, Test Loss: 1.5242\n",
      "Epoch 1006/2000, Train Loss: 1.5279, Test Loss: 1.5299\n",
      "Epoch 1007/2000, Train Loss: 1.5267, Test Loss: 1.5266\n",
      "Epoch 1008/2000, Train Loss: 1.5269, Test Loss: 1.5271\n",
      "Epoch 1009/2000, Train Loss: 1.5270, Test Loss: 1.5202\n",
      "Epoch 1010/2000, Train Loss: 1.5273, Test Loss: 1.5252\n",
      "Epoch 1011/2000, Train Loss: 1.5271, Test Loss: 1.5241\n",
      "Epoch 1012/2000, Train Loss: 1.5277, Test Loss: 1.5243\n",
      "Epoch 1013/2000, Train Loss: 1.5270, Test Loss: 1.5289\n",
      "Epoch 1014/2000, Train Loss: 1.5266, Test Loss: 1.5254\n",
      "Epoch 1015/2000, Train Loss: 1.5272, Test Loss: 1.5231\n",
      "Epoch 1016/2000, Train Loss: 1.5279, Test Loss: 1.5252\n",
      "Epoch 1017/2000, Train Loss: 1.5280, Test Loss: 1.5251\n",
      "Epoch 1018/2000, Train Loss: 1.5270, Test Loss: 1.5224\n",
      "Epoch 1019/2000, Train Loss: 1.5270, Test Loss: 1.5240\n",
      "Epoch 1020/2000, Train Loss: 1.5268, Test Loss: 1.5273\n",
      "Epoch 1021/2000, Train Loss: 1.5265, Test Loss: 1.5211\n",
      "Epoch 1022/2000, Train Loss: 1.5272, Test Loss: 1.5237\n",
      "Epoch 1023/2000, Train Loss: 1.5268, Test Loss: 1.5237\n",
      "Epoch 1024/2000, Train Loss: 1.5273, Test Loss: 1.5246\n",
      "Epoch 1025/2000, Train Loss: 1.5268, Test Loss: 1.5360\n",
      "Epoch 1026/2000, Train Loss: 1.5268, Test Loss: 1.5262\n",
      "Epoch 1027/2000, Train Loss: 1.5278, Test Loss: 1.5305\n",
      "Epoch 1028/2000, Train Loss: 1.5275, Test Loss: 1.5230\n",
      "Epoch 1029/2000, Train Loss: 1.5266, Test Loss: 1.5239\n",
      "Epoch 1030/2000, Train Loss: 1.5270, Test Loss: 1.5227\n",
      "Epoch 1031/2000, Train Loss: 1.5265, Test Loss: 1.5220\n",
      "Epoch 1032/2000, Train Loss: 1.5268, Test Loss: 1.5273\n",
      "Epoch 1033/2000, Train Loss: 1.5279, Test Loss: 1.5376\n",
      "Epoch 1034/2000, Train Loss: 1.5266, Test Loss: 1.5267\n",
      "Epoch 1035/2000, Train Loss: 1.5269, Test Loss: 1.5257\n",
      "Epoch 1036/2000, Train Loss: 1.5285, Test Loss: 1.5253\n",
      "Epoch 1037/2000, Train Loss: 1.5272, Test Loss: 1.5284\n",
      "Epoch 1038/2000, Train Loss: 1.5269, Test Loss: 1.5265\n",
      "Epoch 1039/2000, Train Loss: 1.5272, Test Loss: 1.5212\n",
      "Epoch 1040/2000, Train Loss: 1.5275, Test Loss: 1.5265\n",
      "Epoch 1041/2000, Train Loss: 1.5269, Test Loss: 1.5206\n",
      "Epoch 1042/2000, Train Loss: 1.5267, Test Loss: 1.5220\n",
      "Epoch 1043/2000, Train Loss: 1.5270, Test Loss: 1.5268\n",
      "Epoch 1044/2000, Train Loss: 1.5266, Test Loss: 1.5247\n",
      "Epoch 1045/2000, Train Loss: 1.5263, Test Loss: 1.5241\n",
      "Epoch 1046/2000, Train Loss: 1.5275, Test Loss: 1.5264\n",
      "Epoch 1047/2000, Train Loss: 1.5269, Test Loss: 1.5321\n",
      "Epoch 1048/2000, Train Loss: 1.5272, Test Loss: 1.5265\n",
      "Epoch 1049/2000, Train Loss: 1.5270, Test Loss: 1.5214\n",
      "Epoch 1050/2000, Train Loss: 1.5272, Test Loss: 1.5234\n",
      "Epoch 1051/2000, Train Loss: 1.5274, Test Loss: 1.5238\n",
      "Epoch 1052/2000, Train Loss: 1.5268, Test Loss: 1.5233\n",
      "Epoch 1053/2000, Train Loss: 1.5272, Test Loss: 1.5299\n",
      "Epoch 1054/2000, Train Loss: 1.5265, Test Loss: 1.5204\n",
      "Epoch 1055/2000, Train Loss: 1.5274, Test Loss: 1.5211\n",
      "Epoch 1056/2000, Train Loss: 1.5267, Test Loss: 1.5214\n",
      "Epoch 1057/2000, Train Loss: 1.5276, Test Loss: 1.5208\n",
      "Epoch 1058/2000, Train Loss: 1.5271, Test Loss: 1.5260\n",
      "Epoch 1059/2000, Train Loss: 1.5270, Test Loss: 1.5241\n",
      "Epoch 1060/2000, Train Loss: 1.5273, Test Loss: 1.5238\n",
      "Epoch 1061/2000, Train Loss: 1.5270, Test Loss: 1.5213\n",
      "Epoch 1062/2000, Train Loss: 1.5272, Test Loss: 1.5247\n",
      "Epoch 1063/2000, Train Loss: 1.5281, Test Loss: 1.5233\n",
      "Epoch 1064/2000, Train Loss: 1.5272, Test Loss: 1.5226\n",
      "Epoch 1065/2000, Train Loss: 1.5268, Test Loss: 1.5288\n",
      "Epoch 1066/2000, Train Loss: 1.5275, Test Loss: 1.5249\n",
      "Epoch 1067/2000, Train Loss: 1.5276, Test Loss: 1.5230\n",
      "Epoch 1068/2000, Train Loss: 1.5270, Test Loss: 1.5280\n",
      "Epoch 1069/2000, Train Loss: 1.5270, Test Loss: 1.5270\n",
      "Epoch 1070/2000, Train Loss: 1.5275, Test Loss: 1.5245\n",
      "Epoch 1071/2000, Train Loss: 1.5267, Test Loss: 1.5257\n",
      "Epoch 1072/2000, Train Loss: 1.5279, Test Loss: 1.5303\n",
      "Epoch 1073/2000, Train Loss: 1.5266, Test Loss: 1.5207\n",
      "Epoch 1074/2000, Train Loss: 1.5276, Test Loss: 1.5205\n",
      "Epoch 1075/2000, Train Loss: 1.5276, Test Loss: 1.5249\n",
      "Epoch 1076/2000, Train Loss: 1.5267, Test Loss: 1.5243\n",
      "Epoch 1077/2000, Train Loss: 1.5271, Test Loss: 1.5225\n",
      "Epoch 1078/2000, Train Loss: 1.5268, Test Loss: 1.5234\n",
      "Epoch 1079/2000, Train Loss: 1.5264, Test Loss: 1.5267\n",
      "Epoch 1080/2000, Train Loss: 1.5266, Test Loss: 1.5194\n",
      "Epoch 1081/2000, Train Loss: 1.5267, Test Loss: 1.5267\n",
      "Epoch 1082/2000, Train Loss: 1.5265, Test Loss: 1.5219\n",
      "Epoch 1083/2000, Train Loss: 1.5267, Test Loss: 1.5258\n",
      "Epoch 1084/2000, Train Loss: 1.5262, Test Loss: 1.5306\n",
      "Epoch 1085/2000, Train Loss: 1.5262, Test Loss: 1.5225\n",
      "Epoch 1086/2000, Train Loss: 1.5281, Test Loss: 1.5252\n",
      "Epoch 1087/2000, Train Loss: 1.5265, Test Loss: 1.5225\n",
      "Epoch 1088/2000, Train Loss: 1.5265, Test Loss: 1.5325\n",
      "Epoch 1089/2000, Train Loss: 1.5273, Test Loss: 1.5223\n",
      "Epoch 1090/2000, Train Loss: 1.5270, Test Loss: 1.5280\n",
      "Epoch 1091/2000, Train Loss: 1.5276, Test Loss: 1.5263\n",
      "Epoch 1092/2000, Train Loss: 1.5268, Test Loss: 1.5227\n",
      "Epoch 1093/2000, Train Loss: 1.5269, Test Loss: 1.5242\n",
      "Epoch 1094/2000, Train Loss: 1.5270, Test Loss: 1.5220\n",
      "Epoch 1095/2000, Train Loss: 1.5263, Test Loss: 1.5249\n",
      "Epoch 1096/2000, Train Loss: 1.5270, Test Loss: 1.5229\n",
      "Epoch 1097/2000, Train Loss: 1.5263, Test Loss: 1.5259\n",
      "Epoch 1098/2000, Train Loss: 1.5272, Test Loss: 1.5225\n",
      "Epoch 1099/2000, Train Loss: 1.5272, Test Loss: 1.5226\n",
      "Epoch 1100/2000, Train Loss: 1.5271, Test Loss: 1.5243\n",
      "Epoch 1101/2000, Train Loss: 1.5279, Test Loss: 1.5221\n",
      "Epoch 1102/2000, Train Loss: 1.5276, Test Loss: 1.5207\n",
      "Epoch 1103/2000, Train Loss: 1.5269, Test Loss: 1.5260\n",
      "Epoch 1104/2000, Train Loss: 1.5263, Test Loss: 1.5255\n",
      "Epoch 1105/2000, Train Loss: 1.5272, Test Loss: 1.5237\n",
      "Epoch 1106/2000, Train Loss: 1.5277, Test Loss: 1.5227\n",
      "Epoch 1107/2000, Train Loss: 1.5265, Test Loss: 1.5240\n",
      "Epoch 1108/2000, Train Loss: 1.5274, Test Loss: 1.5290\n",
      "Epoch 1109/2000, Train Loss: 1.5265, Test Loss: 1.5227\n",
      "Epoch 1110/2000, Train Loss: 1.5266, Test Loss: 1.5258\n",
      "Epoch 1111/2000, Train Loss: 1.5266, Test Loss: 1.5287\n",
      "Epoch 1112/2000, Train Loss: 1.5269, Test Loss: 1.5291\n",
      "Epoch 1113/2000, Train Loss: 1.5270, Test Loss: 1.5219\n",
      "Epoch 1114/2000, Train Loss: 1.5263, Test Loss: 1.5226\n",
      "Epoch 1115/2000, Train Loss: 1.5280, Test Loss: 1.5235\n",
      "Epoch 1116/2000, Train Loss: 1.5265, Test Loss: 1.5275\n",
      "Epoch 1117/2000, Train Loss: 1.5276, Test Loss: 1.5237\n",
      "Epoch 1118/2000, Train Loss: 1.5272, Test Loss: 1.5225\n",
      "Epoch 1119/2000, Train Loss: 1.5269, Test Loss: 1.5245\n",
      "Epoch 1120/2000, Train Loss: 1.5272, Test Loss: 1.5329\n",
      "Epoch 1121/2000, Train Loss: 1.5267, Test Loss: 1.5220\n",
      "Epoch 1122/2000, Train Loss: 1.5274, Test Loss: 1.5222\n",
      "Epoch 1123/2000, Train Loss: 1.5269, Test Loss: 1.5229\n",
      "Epoch 1124/2000, Train Loss: 1.5280, Test Loss: 1.5331\n",
      "Epoch 1125/2000, Train Loss: 1.5271, Test Loss: 1.5277\n",
      "Epoch 1126/2000, Train Loss: 1.5274, Test Loss: 1.5218\n",
      "Epoch 1127/2000, Train Loss: 1.5276, Test Loss: 1.5206\n",
      "Epoch 1128/2000, Train Loss: 1.5272, Test Loss: 1.5260\n",
      "Epoch 1129/2000, Train Loss: 1.5266, Test Loss: 1.5255\n",
      "Epoch 1130/2000, Train Loss: 1.5270, Test Loss: 1.5215\n",
      "Epoch 1131/2000, Train Loss: 1.5262, Test Loss: 1.5206\n",
      "Epoch 1132/2000, Train Loss: 1.5271, Test Loss: 1.5254\n",
      "Epoch 1133/2000, Train Loss: 1.5262, Test Loss: 1.5251\n",
      "Epoch 1134/2000, Train Loss: 1.5268, Test Loss: 1.5235\n",
      "Epoch 1135/2000, Train Loss: 1.5271, Test Loss: 1.5245\n",
      "Epoch 1136/2000, Train Loss: 1.5265, Test Loss: 1.5258\n",
      "Epoch 1137/2000, Train Loss: 1.5264, Test Loss: 1.5217\n",
      "Epoch 1138/2000, Train Loss: 1.5278, Test Loss: 1.5257\n",
      "Epoch 1139/2000, Train Loss: 1.5266, Test Loss: 1.5239\n",
      "Epoch 1140/2000, Train Loss: 1.5268, Test Loss: 1.5243\n",
      "Epoch 1141/2000, Train Loss: 1.5265, Test Loss: 1.5223\n",
      "Epoch 1142/2000, Train Loss: 1.5277, Test Loss: 1.5234\n",
      "Epoch 1143/2000, Train Loss: 1.5272, Test Loss: 1.5239\n",
      "Epoch 1144/2000, Train Loss: 1.5271, Test Loss: 1.5228\n",
      "Epoch 1145/2000, Train Loss: 1.5265, Test Loss: 1.5192\n",
      "Epoch 1146/2000, Train Loss: 1.5277, Test Loss: 1.5201\n",
      "Epoch 1147/2000, Train Loss: 1.5262, Test Loss: 1.5241\n",
      "Epoch 1148/2000, Train Loss: 1.5262, Test Loss: 1.5244\n",
      "Epoch 1149/2000, Train Loss: 1.5263, Test Loss: 1.5231\n",
      "Epoch 1150/2000, Train Loss: 1.5265, Test Loss: 1.5216\n",
      "Epoch 1151/2000, Train Loss: 1.5271, Test Loss: 1.5255\n",
      "Epoch 1152/2000, Train Loss: 1.5269, Test Loss: 1.5316\n",
      "Epoch 1153/2000, Train Loss: 1.5261, Test Loss: 1.5254\n",
      "Epoch 1154/2000, Train Loss: 1.5271, Test Loss: 1.5230\n",
      "Epoch 1155/2000, Train Loss: 1.5265, Test Loss: 1.5252\n",
      "Epoch 1156/2000, Train Loss: 1.5273, Test Loss: 1.5252\n",
      "Epoch 1157/2000, Train Loss: 1.5271, Test Loss: 1.5278\n",
      "Epoch 1158/2000, Train Loss: 1.5264, Test Loss: 1.5221\n",
      "Epoch 1159/2000, Train Loss: 1.5270, Test Loss: 1.5224\n",
      "Epoch 1160/2000, Train Loss: 1.5274, Test Loss: 1.5220\n",
      "Epoch 1161/2000, Train Loss: 1.5265, Test Loss: 1.5280\n",
      "Epoch 1162/2000, Train Loss: 1.5268, Test Loss: 1.5227\n",
      "Epoch 1163/2000, Train Loss: 1.5276, Test Loss: 1.5219\n",
      "Epoch 1164/2000, Train Loss: 1.5264, Test Loss: 1.5285\n",
      "Epoch 1165/2000, Train Loss: 1.5268, Test Loss: 1.5263\n",
      "Epoch 1166/2000, Train Loss: 1.5269, Test Loss: 1.5251\n",
      "Epoch 1167/2000, Train Loss: 1.5278, Test Loss: 1.5259\n",
      "Epoch 1168/2000, Train Loss: 1.5263, Test Loss: 1.5214\n",
      "Epoch 1169/2000, Train Loss: 1.5264, Test Loss: 1.5261\n",
      "Epoch 1170/2000, Train Loss: 1.5265, Test Loss: 1.5237\n",
      "Epoch 1171/2000, Train Loss: 1.5273, Test Loss: 1.5237\n",
      "Epoch 1172/2000, Train Loss: 1.5262, Test Loss: 1.5246\n",
      "Epoch 1173/2000, Train Loss: 1.5263, Test Loss: 1.5268\n",
      "Epoch 1174/2000, Train Loss: 1.5258, Test Loss: 1.5398\n",
      "Epoch 1175/2000, Train Loss: 1.5268, Test Loss: 1.5270\n",
      "Epoch 1176/2000, Train Loss: 1.5276, Test Loss: 1.5241\n",
      "Epoch 1177/2000, Train Loss: 1.5268, Test Loss: 1.5258\n",
      "Epoch 1178/2000, Train Loss: 1.5265, Test Loss: 1.5198\n",
      "Epoch 1179/2000, Train Loss: 1.5271, Test Loss: 1.5236\n",
      "Epoch 1180/2000, Train Loss: 1.5275, Test Loss: 1.5250\n",
      "Epoch 1181/2000, Train Loss: 1.5269, Test Loss: 1.5264\n",
      "Epoch 1182/2000, Train Loss: 1.5265, Test Loss: 1.5299\n",
      "Epoch 1183/2000, Train Loss: 1.5266, Test Loss: 1.5240\n",
      "Epoch 1184/2000, Train Loss: 1.5267, Test Loss: 1.5201\n",
      "Epoch 1185/2000, Train Loss: 1.5276, Test Loss: 1.5345\n",
      "Epoch 1186/2000, Train Loss: 1.5262, Test Loss: 1.5259\n",
      "Epoch 1187/2000, Train Loss: 1.5281, Test Loss: 1.5245\n",
      "Epoch 1188/2000, Train Loss: 1.5264, Test Loss: 1.5263\n",
      "Epoch 1189/2000, Train Loss: 1.5265, Test Loss: 1.5350\n",
      "Epoch 1190/2000, Train Loss: 1.5266, Test Loss: 1.5251\n",
      "Epoch 1191/2000, Train Loss: 1.5265, Test Loss: 1.5250\n",
      "Epoch 1192/2000, Train Loss: 1.5264, Test Loss: 1.5266\n",
      "Epoch 1193/2000, Train Loss: 1.5265, Test Loss: 1.5285\n",
      "Epoch 1194/2000, Train Loss: 1.5267, Test Loss: 1.5309\n",
      "Epoch 1195/2000, Train Loss: 1.5270, Test Loss: 1.5218\n",
      "Epoch 1196/2000, Train Loss: 1.5266, Test Loss: 1.5250\n",
      "Epoch 1197/2000, Train Loss: 1.5273, Test Loss: 1.5204\n",
      "Epoch 1198/2000, Train Loss: 1.5265, Test Loss: 1.5213\n",
      "Epoch 1199/2000, Train Loss: 1.5266, Test Loss: 1.5401\n",
      "Epoch 1200/2000, Train Loss: 1.5265, Test Loss: 1.5215\n",
      "Epoch 1201/2000, Train Loss: 1.5264, Test Loss: 1.5222\n",
      "Epoch 1202/2000, Train Loss: 1.5262, Test Loss: 1.5221\n",
      "Epoch 1203/2000, Train Loss: 1.5271, Test Loss: 1.5249\n",
      "Epoch 1204/2000, Train Loss: 1.5269, Test Loss: 1.5259\n",
      "Epoch 1205/2000, Train Loss: 1.5272, Test Loss: 1.5239\n",
      "Epoch 1206/2000, Train Loss: 1.5266, Test Loss: 1.5241\n",
      "Epoch 1207/2000, Train Loss: 1.5264, Test Loss: 1.5221\n",
      "Epoch 1208/2000, Train Loss: 1.5267, Test Loss: 1.5236\n",
      "Epoch 1209/2000, Train Loss: 1.5261, Test Loss: 1.5244\n",
      "Epoch 1210/2000, Train Loss: 1.5265, Test Loss: 1.5234\n",
      "Epoch 1211/2000, Train Loss: 1.5260, Test Loss: 1.5270\n",
      "Epoch 1212/2000, Train Loss: 1.5265, Test Loss: 1.5253\n",
      "Epoch 1213/2000, Train Loss: 1.5266, Test Loss: 1.5200\n",
      "Epoch 1214/2000, Train Loss: 1.5263, Test Loss: 1.5286\n",
      "Epoch 1215/2000, Train Loss: 1.5272, Test Loss: 1.5282\n",
      "Epoch 1216/2000, Train Loss: 1.5275, Test Loss: 1.5245\n",
      "Epoch 1217/2000, Train Loss: 1.5260, Test Loss: 1.5262\n",
      "Epoch 1218/2000, Train Loss: 1.5268, Test Loss: 1.5256\n",
      "Epoch 1219/2000, Train Loss: 1.5267, Test Loss: 1.5236\n",
      "Epoch 1220/2000, Train Loss: 1.5261, Test Loss: 1.5229\n",
      "Epoch 1221/2000, Train Loss: 1.5259, Test Loss: 1.5258\n",
      "Epoch 1222/2000, Train Loss: 1.5263, Test Loss: 1.5246\n",
      "Epoch 1223/2000, Train Loss: 1.5270, Test Loss: 1.5249\n",
      "Epoch 1224/2000, Train Loss: 1.5262, Test Loss: 1.5213\n",
      "Epoch 1225/2000, Train Loss: 1.5277, Test Loss: 1.5213\n",
      "Epoch 1226/2000, Train Loss: 1.5265, Test Loss: 1.5269\n",
      "Epoch 1227/2000, Train Loss: 1.5258, Test Loss: 1.5260\n",
      "Epoch 1228/2000, Train Loss: 1.5270, Test Loss: 1.5205\n",
      "Epoch 1229/2000, Train Loss: 1.5261, Test Loss: 1.5253\n",
      "Epoch 1230/2000, Train Loss: 1.5259, Test Loss: 1.5277\n",
      "Epoch 1231/2000, Train Loss: 1.5272, Test Loss: 1.5301\n",
      "Epoch 1232/2000, Train Loss: 1.5266, Test Loss: 1.5234\n",
      "Epoch 1233/2000, Train Loss: 1.5271, Test Loss: 1.5197\n",
      "Epoch 1234/2000, Train Loss: 1.5262, Test Loss: 1.5266\n",
      "Epoch 1235/2000, Train Loss: 1.5262, Test Loss: 1.5257\n",
      "Epoch 1236/2000, Train Loss: 1.5262, Test Loss: 1.5301\n",
      "Epoch 1237/2000, Train Loss: 1.5265, Test Loss: 1.5248\n",
      "Epoch 1238/2000, Train Loss: 1.5258, Test Loss: 1.5216\n",
      "Epoch 1239/2000, Train Loss: 1.5260, Test Loss: 1.5295\n",
      "Epoch 1240/2000, Train Loss: 1.5266, Test Loss: 1.5249\n",
      "Epoch 1241/2000, Train Loss: 1.5267, Test Loss: 1.5212\n",
      "Epoch 1242/2000, Train Loss: 1.5264, Test Loss: 1.5183\n",
      "Epoch 1243/2000, Train Loss: 1.5269, Test Loss: 1.5265\n",
      "Epoch 1244/2000, Train Loss: 1.5260, Test Loss: 1.5230\n",
      "Epoch 1245/2000, Train Loss: 1.5263, Test Loss: 1.5257\n",
      "Epoch 1246/2000, Train Loss: 1.5259, Test Loss: 1.5274\n",
      "Epoch 1247/2000, Train Loss: 1.5269, Test Loss: 1.5251\n",
      "Epoch 1248/2000, Train Loss: 1.5263, Test Loss: 1.5244\n",
      "Epoch 1249/2000, Train Loss: 1.5259, Test Loss: 1.5247\n",
      "Epoch 1250/2000, Train Loss: 1.5266, Test Loss: 1.5231\n",
      "Epoch 1251/2000, Train Loss: 1.5256, Test Loss: 1.5219\n",
      "Epoch 1252/2000, Train Loss: 1.5264, Test Loss: 1.5237\n",
      "Epoch 1253/2000, Train Loss: 1.5265, Test Loss: 1.5290\n",
      "Epoch 1254/2000, Train Loss: 1.5266, Test Loss: 1.5233\n",
      "Epoch 1255/2000, Train Loss: 1.5269, Test Loss: 1.5252\n",
      "Epoch 1256/2000, Train Loss: 1.5268, Test Loss: 1.5310\n",
      "Epoch 1257/2000, Train Loss: 1.5265, Test Loss: 1.5222\n",
      "Epoch 1258/2000, Train Loss: 1.5265, Test Loss: 1.5267\n",
      "Epoch 1259/2000, Train Loss: 1.5263, Test Loss: 1.5219\n",
      "Epoch 1260/2000, Train Loss: 1.5268, Test Loss: 1.5241\n",
      "Epoch 1261/2000, Train Loss: 1.5267, Test Loss: 1.5287\n",
      "Epoch 1262/2000, Train Loss: 1.5273, Test Loss: 1.5249\n",
      "Epoch 1263/2000, Train Loss: 1.5266, Test Loss: 1.5252\n",
      "Epoch 1264/2000, Train Loss: 1.5270, Test Loss: 1.5254\n",
      "Epoch 1265/2000, Train Loss: 1.5260, Test Loss: 1.5253\n",
      "Epoch 1266/2000, Train Loss: 1.5270, Test Loss: 1.5257\n",
      "Epoch 1267/2000, Train Loss: 1.5266, Test Loss: 1.5203\n",
      "Epoch 1268/2000, Train Loss: 1.5259, Test Loss: 1.5216\n",
      "Epoch 1269/2000, Train Loss: 1.5265, Test Loss: 1.5254\n",
      "Epoch 1270/2000, Train Loss: 1.5261, Test Loss: 1.5320\n",
      "Epoch 1271/2000, Train Loss: 1.5271, Test Loss: 1.5292\n",
      "Epoch 1272/2000, Train Loss: 1.5260, Test Loss: 1.5242\n",
      "Epoch 1273/2000, Train Loss: 1.5262, Test Loss: 1.5228\n",
      "Epoch 1274/2000, Train Loss: 1.5278, Test Loss: 1.5261\n",
      "Epoch 1275/2000, Train Loss: 1.5266, Test Loss: 1.5212\n",
      "Epoch 1276/2000, Train Loss: 1.5264, Test Loss: 1.5237\n",
      "Epoch 1277/2000, Train Loss: 1.5264, Test Loss: 1.5239\n",
      "Epoch 1278/2000, Train Loss: 1.5259, Test Loss: 1.5220\n",
      "Epoch 1279/2000, Train Loss: 1.5263, Test Loss: 1.5229\n",
      "Epoch 1280/2000, Train Loss: 1.5260, Test Loss: 1.5257\n",
      "Epoch 1281/2000, Train Loss: 1.5265, Test Loss: 1.5253\n",
      "Epoch 1282/2000, Train Loss: 1.5263, Test Loss: 1.5217\n",
      "Epoch 1283/2000, Train Loss: 1.5266, Test Loss: 1.5226\n",
      "Epoch 1284/2000, Train Loss: 1.5261, Test Loss: 1.5263\n",
      "Epoch 1285/2000, Train Loss: 1.5266, Test Loss: 1.5270\n",
      "Epoch 1286/2000, Train Loss: 1.5265, Test Loss: 1.5290\n",
      "Epoch 1287/2000, Train Loss: 1.5266, Test Loss: 1.5234\n",
      "Epoch 1288/2000, Train Loss: 1.5264, Test Loss: 1.5225\n",
      "Epoch 1289/2000, Train Loss: 1.5265, Test Loss: 1.5210\n",
      "Epoch 1290/2000, Train Loss: 1.5265, Test Loss: 1.5217\n",
      "Epoch 1291/2000, Train Loss: 1.5270, Test Loss: 1.5291\n",
      "Epoch 1292/2000, Train Loss: 1.5263, Test Loss: 1.5364\n",
      "Epoch 1293/2000, Train Loss: 1.5259, Test Loss: 1.5272\n",
      "Epoch 1294/2000, Train Loss: 1.5254, Test Loss: 1.5279\n",
      "Epoch 1295/2000, Train Loss: 1.5267, Test Loss: 1.5271\n",
      "Epoch 1296/2000, Train Loss: 1.5260, Test Loss: 1.5236\n",
      "Epoch 1297/2000, Train Loss: 1.5258, Test Loss: 1.5263\n",
      "Epoch 1298/2000, Train Loss: 1.5265, Test Loss: 1.5236\n",
      "Epoch 1299/2000, Train Loss: 1.5279, Test Loss: 1.5243\n",
      "Epoch 1300/2000, Train Loss: 1.5261, Test Loss: 1.5298\n",
      "Epoch 1301/2000, Train Loss: 1.5267, Test Loss: 1.5268\n",
      "Epoch 1302/2000, Train Loss: 1.5263, Test Loss: 1.5248\n",
      "Epoch 1303/2000, Train Loss: 1.5271, Test Loss: 1.5213\n",
      "Epoch 1304/2000, Train Loss: 1.5260, Test Loss: 1.5276\n",
      "Epoch 1305/2000, Train Loss: 1.5257, Test Loss: 1.5244\n",
      "Epoch 1306/2000, Train Loss: 1.5272, Test Loss: 1.5235\n",
      "Epoch 1307/2000, Train Loss: 1.5275, Test Loss: 1.5233\n",
      "Epoch 1308/2000, Train Loss: 1.5272, Test Loss: 1.5414\n",
      "Epoch 1309/2000, Train Loss: 1.5270, Test Loss: 1.5281\n",
      "Epoch 1310/2000, Train Loss: 1.5265, Test Loss: 1.5258\n",
      "Epoch 1311/2000, Train Loss: 1.5264, Test Loss: 1.5242\n",
      "Epoch 1312/2000, Train Loss: 1.5261, Test Loss: 1.5254\n",
      "Epoch 1313/2000, Train Loss: 1.5259, Test Loss: 1.5215\n",
      "Epoch 1314/2000, Train Loss: 1.5261, Test Loss: 1.5257\n",
      "Epoch 1315/2000, Train Loss: 1.5267, Test Loss: 1.5244\n",
      "Epoch 1316/2000, Train Loss: 1.5270, Test Loss: 1.5309\n",
      "Epoch 1317/2000, Train Loss: 1.5262, Test Loss: 1.5220\n",
      "Epoch 1318/2000, Train Loss: 1.5269, Test Loss: 1.5250\n",
      "Epoch 1319/2000, Train Loss: 1.5258, Test Loss: 1.5267\n",
      "Epoch 1320/2000, Train Loss: 1.5263, Test Loss: 1.5304\n",
      "Epoch 1321/2000, Train Loss: 1.5268, Test Loss: 1.5221\n",
      "Epoch 1322/2000, Train Loss: 1.5271, Test Loss: 1.5264\n",
      "Epoch 1323/2000, Train Loss: 1.5264, Test Loss: 1.5232\n",
      "Epoch 1324/2000, Train Loss: 1.5263, Test Loss: 1.5242\n",
      "Epoch 1325/2000, Train Loss: 1.5259, Test Loss: 1.5222\n",
      "Epoch 1326/2000, Train Loss: 1.5262, Test Loss: 1.5291\n",
      "Epoch 1327/2000, Train Loss: 1.5259, Test Loss: 1.5220\n",
      "Epoch 1328/2000, Train Loss: 1.5266, Test Loss: 1.5267\n",
      "Epoch 1329/2000, Train Loss: 1.5263, Test Loss: 1.5245\n",
      "Epoch 1330/2000, Train Loss: 1.5267, Test Loss: 1.5279\n",
      "Epoch 1331/2000, Train Loss: 1.5252, Test Loss: 1.5270\n",
      "Epoch 1332/2000, Train Loss: 1.5265, Test Loss: 1.5284\n",
      "Epoch 1333/2000, Train Loss: 1.5270, Test Loss: 1.5259\n",
      "Epoch 1334/2000, Train Loss: 1.5263, Test Loss: 1.5222\n",
      "Epoch 1335/2000, Train Loss: 1.5266, Test Loss: 1.5286\n",
      "Epoch 1336/2000, Train Loss: 1.5266, Test Loss: 1.5233\n",
      "Epoch 1337/2000, Train Loss: 1.5262, Test Loss: 1.5227\n",
      "Epoch 1338/2000, Train Loss: 1.5269, Test Loss: 1.5193\n",
      "Epoch 1339/2000, Train Loss: 1.5261, Test Loss: 1.5301\n",
      "Epoch 1340/2000, Train Loss: 1.5259, Test Loss: 1.5198\n",
      "Epoch 1341/2000, Train Loss: 1.5266, Test Loss: 1.5204\n",
      "Epoch 1342/2000, Train Loss: 1.5261, Test Loss: 1.5222\n",
      "Epoch 1343/2000, Train Loss: 1.5263, Test Loss: 1.5214\n",
      "Epoch 1344/2000, Train Loss: 1.5265, Test Loss: 1.5205\n",
      "Epoch 1345/2000, Train Loss: 1.5255, Test Loss: 1.5193\n",
      "Epoch 1346/2000, Train Loss: 1.5262, Test Loss: 1.5329\n",
      "Epoch 1347/2000, Train Loss: 1.5264, Test Loss: 1.5239\n",
      "Epoch 1348/2000, Train Loss: 1.5257, Test Loss: 1.5216\n",
      "Epoch 1349/2000, Train Loss: 1.5262, Test Loss: 1.5237\n",
      "Epoch 1350/2000, Train Loss: 1.5270, Test Loss: 1.5231\n",
      "Epoch 1351/2000, Train Loss: 1.5258, Test Loss: 1.5293\n",
      "Epoch 1352/2000, Train Loss: 1.5262, Test Loss: 1.5249\n",
      "Epoch 1353/2000, Train Loss: 1.5260, Test Loss: 1.5240\n",
      "Epoch 1354/2000, Train Loss: 1.5270, Test Loss: 1.5210\n",
      "Epoch 1355/2000, Train Loss: 1.5260, Test Loss: 1.5219\n",
      "Epoch 1356/2000, Train Loss: 1.5265, Test Loss: 1.5255\n",
      "Epoch 1357/2000, Train Loss: 1.5263, Test Loss: 1.5217\n",
      "Epoch 1358/2000, Train Loss: 1.5267, Test Loss: 1.5252\n",
      "Epoch 1359/2000, Train Loss: 1.5259, Test Loss: 1.5283\n",
      "Epoch 1360/2000, Train Loss: 1.5262, Test Loss: 1.5216\n",
      "Epoch 1361/2000, Train Loss: 1.5258, Test Loss: 1.5173\n",
      "Epoch 1362/2000, Train Loss: 1.5258, Test Loss: 1.5218\n",
      "Epoch 1363/2000, Train Loss: 1.5272, Test Loss: 1.5241\n",
      "Epoch 1364/2000, Train Loss: 1.5261, Test Loss: 1.5245\n",
      "Epoch 1365/2000, Train Loss: 1.5263, Test Loss: 1.5250\n",
      "Epoch 1366/2000, Train Loss: 1.5267, Test Loss: 1.5226\n",
      "Epoch 1367/2000, Train Loss: 1.5271, Test Loss: 1.5256\n",
      "Epoch 1368/2000, Train Loss: 1.5268, Test Loss: 1.5296\n",
      "Epoch 1369/2000, Train Loss: 1.5265, Test Loss: 1.5215\n",
      "Epoch 1370/2000, Train Loss: 1.5267, Test Loss: 1.5259\n",
      "Epoch 1371/2000, Train Loss: 1.5259, Test Loss: 1.5232\n",
      "Epoch 1372/2000, Train Loss: 1.5264, Test Loss: 1.5232\n",
      "Epoch 1373/2000, Train Loss: 1.5264, Test Loss: 1.5182\n",
      "Epoch 1374/2000, Train Loss: 1.5260, Test Loss: 1.5227\n",
      "Epoch 1375/2000, Train Loss: 1.5265, Test Loss: 1.5270\n",
      "Epoch 1376/2000, Train Loss: 1.5265, Test Loss: 1.5228\n",
      "Epoch 1377/2000, Train Loss: 1.5261, Test Loss: 1.5239\n",
      "Epoch 1378/2000, Train Loss: 1.5264, Test Loss: 1.5266\n",
      "Epoch 1379/2000, Train Loss: 1.5264, Test Loss: 1.5266\n",
      "Epoch 1380/2000, Train Loss: 1.5266, Test Loss: 1.5232\n",
      "Epoch 1381/2000, Train Loss: 1.5263, Test Loss: 1.5249\n",
      "Epoch 1382/2000, Train Loss: 1.5272, Test Loss: 1.5245\n",
      "Epoch 1383/2000, Train Loss: 1.5266, Test Loss: 1.5204\n",
      "Epoch 1384/2000, Train Loss: 1.5257, Test Loss: 1.5240\n",
      "Epoch 1385/2000, Train Loss: 1.5260, Test Loss: 1.5264\n",
      "Epoch 1386/2000, Train Loss: 1.5266, Test Loss: 1.5221\n",
      "Epoch 1387/2000, Train Loss: 1.5260, Test Loss: 1.5218\n",
      "Epoch 1388/2000, Train Loss: 1.5263, Test Loss: 1.5238\n",
      "Epoch 1389/2000, Train Loss: 1.5277, Test Loss: 1.5241\n",
      "Epoch 1390/2000, Train Loss: 1.5260, Test Loss: 1.5248\n",
      "Epoch 1391/2000, Train Loss: 1.5260, Test Loss: 1.5200\n",
      "Epoch 1392/2000, Train Loss: 1.5259, Test Loss: 1.5261\n",
      "Epoch 1393/2000, Train Loss: 1.5258, Test Loss: 1.5295\n",
      "Epoch 1394/2000, Train Loss: 1.5257, Test Loss: 1.5286\n",
      "Epoch 1395/2000, Train Loss: 1.5263, Test Loss: 1.5270\n",
      "Epoch 1396/2000, Train Loss: 1.5263, Test Loss: 1.5234\n",
      "Epoch 1397/2000, Train Loss: 1.5255, Test Loss: 1.5264\n",
      "Epoch 1398/2000, Train Loss: 1.5269, Test Loss: 1.5295\n",
      "Epoch 1399/2000, Train Loss: 1.5258, Test Loss: 1.5221\n",
      "Epoch 1400/2000, Train Loss: 1.5259, Test Loss: 1.5212\n",
      "Epoch 1401/2000, Train Loss: 1.5262, Test Loss: 1.5307\n",
      "Epoch 1402/2000, Train Loss: 1.5262, Test Loss: 1.5244\n",
      "Epoch 1403/2000, Train Loss: 1.5261, Test Loss: 1.5207\n",
      "Epoch 1404/2000, Train Loss: 1.5263, Test Loss: 1.5188\n",
      "Epoch 1405/2000, Train Loss: 1.5261, Test Loss: 1.5213\n",
      "Epoch 1406/2000, Train Loss: 1.5271, Test Loss: 1.5210\n",
      "Epoch 1407/2000, Train Loss: 1.5257, Test Loss: 1.5275\n",
      "Epoch 1408/2000, Train Loss: 1.5260, Test Loss: 1.5260\n",
      "Epoch 1409/2000, Train Loss: 1.5258, Test Loss: 1.5241\n",
      "Epoch 1410/2000, Train Loss: 1.5269, Test Loss: 1.5212\n",
      "Epoch 1411/2000, Train Loss: 1.5262, Test Loss: 1.5191\n",
      "Epoch 1412/2000, Train Loss: 1.5258, Test Loss: 1.5235\n",
      "Epoch 1413/2000, Train Loss: 1.5262, Test Loss: 1.5208\n",
      "Epoch 1414/2000, Train Loss: 1.5261, Test Loss: 1.5239\n",
      "Epoch 1415/2000, Train Loss: 1.5258, Test Loss: 1.5203\n",
      "Epoch 1416/2000, Train Loss: 1.5262, Test Loss: 1.5277\n",
      "Epoch 1417/2000, Train Loss: 1.5265, Test Loss: 1.5279\n",
      "Epoch 1418/2000, Train Loss: 1.5256, Test Loss: 1.5229\n",
      "Epoch 1419/2000, Train Loss: 1.5261, Test Loss: 1.5323\n",
      "Epoch 1420/2000, Train Loss: 1.5267, Test Loss: 1.5229\n",
      "Epoch 1421/2000, Train Loss: 1.5266, Test Loss: 1.5213\n",
      "Epoch 1422/2000, Train Loss: 1.5265, Test Loss: 1.5223\n",
      "Epoch 1423/2000, Train Loss: 1.5273, Test Loss: 1.5256\n",
      "Epoch 1424/2000, Train Loss: 1.5264, Test Loss: 1.5266\n",
      "Epoch 1425/2000, Train Loss: 1.5265, Test Loss: 1.5248\n",
      "Epoch 1426/2000, Train Loss: 1.5256, Test Loss: 1.5242\n",
      "Epoch 1427/2000, Train Loss: 1.5263, Test Loss: 1.5266\n",
      "Epoch 1428/2000, Train Loss: 1.5264, Test Loss: 1.5318\n",
      "Epoch 1429/2000, Train Loss: 1.5262, Test Loss: 1.5250\n",
      "Epoch 1430/2000, Train Loss: 1.5259, Test Loss: 1.5215\n",
      "Epoch 1431/2000, Train Loss: 1.5263, Test Loss: 1.5224\n",
      "Epoch 1432/2000, Train Loss: 1.5264, Test Loss: 1.5233\n",
      "Epoch 1433/2000, Train Loss: 1.5261, Test Loss: 1.5266\n",
      "Epoch 1434/2000, Train Loss: 1.5262, Test Loss: 1.5259\n",
      "Epoch 1435/2000, Train Loss: 1.5256, Test Loss: 1.5253\n",
      "Epoch 1436/2000, Train Loss: 1.5264, Test Loss: 1.5277\n",
      "Epoch 1437/2000, Train Loss: 1.5256, Test Loss: 1.5232\n",
      "Epoch 1438/2000, Train Loss: 1.5254, Test Loss: 1.5235\n",
      "Epoch 1439/2000, Train Loss: 1.5272, Test Loss: 1.5282\n",
      "Epoch 1440/2000, Train Loss: 1.5258, Test Loss: 1.5249\n",
      "Epoch 1441/2000, Train Loss: 1.5257, Test Loss: 1.5275\n",
      "Epoch 1442/2000, Train Loss: 1.5264, Test Loss: 1.5275\n",
      "Epoch 1443/2000, Train Loss: 1.5261, Test Loss: 1.5220\n",
      "Epoch 1444/2000, Train Loss: 1.5260, Test Loss: 1.5249\n",
      "Epoch 1445/2000, Train Loss: 1.5260, Test Loss: 1.5233\n",
      "Epoch 1446/2000, Train Loss: 1.5258, Test Loss: 1.5248\n",
      "Epoch 1447/2000, Train Loss: 1.5265, Test Loss: 1.5237\n",
      "Epoch 1448/2000, Train Loss: 1.5257, Test Loss: 1.5232\n",
      "Epoch 1449/2000, Train Loss: 1.5260, Test Loss: 1.5221\n",
      "Epoch 1450/2000, Train Loss: 1.5259, Test Loss: 1.5230\n",
      "Epoch 1451/2000, Train Loss: 1.5268, Test Loss: 1.5305\n",
      "Epoch 1452/2000, Train Loss: 1.5267, Test Loss: 1.5254\n",
      "Epoch 1453/2000, Train Loss: 1.5268, Test Loss: 1.5217\n",
      "Epoch 1454/2000, Train Loss: 1.5258, Test Loss: 1.5255\n",
      "Epoch 1455/2000, Train Loss: 1.5256, Test Loss: 1.5256\n",
      "Epoch 1456/2000, Train Loss: 1.5257, Test Loss: 1.5252\n",
      "Epoch 1457/2000, Train Loss: 1.5257, Test Loss: 1.5228\n",
      "Epoch 1458/2000, Train Loss: 1.5259, Test Loss: 1.5256\n",
      "Epoch 1459/2000, Train Loss: 1.5261, Test Loss: 1.5293\n",
      "Epoch 1460/2000, Train Loss: 1.5259, Test Loss: 1.5238\n",
      "Epoch 1461/2000, Train Loss: 1.5261, Test Loss: 1.5229\n",
      "Epoch 1462/2000, Train Loss: 1.5259, Test Loss: 1.5250\n",
      "Epoch 1463/2000, Train Loss: 1.5263, Test Loss: 1.5284\n",
      "Epoch 1464/2000, Train Loss: 1.5256, Test Loss: 1.5238\n",
      "Epoch 1465/2000, Train Loss: 1.5255, Test Loss: 1.5261\n",
      "Epoch 1466/2000, Train Loss: 1.5258, Test Loss: 1.5255\n",
      "Epoch 1467/2000, Train Loss: 1.5262, Test Loss: 1.5300\n",
      "Epoch 1468/2000, Train Loss: 1.5266, Test Loss: 1.5267\n",
      "Epoch 1469/2000, Train Loss: 1.5258, Test Loss: 1.5241\n",
      "Epoch 1470/2000, Train Loss: 1.5264, Test Loss: 1.5244\n",
      "Epoch 1471/2000, Train Loss: 1.5269, Test Loss: 1.5237\n",
      "Epoch 1472/2000, Train Loss: 1.5259, Test Loss: 1.5210\n",
      "Epoch 1473/2000, Train Loss: 1.5257, Test Loss: 1.5241\n",
      "Epoch 1474/2000, Train Loss: 1.5261, Test Loss: 1.5214\n",
      "Epoch 1475/2000, Train Loss: 1.5257, Test Loss: 1.5269\n",
      "Epoch 1476/2000, Train Loss: 1.5260, Test Loss: 1.5264\n",
      "Epoch 1477/2000, Train Loss: 1.5258, Test Loss: 1.5263\n",
      "Epoch 1478/2000, Train Loss: 1.5259, Test Loss: 1.5249\n",
      "Epoch 1479/2000, Train Loss: 1.5259, Test Loss: 1.5242\n",
      "Epoch 1480/2000, Train Loss: 1.5269, Test Loss: 1.5275\n",
      "Epoch 1481/2000, Train Loss: 1.5259, Test Loss: 1.5225\n",
      "Epoch 1482/2000, Train Loss: 1.5261, Test Loss: 1.5252\n",
      "Epoch 1483/2000, Train Loss: 1.5256, Test Loss: 1.5216\n",
      "Epoch 1484/2000, Train Loss: 1.5259, Test Loss: 1.5249\n",
      "Epoch 1485/2000, Train Loss: 1.5264, Test Loss: 1.5202\n",
      "Epoch 1486/2000, Train Loss: 1.5257, Test Loss: 1.5253\n",
      "Epoch 1487/2000, Train Loss: 1.5266, Test Loss: 1.5210\n",
      "Epoch 1488/2000, Train Loss: 1.5262, Test Loss: 1.5261\n",
      "Epoch 1489/2000, Train Loss: 1.5255, Test Loss: 1.5250\n",
      "Epoch 1490/2000, Train Loss: 1.5260, Test Loss: 1.5281\n",
      "Epoch 1491/2000, Train Loss: 1.5264, Test Loss: 1.5224\n",
      "Epoch 1492/2000, Train Loss: 1.5261, Test Loss: 1.5215\n",
      "Epoch 1493/2000, Train Loss: 1.5262, Test Loss: 1.5326\n",
      "Epoch 1494/2000, Train Loss: 1.5254, Test Loss: 1.5213\n",
      "Epoch 1495/2000, Train Loss: 1.5262, Test Loss: 1.5257\n",
      "Epoch 1496/2000, Train Loss: 1.5259, Test Loss: 1.5259\n",
      "Epoch 1497/2000, Train Loss: 1.5268, Test Loss: 1.5237\n",
      "Epoch 1498/2000, Train Loss: 1.5253, Test Loss: 1.5220\n",
      "Epoch 1499/2000, Train Loss: 1.5258, Test Loss: 1.5227\n",
      "Epoch 1500/2000, Train Loss: 1.5260, Test Loss: 1.5283\n",
      "Epoch 1501/2000, Train Loss: 1.5260, Test Loss: 1.5213\n",
      "Epoch 1502/2000, Train Loss: 1.5258, Test Loss: 1.5243\n",
      "Epoch 1503/2000, Train Loss: 1.5253, Test Loss: 1.5260\n",
      "Epoch 1504/2000, Train Loss: 1.5262, Test Loss: 1.5223\n",
      "Epoch 1505/2000, Train Loss: 1.5263, Test Loss: 1.5245\n",
      "Epoch 1506/2000, Train Loss: 1.5260, Test Loss: 1.5230\n",
      "Epoch 1507/2000, Train Loss: 1.5259, Test Loss: 1.5216\n",
      "Epoch 1508/2000, Train Loss: 1.5263, Test Loss: 1.5280\n",
      "Epoch 1509/2000, Train Loss: 1.5254, Test Loss: 1.5237\n",
      "Epoch 1510/2000, Train Loss: 1.5257, Test Loss: 1.5220\n",
      "Epoch 1511/2000, Train Loss: 1.5259, Test Loss: 1.5264\n",
      "Epoch 1512/2000, Train Loss: 1.5258, Test Loss: 1.5262\n",
      "Epoch 1513/2000, Train Loss: 1.5257, Test Loss: 1.5216\n",
      "Epoch 1514/2000, Train Loss: 1.5257, Test Loss: 1.5239\n",
      "Epoch 1515/2000, Train Loss: 1.5261, Test Loss: 1.5249\n",
      "Epoch 1516/2000, Train Loss: 1.5269, Test Loss: 1.5269\n",
      "Epoch 1517/2000, Train Loss: 1.5259, Test Loss: 1.5222\n",
      "Epoch 1518/2000, Train Loss: 1.5256, Test Loss: 1.5256\n",
      "Epoch 1519/2000, Train Loss: 1.5261, Test Loss: 1.5258\n",
      "Epoch 1520/2000, Train Loss: 1.5254, Test Loss: 1.5238\n",
      "Epoch 1521/2000, Train Loss: 1.5253, Test Loss: 1.5295\n",
      "Epoch 1522/2000, Train Loss: 1.5270, Test Loss: 1.5289\n",
      "Epoch 1523/2000, Train Loss: 1.5265, Test Loss: 1.5227\n",
      "Epoch 1524/2000, Train Loss: 1.5259, Test Loss: 1.5244\n",
      "Epoch 1525/2000, Train Loss: 1.5258, Test Loss: 1.5279\n",
      "Epoch 1526/2000, Train Loss: 1.5264, Test Loss: 1.5275\n",
      "Epoch 1527/2000, Train Loss: 1.5263, Test Loss: 1.5234\n",
      "Epoch 1528/2000, Train Loss: 1.5260, Test Loss: 1.5246\n",
      "Epoch 1529/2000, Train Loss: 1.5259, Test Loss: 1.5258\n",
      "Epoch 1530/2000, Train Loss: 1.5253, Test Loss: 1.5276\n",
      "Epoch 1531/2000, Train Loss: 1.5256, Test Loss: 1.5279\n",
      "Epoch 1532/2000, Train Loss: 1.5253, Test Loss: 1.5266\n",
      "Epoch 1533/2000, Train Loss: 1.5254, Test Loss: 1.5306\n",
      "Epoch 1534/2000, Train Loss: 1.5255, Test Loss: 1.5206\n",
      "Epoch 1535/2000, Train Loss: 1.5254, Test Loss: 1.5194\n",
      "Epoch 1536/2000, Train Loss: 1.5258, Test Loss: 1.5263\n",
      "Epoch 1537/2000, Train Loss: 1.5256, Test Loss: 1.5280\n",
      "Epoch 1538/2000, Train Loss: 1.5261, Test Loss: 1.5267\n",
      "Epoch 1539/2000, Train Loss: 1.5269, Test Loss: 1.5243\n",
      "Epoch 1540/2000, Train Loss: 1.5257, Test Loss: 1.5366\n",
      "Epoch 1541/2000, Train Loss: 1.5257, Test Loss: 1.5243\n",
      "Epoch 1542/2000, Train Loss: 1.5258, Test Loss: 1.5238\n",
      "Epoch 1543/2000, Train Loss: 1.5260, Test Loss: 1.5270\n",
      "Epoch 1544/2000, Train Loss: 1.5256, Test Loss: 1.5290\n",
      "Epoch 1545/2000, Train Loss: 1.5260, Test Loss: 1.5223\n",
      "Epoch 1546/2000, Train Loss: 1.5258, Test Loss: 1.5207\n",
      "Epoch 1547/2000, Train Loss: 1.5258, Test Loss: 1.5225\n",
      "Epoch 1548/2000, Train Loss: 1.5259, Test Loss: 1.5176\n",
      "Epoch 1549/2000, Train Loss: 1.5255, Test Loss: 1.5290\n",
      "Epoch 1550/2000, Train Loss: 1.5259, Test Loss: 1.5254\n",
      "Epoch 1551/2000, Train Loss: 1.5257, Test Loss: 1.5264\n",
      "Epoch 1552/2000, Train Loss: 1.5252, Test Loss: 1.5235\n",
      "Epoch 1553/2000, Train Loss: 1.5265, Test Loss: 1.5245\n",
      "Epoch 1554/2000, Train Loss: 1.5272, Test Loss: 1.5248\n",
      "Epoch 1555/2000, Train Loss: 1.5266, Test Loss: 1.5196\n",
      "Epoch 1556/2000, Train Loss: 1.5257, Test Loss: 1.5227\n",
      "Epoch 1557/2000, Train Loss: 1.5259, Test Loss: 1.5255\n",
      "Epoch 1558/2000, Train Loss: 1.5258, Test Loss: 1.5246\n",
      "Epoch 1559/2000, Train Loss: 1.5261, Test Loss: 1.5254\n",
      "Epoch 1560/2000, Train Loss: 1.5264, Test Loss: 1.5310\n",
      "Epoch 1561/2000, Train Loss: 1.5268, Test Loss: 1.5247\n",
      "Epoch 1562/2000, Train Loss: 1.5253, Test Loss: 1.5233\n",
      "Epoch 1563/2000, Train Loss: 1.5258, Test Loss: 1.5238\n",
      "Epoch 1564/2000, Train Loss: 1.5261, Test Loss: 1.5219\n",
      "Epoch 1565/2000, Train Loss: 1.5259, Test Loss: 1.5306\n",
      "Epoch 1566/2000, Train Loss: 1.5254, Test Loss: 1.5240\n",
      "Epoch 1567/2000, Train Loss: 1.5265, Test Loss: 1.5243\n",
      "Epoch 1568/2000, Train Loss: 1.5257, Test Loss: 1.5240\n",
      "Epoch 1569/2000, Train Loss: 1.5263, Test Loss: 1.5216\n",
      "Epoch 1570/2000, Train Loss: 1.5265, Test Loss: 1.5264\n",
      "Epoch 1571/2000, Train Loss: 1.5264, Test Loss: 1.5254\n",
      "Epoch 1572/2000, Train Loss: 1.5267, Test Loss: 1.5311\n",
      "Epoch 1573/2000, Train Loss: 1.5255, Test Loss: 1.5222\n",
      "Epoch 1574/2000, Train Loss: 1.5254, Test Loss: 1.5228\n",
      "Epoch 1575/2000, Train Loss: 1.5261, Test Loss: 1.5224\n",
      "Epoch 1576/2000, Train Loss: 1.5254, Test Loss: 1.5236\n",
      "Epoch 1577/2000, Train Loss: 1.5256, Test Loss: 1.5206\n",
      "Epoch 1578/2000, Train Loss: 1.5263, Test Loss: 1.5278\n",
      "Epoch 1579/2000, Train Loss: 1.5258, Test Loss: 1.5298\n",
      "Epoch 1580/2000, Train Loss: 1.5259, Test Loss: 1.5211\n",
      "Epoch 1581/2000, Train Loss: 1.5265, Test Loss: 1.5201\n",
      "Epoch 1582/2000, Train Loss: 1.5260, Test Loss: 1.5227\n",
      "Epoch 1583/2000, Train Loss: 1.5264, Test Loss: 1.5216\n",
      "Epoch 1584/2000, Train Loss: 1.5258, Test Loss: 1.5289\n",
      "Epoch 1585/2000, Train Loss: 1.5255, Test Loss: 1.5295\n",
      "Epoch 1586/2000, Train Loss: 1.5253, Test Loss: 1.5209\n",
      "Epoch 1587/2000, Train Loss: 1.5259, Test Loss: 1.5293\n",
      "Epoch 1588/2000, Train Loss: 1.5266, Test Loss: 1.5223\n",
      "Epoch 1589/2000, Train Loss: 1.5257, Test Loss: 1.5252\n",
      "Epoch 1590/2000, Train Loss: 1.5257, Test Loss: 1.5260\n",
      "Epoch 1591/2000, Train Loss: 1.5258, Test Loss: 1.5257\n",
      "Epoch 1592/2000, Train Loss: 1.5258, Test Loss: 1.5233\n",
      "Epoch 1593/2000, Train Loss: 1.5252, Test Loss: 1.5205\n",
      "Epoch 1594/2000, Train Loss: 1.5263, Test Loss: 1.5219\n",
      "Epoch 1595/2000, Train Loss: 1.5255, Test Loss: 1.5206\n",
      "Epoch 1596/2000, Train Loss: 1.5260, Test Loss: 1.5240\n",
      "Epoch 1597/2000, Train Loss: 1.5257, Test Loss: 1.5246\n",
      "Epoch 1598/2000, Train Loss: 1.5260, Test Loss: 1.5264\n",
      "Epoch 1599/2000, Train Loss: 1.5267, Test Loss: 1.5230\n",
      "Epoch 1600/2000, Train Loss: 1.5263, Test Loss: 1.5206\n",
      "Epoch 1601/2000, Train Loss: 1.5254, Test Loss: 1.5274\n",
      "Epoch 1602/2000, Train Loss: 1.5267, Test Loss: 1.5244\n",
      "Epoch 1603/2000, Train Loss: 1.5256, Test Loss: 1.5304\n",
      "Epoch 1604/2000, Train Loss: 1.5250, Test Loss: 1.5223\n",
      "Epoch 1605/2000, Train Loss: 1.5254, Test Loss: 1.5252\n",
      "Epoch 1606/2000, Train Loss: 1.5264, Test Loss: 1.5238\n",
      "Epoch 1607/2000, Train Loss: 1.5254, Test Loss: 1.5219\n",
      "Epoch 1608/2000, Train Loss: 1.5265, Test Loss: 1.5245\n",
      "Epoch 1609/2000, Train Loss: 1.5262, Test Loss: 1.5319\n",
      "Epoch 1610/2000, Train Loss: 1.5262, Test Loss: 1.5240\n",
      "Epoch 1611/2000, Train Loss: 1.5257, Test Loss: 1.5216\n",
      "Epoch 1612/2000, Train Loss: 1.5256, Test Loss: 1.5222\n",
      "Epoch 1613/2000, Train Loss: 1.5257, Test Loss: 1.5240\n",
      "Epoch 1614/2000, Train Loss: 1.5261, Test Loss: 1.5254\n",
      "Epoch 1615/2000, Train Loss: 1.5270, Test Loss: 1.5227\n",
      "Epoch 1616/2000, Train Loss: 1.5251, Test Loss: 1.5234\n",
      "Epoch 1617/2000, Train Loss: 1.5258, Test Loss: 1.5269\n",
      "Epoch 1618/2000, Train Loss: 1.5254, Test Loss: 1.5313\n",
      "Epoch 1619/2000, Train Loss: 1.5254, Test Loss: 1.5231\n",
      "Epoch 1620/2000, Train Loss: 1.5261, Test Loss: 1.5254\n",
      "Epoch 1621/2000, Train Loss: 1.5252, Test Loss: 1.5317\n",
      "Epoch 1622/2000, Train Loss: 1.5256, Test Loss: 1.5286\n",
      "Epoch 1623/2000, Train Loss: 1.5251, Test Loss: 1.5250\n",
      "Epoch 1624/2000, Train Loss: 1.5258, Test Loss: 1.5249\n",
      "Epoch 1625/2000, Train Loss: 1.5254, Test Loss: 1.5239\n",
      "Epoch 1626/2000, Train Loss: 1.5253, Test Loss: 1.5260\n",
      "Epoch 1627/2000, Train Loss: 1.5252, Test Loss: 1.5317\n",
      "Epoch 1628/2000, Train Loss: 1.5262, Test Loss: 1.5235\n",
      "Epoch 1629/2000, Train Loss: 1.5253, Test Loss: 1.5250\n",
      "Epoch 1630/2000, Train Loss: 1.5253, Test Loss: 1.5278\n",
      "Epoch 1631/2000, Train Loss: 1.5255, Test Loss: 1.5251\n",
      "Epoch 1632/2000, Train Loss: 1.5261, Test Loss: 1.5218\n",
      "Epoch 1633/2000, Train Loss: 1.5254, Test Loss: 1.5216\n",
      "Epoch 1634/2000, Train Loss: 1.5258, Test Loss: 1.5252\n",
      "Epoch 1635/2000, Train Loss: 1.5258, Test Loss: 1.5246\n",
      "Epoch 1636/2000, Train Loss: 1.5258, Test Loss: 1.5374\n",
      "Epoch 1637/2000, Train Loss: 1.5267, Test Loss: 1.5207\n",
      "Epoch 1638/2000, Train Loss: 1.5256, Test Loss: 1.5355\n",
      "Epoch 1639/2000, Train Loss: 1.5256, Test Loss: 1.5227\n",
      "Epoch 1640/2000, Train Loss: 1.5257, Test Loss: 1.5236\n",
      "Epoch 1641/2000, Train Loss: 1.5250, Test Loss: 1.5235\n",
      "Epoch 1642/2000, Train Loss: 1.5258, Test Loss: 1.5219\n",
      "Epoch 1643/2000, Train Loss: 1.5255, Test Loss: 1.5277\n",
      "Epoch 1644/2000, Train Loss: 1.5255, Test Loss: 1.5287\n",
      "Epoch 1645/2000, Train Loss: 1.5260, Test Loss: 1.5260\n",
      "Epoch 1646/2000, Train Loss: 1.5252, Test Loss: 1.5243\n",
      "Epoch 1647/2000, Train Loss: 1.5256, Test Loss: 1.5339\n",
      "Epoch 1648/2000, Train Loss: 1.5262, Test Loss: 1.5237\n",
      "Epoch 1649/2000, Train Loss: 1.5260, Test Loss: 1.5225\n",
      "Epoch 1650/2000, Train Loss: 1.5253, Test Loss: 1.5284\n",
      "Epoch 1651/2000, Train Loss: 1.5257, Test Loss: 1.5205\n",
      "Epoch 1652/2000, Train Loss: 1.5258, Test Loss: 1.5307\n",
      "Epoch 1653/2000, Train Loss: 1.5258, Test Loss: 1.5229\n",
      "Epoch 1654/2000, Train Loss: 1.5256, Test Loss: 1.5250\n",
      "Epoch 1655/2000, Train Loss: 1.5252, Test Loss: 1.5261\n",
      "Epoch 1656/2000, Train Loss: 1.5262, Test Loss: 1.5238\n",
      "Epoch 1657/2000, Train Loss: 1.5258, Test Loss: 1.5279\n",
      "Epoch 1658/2000, Train Loss: 1.5255, Test Loss: 1.5241\n",
      "Epoch 1659/2000, Train Loss: 1.5259, Test Loss: 1.5229\n",
      "Epoch 1660/2000, Train Loss: 1.5260, Test Loss: 1.5257\n",
      "Epoch 1661/2000, Train Loss: 1.5261, Test Loss: 1.5231\n",
      "Epoch 1662/2000, Train Loss: 1.5258, Test Loss: 1.5303\n",
      "Epoch 1663/2000, Train Loss: 1.5254, Test Loss: 1.5228\n",
      "Epoch 1664/2000, Train Loss: 1.5251, Test Loss: 1.5201\n",
      "Epoch 1665/2000, Train Loss: 1.5258, Test Loss: 1.5248\n",
      "Epoch 1666/2000, Train Loss: 1.5257, Test Loss: 1.5248\n",
      "Epoch 1667/2000, Train Loss: 1.5254, Test Loss: 1.5221\n",
      "Epoch 1668/2000, Train Loss: 1.5255, Test Loss: 1.5212\n",
      "Epoch 1669/2000, Train Loss: 1.5259, Test Loss: 1.5224\n",
      "Epoch 1670/2000, Train Loss: 1.5261, Test Loss: 1.5199\n",
      "Epoch 1671/2000, Train Loss: 1.5256, Test Loss: 1.5368\n",
      "Epoch 1672/2000, Train Loss: 1.5253, Test Loss: 1.5205\n",
      "Epoch 1673/2000, Train Loss: 1.5257, Test Loss: 1.5221\n",
      "Epoch 1674/2000, Train Loss: 1.5257, Test Loss: 1.5216\n",
      "Epoch 1675/2000, Train Loss: 1.5261, Test Loss: 1.5256\n",
      "Epoch 1676/2000, Train Loss: 1.5251, Test Loss: 1.5233\n",
      "Epoch 1677/2000, Train Loss: 1.5251, Test Loss: 1.5212\n",
      "Epoch 1678/2000, Train Loss: 1.5259, Test Loss: 1.5328\n",
      "Epoch 1679/2000, Train Loss: 1.5257, Test Loss: 1.5250\n",
      "Epoch 1680/2000, Train Loss: 1.5259, Test Loss: 1.5244\n",
      "Epoch 1681/2000, Train Loss: 1.5263, Test Loss: 1.5233\n",
      "Epoch 1682/2000, Train Loss: 1.5255, Test Loss: 1.5252\n",
      "Epoch 1683/2000, Train Loss: 1.5255, Test Loss: 1.5243\n",
      "Epoch 1684/2000, Train Loss: 1.5268, Test Loss: 1.5215\n",
      "Epoch 1685/2000, Train Loss: 1.5259, Test Loss: 1.5310\n",
      "Epoch 1686/2000, Train Loss: 1.5260, Test Loss: 1.5231\n",
      "Epoch 1687/2000, Train Loss: 1.5260, Test Loss: 1.5299\n",
      "Epoch 1688/2000, Train Loss: 1.5255, Test Loss: 1.5283\n",
      "Epoch 1689/2000, Train Loss: 1.5253, Test Loss: 1.5232\n",
      "Epoch 1690/2000, Train Loss: 1.5263, Test Loss: 1.5273\n",
      "Epoch 1691/2000, Train Loss: 1.5260, Test Loss: 1.5210\n",
      "Epoch 1692/2000, Train Loss: 1.5256, Test Loss: 1.5283\n",
      "Epoch 1693/2000, Train Loss: 1.5252, Test Loss: 1.5199\n",
      "Epoch 1694/2000, Train Loss: 1.5257, Test Loss: 1.5194\n",
      "Epoch 1695/2000, Train Loss: 1.5265, Test Loss: 1.5294\n",
      "Epoch 1696/2000, Train Loss: 1.5258, Test Loss: 1.5262\n",
      "Epoch 1697/2000, Train Loss: 1.5263, Test Loss: 1.5217\n",
      "Epoch 1698/2000, Train Loss: 1.5258, Test Loss: 1.5226\n",
      "Epoch 1699/2000, Train Loss: 1.5254, Test Loss: 1.5273\n",
      "Epoch 1700/2000, Train Loss: 1.5254, Test Loss: 1.5173\n",
      "Epoch 1701/2000, Train Loss: 1.5257, Test Loss: 1.5212\n",
      "Epoch 1702/2000, Train Loss: 1.5259, Test Loss: 1.5185\n",
      "Epoch 1703/2000, Train Loss: 1.5252, Test Loss: 1.5235\n",
      "Epoch 1704/2000, Train Loss: 1.5258, Test Loss: 1.5274\n",
      "Epoch 1705/2000, Train Loss: 1.5252, Test Loss: 1.5262\n",
      "Epoch 1706/2000, Train Loss: 1.5260, Test Loss: 1.5220\n",
      "Epoch 1707/2000, Train Loss: 1.5258, Test Loss: 1.5289\n",
      "Epoch 1708/2000, Train Loss: 1.5261, Test Loss: 1.5253\n",
      "Epoch 1709/2000, Train Loss: 1.5254, Test Loss: 1.5263\n",
      "Epoch 1710/2000, Train Loss: 1.5260, Test Loss: 1.5216\n",
      "Epoch 1711/2000, Train Loss: 1.5260, Test Loss: 1.5266\n",
      "Epoch 1712/2000, Train Loss: 1.5270, Test Loss: 1.5252\n",
      "Epoch 1713/2000, Train Loss: 1.5254, Test Loss: 1.5291\n",
      "Epoch 1714/2000, Train Loss: 1.5256, Test Loss: 1.5245\n",
      "Epoch 1715/2000, Train Loss: 1.5255, Test Loss: 1.5221\n",
      "Epoch 1716/2000, Train Loss: 1.5256, Test Loss: 1.5240\n",
      "Epoch 1717/2000, Train Loss: 1.5258, Test Loss: 1.5207\n",
      "Epoch 1718/2000, Train Loss: 1.5258, Test Loss: 1.5219\n",
      "Epoch 1719/2000, Train Loss: 1.5260, Test Loss: 1.5252\n",
      "Epoch 1720/2000, Train Loss: 1.5253, Test Loss: 1.5247\n",
      "Epoch 1721/2000, Train Loss: 1.5266, Test Loss: 1.5206\n",
      "Epoch 1722/2000, Train Loss: 1.5262, Test Loss: 1.5237\n",
      "Epoch 1723/2000, Train Loss: 1.5255, Test Loss: 1.5227\n",
      "Epoch 1724/2000, Train Loss: 1.5251, Test Loss: 1.5348\n",
      "Epoch 1725/2000, Train Loss: 1.5253, Test Loss: 1.5270\n",
      "Epoch 1726/2000, Train Loss: 1.5260, Test Loss: 1.5249\n",
      "Epoch 1727/2000, Train Loss: 1.5258, Test Loss: 1.5212\n",
      "Epoch 1728/2000, Train Loss: 1.5257, Test Loss: 1.5198\n",
      "Epoch 1729/2000, Train Loss: 1.5265, Test Loss: 1.5228\n",
      "Epoch 1730/2000, Train Loss: 1.5253, Test Loss: 1.5282\n",
      "Epoch 1731/2000, Train Loss: 1.5257, Test Loss: 1.5256\n",
      "Epoch 1732/2000, Train Loss: 1.5253, Test Loss: 1.5227\n",
      "Epoch 1733/2000, Train Loss: 1.5250, Test Loss: 1.5235\n",
      "Epoch 1734/2000, Train Loss: 1.5253, Test Loss: 1.5269\n",
      "Epoch 1735/2000, Train Loss: 1.5249, Test Loss: 1.5258\n",
      "Epoch 1736/2000, Train Loss: 1.5259, Test Loss: 1.5207\n",
      "Epoch 1737/2000, Train Loss: 1.5255, Test Loss: 1.5232\n",
      "Epoch 1738/2000, Train Loss: 1.5257, Test Loss: 1.5232\n",
      "Epoch 1739/2000, Train Loss: 1.5260, Test Loss: 1.5241\n",
      "Epoch 1740/2000, Train Loss: 1.5259, Test Loss: 1.5250\n",
      "Epoch 1741/2000, Train Loss: 1.5256, Test Loss: 1.5225\n",
      "Epoch 1742/2000, Train Loss: 1.5255, Test Loss: 1.5305\n",
      "Epoch 1743/2000, Train Loss: 1.5256, Test Loss: 1.5292\n",
      "Epoch 1744/2000, Train Loss: 1.5256, Test Loss: 1.5238\n",
      "Epoch 1745/2000, Train Loss: 1.5261, Test Loss: 1.5230\n",
      "Epoch 1746/2000, Train Loss: 1.5260, Test Loss: 1.5281\n",
      "Epoch 1747/2000, Train Loss: 1.5254, Test Loss: 1.5232\n",
      "Epoch 1748/2000, Train Loss: 1.5252, Test Loss: 1.5209\n",
      "Epoch 1749/2000, Train Loss: 1.5254, Test Loss: 1.5203\n",
      "Epoch 1750/2000, Train Loss: 1.5250, Test Loss: 1.5283\n",
      "Epoch 1751/2000, Train Loss: 1.5257, Test Loss: 1.5238\n",
      "Epoch 1752/2000, Train Loss: 1.5255, Test Loss: 1.5234\n",
      "Epoch 1753/2000, Train Loss: 1.5254, Test Loss: 1.5216\n",
      "Epoch 1754/2000, Train Loss: 1.5261, Test Loss: 1.5238\n",
      "Epoch 1755/2000, Train Loss: 1.5255, Test Loss: 1.5256\n",
      "Epoch 1756/2000, Train Loss: 1.5257, Test Loss: 1.5258\n",
      "Epoch 1757/2000, Train Loss: 1.5254, Test Loss: 1.5233\n",
      "Epoch 1758/2000, Train Loss: 1.5257, Test Loss: 1.5254\n",
      "Epoch 1759/2000, Train Loss: 1.5250, Test Loss: 1.5238\n",
      "Epoch 1760/2000, Train Loss: 1.5256, Test Loss: 1.5266\n",
      "Epoch 1761/2000, Train Loss: 1.5256, Test Loss: 1.5246\n",
      "Epoch 1762/2000, Train Loss: 1.5257, Test Loss: 1.5252\n",
      "Epoch 1763/2000, Train Loss: 1.5257, Test Loss: 1.5275\n",
      "Epoch 1764/2000, Train Loss: 1.5254, Test Loss: 1.5265\n",
      "Epoch 1765/2000, Train Loss: 1.5251, Test Loss: 1.5234\n",
      "Epoch 1766/2000, Train Loss: 1.5257, Test Loss: 1.5242\n",
      "Epoch 1767/2000, Train Loss: 1.5258, Test Loss: 1.5220\n",
      "Epoch 1768/2000, Train Loss: 1.5254, Test Loss: 1.5258\n",
      "Epoch 1769/2000, Train Loss: 1.5261, Test Loss: 1.5241\n",
      "Epoch 1770/2000, Train Loss: 1.5251, Test Loss: 1.5223\n",
      "Epoch 1771/2000, Train Loss: 1.5256, Test Loss: 1.5227\n",
      "Epoch 1772/2000, Train Loss: 1.5251, Test Loss: 1.5311\n",
      "Epoch 1773/2000, Train Loss: 1.5263, Test Loss: 1.5249\n",
      "Epoch 1774/2000, Train Loss: 1.5262, Test Loss: 1.5197\n",
      "Epoch 1775/2000, Train Loss: 1.5251, Test Loss: 1.5209\n",
      "Epoch 1776/2000, Train Loss: 1.5258, Test Loss: 1.5265\n",
      "Epoch 1777/2000, Train Loss: 1.5261, Test Loss: 1.5235\n",
      "Epoch 1778/2000, Train Loss: 1.5261, Test Loss: 1.5198\n",
      "Epoch 1779/2000, Train Loss: 1.5252, Test Loss: 1.5260\n",
      "Epoch 1780/2000, Train Loss: 1.5248, Test Loss: 1.5261\n",
      "Epoch 1781/2000, Train Loss: 1.5258, Test Loss: 1.5213\n",
      "Epoch 1782/2000, Train Loss: 1.5252, Test Loss: 1.5235\n",
      "Epoch 1783/2000, Train Loss: 1.5264, Test Loss: 1.5269\n",
      "Epoch 1784/2000, Train Loss: 1.5251, Test Loss: 1.5302\n",
      "Epoch 1785/2000, Train Loss: 1.5261, Test Loss: 1.5225\n",
      "Epoch 1786/2000, Train Loss: 1.5254, Test Loss: 1.5225\n",
      "Epoch 1787/2000, Train Loss: 1.5258, Test Loss: 1.5229\n",
      "Epoch 1788/2000, Train Loss: 1.5254, Test Loss: 1.5260\n",
      "Epoch 1789/2000, Train Loss: 1.5262, Test Loss: 1.5220\n",
      "Epoch 1790/2000, Train Loss: 1.5255, Test Loss: 1.5254\n",
      "Epoch 1791/2000, Train Loss: 1.5261, Test Loss: 1.5192\n",
      "Epoch 1792/2000, Train Loss: 1.5255, Test Loss: 1.5250\n",
      "Epoch 1793/2000, Train Loss: 1.5250, Test Loss: 1.5268\n",
      "Epoch 1794/2000, Train Loss: 1.5257, Test Loss: 1.5299\n",
      "Epoch 1795/2000, Train Loss: 1.5263, Test Loss: 1.5206\n",
      "Epoch 1796/2000, Train Loss: 1.5250, Test Loss: 1.5225\n",
      "Epoch 1797/2000, Train Loss: 1.5257, Test Loss: 1.5273\n",
      "Epoch 1798/2000, Train Loss: 1.5258, Test Loss: 1.5250\n",
      "Epoch 1799/2000, Train Loss: 1.5253, Test Loss: 1.5358\n",
      "Epoch 1800/2000, Train Loss: 1.5254, Test Loss: 1.5234\n",
      "Epoch 1801/2000, Train Loss: 1.5259, Test Loss: 1.5275\n",
      "Epoch 1802/2000, Train Loss: 1.5263, Test Loss: 1.5231\n",
      "Epoch 1803/2000, Train Loss: 1.5255, Test Loss: 1.5221\n",
      "Epoch 1804/2000, Train Loss: 1.5254, Test Loss: 1.5234\n",
      "Epoch 1805/2000, Train Loss: 1.5252, Test Loss: 1.5196\n",
      "Epoch 1806/2000, Train Loss: 1.5258, Test Loss: 1.5201\n",
      "Epoch 1807/2000, Train Loss: 1.5255, Test Loss: 1.5193\n",
      "Epoch 1808/2000, Train Loss: 1.5254, Test Loss: 1.5298\n",
      "Epoch 1809/2000, Train Loss: 1.5253, Test Loss: 1.5251\n",
      "Epoch 1810/2000, Train Loss: 1.5255, Test Loss: 1.5207\n",
      "Epoch 1811/2000, Train Loss: 1.5254, Test Loss: 1.5236\n",
      "Epoch 1812/2000, Train Loss: 1.5253, Test Loss: 1.5212\n",
      "Epoch 1813/2000, Train Loss: 1.5255, Test Loss: 1.5263\n",
      "Epoch 1814/2000, Train Loss: 1.5265, Test Loss: 1.5211\n",
      "Epoch 1815/2000, Train Loss: 1.5256, Test Loss: 1.5259\n",
      "Epoch 1816/2000, Train Loss: 1.5263, Test Loss: 1.5224\n",
      "Epoch 1817/2000, Train Loss: 1.5250, Test Loss: 1.5396\n",
      "Epoch 1818/2000, Train Loss: 1.5252, Test Loss: 1.5237\n",
      "Epoch 1819/2000, Train Loss: 1.5258, Test Loss: 1.5234\n",
      "Epoch 1820/2000, Train Loss: 1.5255, Test Loss: 1.5246\n",
      "Epoch 1821/2000, Train Loss: 1.5254, Test Loss: 1.5268\n",
      "Epoch 1822/2000, Train Loss: 1.5260, Test Loss: 1.5260\n",
      "Epoch 1823/2000, Train Loss: 1.5259, Test Loss: 1.5248\n",
      "Epoch 1824/2000, Train Loss: 1.5253, Test Loss: 1.5224\n",
      "Epoch 1825/2000, Train Loss: 1.5253, Test Loss: 1.5253\n",
      "Epoch 1826/2000, Train Loss: 1.5253, Test Loss: 1.5234\n",
      "Epoch 1827/2000, Train Loss: 1.5253, Test Loss: 1.5228\n",
      "Epoch 1828/2000, Train Loss: 1.5253, Test Loss: 1.5237\n",
      "Epoch 1829/2000, Train Loss: 1.5253, Test Loss: 1.5253\n",
      "Epoch 1830/2000, Train Loss: 1.5256, Test Loss: 1.5219\n",
      "Epoch 1831/2000, Train Loss: 1.5259, Test Loss: 1.5255\n",
      "Epoch 1832/2000, Train Loss: 1.5269, Test Loss: 1.5208\n",
      "Epoch 1833/2000, Train Loss: 1.5260, Test Loss: 1.5235\n",
      "Epoch 1834/2000, Train Loss: 1.5252, Test Loss: 1.5240\n",
      "Epoch 1835/2000, Train Loss: 1.5250, Test Loss: 1.5215\n",
      "Epoch 1836/2000, Train Loss: 1.5251, Test Loss: 1.5254\n",
      "Epoch 1837/2000, Train Loss: 1.5255, Test Loss: 1.5273\n",
      "Epoch 1838/2000, Train Loss: 1.5256, Test Loss: 1.5195\n",
      "Epoch 1839/2000, Train Loss: 1.5261, Test Loss: 1.5240\n",
      "Epoch 1840/2000, Train Loss: 1.5258, Test Loss: 1.5236\n",
      "Epoch 1841/2000, Train Loss: 1.5250, Test Loss: 1.5252\n",
      "Epoch 1842/2000, Train Loss: 1.5253, Test Loss: 1.5290\n",
      "Epoch 1843/2000, Train Loss: 1.5268, Test Loss: 1.5266\n",
      "Epoch 1844/2000, Train Loss: 1.5259, Test Loss: 1.5232\n",
      "Epoch 1845/2000, Train Loss: 1.5265, Test Loss: 1.5256\n",
      "Epoch 1846/2000, Train Loss: 1.5257, Test Loss: 1.5215\n",
      "Epoch 1847/2000, Train Loss: 1.5255, Test Loss: 1.5221\n",
      "Epoch 1848/2000, Train Loss: 1.5249, Test Loss: 1.5210\n",
      "Epoch 1849/2000, Train Loss: 1.5255, Test Loss: 1.5265\n",
      "Epoch 1850/2000, Train Loss: 1.5254, Test Loss: 1.5204\n",
      "Epoch 1851/2000, Train Loss: 1.5252, Test Loss: 1.5311\n",
      "Epoch 1852/2000, Train Loss: 1.5256, Test Loss: 1.5246\n",
      "Epoch 1853/2000, Train Loss: 1.5256, Test Loss: 1.5262\n",
      "Epoch 1854/2000, Train Loss: 1.5261, Test Loss: 1.5246\n",
      "Epoch 1855/2000, Train Loss: 1.5257, Test Loss: 1.5181\n",
      "Epoch 1856/2000, Train Loss: 1.5254, Test Loss: 1.5230\n",
      "Epoch 1857/2000, Train Loss: 1.5257, Test Loss: 1.5232\n",
      "Epoch 1858/2000, Train Loss: 1.5256, Test Loss: 1.5247\n",
      "Epoch 1859/2000, Train Loss: 1.5250, Test Loss: 1.5304\n",
      "Epoch 1860/2000, Train Loss: 1.5256, Test Loss: 1.5250\n",
      "Epoch 1861/2000, Train Loss: 1.5252, Test Loss: 1.5218\n",
      "Epoch 1862/2000, Train Loss: 1.5253, Test Loss: 1.5231\n",
      "Epoch 1863/2000, Train Loss: 1.5252, Test Loss: 1.5245\n",
      "Epoch 1864/2000, Train Loss: 1.5253, Test Loss: 1.5260\n",
      "Epoch 1865/2000, Train Loss: 1.5254, Test Loss: 1.5251\n",
      "Epoch 1866/2000, Train Loss: 1.5265, Test Loss: 1.5223\n",
      "Epoch 1867/2000, Train Loss: 1.5257, Test Loss: 1.5291\n",
      "Epoch 1868/2000, Train Loss: 1.5247, Test Loss: 1.5263\n",
      "Epoch 1869/2000, Train Loss: 1.5259, Test Loss: 1.5283\n",
      "Epoch 1870/2000, Train Loss: 1.5257, Test Loss: 1.5239\n",
      "Epoch 1871/2000, Train Loss: 1.5253, Test Loss: 1.5259\n",
      "Epoch 1872/2000, Train Loss: 1.5252, Test Loss: 1.5252\n",
      "Epoch 1873/2000, Train Loss: 1.5251, Test Loss: 1.5224\n",
      "Epoch 1874/2000, Train Loss: 1.5252, Test Loss: 1.5257\n",
      "Epoch 1875/2000, Train Loss: 1.5258, Test Loss: 1.5253\n",
      "Epoch 1876/2000, Train Loss: 1.5249, Test Loss: 1.5273\n",
      "Epoch 1877/2000, Train Loss: 1.5263, Test Loss: 1.5231\n",
      "Epoch 1878/2000, Train Loss: 1.5251, Test Loss: 1.5236\n",
      "Epoch 1879/2000, Train Loss: 1.5256, Test Loss: 1.5252\n",
      "Epoch 1880/2000, Train Loss: 1.5251, Test Loss: 1.5275\n",
      "Epoch 1881/2000, Train Loss: 1.5258, Test Loss: 1.5242\n",
      "Epoch 1882/2000, Train Loss: 1.5255, Test Loss: 1.5248\n",
      "Epoch 1883/2000, Train Loss: 1.5252, Test Loss: 1.5239\n",
      "Epoch 1884/2000, Train Loss: 1.5255, Test Loss: 1.5213\n",
      "Epoch 1885/2000, Train Loss: 1.5253, Test Loss: 1.5245\n",
      "Epoch 1886/2000, Train Loss: 1.5255, Test Loss: 1.5238\n",
      "Epoch 1887/2000, Train Loss: 1.5254, Test Loss: 1.5231\n",
      "Epoch 1888/2000, Train Loss: 1.5253, Test Loss: 1.5276\n",
      "Epoch 1889/2000, Train Loss: 1.5255, Test Loss: 1.5252\n",
      "Epoch 1890/2000, Train Loss: 1.5252, Test Loss: 1.5238\n",
      "Epoch 1891/2000, Train Loss: 1.5255, Test Loss: 1.5239\n",
      "Epoch 1892/2000, Train Loss: 1.5259, Test Loss: 1.5197\n",
      "Epoch 1893/2000, Train Loss: 1.5254, Test Loss: 1.5212\n",
      "Epoch 1894/2000, Train Loss: 1.5252, Test Loss: 1.5227\n",
      "Epoch 1895/2000, Train Loss: 1.5253, Test Loss: 1.5245\n",
      "Epoch 1896/2000, Train Loss: 1.5260, Test Loss: 1.5233\n",
      "Epoch 1897/2000, Train Loss: 1.5267, Test Loss: 1.5263\n",
      "Epoch 1898/2000, Train Loss: 1.5257, Test Loss: 1.5236\n",
      "Epoch 1899/2000, Train Loss: 1.5253, Test Loss: 1.5221\n",
      "Epoch 1900/2000, Train Loss: 1.5265, Test Loss: 1.5237\n",
      "Epoch 1901/2000, Train Loss: 1.5252, Test Loss: 1.5288\n",
      "Epoch 1902/2000, Train Loss: 1.5262, Test Loss: 1.5262\n",
      "Epoch 1903/2000, Train Loss: 1.5251, Test Loss: 1.5249\n",
      "Epoch 1904/2000, Train Loss: 1.5261, Test Loss: 1.5271\n",
      "Epoch 1905/2000, Train Loss: 1.5259, Test Loss: 1.5241\n",
      "Epoch 1906/2000, Train Loss: 1.5257, Test Loss: 1.5238\n",
      "Epoch 1907/2000, Train Loss: 1.5250, Test Loss: 1.5258\n",
      "Epoch 1908/2000, Train Loss: 1.5257, Test Loss: 1.5252\n",
      "Epoch 1909/2000, Train Loss: 1.5255, Test Loss: 1.5218\n",
      "Epoch 1910/2000, Train Loss: 1.5252, Test Loss: 1.5293\n",
      "Epoch 1911/2000, Train Loss: 1.5248, Test Loss: 1.5201\n",
      "Epoch 1912/2000, Train Loss: 1.5258, Test Loss: 1.5278\n",
      "Epoch 1913/2000, Train Loss: 1.5265, Test Loss: 1.5246\n",
      "Epoch 1914/2000, Train Loss: 1.5258, Test Loss: 1.5237\n",
      "Epoch 1915/2000, Train Loss: 1.5257, Test Loss: 1.5263\n",
      "Epoch 1916/2000, Train Loss: 1.5251, Test Loss: 1.5266\n",
      "Epoch 1917/2000, Train Loss: 1.5254, Test Loss: 1.5225\n",
      "Epoch 1918/2000, Train Loss: 1.5257, Test Loss: 1.5212\n",
      "Epoch 1919/2000, Train Loss: 1.5254, Test Loss: 1.5206\n",
      "Epoch 1920/2000, Train Loss: 1.5252, Test Loss: 1.5231\n",
      "Epoch 1921/2000, Train Loss: 1.5252, Test Loss: 1.5240\n",
      "Epoch 1922/2000, Train Loss: 1.5254, Test Loss: 1.5237\n",
      "Epoch 1923/2000, Train Loss: 1.5251, Test Loss: 1.5264\n",
      "Epoch 1924/2000, Train Loss: 1.5249, Test Loss: 1.5204\n",
      "Epoch 1925/2000, Train Loss: 1.5252, Test Loss: 1.5271\n",
      "Epoch 1926/2000, Train Loss: 1.5256, Test Loss: 1.5279\n",
      "Epoch 1927/2000, Train Loss: 1.5251, Test Loss: 1.5263\n",
      "Epoch 1928/2000, Train Loss: 1.5254, Test Loss: 1.5203\n",
      "Epoch 1929/2000, Train Loss: 1.5253, Test Loss: 1.5234\n",
      "Epoch 1930/2000, Train Loss: 1.5252, Test Loss: 1.5260\n",
      "Epoch 1931/2000, Train Loss: 1.5261, Test Loss: 1.5217\n",
      "Epoch 1932/2000, Train Loss: 1.5251, Test Loss: 1.5310\n",
      "Epoch 1933/2000, Train Loss: 1.5264, Test Loss: 1.5356\n",
      "Epoch 1934/2000, Train Loss: 1.5254, Test Loss: 1.5235\n",
      "Epoch 1935/2000, Train Loss: 1.5255, Test Loss: 1.5242\n",
      "Epoch 1936/2000, Train Loss: 1.5256, Test Loss: 1.5262\n",
      "Epoch 1937/2000, Train Loss: 1.5260, Test Loss: 1.5214\n",
      "Epoch 1938/2000, Train Loss: 1.5252, Test Loss: 1.5233\n",
      "Epoch 1939/2000, Train Loss: 1.5252, Test Loss: 1.5227\n",
      "Epoch 1940/2000, Train Loss: 1.5254, Test Loss: 1.5291\n",
      "Epoch 1941/2000, Train Loss: 1.5256, Test Loss: 1.5268\n",
      "Epoch 1942/2000, Train Loss: 1.5258, Test Loss: 1.5216\n",
      "Epoch 1943/2000, Train Loss: 1.5260, Test Loss: 1.5243\n",
      "Epoch 1944/2000, Train Loss: 1.5250, Test Loss: 1.5221\n",
      "Epoch 1945/2000, Train Loss: 1.5253, Test Loss: 1.5241\n",
      "Epoch 1946/2000, Train Loss: 1.5254, Test Loss: 1.5273\n",
      "Epoch 1947/2000, Train Loss: 1.5252, Test Loss: 1.5222\n",
      "Epoch 1948/2000, Train Loss: 1.5251, Test Loss: 1.5236\n",
      "Epoch 1949/2000, Train Loss: 1.5250, Test Loss: 1.5244\n",
      "Epoch 1950/2000, Train Loss: 1.5250, Test Loss: 1.5286\n",
      "Epoch 1951/2000, Train Loss: 1.5258, Test Loss: 1.5244\n",
      "Epoch 1952/2000, Train Loss: 1.5253, Test Loss: 1.5233\n",
      "Epoch 1953/2000, Train Loss: 1.5254, Test Loss: 1.5243\n",
      "Epoch 1954/2000, Train Loss: 1.5256, Test Loss: 1.5254\n",
      "Epoch 1955/2000, Train Loss: 1.5256, Test Loss: 1.5260\n",
      "Epoch 1956/2000, Train Loss: 1.5254, Test Loss: 1.5228\n",
      "Epoch 1957/2000, Train Loss: 1.5248, Test Loss: 1.5233\n",
      "Epoch 1958/2000, Train Loss: 1.5252, Test Loss: 1.5276\n",
      "Epoch 1959/2000, Train Loss: 1.5253, Test Loss: 1.5236\n",
      "Epoch 1960/2000, Train Loss: 1.5250, Test Loss: 1.5195\n",
      "Epoch 1961/2000, Train Loss: 1.5249, Test Loss: 1.5225\n",
      "Epoch 1962/2000, Train Loss: 1.5259, Test Loss: 1.5221\n",
      "Epoch 1963/2000, Train Loss: 1.5251, Test Loss: 1.5226\n",
      "Epoch 1964/2000, Train Loss: 1.5258, Test Loss: 1.5255\n",
      "Epoch 1965/2000, Train Loss: 1.5261, Test Loss: 1.5231\n",
      "Epoch 1966/2000, Train Loss: 1.5255, Test Loss: 1.5240\n",
      "Epoch 1967/2000, Train Loss: 1.5251, Test Loss: 1.5209\n",
      "Epoch 1968/2000, Train Loss: 1.5254, Test Loss: 1.5239\n",
      "Epoch 1969/2000, Train Loss: 1.5251, Test Loss: 1.5311\n",
      "Epoch 1970/2000, Train Loss: 1.5254, Test Loss: 1.5255\n",
      "Epoch 1971/2000, Train Loss: 1.5254, Test Loss: 1.5245\n",
      "Epoch 1972/2000, Train Loss: 1.5253, Test Loss: 1.5255\n",
      "Epoch 1973/2000, Train Loss: 1.5251, Test Loss: 1.5222\n",
      "Epoch 1974/2000, Train Loss: 1.5250, Test Loss: 1.5204\n",
      "Epoch 1975/2000, Train Loss: 1.5252, Test Loss: 1.5259\n",
      "Epoch 1976/2000, Train Loss: 1.5251, Test Loss: 1.5232\n",
      "Epoch 1977/2000, Train Loss: 1.5250, Test Loss: 1.5212\n",
      "Epoch 1978/2000, Train Loss: 1.5251, Test Loss: 1.5251\n",
      "Epoch 1979/2000, Train Loss: 1.5252, Test Loss: 1.5199\n",
      "Epoch 1980/2000, Train Loss: 1.5264, Test Loss: 1.5230\n",
      "Epoch 1981/2000, Train Loss: 1.5254, Test Loss: 1.5308\n",
      "Epoch 1982/2000, Train Loss: 1.5252, Test Loss: 1.5261\n",
      "Epoch 1983/2000, Train Loss: 1.5258, Test Loss: 1.5245\n",
      "Epoch 1984/2000, Train Loss: 1.5255, Test Loss: 1.5226\n",
      "Epoch 1985/2000, Train Loss: 1.5248, Test Loss: 1.5224\n",
      "Epoch 1986/2000, Train Loss: 1.5250, Test Loss: 1.5256\n",
      "Epoch 1987/2000, Train Loss: 1.5247, Test Loss: 1.5281\n",
      "Epoch 1988/2000, Train Loss: 1.5251, Test Loss: 1.5225\n",
      "Epoch 1989/2000, Train Loss: 1.5251, Test Loss: 1.5240\n",
      "Epoch 1990/2000, Train Loss: 1.5248, Test Loss: 1.5199\n",
      "Epoch 1991/2000, Train Loss: 1.5252, Test Loss: 1.5293\n",
      "Epoch 1992/2000, Train Loss: 1.5253, Test Loss: 1.5235\n",
      "Epoch 1993/2000, Train Loss: 1.5254, Test Loss: 1.5197\n",
      "Epoch 1994/2000, Train Loss: 1.5246, Test Loss: 1.5230\n",
      "Epoch 1995/2000, Train Loss: 1.5254, Test Loss: 1.5252\n",
      "Epoch 1996/2000, Train Loss: 1.5257, Test Loss: 1.5273\n",
      "Epoch 1997/2000, Train Loss: 1.5255, Test Loss: 1.5245\n",
      "Epoch 1998/2000, Train Loss: 1.5250, Test Loss: 1.5265\n",
      "Epoch 1999/2000, Train Loss: 1.5254, Test Loss: 1.5245\n",
      "Epoch 2000/2000, Train Loss: 1.5247, Test Loss: 1.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.3997</td></tr><tr><td>accuracy/train</td><td>0.4022</td></tr><tr><td>batch_loss</td><td>1.23251</td></tr><tr><td>epoch</td><td>1999</td></tr><tr><td>loss/test</td><td>1.52275</td></tr><tr><td>loss/train</td><td>1.52469</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-water-260</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/o25bw72b' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/o25bw72b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240312_170907-o25bw72b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240312_194128-49z1ix20</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/49z1ix20' target=\"_blank\">true-music-261</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/49z1ix20' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/49z1ix20</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Train Loss: 1.2595, Test Loss: 0.9694\n",
      "Epoch 2/2000, Train Loss: 0.9204, Test Loss: 0.8633\n",
      "Epoch 3/2000, Train Loss: 0.8205, Test Loss: 0.7995\n",
      "Epoch 4/2000, Train Loss: 0.7943, Test Loss: 0.7876\n",
      "Epoch 5/2000, Train Loss: 0.7610, Test Loss: 0.7596\n",
      "Epoch 6/2000, Train Loss: 0.7637, Test Loss: 0.7566\n",
      "Epoch 7/2000, Train Loss: 0.7512, Test Loss: 0.7594\n",
      "Epoch 8/2000, Train Loss: 0.7426, Test Loss: 0.7743\n",
      "Epoch 9/2000, Train Loss: 0.7361, Test Loss: 0.7576\n",
      "Epoch 10/2000, Train Loss: 0.7273, Test Loss: 0.7494\n",
      "Epoch 11/2000, Train Loss: 0.7251, Test Loss: 0.7651\n",
      "Epoch 12/2000, Train Loss: 0.7268, Test Loss: 0.7326\n",
      "Epoch 13/2000, Train Loss: 0.7174, Test Loss: 0.7297\n",
      "Epoch 14/2000, Train Loss: 0.7140, Test Loss: 0.7403\n",
      "Epoch 15/2000, Train Loss: 0.7092, Test Loss: 0.7493\n",
      "Epoch 16/2000, Train Loss: 0.7083, Test Loss: 0.7203\n",
      "Epoch 17/2000, Train Loss: 0.7092, Test Loss: 0.7599\n",
      "Epoch 18/2000, Train Loss: 0.7003, Test Loss: 0.7500\n",
      "Epoch 19/2000, Train Loss: 0.7022, Test Loss: 0.7357\n",
      "Epoch 20/2000, Train Loss: 0.7004, Test Loss: 0.7294\n",
      "Epoch 21/2000, Train Loss: 0.6973, Test Loss: 0.7243\n",
      "Epoch 22/2000, Train Loss: 0.7030, Test Loss: 0.7445\n",
      "Epoch 23/2000, Train Loss: 0.6961, Test Loss: 0.7184\n",
      "Epoch 24/2000, Train Loss: 0.6936, Test Loss: 0.7142\n",
      "Epoch 25/2000, Train Loss: 0.6946, Test Loss: 0.7064\n",
      "Epoch 26/2000, Train Loss: 0.6928, Test Loss: 0.7123\n",
      "Epoch 27/2000, Train Loss: 0.6913, Test Loss: 0.7102\n",
      "Epoch 28/2000, Train Loss: 0.6883, Test Loss: 0.7132\n",
      "Epoch 29/2000, Train Loss: 0.6892, Test Loss: 0.7109\n",
      "Epoch 30/2000, Train Loss: 0.6876, Test Loss: 0.7120\n",
      "Epoch 31/2000, Train Loss: 0.6835, Test Loss: 0.7160\n",
      "Epoch 32/2000, Train Loss: 0.6865, Test Loss: 0.7241\n",
      "Epoch 33/2000, Train Loss: 0.6851, Test Loss: 0.6977\n",
      "Epoch 34/2000, Train Loss: 0.6823, Test Loss: 0.7200\n",
      "Epoch 35/2000, Train Loss: 0.6806, Test Loss: 0.7240\n",
      "Epoch 36/2000, Train Loss: 0.6816, Test Loss: 0.7043\n",
      "Epoch 37/2000, Train Loss: 0.6780, Test Loss: 0.6999\n",
      "Epoch 38/2000, Train Loss: 0.6770, Test Loss: 0.7216\n",
      "Epoch 39/2000, Train Loss: 0.6778, Test Loss: 0.7276\n",
      "Epoch 40/2000, Train Loss: 0.6827, Test Loss: 0.7157\n",
      "Epoch 41/2000, Train Loss: 0.6797, Test Loss: 0.7098\n",
      "Epoch 42/2000, Train Loss: 0.6762, Test Loss: 0.7038\n",
      "Epoch 43/2000, Train Loss: 0.6752, Test Loss: 0.6988\n",
      "Epoch 44/2000, Train Loss: 0.6755, Test Loss: 0.7024\n",
      "Epoch 45/2000, Train Loss: 0.6792, Test Loss: 0.7033\n",
      "Epoch 46/2000, Train Loss: 0.6808, Test Loss: 0.7096\n",
      "Epoch 47/2000, Train Loss: 0.6762, Test Loss: 0.7169\n",
      "Epoch 48/2000, Train Loss: 0.6705, Test Loss: 0.7057\n",
      "Epoch 49/2000, Train Loss: 0.6732, Test Loss: 0.7005\n",
      "Epoch 50/2000, Train Loss: 0.6732, Test Loss: 0.6971\n",
      "Epoch 51/2000, Train Loss: 0.6709, Test Loss: 0.7010\n",
      "Epoch 52/2000, Train Loss: 0.6708, Test Loss: 0.7283\n",
      "Epoch 53/2000, Train Loss: 0.6714, Test Loss: 0.7025\n",
      "Epoch 54/2000, Train Loss: 0.6678, Test Loss: 0.6952\n",
      "Epoch 55/2000, Train Loss: 0.6723, Test Loss: 0.6977\n",
      "Epoch 56/2000, Train Loss: 0.6677, Test Loss: 0.7111\n",
      "Epoch 57/2000, Train Loss: 0.6698, Test Loss: 0.7045\n",
      "Epoch 58/2000, Train Loss: 0.6716, Test Loss: 0.7026\n",
      "Epoch 59/2000, Train Loss: 0.6697, Test Loss: 0.7042\n",
      "Epoch 60/2000, Train Loss: 0.6669, Test Loss: 0.6938\n",
      "Epoch 61/2000, Train Loss: 0.6654, Test Loss: 0.7074\n",
      "Epoch 62/2000, Train Loss: 0.6667, Test Loss: 0.6938\n",
      "Epoch 63/2000, Train Loss: 0.6678, Test Loss: 0.6894\n",
      "Epoch 64/2000, Train Loss: 0.6679, Test Loss: 0.7043\n",
      "Epoch 65/2000, Train Loss: 0.6653, Test Loss: 0.6912\n",
      "Epoch 66/2000, Train Loss: 0.6625, Test Loss: 0.6992\n",
      "Epoch 67/2000, Train Loss: 0.6652, Test Loss: 0.6893\n",
      "Epoch 68/2000, Train Loss: 0.6681, Test Loss: 0.6894\n",
      "Epoch 69/2000, Train Loss: 0.6627, Test Loss: 0.6972\n",
      "Epoch 70/2000, Train Loss: 0.6617, Test Loss: 0.6999\n",
      "Epoch 71/2000, Train Loss: 0.6625, Test Loss: 0.6881\n",
      "Epoch 72/2000, Train Loss: 0.6630, Test Loss: 0.6875\n",
      "Epoch 73/2000, Train Loss: 0.6599, Test Loss: 0.6951\n",
      "Epoch 74/2000, Train Loss: 0.6614, Test Loss: 0.6870\n",
      "Epoch 75/2000, Train Loss: 0.6644, Test Loss: 0.7029\n",
      "Epoch 76/2000, Train Loss: 0.6606, Test Loss: 0.6973\n",
      "Epoch 77/2000, Train Loss: 0.6593, Test Loss: 0.7079\n",
      "Epoch 78/2000, Train Loss: 0.6586, Test Loss: 0.6966\n",
      "Epoch 79/2000, Train Loss: 0.6590, Test Loss: 0.6855\n",
      "Epoch 80/2000, Train Loss: 0.6610, Test Loss: 0.6967\n",
      "Epoch 81/2000, Train Loss: 0.6607, Test Loss: 0.6935\n",
      "Epoch 82/2000, Train Loss: 0.6600, Test Loss: 0.6953\n",
      "Epoch 83/2000, Train Loss: 0.6584, Test Loss: 0.6918\n",
      "Epoch 84/2000, Train Loss: 0.6605, Test Loss: 0.6848\n",
      "Epoch 85/2000, Train Loss: 0.6560, Test Loss: 0.6847\n",
      "Epoch 86/2000, Train Loss: 0.6627, Test Loss: 0.6850\n",
      "Epoch 87/2000, Train Loss: 0.6596, Test Loss: 0.6965\n",
      "Epoch 88/2000, Train Loss: 0.6550, Test Loss: 0.6908\n",
      "Epoch 89/2000, Train Loss: 0.6571, Test Loss: 0.6995\n",
      "Epoch 90/2000, Train Loss: 0.6577, Test Loss: 0.6967\n",
      "Epoch 91/2000, Train Loss: 0.6570, Test Loss: 0.6857\n",
      "Epoch 92/2000, Train Loss: 0.6568, Test Loss: 0.6863\n",
      "Epoch 93/2000, Train Loss: 0.6562, Test Loss: 0.7022\n",
      "Epoch 94/2000, Train Loss: 0.6558, Test Loss: 0.6847\n",
      "Epoch 95/2000, Train Loss: 0.6563, Test Loss: 0.6963\n",
      "Epoch 96/2000, Train Loss: 0.6561, Test Loss: 0.6887\n",
      "Epoch 97/2000, Train Loss: 0.6568, Test Loss: 0.6912\n",
      "Epoch 98/2000, Train Loss: 0.6519, Test Loss: 0.6887\n",
      "Epoch 99/2000, Train Loss: 0.6535, Test Loss: 0.6923\n",
      "Epoch 100/2000, Train Loss: 0.6533, Test Loss: 0.6859\n",
      "Epoch 101/2000, Train Loss: 0.6542, Test Loss: 0.6941\n",
      "Epoch 102/2000, Train Loss: 0.6548, Test Loss: 0.6864\n",
      "Epoch 103/2000, Train Loss: 0.6546, Test Loss: 0.6885\n",
      "Epoch 104/2000, Train Loss: 0.6561, Test Loss: 0.6845\n",
      "Epoch 105/2000, Train Loss: 0.6526, Test Loss: 0.6983\n",
      "Epoch 106/2000, Train Loss: 0.6516, Test Loss: 0.6851\n",
      "Epoch 107/2000, Train Loss: 0.6527, Test Loss: 0.6886\n",
      "Epoch 108/2000, Train Loss: 0.6543, Test Loss: 0.6958\n",
      "Epoch 109/2000, Train Loss: 0.6548, Test Loss: 0.6904\n",
      "Epoch 110/2000, Train Loss: 0.6533, Test Loss: 0.6853\n",
      "Epoch 111/2000, Train Loss: 0.6516, Test Loss: 0.6897\n",
      "Epoch 112/2000, Train Loss: 0.6505, Test Loss: 0.6878\n",
      "Epoch 113/2000, Train Loss: 0.6539, Test Loss: 0.6848\n",
      "Epoch 114/2000, Train Loss: 0.6524, Test Loss: 0.6852\n",
      "Epoch 115/2000, Train Loss: 0.6531, Test Loss: 0.7000\n",
      "Epoch 116/2000, Train Loss: 0.6502, Test Loss: 0.6883\n",
      "Epoch 117/2000, Train Loss: 0.6515, Test Loss: 0.6873\n",
      "Epoch 118/2000, Train Loss: 0.6508, Test Loss: 0.6861\n",
      "Epoch 119/2000, Train Loss: 0.6504, Test Loss: 0.6883\n",
      "Epoch 120/2000, Train Loss: 0.6544, Test Loss: 0.6858\n",
      "Epoch 121/2000, Train Loss: 0.6497, Test Loss: 0.7006\n",
      "Epoch 122/2000, Train Loss: 0.6502, Test Loss: 0.6841\n",
      "Epoch 123/2000, Train Loss: 0.6502, Test Loss: 0.6889\n",
      "Epoch 124/2000, Train Loss: 0.6511, Test Loss: 0.6819\n",
      "Epoch 125/2000, Train Loss: 0.6496, Test Loss: 0.6917\n",
      "Epoch 126/2000, Train Loss: 0.6507, Test Loss: 0.6912\n",
      "Epoch 127/2000, Train Loss: 0.6495, Test Loss: 0.6804\n",
      "Epoch 128/2000, Train Loss: 0.6513, Test Loss: 0.6814\n",
      "Epoch 129/2000, Train Loss: 0.6512, Test Loss: 0.6919\n",
      "Epoch 130/2000, Train Loss: 0.6499, Test Loss: 0.6947\n",
      "Epoch 131/2000, Train Loss: 0.6475, Test Loss: 0.6830\n",
      "Epoch 132/2000, Train Loss: 0.6494, Test Loss: 0.6843\n",
      "Epoch 133/2000, Train Loss: 0.6481, Test Loss: 0.6895\n",
      "Epoch 134/2000, Train Loss: 0.6495, Test Loss: 0.6901\n",
      "Epoch 135/2000, Train Loss: 0.6478, Test Loss: 0.6924\n",
      "Epoch 136/2000, Train Loss: 0.6513, Test Loss: 0.6863\n",
      "Epoch 137/2000, Train Loss: 0.6468, Test Loss: 0.6859\n",
      "Epoch 138/2000, Train Loss: 0.6477, Test Loss: 0.6873\n",
      "Epoch 139/2000, Train Loss: 0.6485, Test Loss: 0.6884\n",
      "Epoch 140/2000, Train Loss: 0.6519, Test Loss: 0.7022\n",
      "Epoch 141/2000, Train Loss: 0.6482, Test Loss: 0.6987\n",
      "Epoch 142/2000, Train Loss: 0.6471, Test Loss: 0.6879\n",
      "Epoch 143/2000, Train Loss: 0.6476, Test Loss: 0.6831\n",
      "Epoch 144/2000, Train Loss: 0.6468, Test Loss: 0.6800\n",
      "Epoch 145/2000, Train Loss: 0.6484, Test Loss: 0.6885\n",
      "Epoch 146/2000, Train Loss: 0.6472, Test Loss: 0.6824\n",
      "Epoch 147/2000, Train Loss: 0.6470, Test Loss: 0.6927\n",
      "Epoch 148/2000, Train Loss: 0.6465, Test Loss: 0.6961\n",
      "Epoch 149/2000, Train Loss: 0.6500, Test Loss: 0.7064\n",
      "Epoch 150/2000, Train Loss: 0.6459, Test Loss: 0.6850\n",
      "Epoch 151/2000, Train Loss: 0.6474, Test Loss: 0.6923\n",
      "Epoch 152/2000, Train Loss: 0.6493, Test Loss: 0.6809\n",
      "Epoch 153/2000, Train Loss: 0.6443, Test Loss: 0.6894\n",
      "Epoch 154/2000, Train Loss: 0.6445, Test Loss: 0.6843\n",
      "Epoch 155/2000, Train Loss: 0.6451, Test Loss: 0.6833\n",
      "Epoch 156/2000, Train Loss: 0.6463, Test Loss: 0.6827\n",
      "Epoch 157/2000, Train Loss: 0.6486, Test Loss: 0.6797\n",
      "Epoch 158/2000, Train Loss: 0.6453, Test Loss: 0.6851\n",
      "Epoch 159/2000, Train Loss: 0.6454, Test Loss: 0.6868\n",
      "Epoch 160/2000, Train Loss: 0.6459, Test Loss: 0.6796\n",
      "Epoch 161/2000, Train Loss: 0.6466, Test Loss: 0.6847\n",
      "Epoch 162/2000, Train Loss: 0.6461, Test Loss: 0.6923\n",
      "Epoch 163/2000, Train Loss: 0.6438, Test Loss: 0.6853\n",
      "Epoch 164/2000, Train Loss: 0.6459, Test Loss: 0.6855\n",
      "Epoch 165/2000, Train Loss: 0.6460, Test Loss: 0.6881\n",
      "Epoch 166/2000, Train Loss: 0.6434, Test Loss: 0.6865\n",
      "Epoch 167/2000, Train Loss: 0.6452, Test Loss: 0.6884\n",
      "Epoch 168/2000, Train Loss: 0.6443, Test Loss: 0.6805\n",
      "Epoch 169/2000, Train Loss: 0.6448, Test Loss: 0.6844\n",
      "Epoch 170/2000, Train Loss: 0.6430, Test Loss: 0.6809\n",
      "Epoch 171/2000, Train Loss: 0.6462, Test Loss: 0.6923\n",
      "Epoch 172/2000, Train Loss: 0.6442, Test Loss: 0.6829\n",
      "Epoch 173/2000, Train Loss: 0.6428, Test Loss: 0.6839\n",
      "Epoch 174/2000, Train Loss: 0.6446, Test Loss: 0.6845\n",
      "Epoch 175/2000, Train Loss: 0.6441, Test Loss: 0.6812\n",
      "Epoch 176/2000, Train Loss: 0.6454, Test Loss: 0.6832\n",
      "Epoch 177/2000, Train Loss: 0.6450, Test Loss: 0.6824\n",
      "Epoch 178/2000, Train Loss: 0.6452, Test Loss: 0.6913\n",
      "Epoch 179/2000, Train Loss: 0.6437, Test Loss: 0.6915\n",
      "Epoch 180/2000, Train Loss: 0.6425, Test Loss: 0.6836\n",
      "Epoch 181/2000, Train Loss: 0.6446, Test Loss: 0.6843\n",
      "Epoch 182/2000, Train Loss: 0.6445, Test Loss: 0.6822\n",
      "Epoch 183/2000, Train Loss: 0.6448, Test Loss: 0.6904\n",
      "Epoch 184/2000, Train Loss: 0.6425, Test Loss: 0.6862\n",
      "Epoch 185/2000, Train Loss: 0.6439, Test Loss: 0.6816\n",
      "Epoch 186/2000, Train Loss: 0.6434, Test Loss: 0.6849\n",
      "Epoch 187/2000, Train Loss: 0.6439, Test Loss: 0.6871\n",
      "Epoch 188/2000, Train Loss: 0.6427, Test Loss: 0.6832\n",
      "Epoch 189/2000, Train Loss: 0.6454, Test Loss: 0.6856\n",
      "Epoch 190/2000, Train Loss: 0.6422, Test Loss: 0.6792\n",
      "Epoch 191/2000, Train Loss: 0.6450, Test Loss: 0.6858\n",
      "Epoch 192/2000, Train Loss: 0.6419, Test Loss: 0.6806\n",
      "Epoch 193/2000, Train Loss: 0.6433, Test Loss: 0.6797\n",
      "Epoch 194/2000, Train Loss: 0.6430, Test Loss: 0.6900\n",
      "Epoch 195/2000, Train Loss: 0.6426, Test Loss: 0.6807\n",
      "Epoch 196/2000, Train Loss: 0.6410, Test Loss: 0.6767\n",
      "Epoch 197/2000, Train Loss: 0.6422, Test Loss: 0.7100\n",
      "Epoch 198/2000, Train Loss: 0.6435, Test Loss: 0.6868\n",
      "Epoch 199/2000, Train Loss: 0.6443, Test Loss: 0.6921\n",
      "Epoch 200/2000, Train Loss: 0.6426, Test Loss: 0.6821\n",
      "Epoch 201/2000, Train Loss: 0.6448, Test Loss: 0.6889\n",
      "Epoch 202/2000, Train Loss: 0.6430, Test Loss: 0.6897\n",
      "Epoch 203/2000, Train Loss: 0.6421, Test Loss: 0.6772\n",
      "Epoch 204/2000, Train Loss: 0.6408, Test Loss: 0.6871\n",
      "Epoch 205/2000, Train Loss: 0.6424, Test Loss: 0.6886\n",
      "Epoch 206/2000, Train Loss: 0.6414, Test Loss: 0.6812\n",
      "Epoch 207/2000, Train Loss: 0.6429, Test Loss: 0.6820\n",
      "Epoch 208/2000, Train Loss: 0.6418, Test Loss: 0.6789\n",
      "Epoch 209/2000, Train Loss: 0.6411, Test Loss: 0.6892\n",
      "Epoch 210/2000, Train Loss: 0.6418, Test Loss: 0.6824\n",
      "Epoch 211/2000, Train Loss: 0.6401, Test Loss: 0.6861\n",
      "Epoch 212/2000, Train Loss: 0.6437, Test Loss: 0.6893\n",
      "Epoch 213/2000, Train Loss: 0.6417, Test Loss: 0.6845\n",
      "Epoch 214/2000, Train Loss: 0.6421, Test Loss: 0.6798\n",
      "Epoch 215/2000, Train Loss: 0.6402, Test Loss: 0.6807\n",
      "Epoch 216/2000, Train Loss: 0.6421, Test Loss: 0.6914\n",
      "Epoch 217/2000, Train Loss: 0.6423, Test Loss: 0.6886\n",
      "Epoch 218/2000, Train Loss: 0.6404, Test Loss: 0.6842\n",
      "Epoch 219/2000, Train Loss: 0.6419, Test Loss: 0.6901\n",
      "Epoch 220/2000, Train Loss: 0.6406, Test Loss: 0.6781\n",
      "Epoch 221/2000, Train Loss: 0.6396, Test Loss: 0.6829\n",
      "Epoch 222/2000, Train Loss: 0.6412, Test Loss: 0.6871\n",
      "Epoch 223/2000, Train Loss: 0.6412, Test Loss: 0.6953\n",
      "Epoch 224/2000, Train Loss: 0.6416, Test Loss: 0.6808\n",
      "Epoch 225/2000, Train Loss: 0.6397, Test Loss: 0.6918\n",
      "Epoch 226/2000, Train Loss: 0.6400, Test Loss: 0.6855\n",
      "Epoch 227/2000, Train Loss: 0.6408, Test Loss: 0.6806\n",
      "Epoch 228/2000, Train Loss: 0.6420, Test Loss: 0.6922\n",
      "Epoch 229/2000, Train Loss: 0.6398, Test Loss: 0.6807\n",
      "Epoch 230/2000, Train Loss: 0.6407, Test Loss: 0.6754\n",
      "Epoch 231/2000, Train Loss: 0.6410, Test Loss: 0.6879\n",
      "Epoch 232/2000, Train Loss: 0.6404, Test Loss: 0.6794\n",
      "Epoch 233/2000, Train Loss: 0.6402, Test Loss: 0.6837\n",
      "Epoch 234/2000, Train Loss: 0.6398, Test Loss: 0.6785\n",
      "Epoch 235/2000, Train Loss: 0.6382, Test Loss: 0.6873\n",
      "Epoch 236/2000, Train Loss: 0.6397, Test Loss: 0.6843\n",
      "Epoch 237/2000, Train Loss: 0.6392, Test Loss: 0.6830\n",
      "Epoch 238/2000, Train Loss: 0.6394, Test Loss: 0.6785\n",
      "Epoch 239/2000, Train Loss: 0.6408, Test Loss: 0.6808\n",
      "Epoch 240/2000, Train Loss: 0.6377, Test Loss: 0.6870\n",
      "Epoch 241/2000, Train Loss: 0.6389, Test Loss: 0.6863\n",
      "Epoch 242/2000, Train Loss: 0.6417, Test Loss: 0.6811\n",
      "Epoch 243/2000, Train Loss: 0.6396, Test Loss: 0.6915\n",
      "Epoch 244/2000, Train Loss: 0.6401, Test Loss: 0.6802\n",
      "Epoch 245/2000, Train Loss: 0.6409, Test Loss: 0.6768\n",
      "Epoch 246/2000, Train Loss: 0.6392, Test Loss: 0.6849\n",
      "Epoch 247/2000, Train Loss: 0.6388, Test Loss: 0.6848\n",
      "Epoch 248/2000, Train Loss: 0.6392, Test Loss: 0.6922\n",
      "Epoch 249/2000, Train Loss: 0.6388, Test Loss: 0.6834\n",
      "Epoch 250/2000, Train Loss: 0.6398, Test Loss: 0.7031\n",
      "Epoch 251/2000, Train Loss: 0.6399, Test Loss: 0.6847\n",
      "Epoch 252/2000, Train Loss: 0.6396, Test Loss: 0.6943\n",
      "Epoch 253/2000, Train Loss: 0.6398, Test Loss: 0.6846\n",
      "Epoch 254/2000, Train Loss: 0.6394, Test Loss: 0.6807\n",
      "Epoch 255/2000, Train Loss: 0.6386, Test Loss: 0.6845\n",
      "Epoch 256/2000, Train Loss: 0.6380, Test Loss: 0.6889\n",
      "Epoch 257/2000, Train Loss: 0.6378, Test Loss: 0.6787\n",
      "Epoch 258/2000, Train Loss: 0.6389, Test Loss: 0.6892\n",
      "Epoch 259/2000, Train Loss: 0.6395, Test Loss: 0.6894\n",
      "Epoch 260/2000, Train Loss: 0.6388, Test Loss: 0.6829\n",
      "Epoch 261/2000, Train Loss: 0.6384, Test Loss: 0.6898\n",
      "Epoch 262/2000, Train Loss: 0.6380, Test Loss: 0.6894\n",
      "Epoch 263/2000, Train Loss: 0.6395, Test Loss: 0.6835\n",
      "Epoch 264/2000, Train Loss: 0.6383, Test Loss: 0.6802\n",
      "Epoch 265/2000, Train Loss: 0.6399, Test Loss: 0.6791\n",
      "Epoch 266/2000, Train Loss: 0.6374, Test Loss: 0.6903\n",
      "Epoch 267/2000, Train Loss: 0.6393, Test Loss: 0.6800\n",
      "Epoch 268/2000, Train Loss: 0.6382, Test Loss: 0.6818\n",
      "Epoch 269/2000, Train Loss: 0.6391, Test Loss: 0.6805\n",
      "Epoch 270/2000, Train Loss: 0.6379, Test Loss: 0.6826\n",
      "Epoch 271/2000, Train Loss: 0.6396, Test Loss: 0.6867\n",
      "Epoch 272/2000, Train Loss: 0.6391, Test Loss: 0.6798\n",
      "Epoch 273/2000, Train Loss: 0.6370, Test Loss: 0.6800\n",
      "Epoch 274/2000, Train Loss: 0.6365, Test Loss: 0.6999\n",
      "Epoch 275/2000, Train Loss: 0.6396, Test Loss: 0.6829\n",
      "Epoch 276/2000, Train Loss: 0.6396, Test Loss: 0.6894\n",
      "Epoch 277/2000, Train Loss: 0.6383, Test Loss: 0.6819\n",
      "Epoch 278/2000, Train Loss: 0.6373, Test Loss: 0.6848\n",
      "Epoch 279/2000, Train Loss: 0.6395, Test Loss: 0.6900\n",
      "Epoch 280/2000, Train Loss: 0.6382, Test Loss: 0.6976\n",
      "Epoch 281/2000, Train Loss: 0.6387, Test Loss: 0.6785\n",
      "Epoch 282/2000, Train Loss: 0.6387, Test Loss: 0.6842\n",
      "Epoch 283/2000, Train Loss: 0.6381, Test Loss: 0.6815\n",
      "Epoch 284/2000, Train Loss: 0.6369, Test Loss: 0.6769\n",
      "Epoch 285/2000, Train Loss: 0.6380, Test Loss: 0.6891\n",
      "Epoch 286/2000, Train Loss: 0.6392, Test Loss: 0.6812\n",
      "Epoch 287/2000, Train Loss: 0.6380, Test Loss: 0.6900\n",
      "Epoch 288/2000, Train Loss: 0.6393, Test Loss: 0.6833\n",
      "Epoch 289/2000, Train Loss: 0.6360, Test Loss: 0.6893\n",
      "Epoch 290/2000, Train Loss: 0.6376, Test Loss: 0.6904\n",
      "Epoch 291/2000, Train Loss: 0.6361, Test Loss: 0.6856\n",
      "Epoch 292/2000, Train Loss: 0.6357, Test Loss: 0.6797\n",
      "Epoch 293/2000, Train Loss: 0.6389, Test Loss: 0.6829\n",
      "Epoch 294/2000, Train Loss: 0.6381, Test Loss: 0.6857\n",
      "Epoch 295/2000, Train Loss: 0.6375, Test Loss: 0.6835\n",
      "Epoch 296/2000, Train Loss: 0.6376, Test Loss: 0.6862\n",
      "Epoch 297/2000, Train Loss: 0.6385, Test Loss: 0.6839\n",
      "Epoch 298/2000, Train Loss: 0.6361, Test Loss: 0.6795\n",
      "Epoch 299/2000, Train Loss: 0.6373, Test Loss: 0.6854\n",
      "Epoch 300/2000, Train Loss: 0.6363, Test Loss: 0.6890\n",
      "Epoch 301/2000, Train Loss: 0.6363, Test Loss: 0.6759\n",
      "Epoch 302/2000, Train Loss: 0.6382, Test Loss: 0.6799\n",
      "Epoch 303/2000, Train Loss: 0.6377, Test Loss: 0.6828\n",
      "Epoch 304/2000, Train Loss: 0.6371, Test Loss: 0.6749\n",
      "Epoch 305/2000, Train Loss: 0.6363, Test Loss: 0.6809\n",
      "Epoch 306/2000, Train Loss: 0.6358, Test Loss: 0.6832\n",
      "Epoch 307/2000, Train Loss: 0.6364, Test Loss: 0.6870\n",
      "Epoch 308/2000, Train Loss: 0.6386, Test Loss: 0.6846\n",
      "Epoch 309/2000, Train Loss: 0.6369, Test Loss: 0.6895\n",
      "Epoch 310/2000, Train Loss: 0.6364, Test Loss: 0.6810\n",
      "Epoch 311/2000, Train Loss: 0.6363, Test Loss: 0.6776\n",
      "Epoch 312/2000, Train Loss: 0.6357, Test Loss: 0.6798\n",
      "Epoch 313/2000, Train Loss: 0.6366, Test Loss: 0.6788\n",
      "Epoch 314/2000, Train Loss: 0.6362, Test Loss: 0.6849\n",
      "Epoch 315/2000, Train Loss: 0.6355, Test Loss: 0.6880\n",
      "Epoch 316/2000, Train Loss: 0.6360, Test Loss: 0.6829\n",
      "Epoch 317/2000, Train Loss: 0.6370, Test Loss: 0.6780\n",
      "Epoch 318/2000, Train Loss: 0.6366, Test Loss: 0.6855\n",
      "Epoch 319/2000, Train Loss: 0.6359, Test Loss: 0.6861\n",
      "Epoch 320/2000, Train Loss: 0.6354, Test Loss: 0.6803\n",
      "Epoch 321/2000, Train Loss: 0.6369, Test Loss: 0.6765\n",
      "Epoch 322/2000, Train Loss: 0.6358, Test Loss: 0.6785\n",
      "Epoch 323/2000, Train Loss: 0.6372, Test Loss: 0.6857\n",
      "Epoch 324/2000, Train Loss: 0.6356, Test Loss: 0.6825\n",
      "Epoch 325/2000, Train Loss: 0.6372, Test Loss: 0.6925\n",
      "Epoch 326/2000, Train Loss: 0.6373, Test Loss: 0.6860\n",
      "Epoch 327/2000, Train Loss: 0.6357, Test Loss: 0.6845\n",
      "Epoch 328/2000, Train Loss: 0.6363, Test Loss: 0.6816\n",
      "Epoch 329/2000, Train Loss: 0.6355, Test Loss: 0.6789\n",
      "Epoch 330/2000, Train Loss: 0.6366, Test Loss: 0.6823\n",
      "Epoch 331/2000, Train Loss: 0.6348, Test Loss: 0.6851\n",
      "Epoch 332/2000, Train Loss: 0.6366, Test Loss: 0.6805\n",
      "Epoch 333/2000, Train Loss: 0.6353, Test Loss: 0.6845\n",
      "Epoch 334/2000, Train Loss: 0.6348, Test Loss: 0.6814\n",
      "Epoch 335/2000, Train Loss: 0.6350, Test Loss: 0.6830\n",
      "Epoch 336/2000, Train Loss: 0.6348, Test Loss: 0.6760\n",
      "Epoch 337/2000, Train Loss: 0.6369, Test Loss: 0.6808\n",
      "Epoch 338/2000, Train Loss: 0.6366, Test Loss: 0.6871\n",
      "Epoch 339/2000, Train Loss: 0.6360, Test Loss: 0.6818\n",
      "Epoch 340/2000, Train Loss: 0.6362, Test Loss: 0.6837\n",
      "Epoch 341/2000, Train Loss: 0.6341, Test Loss: 0.6835\n",
      "Epoch 342/2000, Train Loss: 0.6346, Test Loss: 0.6826\n",
      "Epoch 343/2000, Train Loss: 0.6344, Test Loss: 0.6811\n",
      "Epoch 344/2000, Train Loss: 0.6349, Test Loss: 0.6839\n",
      "Epoch 345/2000, Train Loss: 0.6351, Test Loss: 0.6780\n",
      "Epoch 346/2000, Train Loss: 0.6362, Test Loss: 0.6864\n",
      "Epoch 347/2000, Train Loss: 0.6345, Test Loss: 0.6790\n",
      "Epoch 348/2000, Train Loss: 0.6342, Test Loss: 0.6794\n",
      "Epoch 349/2000, Train Loss: 0.6351, Test Loss: 0.6832\n",
      "Epoch 350/2000, Train Loss: 0.6359, Test Loss: 0.6842\n",
      "Epoch 351/2000, Train Loss: 0.6356, Test Loss: 0.6935\n",
      "Epoch 352/2000, Train Loss: 0.6351, Test Loss: 0.6776\n",
      "Epoch 353/2000, Train Loss: 0.6344, Test Loss: 0.6795\n",
      "Epoch 354/2000, Train Loss: 0.6346, Test Loss: 0.6783\n",
      "Epoch 355/2000, Train Loss: 0.6355, Test Loss: 0.7029\n",
      "Epoch 356/2000, Train Loss: 0.6357, Test Loss: 0.6803\n",
      "Epoch 357/2000, Train Loss: 0.6347, Test Loss: 0.6771\n",
      "Epoch 358/2000, Train Loss: 0.6349, Test Loss: 0.6913\n",
      "Epoch 359/2000, Train Loss: 0.6347, Test Loss: 0.6853\n",
      "Epoch 360/2000, Train Loss: 0.6341, Test Loss: 0.6906\n",
      "Epoch 361/2000, Train Loss: 0.6351, Test Loss: 0.6774\n",
      "Epoch 362/2000, Train Loss: 0.6361, Test Loss: 0.6795\n",
      "Epoch 363/2000, Train Loss: 0.6349, Test Loss: 0.6953\n",
      "Epoch 364/2000, Train Loss: 0.6336, Test Loss: 0.6815\n",
      "Epoch 365/2000, Train Loss: 0.6338, Test Loss: 0.6863\n",
      "Epoch 366/2000, Train Loss: 0.6365, Test Loss: 0.6826\n",
      "Epoch 367/2000, Train Loss: 0.6348, Test Loss: 0.6865\n",
      "Epoch 368/2000, Train Loss: 0.6349, Test Loss: 0.6848\n",
      "Epoch 369/2000, Train Loss: 0.6355, Test Loss: 0.6812\n",
      "Epoch 370/2000, Train Loss: 0.6342, Test Loss: 0.6822\n",
      "Epoch 371/2000, Train Loss: 0.6364, Test Loss: 0.6878\n",
      "Epoch 372/2000, Train Loss: 0.6335, Test Loss: 0.6931\n",
      "Epoch 373/2000, Train Loss: 0.6351, Test Loss: 0.6765\n",
      "Epoch 374/2000, Train Loss: 0.6339, Test Loss: 0.6891\n",
      "Epoch 375/2000, Train Loss: 0.6337, Test Loss: 0.6814\n",
      "Epoch 376/2000, Train Loss: 0.6336, Test Loss: 0.6903\n",
      "Epoch 377/2000, Train Loss: 0.6344, Test Loss: 0.6790\n",
      "Epoch 378/2000, Train Loss: 0.6369, Test Loss: 0.6986\n",
      "Epoch 379/2000, Train Loss: 0.6367, Test Loss: 0.6880\n",
      "Epoch 380/2000, Train Loss: 0.6346, Test Loss: 0.6800\n",
      "Epoch 381/2000, Train Loss: 0.6349, Test Loss: 0.6821\n",
      "Epoch 382/2000, Train Loss: 0.6351, Test Loss: 0.6876\n",
      "Epoch 383/2000, Train Loss: 0.6350, Test Loss: 0.6800\n",
      "Epoch 384/2000, Train Loss: 0.6347, Test Loss: 0.6895\n",
      "Epoch 385/2000, Train Loss: 0.6358, Test Loss: 0.6876\n",
      "Epoch 386/2000, Train Loss: 0.6344, Test Loss: 0.6813\n",
      "Epoch 387/2000, Train Loss: 0.6346, Test Loss: 0.6885\n",
      "Epoch 388/2000, Train Loss: 0.6335, Test Loss: 0.6841\n",
      "Epoch 389/2000, Train Loss: 0.6346, Test Loss: 0.6871\n",
      "Epoch 390/2000, Train Loss: 0.6337, Test Loss: 0.6784\n",
      "Epoch 391/2000, Train Loss: 0.6351, Test Loss: 0.6816\n",
      "Epoch 392/2000, Train Loss: 0.6336, Test Loss: 0.6773\n",
      "Epoch 393/2000, Train Loss: 0.6338, Test Loss: 0.6780\n",
      "Epoch 394/2000, Train Loss: 0.6327, Test Loss: 0.6859\n",
      "Epoch 395/2000, Train Loss: 0.6339, Test Loss: 0.6787\n",
      "Epoch 396/2000, Train Loss: 0.6341, Test Loss: 0.6886\n",
      "Epoch 397/2000, Train Loss: 0.6336, Test Loss: 0.6817\n",
      "Epoch 398/2000, Train Loss: 0.6344, Test Loss: 0.6845\n",
      "Epoch 399/2000, Train Loss: 0.6331, Test Loss: 0.6926\n",
      "Epoch 400/2000, Train Loss: 0.6350, Test Loss: 0.6850\n",
      "Epoch 401/2000, Train Loss: 0.6329, Test Loss: 0.6886\n",
      "Epoch 402/2000, Train Loss: 0.6341, Test Loss: 0.6872\n",
      "Epoch 403/2000, Train Loss: 0.6362, Test Loss: 0.6904\n",
      "Epoch 404/2000, Train Loss: 0.6345, Test Loss: 0.6805\n",
      "Epoch 405/2000, Train Loss: 0.6336, Test Loss: 0.6807\n",
      "Epoch 406/2000, Train Loss: 0.6341, Test Loss: 0.6870\n",
      "Epoch 407/2000, Train Loss: 0.6327, Test Loss: 0.6795\n",
      "Epoch 408/2000, Train Loss: 0.6329, Test Loss: 0.6780\n",
      "Epoch 409/2000, Train Loss: 0.6329, Test Loss: 0.6801\n",
      "Epoch 410/2000, Train Loss: 0.6333, Test Loss: 0.6806\n",
      "Epoch 411/2000, Train Loss: 0.6339, Test Loss: 0.6797\n",
      "Epoch 412/2000, Train Loss: 0.6334, Test Loss: 0.6787\n",
      "Epoch 413/2000, Train Loss: 0.6337, Test Loss: 0.6764\n",
      "Epoch 414/2000, Train Loss: 0.6325, Test Loss: 0.6918\n",
      "Epoch 415/2000, Train Loss: 0.6339, Test Loss: 0.6826\n",
      "Epoch 416/2000, Train Loss: 0.6334, Test Loss: 0.6881\n",
      "Epoch 417/2000, Train Loss: 0.6325, Test Loss: 0.6804\n",
      "Epoch 418/2000, Train Loss: 0.6328, Test Loss: 0.6875\n",
      "Epoch 419/2000, Train Loss: 0.6335, Test Loss: 0.6854\n",
      "Epoch 420/2000, Train Loss: 0.6329, Test Loss: 0.6899\n",
      "Epoch 421/2000, Train Loss: 0.6331, Test Loss: 0.6760\n",
      "Epoch 422/2000, Train Loss: 0.6324, Test Loss: 0.6817\n",
      "Epoch 423/2000, Train Loss: 0.6327, Test Loss: 0.6826\n",
      "Epoch 424/2000, Train Loss: 0.6341, Test Loss: 0.6804\n",
      "Epoch 425/2000, Train Loss: 0.6330, Test Loss: 0.6782\n",
      "Epoch 426/2000, Train Loss: 0.6332, Test Loss: 0.6840\n",
      "Epoch 427/2000, Train Loss: 0.6336, Test Loss: 0.6814\n",
      "Epoch 428/2000, Train Loss: 0.6327, Test Loss: 0.6974\n",
      "Epoch 429/2000, Train Loss: 0.6356, Test Loss: 0.6878\n",
      "Epoch 430/2000, Train Loss: 0.6334, Test Loss: 0.6772\n",
      "Epoch 431/2000, Train Loss: 0.6331, Test Loss: 0.6953\n",
      "Epoch 432/2000, Train Loss: 0.6325, Test Loss: 0.6824\n",
      "Epoch 433/2000, Train Loss: 0.6319, Test Loss: 0.6846\n",
      "Epoch 434/2000, Train Loss: 0.6337, Test Loss: 0.6937\n",
      "Epoch 435/2000, Train Loss: 0.6329, Test Loss: 0.6803\n",
      "Epoch 436/2000, Train Loss: 0.6327, Test Loss: 0.6835\n",
      "Epoch 437/2000, Train Loss: 0.6323, Test Loss: 0.6842\n",
      "Epoch 438/2000, Train Loss: 0.6339, Test Loss: 0.6927\n",
      "Epoch 439/2000, Train Loss: 0.6331, Test Loss: 0.6837\n",
      "Epoch 440/2000, Train Loss: 0.6330, Test Loss: 0.6847\n",
      "Epoch 441/2000, Train Loss: 0.6346, Test Loss: 0.6838\n",
      "Epoch 442/2000, Train Loss: 0.6325, Test Loss: 0.6809\n",
      "Epoch 443/2000, Train Loss: 0.6333, Test Loss: 0.6830\n",
      "Epoch 444/2000, Train Loss: 0.6340, Test Loss: 0.6811\n",
      "Epoch 445/2000, Train Loss: 0.6324, Test Loss: 0.6742\n",
      "Epoch 446/2000, Train Loss: 0.6335, Test Loss: 0.6837\n",
      "Epoch 447/2000, Train Loss: 0.6321, Test Loss: 0.6784\n",
      "Epoch 448/2000, Train Loss: 0.6312, Test Loss: 0.6841\n",
      "Epoch 449/2000, Train Loss: 0.6317, Test Loss: 0.6786\n",
      "Epoch 450/2000, Train Loss: 0.6335, Test Loss: 0.6822\n",
      "Epoch 451/2000, Train Loss: 0.6330, Test Loss: 0.6942\n",
      "Epoch 452/2000, Train Loss: 0.6323, Test Loss: 0.6765\n",
      "Epoch 453/2000, Train Loss: 0.6315, Test Loss: 0.6788\n",
      "Epoch 454/2000, Train Loss: 0.6331, Test Loss: 0.6878\n",
      "Epoch 455/2000, Train Loss: 0.6335, Test Loss: 0.6795\n",
      "Epoch 456/2000, Train Loss: 0.6332, Test Loss: 0.6942\n",
      "Epoch 457/2000, Train Loss: 0.6330, Test Loss: 0.6847\n",
      "Epoch 458/2000, Train Loss: 0.6320, Test Loss: 0.6817\n",
      "Epoch 459/2000, Train Loss: 0.6321, Test Loss: 0.6856\n",
      "Epoch 460/2000, Train Loss: 0.6336, Test Loss: 0.6823\n",
      "Epoch 461/2000, Train Loss: 0.6333, Test Loss: 0.6804\n",
      "Epoch 462/2000, Train Loss: 0.6335, Test Loss: 0.6782\n",
      "Epoch 463/2000, Train Loss: 0.6321, Test Loss: 0.6884\n",
      "Epoch 464/2000, Train Loss: 0.6327, Test Loss: 0.6935\n",
      "Epoch 465/2000, Train Loss: 0.6326, Test Loss: 0.6909\n",
      "Epoch 466/2000, Train Loss: 0.6335, Test Loss: 0.6743\n",
      "Epoch 467/2000, Train Loss: 0.6328, Test Loss: 0.6796\n",
      "Epoch 468/2000, Train Loss: 0.6332, Test Loss: 0.6768\n",
      "Epoch 469/2000, Train Loss: 0.6310, Test Loss: 0.6778\n",
      "Epoch 470/2000, Train Loss: 0.6329, Test Loss: 0.6825\n",
      "Epoch 471/2000, Train Loss: 0.6331, Test Loss: 0.6900\n",
      "Epoch 472/2000, Train Loss: 0.6321, Test Loss: 0.6818\n",
      "Epoch 473/2000, Train Loss: 0.6323, Test Loss: 0.6814\n",
      "Epoch 474/2000, Train Loss: 0.6326, Test Loss: 0.6842\n",
      "Epoch 475/2000, Train Loss: 0.6334, Test Loss: 0.6799\n",
      "Epoch 476/2000, Train Loss: 0.6319, Test Loss: 0.6765\n",
      "Epoch 477/2000, Train Loss: 0.6329, Test Loss: 0.6795\n",
      "Epoch 478/2000, Train Loss: 0.6311, Test Loss: 0.6832\n",
      "Epoch 479/2000, Train Loss: 0.6313, Test Loss: 0.6792\n",
      "Epoch 480/2000, Train Loss: 0.6314, Test Loss: 0.6809\n",
      "Epoch 481/2000, Train Loss: 0.6312, Test Loss: 0.6907\n",
      "Epoch 482/2000, Train Loss: 0.6320, Test Loss: 0.6796\n",
      "Epoch 483/2000, Train Loss: 0.6320, Test Loss: 0.6926\n",
      "Epoch 484/2000, Train Loss: 0.6348, Test Loss: 0.6808\n",
      "Epoch 485/2000, Train Loss: 0.6325, Test Loss: 0.6792\n",
      "Epoch 486/2000, Train Loss: 0.6324, Test Loss: 0.6847\n",
      "Epoch 487/2000, Train Loss: 0.6324, Test Loss: 0.6804\n",
      "Epoch 488/2000, Train Loss: 0.6310, Test Loss: 0.6801\n",
      "Epoch 489/2000, Train Loss: 0.6324, Test Loss: 0.6829\n",
      "Epoch 490/2000, Train Loss: 0.6329, Test Loss: 0.6777\n",
      "Epoch 491/2000, Train Loss: 0.6317, Test Loss: 0.6816\n",
      "Epoch 492/2000, Train Loss: 0.6321, Test Loss: 0.6781\n",
      "Epoch 493/2000, Train Loss: 0.6327, Test Loss: 0.6869\n",
      "Epoch 494/2000, Train Loss: 0.6337, Test Loss: 0.6859\n",
      "Epoch 495/2000, Train Loss: 0.6330, Test Loss: 0.6857\n",
      "Epoch 496/2000, Train Loss: 0.6330, Test Loss: 0.6978\n",
      "Epoch 497/2000, Train Loss: 0.6319, Test Loss: 0.6810\n",
      "Epoch 498/2000, Train Loss: 0.6333, Test Loss: 0.6827\n",
      "Epoch 499/2000, Train Loss: 0.6314, Test Loss: 0.6815\n",
      "Epoch 500/2000, Train Loss: 0.6317, Test Loss: 0.6799\n",
      "Epoch 501/2000, Train Loss: 0.6331, Test Loss: 0.6778\n",
      "Epoch 502/2000, Train Loss: 0.6324, Test Loss: 0.6927\n",
      "Epoch 503/2000, Train Loss: 0.6319, Test Loss: 0.6898\n",
      "Epoch 504/2000, Train Loss: 0.6332, Test Loss: 0.6737\n",
      "Epoch 505/2000, Train Loss: 0.6304, Test Loss: 0.6795\n",
      "Epoch 506/2000, Train Loss: 0.6325, Test Loss: 0.6861\n",
      "Epoch 507/2000, Train Loss: 0.6321, Test Loss: 0.6896\n",
      "Epoch 508/2000, Train Loss: 0.6313, Test Loss: 0.6783\n",
      "Epoch 509/2000, Train Loss: 0.6308, Test Loss: 0.6877\n",
      "Epoch 510/2000, Train Loss: 0.6315, Test Loss: 0.6797\n",
      "Epoch 511/2000, Train Loss: 0.6322, Test Loss: 0.6877\n",
      "Epoch 512/2000, Train Loss: 0.6317, Test Loss: 0.6821\n",
      "Epoch 513/2000, Train Loss: 0.6319, Test Loss: 0.6796\n",
      "Epoch 514/2000, Train Loss: 0.6310, Test Loss: 0.6835\n",
      "Epoch 515/2000, Train Loss: 0.6300, Test Loss: 0.6801\n",
      "Epoch 516/2000, Train Loss: 0.6310, Test Loss: 0.6772\n",
      "Epoch 517/2000, Train Loss: 0.6309, Test Loss: 0.6801\n",
      "Epoch 518/2000, Train Loss: 0.6310, Test Loss: 0.6761\n",
      "Epoch 519/2000, Train Loss: 0.6309, Test Loss: 0.6848\n",
      "Epoch 520/2000, Train Loss: 0.6303, Test Loss: 0.6757\n",
      "Epoch 521/2000, Train Loss: 0.6325, Test Loss: 0.7008\n",
      "Epoch 522/2000, Train Loss: 0.6334, Test Loss: 0.6855\n",
      "Epoch 523/2000, Train Loss: 0.6312, Test Loss: 0.6840\n",
      "Epoch 524/2000, Train Loss: 0.6317, Test Loss: 0.6822\n",
      "Epoch 525/2000, Train Loss: 0.6315, Test Loss: 0.6784\n",
      "Epoch 526/2000, Train Loss: 0.6306, Test Loss: 0.6854\n",
      "Epoch 527/2000, Train Loss: 0.6305, Test Loss: 0.6796\n",
      "Epoch 528/2000, Train Loss: 0.6312, Test Loss: 0.6793\n",
      "Epoch 529/2000, Train Loss: 0.6307, Test Loss: 0.6875\n",
      "Epoch 530/2000, Train Loss: 0.6308, Test Loss: 0.6767\n",
      "Epoch 531/2000, Train Loss: 0.6301, Test Loss: 0.6806\n",
      "Epoch 532/2000, Train Loss: 0.6318, Test Loss: 0.6784\n",
      "Epoch 533/2000, Train Loss: 0.6315, Test Loss: 0.6869\n",
      "Epoch 534/2000, Train Loss: 0.6327, Test Loss: 0.6824\n",
      "Epoch 535/2000, Train Loss: 0.6306, Test Loss: 0.6799\n",
      "Epoch 536/2000, Train Loss: 0.6314, Test Loss: 0.6852\n",
      "Epoch 537/2000, Train Loss: 0.6312, Test Loss: 0.6888\n",
      "Epoch 538/2000, Train Loss: 0.6303, Test Loss: 0.6852\n",
      "Epoch 539/2000, Train Loss: 0.6315, Test Loss: 0.6858\n",
      "Epoch 540/2000, Train Loss: 0.6301, Test Loss: 0.6783\n",
      "Epoch 541/2000, Train Loss: 0.6316, Test Loss: 0.6817\n",
      "Epoch 542/2000, Train Loss: 0.6309, Test Loss: 0.6841\n",
      "Epoch 543/2000, Train Loss: 0.6311, Test Loss: 0.6780\n",
      "Epoch 544/2000, Train Loss: 0.6314, Test Loss: 0.6828\n",
      "Epoch 545/2000, Train Loss: 0.6314, Test Loss: 0.6808\n",
      "Epoch 546/2000, Train Loss: 0.6311, Test Loss: 0.6959\n",
      "Epoch 547/2000, Train Loss: 0.6308, Test Loss: 0.6846\n",
      "Epoch 548/2000, Train Loss: 0.6337, Test Loss: 0.6780\n",
      "Epoch 549/2000, Train Loss: 0.6303, Test Loss: 0.6803\n",
      "Epoch 550/2000, Train Loss: 0.6322, Test Loss: 0.6797\n",
      "Epoch 551/2000, Train Loss: 0.6312, Test Loss: 0.6786\n",
      "Epoch 552/2000, Train Loss: 0.6329, Test Loss: 0.6765\n",
      "Epoch 553/2000, Train Loss: 0.6322, Test Loss: 0.6789\n",
      "Epoch 554/2000, Train Loss: 0.6306, Test Loss: 0.6807\n",
      "Epoch 555/2000, Train Loss: 0.6312, Test Loss: 0.6873\n",
      "Epoch 556/2000, Train Loss: 0.6307, Test Loss: 0.6849\n",
      "Epoch 557/2000, Train Loss: 0.6325, Test Loss: 0.6787\n",
      "Epoch 558/2000, Train Loss: 0.6318, Test Loss: 0.6793\n",
      "Epoch 559/2000, Train Loss: 0.6297, Test Loss: 0.6803\n",
      "Epoch 560/2000, Train Loss: 0.6313, Test Loss: 0.6769\n",
      "Epoch 561/2000, Train Loss: 0.6315, Test Loss: 0.6920\n",
      "Epoch 562/2000, Train Loss: 0.6319, Test Loss: 0.6828\n",
      "Epoch 563/2000, Train Loss: 0.6314, Test Loss: 0.6828\n",
      "Epoch 564/2000, Train Loss: 0.6302, Test Loss: 0.6850\n",
      "Epoch 565/2000, Train Loss: 0.6308, Test Loss: 0.6877\n",
      "Epoch 566/2000, Train Loss: 0.6323, Test Loss: 0.6885\n",
      "Epoch 567/2000, Train Loss: 0.6319, Test Loss: 0.6883\n",
      "Epoch 568/2000, Train Loss: 0.6316, Test Loss: 0.6828\n",
      "Epoch 569/2000, Train Loss: 0.6322, Test Loss: 0.6934\n",
      "Epoch 570/2000, Train Loss: 0.6307, Test Loss: 0.6944\n",
      "Epoch 571/2000, Train Loss: 0.6307, Test Loss: 0.6805\n",
      "Epoch 572/2000, Train Loss: 0.6307, Test Loss: 0.6965\n",
      "Epoch 573/2000, Train Loss: 0.6315, Test Loss: 0.6825\n",
      "Epoch 574/2000, Train Loss: 0.6304, Test Loss: 0.6833\n",
      "Epoch 575/2000, Train Loss: 0.6316, Test Loss: 0.6799\n",
      "Epoch 576/2000, Train Loss: 0.6317, Test Loss: 0.6842\n",
      "Epoch 577/2000, Train Loss: 0.6314, Test Loss: 0.6788\n",
      "Epoch 578/2000, Train Loss: 0.6300, Test Loss: 0.6836\n",
      "Epoch 579/2000, Train Loss: 0.6302, Test Loss: 0.6840\n",
      "Epoch 580/2000, Train Loss: 0.6303, Test Loss: 0.6816\n",
      "Epoch 581/2000, Train Loss: 0.6312, Test Loss: 0.6853\n",
      "Epoch 582/2000, Train Loss: 0.6301, Test Loss: 0.6800\n",
      "Epoch 583/2000, Train Loss: 0.6303, Test Loss: 0.6856\n",
      "Epoch 584/2000, Train Loss: 0.6298, Test Loss: 0.6793\n",
      "Epoch 585/2000, Train Loss: 0.6319, Test Loss: 0.6839\n",
      "Epoch 586/2000, Train Loss: 0.6303, Test Loss: 0.6792\n",
      "Epoch 587/2000, Train Loss: 0.6304, Test Loss: 0.6805\n",
      "Epoch 588/2000, Train Loss: 0.6300, Test Loss: 0.6830\n",
      "Epoch 589/2000, Train Loss: 0.6299, Test Loss: 0.6848\n",
      "Epoch 590/2000, Train Loss: 0.6307, Test Loss: 0.6915\n",
      "Epoch 591/2000, Train Loss: 0.6309, Test Loss: 0.6867\n",
      "Epoch 592/2000, Train Loss: 0.6298, Test Loss: 0.6791\n",
      "Epoch 593/2000, Train Loss: 0.6315, Test Loss: 0.6876\n",
      "Epoch 594/2000, Train Loss: 0.6302, Test Loss: 0.6844\n",
      "Epoch 595/2000, Train Loss: 0.6300, Test Loss: 0.6842\n",
      "Epoch 596/2000, Train Loss: 0.6311, Test Loss: 0.6937\n",
      "Epoch 597/2000, Train Loss: 0.6307, Test Loss: 0.6845\n",
      "Epoch 598/2000, Train Loss: 0.6300, Test Loss: 0.6779\n",
      "Epoch 599/2000, Train Loss: 0.6304, Test Loss: 0.6825\n",
      "Epoch 600/2000, Train Loss: 0.6300, Test Loss: 0.6800\n",
      "Epoch 601/2000, Train Loss: 0.6314, Test Loss: 0.6798\n",
      "Epoch 602/2000, Train Loss: 0.6304, Test Loss: 0.6880\n",
      "Epoch 603/2000, Train Loss: 0.6312, Test Loss: 0.6783\n",
      "Epoch 604/2000, Train Loss: 0.6297, Test Loss: 0.6866\n",
      "Epoch 605/2000, Train Loss: 0.6306, Test Loss: 0.6825\n",
      "Epoch 606/2000, Train Loss: 0.6306, Test Loss: 0.6745\n",
      "Epoch 607/2000, Train Loss: 0.6295, Test Loss: 0.6859\n",
      "Epoch 608/2000, Train Loss: 0.6298, Test Loss: 0.6812\n",
      "Epoch 609/2000, Train Loss: 0.6299, Test Loss: 0.6807\n",
      "Epoch 610/2000, Train Loss: 0.6317, Test Loss: 0.6838\n",
      "Epoch 611/2000, Train Loss: 0.6306, Test Loss: 0.6840\n",
      "Epoch 612/2000, Train Loss: 0.6305, Test Loss: 0.6823\n",
      "Epoch 613/2000, Train Loss: 0.6287, Test Loss: 0.6846\n",
      "Epoch 614/2000, Train Loss: 0.6296, Test Loss: 0.6808\n",
      "Epoch 615/2000, Train Loss: 0.6312, Test Loss: 0.6787\n",
      "Epoch 616/2000, Train Loss: 0.6307, Test Loss: 0.6844\n",
      "Epoch 617/2000, Train Loss: 0.6311, Test Loss: 0.6824\n",
      "Epoch 618/2000, Train Loss: 0.6297, Test Loss: 0.6865\n",
      "Epoch 619/2000, Train Loss: 0.6295, Test Loss: 0.6838\n",
      "Epoch 620/2000, Train Loss: 0.6289, Test Loss: 0.6780\n",
      "Epoch 621/2000, Train Loss: 0.6305, Test Loss: 0.6839\n",
      "Epoch 622/2000, Train Loss: 0.6305, Test Loss: 0.6819\n",
      "Epoch 623/2000, Train Loss: 0.6297, Test Loss: 0.6822\n",
      "Epoch 624/2000, Train Loss: 0.6307, Test Loss: 0.6833\n",
      "Epoch 625/2000, Train Loss: 0.6306, Test Loss: 0.6793\n",
      "Epoch 626/2000, Train Loss: 0.6301, Test Loss: 0.6824\n",
      "Epoch 627/2000, Train Loss: 0.6299, Test Loss: 0.6768\n",
      "Epoch 628/2000, Train Loss: 0.6311, Test Loss: 0.6780\n",
      "Epoch 629/2000, Train Loss: 0.6298, Test Loss: 0.6961\n",
      "Epoch 630/2000, Train Loss: 0.6296, Test Loss: 0.6797\n",
      "Epoch 631/2000, Train Loss: 0.6302, Test Loss: 0.6806\n",
      "Epoch 632/2000, Train Loss: 0.6292, Test Loss: 0.6929\n",
      "Epoch 633/2000, Train Loss: 0.6318, Test Loss: 0.6833\n",
      "Epoch 634/2000, Train Loss: 0.6300, Test Loss: 0.6904\n",
      "Epoch 635/2000, Train Loss: 0.6294, Test Loss: 0.6971\n",
      "Epoch 636/2000, Train Loss: 0.6294, Test Loss: 0.6818\n",
      "Epoch 637/2000, Train Loss: 0.6293, Test Loss: 0.6887\n",
      "Epoch 638/2000, Train Loss: 0.6316, Test Loss: 0.6880\n",
      "Epoch 639/2000, Train Loss: 0.6302, Test Loss: 0.6887\n",
      "Epoch 640/2000, Train Loss: 0.6293, Test Loss: 0.6771\n",
      "Epoch 641/2000, Train Loss: 0.6288, Test Loss: 0.6885\n",
      "Epoch 642/2000, Train Loss: 0.6296, Test Loss: 0.6824\n",
      "Epoch 643/2000, Train Loss: 0.6300, Test Loss: 0.6855\n",
      "Epoch 644/2000, Train Loss: 0.6310, Test Loss: 0.6799\n",
      "Epoch 645/2000, Train Loss: 0.6300, Test Loss: 0.6814\n",
      "Epoch 646/2000, Train Loss: 0.6310, Test Loss: 0.6779\n",
      "Epoch 647/2000, Train Loss: 0.6290, Test Loss: 0.6804\n",
      "Epoch 648/2000, Train Loss: 0.6289, Test Loss: 0.6789\n",
      "Epoch 649/2000, Train Loss: 0.6302, Test Loss: 0.6797\n",
      "Epoch 650/2000, Train Loss: 0.6302, Test Loss: 0.6796\n",
      "Epoch 651/2000, Train Loss: 0.6288, Test Loss: 0.6771\n",
      "Epoch 652/2000, Train Loss: 0.6292, Test Loss: 0.7032\n",
      "Epoch 653/2000, Train Loss: 0.6309, Test Loss: 0.6814\n",
      "Epoch 654/2000, Train Loss: 0.6285, Test Loss: 0.6800\n",
      "Epoch 655/2000, Train Loss: 0.6286, Test Loss: 0.6799\n",
      "Epoch 656/2000, Train Loss: 0.6294, Test Loss: 0.6887\n",
      "Epoch 657/2000, Train Loss: 0.6310, Test Loss: 0.6853\n",
      "Epoch 658/2000, Train Loss: 0.6286, Test Loss: 0.6766\n",
      "Epoch 659/2000, Train Loss: 0.6291, Test Loss: 0.6763\n",
      "Epoch 660/2000, Train Loss: 0.6291, Test Loss: 0.6829\n",
      "Epoch 661/2000, Train Loss: 0.6296, Test Loss: 0.6816\n",
      "Epoch 662/2000, Train Loss: 0.6299, Test Loss: 0.6923\n",
      "Epoch 663/2000, Train Loss: 0.6306, Test Loss: 0.6814\n",
      "Epoch 664/2000, Train Loss: 0.6298, Test Loss: 0.6814\n",
      "Epoch 665/2000, Train Loss: 0.6294, Test Loss: 0.6826\n",
      "Epoch 666/2000, Train Loss: 0.6293, Test Loss: 0.6841\n",
      "Epoch 667/2000, Train Loss: 0.6302, Test Loss: 0.6815\n",
      "Epoch 668/2000, Train Loss: 0.6283, Test Loss: 0.6820\n",
      "Epoch 669/2000, Train Loss: 0.6297, Test Loss: 0.6845\n",
      "Epoch 670/2000, Train Loss: 0.6292, Test Loss: 0.6883\n",
      "Epoch 671/2000, Train Loss: 0.6331, Test Loss: 0.6830\n",
      "Epoch 672/2000, Train Loss: 0.6301, Test Loss: 0.6841\n",
      "Epoch 673/2000, Train Loss: 0.6308, Test Loss: 0.6929\n",
      "Epoch 674/2000, Train Loss: 0.6295, Test Loss: 0.6771\n",
      "Epoch 675/2000, Train Loss: 0.6312, Test Loss: 0.6837\n",
      "Epoch 676/2000, Train Loss: 0.6304, Test Loss: 0.6910\n",
      "Epoch 677/2000, Train Loss: 0.6288, Test Loss: 0.6869\n",
      "Epoch 678/2000, Train Loss: 0.6291, Test Loss: 0.6818\n",
      "Epoch 679/2000, Train Loss: 0.6283, Test Loss: 0.6788\n",
      "Epoch 680/2000, Train Loss: 0.6278, Test Loss: 0.6848\n",
      "Epoch 681/2000, Train Loss: 0.6311, Test Loss: 0.6803\n",
      "Epoch 682/2000, Train Loss: 0.6284, Test Loss: 0.6797\n",
      "Epoch 683/2000, Train Loss: 0.6290, Test Loss: 0.6780\n",
      "Epoch 684/2000, Train Loss: 0.6289, Test Loss: 0.6812\n",
      "Epoch 685/2000, Train Loss: 0.6304, Test Loss: 0.6781\n",
      "Epoch 686/2000, Train Loss: 0.6297, Test Loss: 0.6794\n",
      "Epoch 687/2000, Train Loss: 0.6294, Test Loss: 0.6818\n",
      "Epoch 688/2000, Train Loss: 0.6292, Test Loss: 0.6857\n",
      "Epoch 689/2000, Train Loss: 0.6288, Test Loss: 0.6785\n",
      "Epoch 690/2000, Train Loss: 0.6288, Test Loss: 0.6782\n",
      "Epoch 691/2000, Train Loss: 0.6292, Test Loss: 0.6839\n",
      "Epoch 692/2000, Train Loss: 0.6295, Test Loss: 0.6842\n",
      "Epoch 693/2000, Train Loss: 0.6283, Test Loss: 0.6830\n",
      "Epoch 694/2000, Train Loss: 0.6291, Test Loss: 0.6823\n",
      "Epoch 695/2000, Train Loss: 0.6290, Test Loss: 0.6793\n",
      "Epoch 696/2000, Train Loss: 0.6285, Test Loss: 0.6814\n",
      "Epoch 697/2000, Train Loss: 0.6293, Test Loss: 0.6817\n",
      "Epoch 698/2000, Train Loss: 0.6299, Test Loss: 0.6803\n",
      "Epoch 699/2000, Train Loss: 0.6297, Test Loss: 0.6798\n",
      "Epoch 700/2000, Train Loss: 0.6295, Test Loss: 0.6793\n",
      "Epoch 701/2000, Train Loss: 0.6289, Test Loss: 0.6903\n",
      "Epoch 702/2000, Train Loss: 0.6291, Test Loss: 0.6830\n",
      "Epoch 703/2000, Train Loss: 0.6290, Test Loss: 0.6959\n",
      "Epoch 704/2000, Train Loss: 0.6310, Test Loss: 0.6817\n",
      "Epoch 705/2000, Train Loss: 0.6289, Test Loss: 0.6841\n",
      "Epoch 706/2000, Train Loss: 0.6307, Test Loss: 0.6838\n",
      "Epoch 707/2000, Train Loss: 0.6295, Test Loss: 0.6808\n",
      "Epoch 708/2000, Train Loss: 0.6282, Test Loss: 0.6782\n",
      "Epoch 709/2000, Train Loss: 0.6292, Test Loss: 0.6861\n",
      "Epoch 710/2000, Train Loss: 0.6307, Test Loss: 0.6758\n",
      "Epoch 711/2000, Train Loss: 0.6299, Test Loss: 0.6779\n",
      "Epoch 712/2000, Train Loss: 0.6282, Test Loss: 0.6898\n",
      "Epoch 713/2000, Train Loss: 0.6290, Test Loss: 0.6873\n",
      "Epoch 714/2000, Train Loss: 0.6306, Test Loss: 0.6882\n",
      "Epoch 715/2000, Train Loss: 0.6285, Test Loss: 0.6827\n",
      "Epoch 716/2000, Train Loss: 0.6298, Test Loss: 0.6783\n",
      "Epoch 717/2000, Train Loss: 0.6295, Test Loss: 0.6889\n",
      "Epoch 718/2000, Train Loss: 0.6285, Test Loss: 0.6831\n",
      "Epoch 719/2000, Train Loss: 0.6301, Test Loss: 0.6837\n",
      "Epoch 720/2000, Train Loss: 0.6274, Test Loss: 0.6789\n",
      "Epoch 721/2000, Train Loss: 0.6289, Test Loss: 0.6803\n",
      "Epoch 722/2000, Train Loss: 0.6289, Test Loss: 0.6794\n",
      "Epoch 723/2000, Train Loss: 0.6301, Test Loss: 0.6935\n",
      "Epoch 724/2000, Train Loss: 0.6305, Test Loss: 0.6793\n",
      "Epoch 725/2000, Train Loss: 0.6302, Test Loss: 0.6805\n",
      "Epoch 726/2000, Train Loss: 0.6298, Test Loss: 0.6795\n",
      "Epoch 727/2000, Train Loss: 0.6295, Test Loss: 0.6894\n",
      "Epoch 728/2000, Train Loss: 0.6287, Test Loss: 0.6855\n",
      "Epoch 729/2000, Train Loss: 0.6285, Test Loss: 0.6787\n",
      "Epoch 730/2000, Train Loss: 0.6294, Test Loss: 0.6837\n",
      "Epoch 731/2000, Train Loss: 0.6282, Test Loss: 0.6805\n",
      "Epoch 732/2000, Train Loss: 0.6285, Test Loss: 0.6844\n",
      "Epoch 733/2000, Train Loss: 0.6291, Test Loss: 0.6915\n",
      "Epoch 734/2000, Train Loss: 0.6280, Test Loss: 0.6839\n",
      "Epoch 735/2000, Train Loss: 0.6290, Test Loss: 0.6770\n",
      "Epoch 736/2000, Train Loss: 0.6287, Test Loss: 0.6809\n",
      "Epoch 737/2000, Train Loss: 0.6294, Test Loss: 0.6812\n",
      "Epoch 738/2000, Train Loss: 0.6278, Test Loss: 0.6802\n",
      "Epoch 739/2000, Train Loss: 0.6288, Test Loss: 0.6966\n",
      "Epoch 740/2000, Train Loss: 0.6279, Test Loss: 0.6771\n",
      "Epoch 741/2000, Train Loss: 0.6284, Test Loss: 0.6823\n",
      "Epoch 742/2000, Train Loss: 0.6273, Test Loss: 0.6785\n",
      "Epoch 743/2000, Train Loss: 0.6291, Test Loss: 0.6778\n",
      "Epoch 744/2000, Train Loss: 0.6289, Test Loss: 0.6894\n",
      "Epoch 745/2000, Train Loss: 0.6292, Test Loss: 0.6838\n",
      "Epoch 746/2000, Train Loss: 0.6293, Test Loss: 0.6792\n",
      "Epoch 747/2000, Train Loss: 0.6287, Test Loss: 0.6794\n",
      "Epoch 748/2000, Train Loss: 0.6283, Test Loss: 0.6833\n",
      "Epoch 749/2000, Train Loss: 0.6287, Test Loss: 0.6858\n",
      "Epoch 750/2000, Train Loss: 0.6285, Test Loss: 0.6851\n",
      "Epoch 751/2000, Train Loss: 0.6281, Test Loss: 0.6843\n",
      "Epoch 752/2000, Train Loss: 0.6274, Test Loss: 0.6811\n",
      "Epoch 753/2000, Train Loss: 0.6284, Test Loss: 0.6785\n",
      "Epoch 754/2000, Train Loss: 0.6278, Test Loss: 0.6789\n",
      "Epoch 755/2000, Train Loss: 0.6306, Test Loss: 0.6796\n",
      "Epoch 756/2000, Train Loss: 0.6285, Test Loss: 0.6790\n",
      "Epoch 757/2000, Train Loss: 0.6286, Test Loss: 0.6775\n",
      "Epoch 758/2000, Train Loss: 0.6299, Test Loss: 0.6765\n",
      "Epoch 759/2000, Train Loss: 0.6287, Test Loss: 0.6777\n",
      "Epoch 760/2000, Train Loss: 0.6286, Test Loss: 0.6796\n",
      "Epoch 761/2000, Train Loss: 0.6274, Test Loss: 0.6771\n",
      "Epoch 762/2000, Train Loss: 0.6279, Test Loss: 0.6928\n",
      "Epoch 763/2000, Train Loss: 0.6281, Test Loss: 0.6870\n",
      "Epoch 764/2000, Train Loss: 0.6280, Test Loss: 0.6825\n",
      "Epoch 765/2000, Train Loss: 0.6272, Test Loss: 0.6818\n",
      "Epoch 766/2000, Train Loss: 0.6288, Test Loss: 0.6789\n",
      "Epoch 767/2000, Train Loss: 0.6293, Test Loss: 0.6768\n",
      "Epoch 768/2000, Train Loss: 0.6289, Test Loss: 0.6851\n",
      "Epoch 769/2000, Train Loss: 0.6291, Test Loss: 0.6863\n",
      "Epoch 770/2000, Train Loss: 0.6295, Test Loss: 0.6839\n",
      "Epoch 771/2000, Train Loss: 0.6279, Test Loss: 0.6782\n",
      "Epoch 772/2000, Train Loss: 0.6281, Test Loss: 0.6830\n",
      "Epoch 773/2000, Train Loss: 0.6284, Test Loss: 0.6776\n",
      "Epoch 774/2000, Train Loss: 0.6292, Test Loss: 0.6973\n",
      "Epoch 775/2000, Train Loss: 0.6280, Test Loss: 0.6816\n",
      "Epoch 776/2000, Train Loss: 0.6271, Test Loss: 0.6810\n",
      "Epoch 777/2000, Train Loss: 0.6286, Test Loss: 0.6951\n",
      "Epoch 778/2000, Train Loss: 0.6280, Test Loss: 0.6808\n",
      "Epoch 779/2000, Train Loss: 0.6291, Test Loss: 0.6796\n",
      "Epoch 780/2000, Train Loss: 0.6281, Test Loss: 0.6809\n",
      "Epoch 781/2000, Train Loss: 0.6288, Test Loss: 0.6786\n",
      "Epoch 782/2000, Train Loss: 0.6288, Test Loss: 0.6814\n",
      "Epoch 783/2000, Train Loss: 0.6301, Test Loss: 0.6922\n",
      "Epoch 784/2000, Train Loss: 0.6278, Test Loss: 0.6769\n",
      "Epoch 785/2000, Train Loss: 0.6278, Test Loss: 0.6852\n",
      "Epoch 786/2000, Train Loss: 0.6285, Test Loss: 0.6878\n",
      "Epoch 787/2000, Train Loss: 0.6278, Test Loss: 0.6887\n",
      "Epoch 788/2000, Train Loss: 0.6281, Test Loss: 0.6828\n",
      "Epoch 789/2000, Train Loss: 0.6298, Test Loss: 0.6778\n",
      "Epoch 790/2000, Train Loss: 0.6275, Test Loss: 0.6784\n",
      "Epoch 791/2000, Train Loss: 0.6297, Test Loss: 0.6836\n",
      "Epoch 792/2000, Train Loss: 0.6290, Test Loss: 0.6867\n",
      "Epoch 793/2000, Train Loss: 0.6280, Test Loss: 0.6859\n",
      "Epoch 794/2000, Train Loss: 0.6288, Test Loss: 0.6842\n",
      "Epoch 795/2000, Train Loss: 0.6284, Test Loss: 0.6839\n",
      "Epoch 796/2000, Train Loss: 0.6284, Test Loss: 0.6771\n",
      "Epoch 797/2000, Train Loss: 0.6285, Test Loss: 0.6822\n",
      "Epoch 798/2000, Train Loss: 0.6274, Test Loss: 0.6795\n",
      "Epoch 799/2000, Train Loss: 0.6275, Test Loss: 0.6802\n",
      "Epoch 800/2000, Train Loss: 0.6281, Test Loss: 0.6770\n",
      "Epoch 801/2000, Train Loss: 0.6277, Test Loss: 0.6877\n",
      "Epoch 802/2000, Train Loss: 0.6283, Test Loss: 0.6794\n",
      "Epoch 803/2000, Train Loss: 0.6276, Test Loss: 0.6791\n",
      "Epoch 804/2000, Train Loss: 0.6279, Test Loss: 0.6796\n",
      "Epoch 805/2000, Train Loss: 0.6273, Test Loss: 0.6758\n",
      "Epoch 806/2000, Train Loss: 0.6276, Test Loss: 0.6809\n",
      "Epoch 807/2000, Train Loss: 0.6272, Test Loss: 0.6809\n",
      "Epoch 808/2000, Train Loss: 0.6296, Test Loss: 0.6897\n",
      "Epoch 809/2000, Train Loss: 0.6288, Test Loss: 0.6833\n",
      "Epoch 810/2000, Train Loss: 0.6279, Test Loss: 0.6876\n",
      "Epoch 811/2000, Train Loss: 0.6290, Test Loss: 0.6861\n",
      "Epoch 812/2000, Train Loss: 0.6302, Test Loss: 0.6804\n",
      "Epoch 813/2000, Train Loss: 0.6278, Test Loss: 0.6782\n",
      "Epoch 814/2000, Train Loss: 0.6284, Test Loss: 0.6822\n",
      "Epoch 815/2000, Train Loss: 0.6275, Test Loss: 0.6840\n",
      "Epoch 816/2000, Train Loss: 0.6280, Test Loss: 0.6824\n",
      "Epoch 817/2000, Train Loss: 0.6286, Test Loss: 0.6785\n",
      "Epoch 818/2000, Train Loss: 0.6288, Test Loss: 0.6806\n",
      "Epoch 819/2000, Train Loss: 0.6271, Test Loss: 0.6846\n",
      "Epoch 820/2000, Train Loss: 0.6285, Test Loss: 0.6811\n",
      "Epoch 821/2000, Train Loss: 0.6289, Test Loss: 0.6784\n",
      "Epoch 822/2000, Train Loss: 0.6279, Test Loss: 0.6873\n",
      "Epoch 823/2000, Train Loss: 0.6278, Test Loss: 0.6811\n",
      "Epoch 824/2000, Train Loss: 0.6271, Test Loss: 0.6775\n",
      "Epoch 825/2000, Train Loss: 0.6277, Test Loss: 0.6900\n",
      "Epoch 826/2000, Train Loss: 0.6274, Test Loss: 0.6810\n",
      "Epoch 827/2000, Train Loss: 0.6285, Test Loss: 0.6804\n",
      "Epoch 828/2000, Train Loss: 0.6266, Test Loss: 0.6793\n",
      "Epoch 829/2000, Train Loss: 0.6282, Test Loss: 0.6819\n",
      "Epoch 830/2000, Train Loss: 0.6296, Test Loss: 0.6766\n",
      "Epoch 831/2000, Train Loss: 0.6276, Test Loss: 0.6792\n",
      "Epoch 832/2000, Train Loss: 0.6274, Test Loss: 0.6811\n",
      "Epoch 833/2000, Train Loss: 0.6283, Test Loss: 0.6824\n",
      "Epoch 834/2000, Train Loss: 0.6280, Test Loss: 0.6787\n",
      "Epoch 835/2000, Train Loss: 0.6284, Test Loss: 0.6807\n",
      "Epoch 836/2000, Train Loss: 0.6284, Test Loss: 0.6988\n",
      "Epoch 837/2000, Train Loss: 0.6276, Test Loss: 0.6829\n",
      "Epoch 838/2000, Train Loss: 0.6285, Test Loss: 0.6772\n",
      "Epoch 839/2000, Train Loss: 0.6284, Test Loss: 0.6766\n",
      "Epoch 840/2000, Train Loss: 0.6276, Test Loss: 0.6793\n",
      "Epoch 841/2000, Train Loss: 0.6267, Test Loss: 0.6808\n",
      "Epoch 842/2000, Train Loss: 0.6278, Test Loss: 0.6973\n",
      "Epoch 843/2000, Train Loss: 0.6272, Test Loss: 0.6852\n",
      "Epoch 844/2000, Train Loss: 0.6284, Test Loss: 0.6877\n",
      "Epoch 845/2000, Train Loss: 0.6274, Test Loss: 0.6814\n",
      "Epoch 846/2000, Train Loss: 0.6271, Test Loss: 0.6820\n",
      "Epoch 847/2000, Train Loss: 0.6270, Test Loss: 0.6854\n",
      "Epoch 848/2000, Train Loss: 0.6279, Test Loss: 0.6807\n",
      "Epoch 849/2000, Train Loss: 0.6279, Test Loss: 0.6824\n",
      "Epoch 850/2000, Train Loss: 0.6267, Test Loss: 0.6875\n",
      "Epoch 851/2000, Train Loss: 0.6273, Test Loss: 0.6837\n",
      "Epoch 852/2000, Train Loss: 0.6284, Test Loss: 0.6762\n",
      "Epoch 853/2000, Train Loss: 0.6286, Test Loss: 0.6860\n",
      "Epoch 854/2000, Train Loss: 0.6284, Test Loss: 0.6878\n",
      "Epoch 855/2000, Train Loss: 0.6276, Test Loss: 0.6795\n",
      "Epoch 856/2000, Train Loss: 0.6290, Test Loss: 0.6826\n",
      "Epoch 857/2000, Train Loss: 0.6275, Test Loss: 0.6782\n",
      "Epoch 858/2000, Train Loss: 0.6269, Test Loss: 0.6782\n",
      "Epoch 859/2000, Train Loss: 0.6277, Test Loss: 0.6849\n",
      "Epoch 860/2000, Train Loss: 0.6288, Test Loss: 0.6831\n",
      "Epoch 861/2000, Train Loss: 0.6274, Test Loss: 0.6891\n",
      "Epoch 862/2000, Train Loss: 0.6271, Test Loss: 0.6833\n",
      "Epoch 863/2000, Train Loss: 0.6269, Test Loss: 0.6859\n",
      "Epoch 864/2000, Train Loss: 0.6280, Test Loss: 0.6854\n",
      "Epoch 865/2000, Train Loss: 0.6275, Test Loss: 0.6812\n",
      "Epoch 866/2000, Train Loss: 0.6275, Test Loss: 0.6807\n",
      "Epoch 867/2000, Train Loss: 0.6276, Test Loss: 0.6835\n",
      "Epoch 868/2000, Train Loss: 0.6272, Test Loss: 0.6840\n",
      "Epoch 869/2000, Train Loss: 0.6270, Test Loss: 0.6811\n",
      "Epoch 870/2000, Train Loss: 0.6272, Test Loss: 0.6766\n",
      "Epoch 871/2000, Train Loss: 0.6273, Test Loss: 0.6783\n",
      "Epoch 872/2000, Train Loss: 0.6283, Test Loss: 0.6881\n",
      "Epoch 873/2000, Train Loss: 0.6277, Test Loss: 0.6762\n",
      "Epoch 874/2000, Train Loss: 0.6266, Test Loss: 0.6800\n",
      "Epoch 875/2000, Train Loss: 0.6275, Test Loss: 0.6864\n",
      "Epoch 876/2000, Train Loss: 0.6273, Test Loss: 0.6818\n",
      "Epoch 877/2000, Train Loss: 0.6279, Test Loss: 0.6768\n",
      "Epoch 878/2000, Train Loss: 0.6270, Test Loss: 0.6800\n",
      "Epoch 879/2000, Train Loss: 0.6272, Test Loss: 0.6799\n",
      "Epoch 880/2000, Train Loss: 0.6275, Test Loss: 0.6910\n",
      "Epoch 881/2000, Train Loss: 0.6267, Test Loss: 0.6864\n",
      "Epoch 882/2000, Train Loss: 0.6268, Test Loss: 0.6814\n",
      "Epoch 883/2000, Train Loss: 0.6275, Test Loss: 0.6857\n",
      "Epoch 884/2000, Train Loss: 0.6268, Test Loss: 0.6895\n",
      "Epoch 885/2000, Train Loss: 0.6286, Test Loss: 0.6810\n",
      "Epoch 886/2000, Train Loss: 0.6271, Test Loss: 0.6890\n",
      "Epoch 887/2000, Train Loss: 0.6280, Test Loss: 0.6854\n",
      "Epoch 888/2000, Train Loss: 0.6265, Test Loss: 0.6809\n",
      "Epoch 889/2000, Train Loss: 0.6281, Test Loss: 0.6896\n",
      "Epoch 890/2000, Train Loss: 0.6276, Test Loss: 0.6800\n",
      "Epoch 891/2000, Train Loss: 0.6273, Test Loss: 0.6843\n",
      "Epoch 892/2000, Train Loss: 0.6272, Test Loss: 0.6794\n",
      "Epoch 893/2000, Train Loss: 0.6268, Test Loss: 0.6945\n",
      "Epoch 894/2000, Train Loss: 0.6270, Test Loss: 0.6791\n",
      "Epoch 895/2000, Train Loss: 0.6267, Test Loss: 0.6769\n",
      "Epoch 896/2000, Train Loss: 0.6282, Test Loss: 0.6880\n",
      "Epoch 897/2000, Train Loss: 0.6277, Test Loss: 0.6984\n",
      "Epoch 898/2000, Train Loss: 0.6276, Test Loss: 0.6851\n",
      "Epoch 899/2000, Train Loss: 0.6288, Test Loss: 0.6816\n",
      "Epoch 900/2000, Train Loss: 0.6265, Test Loss: 0.6893\n",
      "Epoch 901/2000, Train Loss: 0.6284, Test Loss: 0.6824\n",
      "Epoch 902/2000, Train Loss: 0.6265, Test Loss: 0.6882\n",
      "Epoch 903/2000, Train Loss: 0.6299, Test Loss: 0.6892\n",
      "Epoch 904/2000, Train Loss: 0.6285, Test Loss: 0.6852\n",
      "Epoch 905/2000, Train Loss: 0.6278, Test Loss: 0.6757\n",
      "Epoch 906/2000, Train Loss: 0.6277, Test Loss: 0.6795\n",
      "Epoch 907/2000, Train Loss: 0.6268, Test Loss: 0.6848\n",
      "Epoch 908/2000, Train Loss: 0.6266, Test Loss: 0.6869\n",
      "Epoch 909/2000, Train Loss: 0.6267, Test Loss: 0.6829\n",
      "Epoch 910/2000, Train Loss: 0.6269, Test Loss: 0.6826\n",
      "Epoch 911/2000, Train Loss: 0.6273, Test Loss: 0.6862\n",
      "Epoch 912/2000, Train Loss: 0.6283, Test Loss: 0.6763\n",
      "Epoch 913/2000, Train Loss: 0.6266, Test Loss: 0.6889\n",
      "Epoch 914/2000, Train Loss: 0.6274, Test Loss: 0.6825\n",
      "Epoch 915/2000, Train Loss: 0.6268, Test Loss: 0.6907\n",
      "Epoch 916/2000, Train Loss: 0.6270, Test Loss: 0.6861\n",
      "Epoch 917/2000, Train Loss: 0.6273, Test Loss: 0.6835\n",
      "Epoch 918/2000, Train Loss: 0.6278, Test Loss: 0.6816\n",
      "Epoch 919/2000, Train Loss: 0.6265, Test Loss: 0.6798\n",
      "Epoch 920/2000, Train Loss: 0.6270, Test Loss: 0.6791\n",
      "Epoch 921/2000, Train Loss: 0.6260, Test Loss: 0.6788\n",
      "Epoch 922/2000, Train Loss: 0.6268, Test Loss: 0.6873\n",
      "Epoch 923/2000, Train Loss: 0.6262, Test Loss: 0.6899\n",
      "Epoch 924/2000, Train Loss: 0.6288, Test Loss: 0.6848\n",
      "Epoch 925/2000, Train Loss: 0.6269, Test Loss: 0.6921\n",
      "Epoch 926/2000, Train Loss: 0.6259, Test Loss: 0.6790\n",
      "Epoch 927/2000, Train Loss: 0.6261, Test Loss: 0.6748\n",
      "Epoch 928/2000, Train Loss: 0.6277, Test Loss: 0.6778\n",
      "Epoch 929/2000, Train Loss: 0.6267, Test Loss: 0.6778\n",
      "Epoch 930/2000, Train Loss: 0.6264, Test Loss: 0.6852\n",
      "Epoch 931/2000, Train Loss: 0.6272, Test Loss: 0.6786\n",
      "Epoch 932/2000, Train Loss: 0.6268, Test Loss: 0.6812\n",
      "Epoch 933/2000, Train Loss: 0.6269, Test Loss: 0.6828\n",
      "Epoch 934/2000, Train Loss: 0.6265, Test Loss: 0.6830\n",
      "Epoch 935/2000, Train Loss: 0.6265, Test Loss: 0.6778\n",
      "Epoch 936/2000, Train Loss: 0.6279, Test Loss: 0.6842\n",
      "Epoch 937/2000, Train Loss: 0.6277, Test Loss: 0.6807\n",
      "Epoch 938/2000, Train Loss: 0.6268, Test Loss: 0.6858\n",
      "Epoch 939/2000, Train Loss: 0.6280, Test Loss: 0.6792\n",
      "Epoch 940/2000, Train Loss: 0.6271, Test Loss: 0.6909\n",
      "Epoch 941/2000, Train Loss: 0.6263, Test Loss: 0.6780\n",
      "Epoch 942/2000, Train Loss: 0.6266, Test Loss: 0.6815\n",
      "Epoch 943/2000, Train Loss: 0.6272, Test Loss: 0.6798\n",
      "Epoch 944/2000, Train Loss: 0.6267, Test Loss: 0.6790\n",
      "Epoch 945/2000, Train Loss: 0.6275, Test Loss: 0.6845\n",
      "Epoch 946/2000, Train Loss: 0.6267, Test Loss: 0.6864\n",
      "Epoch 947/2000, Train Loss: 0.6270, Test Loss: 0.6813\n",
      "Epoch 948/2000, Train Loss: 0.6273, Test Loss: 0.6863\n",
      "Epoch 949/2000, Train Loss: 0.6271, Test Loss: 0.6849\n",
      "Epoch 950/2000, Train Loss: 0.6270, Test Loss: 0.6808\n",
      "Epoch 951/2000, Train Loss: 0.6264, Test Loss: 0.6837\n",
      "Epoch 952/2000, Train Loss: 0.6278, Test Loss: 0.6802\n",
      "Epoch 953/2000, Train Loss: 0.6267, Test Loss: 0.6801\n",
      "Epoch 954/2000, Train Loss: 0.6276, Test Loss: 0.6875\n",
      "Epoch 955/2000, Train Loss: 0.6268, Test Loss: 0.6793\n",
      "Epoch 956/2000, Train Loss: 0.6278, Test Loss: 0.6774\n",
      "Epoch 957/2000, Train Loss: 0.6273, Test Loss: 0.6831\n",
      "Epoch 958/2000, Train Loss: 0.6271, Test Loss: 0.6762\n",
      "Epoch 959/2000, Train Loss: 0.6268, Test Loss: 0.6763\n",
      "Epoch 960/2000, Train Loss: 0.6261, Test Loss: 0.6845\n",
      "Epoch 961/2000, Train Loss: 0.6271, Test Loss: 0.6809\n",
      "Epoch 962/2000, Train Loss: 0.6274, Test Loss: 0.6796\n",
      "Epoch 963/2000, Train Loss: 0.6267, Test Loss: 0.6812\n",
      "Epoch 964/2000, Train Loss: 0.6264, Test Loss: 0.6762\n",
      "Epoch 965/2000, Train Loss: 0.6270, Test Loss: 0.6768\n",
      "Epoch 966/2000, Train Loss: 0.6258, Test Loss: 0.6814\n",
      "Epoch 967/2000, Train Loss: 0.6259, Test Loss: 0.7111\n",
      "Epoch 968/2000, Train Loss: 0.6268, Test Loss: 0.6804\n",
      "Epoch 969/2000, Train Loss: 0.6271, Test Loss: 0.6873\n",
      "Epoch 970/2000, Train Loss: 0.6277, Test Loss: 0.6844\n",
      "Epoch 971/2000, Train Loss: 0.6275, Test Loss: 0.6832\n",
      "Epoch 972/2000, Train Loss: 0.6261, Test Loss: 0.6816\n",
      "Epoch 973/2000, Train Loss: 0.6267, Test Loss: 0.6805\n",
      "Epoch 974/2000, Train Loss: 0.6262, Test Loss: 0.6758\n",
      "Epoch 975/2000, Train Loss: 0.6266, Test Loss: 0.6783\n",
      "Epoch 976/2000, Train Loss: 0.6290, Test Loss: 0.6872\n",
      "Epoch 977/2000, Train Loss: 0.6271, Test Loss: 0.6878\n",
      "Epoch 978/2000, Train Loss: 0.6252, Test Loss: 0.6792\n",
      "Epoch 979/2000, Train Loss: 0.6263, Test Loss: 0.6887\n",
      "Epoch 980/2000, Train Loss: 0.6276, Test Loss: 0.6783\n",
      "Epoch 981/2000, Train Loss: 0.6263, Test Loss: 0.6779\n",
      "Epoch 982/2000, Train Loss: 0.6263, Test Loss: 0.6813\n",
      "Epoch 983/2000, Train Loss: 0.6254, Test Loss: 0.6766\n",
      "Epoch 984/2000, Train Loss: 0.6276, Test Loss: 0.6809\n",
      "Epoch 985/2000, Train Loss: 0.6259, Test Loss: 0.6920\n",
      "Epoch 986/2000, Train Loss: 0.6258, Test Loss: 0.6780\n",
      "Epoch 987/2000, Train Loss: 0.6259, Test Loss: 0.6782\n",
      "Epoch 988/2000, Train Loss: 0.6261, Test Loss: 0.6805\n",
      "Epoch 989/2000, Train Loss: 0.6264, Test Loss: 0.6785\n",
      "Epoch 990/2000, Train Loss: 0.6257, Test Loss: 0.6774\n",
      "Epoch 991/2000, Train Loss: 0.6265, Test Loss: 0.6817\n",
      "Epoch 992/2000, Train Loss: 0.6276, Test Loss: 0.6846\n",
      "Epoch 993/2000, Train Loss: 0.6270, Test Loss: 0.6838\n",
      "Epoch 994/2000, Train Loss: 0.6267, Test Loss: 0.6779\n",
      "Epoch 995/2000, Train Loss: 0.6268, Test Loss: 0.6813\n",
      "Epoch 996/2000, Train Loss: 0.6266, Test Loss: 0.6798\n",
      "Epoch 997/2000, Train Loss: 0.6276, Test Loss: 0.6813\n",
      "Epoch 998/2000, Train Loss: 0.6266, Test Loss: 0.6860\n",
      "Epoch 999/2000, Train Loss: 0.6266, Test Loss: 0.6784\n",
      "Epoch 1000/2000, Train Loss: 0.6265, Test Loss: 0.6957\n",
      "Epoch 1001/2000, Train Loss: 0.6263, Test Loss: 0.6833\n",
      "Epoch 1002/2000, Train Loss: 0.6256, Test Loss: 0.6806\n",
      "Epoch 1003/2000, Train Loss: 0.6265, Test Loss: 0.6819\n",
      "Epoch 1004/2000, Train Loss: 0.6261, Test Loss: 0.6825\n",
      "Epoch 1005/2000, Train Loss: 0.6278, Test Loss: 0.6773\n",
      "Epoch 1006/2000, Train Loss: 0.6275, Test Loss: 0.6879\n",
      "Epoch 1007/2000, Train Loss: 0.6256, Test Loss: 0.6910\n",
      "Epoch 1008/2000, Train Loss: 0.6264, Test Loss: 0.6820\n",
      "Epoch 1009/2000, Train Loss: 0.6262, Test Loss: 0.6797\n",
      "Epoch 1010/2000, Train Loss: 0.6261, Test Loss: 0.6804\n",
      "Epoch 1011/2000, Train Loss: 0.6265, Test Loss: 0.6775\n",
      "Epoch 1012/2000, Train Loss: 0.6285, Test Loss: 0.6804\n",
      "Epoch 1013/2000, Train Loss: 0.6260, Test Loss: 0.6973\n",
      "Epoch 1014/2000, Train Loss: 0.6268, Test Loss: 0.6802\n",
      "Epoch 1015/2000, Train Loss: 0.6272, Test Loss: 0.6855\n",
      "Epoch 1016/2000, Train Loss: 0.6269, Test Loss: 0.6776\n",
      "Epoch 1017/2000, Train Loss: 0.6263, Test Loss: 0.6773\n",
      "Epoch 1018/2000, Train Loss: 0.6271, Test Loss: 0.6804\n",
      "Epoch 1019/2000, Train Loss: 0.6273, Test Loss: 0.6825\n",
      "Epoch 1020/2000, Train Loss: 0.6270, Test Loss: 0.6900\n",
      "Epoch 1021/2000, Train Loss: 0.6259, Test Loss: 0.6780\n",
      "Epoch 1022/2000, Train Loss: 0.6265, Test Loss: 0.6875\n",
      "Epoch 1023/2000, Train Loss: 0.6272, Test Loss: 0.6857\n",
      "Epoch 1024/2000, Train Loss: 0.6265, Test Loss: 0.6812\n",
      "Epoch 1025/2000, Train Loss: 0.6265, Test Loss: 0.6826\n",
      "Epoch 1026/2000, Train Loss: 0.6259, Test Loss: 0.6834\n",
      "Epoch 1027/2000, Train Loss: 0.6273, Test Loss: 0.6780\n",
      "Epoch 1028/2000, Train Loss: 0.6271, Test Loss: 0.6851\n",
      "Epoch 1029/2000, Train Loss: 0.6271, Test Loss: 0.6872\n",
      "Epoch 1030/2000, Train Loss: 0.6264, Test Loss: 0.6893\n",
      "Epoch 1031/2000, Train Loss: 0.6269, Test Loss: 0.6836\n",
      "Epoch 1032/2000, Train Loss: 0.6253, Test Loss: 0.6810\n",
      "Epoch 1033/2000, Train Loss: 0.6259, Test Loss: 0.6758\n",
      "Epoch 1034/2000, Train Loss: 0.6272, Test Loss: 0.6854\n",
      "Epoch 1035/2000, Train Loss: 0.6260, Test Loss: 0.6877\n",
      "Epoch 1036/2000, Train Loss: 0.6260, Test Loss: 0.6790\n",
      "Epoch 1037/2000, Train Loss: 0.6261, Test Loss: 0.6798\n",
      "Epoch 1038/2000, Train Loss: 0.6260, Test Loss: 0.6850\n",
      "Epoch 1039/2000, Train Loss: 0.6265, Test Loss: 0.6814\n",
      "Epoch 1040/2000, Train Loss: 0.6263, Test Loss: 0.6804\n",
      "Epoch 1041/2000, Train Loss: 0.6256, Test Loss: 0.6857\n",
      "Epoch 1042/2000, Train Loss: 0.6262, Test Loss: 0.6905\n",
      "Epoch 1043/2000, Train Loss: 0.6268, Test Loss: 0.6793\n",
      "Epoch 1044/2000, Train Loss: 0.6261, Test Loss: 0.6857\n",
      "Epoch 1045/2000, Train Loss: 0.6266, Test Loss: 0.6841\n",
      "Epoch 1046/2000, Train Loss: 0.6267, Test Loss: 0.6808\n",
      "Epoch 1047/2000, Train Loss: 0.6273, Test Loss: 0.6798\n",
      "Epoch 1048/2000, Train Loss: 0.6281, Test Loss: 0.6824\n",
      "Epoch 1049/2000, Train Loss: 0.6271, Test Loss: 0.6856\n",
      "Epoch 1050/2000, Train Loss: 0.6260, Test Loss: 0.6794\n",
      "Epoch 1051/2000, Train Loss: 0.6262, Test Loss: 0.6828\n",
      "Epoch 1052/2000, Train Loss: 0.6254, Test Loss: 0.6852\n",
      "Epoch 1053/2000, Train Loss: 0.6266, Test Loss: 0.6836\n",
      "Epoch 1054/2000, Train Loss: 0.6266, Test Loss: 0.6803\n",
      "Epoch 1055/2000, Train Loss: 0.6266, Test Loss: 0.6897\n",
      "Epoch 1056/2000, Train Loss: 0.6271, Test Loss: 0.6798\n",
      "Epoch 1057/2000, Train Loss: 0.6250, Test Loss: 0.6813\n",
      "Epoch 1058/2000, Train Loss: 0.6269, Test Loss: 0.6790\n",
      "Epoch 1059/2000, Train Loss: 0.6255, Test Loss: 0.6852\n",
      "Epoch 1060/2000, Train Loss: 0.6267, Test Loss: 0.6901\n",
      "Epoch 1061/2000, Train Loss: 0.6258, Test Loss: 0.6785\n",
      "Epoch 1062/2000, Train Loss: 0.6260, Test Loss: 0.6838\n",
      "Epoch 1063/2000, Train Loss: 0.6271, Test Loss: 0.6797\n",
      "Epoch 1064/2000, Train Loss: 0.6261, Test Loss: 0.6794\n",
      "Epoch 1065/2000, Train Loss: 0.6261, Test Loss: 0.6817\n",
      "Epoch 1066/2000, Train Loss: 0.6253, Test Loss: 0.6796\n",
      "Epoch 1067/2000, Train Loss: 0.6268, Test Loss: 0.6807\n",
      "Epoch 1068/2000, Train Loss: 0.6276, Test Loss: 0.6883\n",
      "Epoch 1069/2000, Train Loss: 0.6253, Test Loss: 0.6801\n",
      "Epoch 1070/2000, Train Loss: 0.6267, Test Loss: 0.6837\n",
      "Epoch 1071/2000, Train Loss: 0.6264, Test Loss: 0.6802\n",
      "Epoch 1072/2000, Train Loss: 0.6266, Test Loss: 0.6846\n",
      "Epoch 1073/2000, Train Loss: 0.6265, Test Loss: 0.6829\n",
      "Epoch 1074/2000, Train Loss: 0.6257, Test Loss: 0.6849\n",
      "Epoch 1075/2000, Train Loss: 0.6265, Test Loss: 0.6783\n",
      "Epoch 1076/2000, Train Loss: 0.6257, Test Loss: 0.6815\n",
      "Epoch 1077/2000, Train Loss: 0.6273, Test Loss: 0.6784\n",
      "Epoch 1078/2000, Train Loss: 0.6263, Test Loss: 0.6752\n",
      "Epoch 1079/2000, Train Loss: 0.6260, Test Loss: 0.6849\n",
      "Epoch 1080/2000, Train Loss: 0.6258, Test Loss: 0.6821\n",
      "Epoch 1081/2000, Train Loss: 0.6271, Test Loss: 0.6806\n",
      "Epoch 1082/2000, Train Loss: 0.6270, Test Loss: 0.6874\n",
      "Epoch 1083/2000, Train Loss: 0.6263, Test Loss: 0.6801\n",
      "Epoch 1084/2000, Train Loss: 0.6259, Test Loss: 0.6813\n",
      "Epoch 1085/2000, Train Loss: 0.6262, Test Loss: 0.6853\n",
      "Epoch 1086/2000, Train Loss: 0.6268, Test Loss: 0.6783\n",
      "Epoch 1087/2000, Train Loss: 0.6265, Test Loss: 0.6815\n",
      "Epoch 1088/2000, Train Loss: 0.6255, Test Loss: 0.6822\n",
      "Epoch 1089/2000, Train Loss: 0.6253, Test Loss: 0.6814\n",
      "Epoch 1090/2000, Train Loss: 0.6257, Test Loss: 0.6837\n",
      "Epoch 1091/2000, Train Loss: 0.6265, Test Loss: 0.6812\n",
      "Epoch 1092/2000, Train Loss: 0.6258, Test Loss: 0.6863\n",
      "Epoch 1093/2000, Train Loss: 0.6260, Test Loss: 0.6777\n",
      "Epoch 1094/2000, Train Loss: 0.6260, Test Loss: 0.6840\n",
      "Epoch 1095/2000, Train Loss: 0.6277, Test Loss: 0.6804\n",
      "Epoch 1096/2000, Train Loss: 0.6269, Test Loss: 0.6850\n",
      "Epoch 1097/2000, Train Loss: 0.6263, Test Loss: 0.6962\n",
      "Epoch 1098/2000, Train Loss: 0.6261, Test Loss: 0.6823\n",
      "Epoch 1099/2000, Train Loss: 0.6263, Test Loss: 0.6905\n",
      "Epoch 1100/2000, Train Loss: 0.6264, Test Loss: 0.6890\n",
      "Epoch 1101/2000, Train Loss: 0.6253, Test Loss: 0.6812\n",
      "Epoch 1102/2000, Train Loss: 0.6259, Test Loss: 0.6849\n",
      "Epoch 1103/2000, Train Loss: 0.6269, Test Loss: 0.6779\n",
      "Epoch 1104/2000, Train Loss: 0.6256, Test Loss: 0.6869\n",
      "Epoch 1105/2000, Train Loss: 0.6266, Test Loss: 0.6876\n",
      "Epoch 1106/2000, Train Loss: 0.6255, Test Loss: 0.6816\n",
      "Epoch 1107/2000, Train Loss: 0.6267, Test Loss: 0.6824\n",
      "Epoch 1108/2000, Train Loss: 0.6263, Test Loss: 0.6817\n",
      "Epoch 1109/2000, Train Loss: 0.6270, Test Loss: 0.6779\n",
      "Epoch 1110/2000, Train Loss: 0.6272, Test Loss: 0.6809\n",
      "Epoch 1111/2000, Train Loss: 0.6263, Test Loss: 0.6808\n",
      "Epoch 1112/2000, Train Loss: 0.6255, Test Loss: 0.6858\n",
      "Epoch 1113/2000, Train Loss: 0.6255, Test Loss: 0.6889\n",
      "Epoch 1114/2000, Train Loss: 0.6265, Test Loss: 0.6821\n",
      "Epoch 1115/2000, Train Loss: 0.6256, Test Loss: 0.6799\n",
      "Epoch 1116/2000, Train Loss: 0.6263, Test Loss: 0.6774\n",
      "Epoch 1117/2000, Train Loss: 0.6262, Test Loss: 0.6883\n",
      "Epoch 1118/2000, Train Loss: 0.6276, Test Loss: 0.6832\n",
      "Epoch 1119/2000, Train Loss: 0.6257, Test Loss: 0.6792\n",
      "Epoch 1120/2000, Train Loss: 0.6254, Test Loss: 0.6856\n",
      "Epoch 1121/2000, Train Loss: 0.6254, Test Loss: 0.6786\n",
      "Epoch 1122/2000, Train Loss: 0.6262, Test Loss: 0.6818\n",
      "Epoch 1123/2000, Train Loss: 0.6258, Test Loss: 0.6793\n",
      "Epoch 1124/2000, Train Loss: 0.6268, Test Loss: 0.6849\n",
      "Epoch 1125/2000, Train Loss: 0.6246, Test Loss: 0.6817\n",
      "Epoch 1126/2000, Train Loss: 0.6257, Test Loss: 0.6792\n",
      "Epoch 1127/2000, Train Loss: 0.6261, Test Loss: 0.6842\n",
      "Epoch 1128/2000, Train Loss: 0.6270, Test Loss: 0.6885\n",
      "Epoch 1129/2000, Train Loss: 0.6264, Test Loss: 0.6828\n",
      "Epoch 1130/2000, Train Loss: 0.6261, Test Loss: 0.6917\n",
      "Epoch 1131/2000, Train Loss: 0.6252, Test Loss: 0.6815\n",
      "Epoch 1132/2000, Train Loss: 0.6255, Test Loss: 0.6896\n",
      "Epoch 1133/2000, Train Loss: 0.6250, Test Loss: 0.7037\n",
      "Epoch 1134/2000, Train Loss: 0.6248, Test Loss: 0.6792\n",
      "Epoch 1135/2000, Train Loss: 0.6258, Test Loss: 0.6958\n",
      "Epoch 1136/2000, Train Loss: 0.6281, Test Loss: 0.6813\n",
      "Epoch 1137/2000, Train Loss: 0.6253, Test Loss: 0.6826\n",
      "Epoch 1138/2000, Train Loss: 0.6255, Test Loss: 0.6793\n",
      "Epoch 1139/2000, Train Loss: 0.6258, Test Loss: 0.6848\n",
      "Epoch 1140/2000, Train Loss: 0.6256, Test Loss: 0.6874\n",
      "Epoch 1141/2000, Train Loss: 0.6254, Test Loss: 0.6796\n",
      "Epoch 1142/2000, Train Loss: 0.6255, Test Loss: 0.6800\n",
      "Epoch 1143/2000, Train Loss: 0.6254, Test Loss: 0.6824\n",
      "Epoch 1144/2000, Train Loss: 0.6245, Test Loss: 0.6823\n",
      "Epoch 1145/2000, Train Loss: 0.6266, Test Loss: 0.6839\n",
      "Epoch 1146/2000, Train Loss: 0.6258, Test Loss: 0.6805\n",
      "Epoch 1147/2000, Train Loss: 0.6263, Test Loss: 0.6854\n",
      "Epoch 1148/2000, Train Loss: 0.6252, Test Loss: 0.6802\n",
      "Epoch 1149/2000, Train Loss: 0.6266, Test Loss: 0.6831\n",
      "Epoch 1150/2000, Train Loss: 0.6249, Test Loss: 0.6812\n",
      "Epoch 1151/2000, Train Loss: 0.6256, Test Loss: 0.6862\n",
      "Epoch 1152/2000, Train Loss: 0.6280, Test Loss: 0.6815\n",
      "Epoch 1153/2000, Train Loss: 0.6264, Test Loss: 0.6802\n",
      "Epoch 1154/2000, Train Loss: 0.6264, Test Loss: 0.6860\n",
      "Epoch 1155/2000, Train Loss: 0.6260, Test Loss: 0.6828\n",
      "Epoch 1156/2000, Train Loss: 0.6258, Test Loss: 0.6849\n",
      "Epoch 1157/2000, Train Loss: 0.6252, Test Loss: 0.6787\n",
      "Epoch 1158/2000, Train Loss: 0.6261, Test Loss: 0.6922\n",
      "Epoch 1159/2000, Train Loss: 0.6250, Test Loss: 0.6808\n",
      "Epoch 1160/2000, Train Loss: 0.6259, Test Loss: 0.6858\n",
      "Epoch 1161/2000, Train Loss: 0.6252, Test Loss: 0.6825\n",
      "Epoch 1162/2000, Train Loss: 0.6256, Test Loss: 0.6853\n",
      "Epoch 1163/2000, Train Loss: 0.6270, Test Loss: 0.6882\n",
      "Epoch 1164/2000, Train Loss: 0.6258, Test Loss: 0.6784\n",
      "Epoch 1165/2000, Train Loss: 0.6259, Test Loss: 0.6903\n",
      "Epoch 1166/2000, Train Loss: 0.6267, Test Loss: 0.6870\n",
      "Epoch 1167/2000, Train Loss: 0.6253, Test Loss: 0.6878\n",
      "Epoch 1168/2000, Train Loss: 0.6256, Test Loss: 0.6793\n",
      "Epoch 1169/2000, Train Loss: 0.6261, Test Loss: 0.6831\n",
      "Epoch 1170/2000, Train Loss: 0.6255, Test Loss: 0.6774\n",
      "Epoch 1171/2000, Train Loss: 0.6257, Test Loss: 0.6806\n",
      "Epoch 1172/2000, Train Loss: 0.6259, Test Loss: 0.6811\n",
      "Epoch 1173/2000, Train Loss: 0.6252, Test Loss: 0.6805\n",
      "Epoch 1174/2000, Train Loss: 0.6267, Test Loss: 0.6857\n",
      "Epoch 1175/2000, Train Loss: 0.6259, Test Loss: 0.6808\n",
      "Epoch 1176/2000, Train Loss: 0.6265, Test Loss: 0.6789\n",
      "Epoch 1177/2000, Train Loss: 0.6261, Test Loss: 0.6813\n",
      "Epoch 1178/2000, Train Loss: 0.6254, Test Loss: 0.6831\n",
      "Epoch 1179/2000, Train Loss: 0.6261, Test Loss: 0.6827\n",
      "Epoch 1180/2000, Train Loss: 0.6254, Test Loss: 0.6856\n",
      "Epoch 1181/2000, Train Loss: 0.6258, Test Loss: 0.6856\n",
      "Epoch 1182/2000, Train Loss: 0.6266, Test Loss: 0.6795\n",
      "Epoch 1183/2000, Train Loss: 0.6251, Test Loss: 0.6810\n",
      "Epoch 1184/2000, Train Loss: 0.6260, Test Loss: 0.6791\n",
      "Epoch 1185/2000, Train Loss: 0.6250, Test Loss: 0.6875\n",
      "Epoch 1186/2000, Train Loss: 0.6249, Test Loss: 0.6844\n",
      "Epoch 1187/2000, Train Loss: 0.6246, Test Loss: 0.6832\n",
      "Epoch 1188/2000, Train Loss: 0.6256, Test Loss: 0.6839\n",
      "Epoch 1189/2000, Train Loss: 0.6260, Test Loss: 0.6857\n",
      "Epoch 1190/2000, Train Loss: 0.6254, Test Loss: 0.6831\n",
      "Epoch 1191/2000, Train Loss: 0.6260, Test Loss: 0.6816\n",
      "Epoch 1192/2000, Train Loss: 0.6262, Test Loss: 0.7031\n",
      "Epoch 1193/2000, Train Loss: 0.6252, Test Loss: 0.6923\n",
      "Epoch 1194/2000, Train Loss: 0.6254, Test Loss: 0.6826\n",
      "Epoch 1195/2000, Train Loss: 0.6255, Test Loss: 0.6831\n",
      "Epoch 1196/2000, Train Loss: 0.6253, Test Loss: 0.6796\n",
      "Epoch 1197/2000, Train Loss: 0.6259, Test Loss: 0.6885\n",
      "Epoch 1198/2000, Train Loss: 0.6251, Test Loss: 0.6823\n",
      "Epoch 1199/2000, Train Loss: 0.6260, Test Loss: 0.6825\n",
      "Epoch 1200/2000, Train Loss: 0.6259, Test Loss: 0.6806\n",
      "Epoch 1201/2000, Train Loss: 0.6261, Test Loss: 0.6783\n",
      "Epoch 1202/2000, Train Loss: 0.6249, Test Loss: 0.6781\n",
      "Epoch 1203/2000, Train Loss: 0.6259, Test Loss: 0.6844\n",
      "Epoch 1204/2000, Train Loss: 0.6247, Test Loss: 0.6891\n",
      "Epoch 1205/2000, Train Loss: 0.6253, Test Loss: 0.6825\n",
      "Epoch 1206/2000, Train Loss: 0.6252, Test Loss: 0.6864\n",
      "Epoch 1207/2000, Train Loss: 0.6256, Test Loss: 0.7012\n",
      "Epoch 1208/2000, Train Loss: 0.6262, Test Loss: 0.6889\n",
      "Epoch 1209/2000, Train Loss: 0.6252, Test Loss: 0.6847\n",
      "Epoch 1210/2000, Train Loss: 0.6257, Test Loss: 0.6863\n",
      "Epoch 1211/2000, Train Loss: 0.6248, Test Loss: 0.6773\n",
      "Epoch 1212/2000, Train Loss: 0.6255, Test Loss: 0.6857\n",
      "Epoch 1213/2000, Train Loss: 0.6248, Test Loss: 0.6825\n",
      "Epoch 1214/2000, Train Loss: 0.6263, Test Loss: 0.6803\n",
      "Epoch 1215/2000, Train Loss: 0.6262, Test Loss: 0.6809\n",
      "Epoch 1216/2000, Train Loss: 0.6250, Test Loss: 0.6848\n",
      "Epoch 1217/2000, Train Loss: 0.6250, Test Loss: 0.6798\n",
      "Epoch 1218/2000, Train Loss: 0.6253, Test Loss: 0.6804\n",
      "Epoch 1219/2000, Train Loss: 0.6255, Test Loss: 0.6814\n",
      "Epoch 1220/2000, Train Loss: 0.6267, Test Loss: 0.6879\n",
      "Epoch 1221/2000, Train Loss: 0.6246, Test Loss: 0.6845\n",
      "Epoch 1222/2000, Train Loss: 0.6257, Test Loss: 0.6871\n",
      "Epoch 1223/2000, Train Loss: 0.6253, Test Loss: 0.6816\n",
      "Epoch 1224/2000, Train Loss: 0.6254, Test Loss: 0.6888\n",
      "Epoch 1225/2000, Train Loss: 0.6260, Test Loss: 0.6854\n",
      "Epoch 1226/2000, Train Loss: 0.6259, Test Loss: 0.6813\n",
      "Epoch 1227/2000, Train Loss: 0.6258, Test Loss: 0.6818\n",
      "Epoch 1228/2000, Train Loss: 0.6245, Test Loss: 0.6834\n",
      "Epoch 1229/2000, Train Loss: 0.6247, Test Loss: 0.6802\n",
      "Epoch 1230/2000, Train Loss: 0.6250, Test Loss: 0.6824\n",
      "Epoch 1231/2000, Train Loss: 0.6262, Test Loss: 0.6835\n",
      "Epoch 1232/2000, Train Loss: 0.6253, Test Loss: 0.6862\n",
      "Epoch 1233/2000, Train Loss: 0.6250, Test Loss: 0.6819\n",
      "Epoch 1234/2000, Train Loss: 0.6243, Test Loss: 0.6858\n",
      "Epoch 1235/2000, Train Loss: 0.6256, Test Loss: 0.6844\n",
      "Epoch 1236/2000, Train Loss: 0.6263, Test Loss: 0.6868\n",
      "Epoch 1237/2000, Train Loss: 0.6258, Test Loss: 0.6794\n",
      "Epoch 1238/2000, Train Loss: 0.6252, Test Loss: 0.6825\n",
      "Epoch 1239/2000, Train Loss: 0.6243, Test Loss: 0.6818\n",
      "Epoch 1240/2000, Train Loss: 0.6260, Test Loss: 0.6851\n",
      "Epoch 1241/2000, Train Loss: 0.6258, Test Loss: 0.6776\n",
      "Epoch 1242/2000, Train Loss: 0.6260, Test Loss: 0.6855\n",
      "Epoch 1243/2000, Train Loss: 0.6253, Test Loss: 0.6847\n",
      "Epoch 1244/2000, Train Loss: 0.6249, Test Loss: 0.6837\n",
      "Epoch 1245/2000, Train Loss: 0.6259, Test Loss: 0.6780\n",
      "Epoch 1246/2000, Train Loss: 0.6255, Test Loss: 0.6904\n",
      "Epoch 1247/2000, Train Loss: 0.6249, Test Loss: 0.6817\n",
      "Epoch 1248/2000, Train Loss: 0.6256, Test Loss: 0.6860\n",
      "Epoch 1249/2000, Train Loss: 0.6263, Test Loss: 0.6820\n",
      "Epoch 1250/2000, Train Loss: 0.6264, Test Loss: 0.6905\n",
      "Epoch 1251/2000, Train Loss: 0.6250, Test Loss: 0.6863\n",
      "Epoch 1252/2000, Train Loss: 0.6250, Test Loss: 0.6792\n",
      "Epoch 1253/2000, Train Loss: 0.6259, Test Loss: 0.6806\n",
      "Epoch 1254/2000, Train Loss: 0.6258, Test Loss: 0.6846\n",
      "Epoch 1255/2000, Train Loss: 0.6250, Test Loss: 0.6842\n",
      "Epoch 1256/2000, Train Loss: 0.6254, Test Loss: 0.6892\n",
      "Epoch 1257/2000, Train Loss: 0.6259, Test Loss: 0.6875\n",
      "Epoch 1258/2000, Train Loss: 0.6291, Test Loss: 0.6817\n",
      "Epoch 1259/2000, Train Loss: 0.6248, Test Loss: 0.6807\n",
      "Epoch 1260/2000, Train Loss: 0.6243, Test Loss: 0.6793\n",
      "Epoch 1261/2000, Train Loss: 0.6263, Test Loss: 0.6935\n",
      "Epoch 1262/2000, Train Loss: 0.6261, Test Loss: 0.6831\n",
      "Epoch 1263/2000, Train Loss: 0.6253, Test Loss: 0.6797\n",
      "Epoch 1264/2000, Train Loss: 0.6249, Test Loss: 0.6800\n",
      "Epoch 1265/2000, Train Loss: 0.6246, Test Loss: 0.6845\n",
      "Epoch 1266/2000, Train Loss: 0.6256, Test Loss: 0.6859\n",
      "Epoch 1267/2000, Train Loss: 0.6246, Test Loss: 0.6768\n",
      "Epoch 1268/2000, Train Loss: 0.6246, Test Loss: 0.6796\n",
      "Epoch 1269/2000, Train Loss: 0.6254, Test Loss: 0.6810\n",
      "Epoch 1270/2000, Train Loss: 0.6256, Test Loss: 0.6798\n",
      "Epoch 1271/2000, Train Loss: 0.6251, Test Loss: 0.6875\n",
      "Epoch 1272/2000, Train Loss: 0.6253, Test Loss: 0.6820\n",
      "Epoch 1273/2000, Train Loss: 0.6263, Test Loss: 0.6885\n",
      "Epoch 1274/2000, Train Loss: 0.6250, Test Loss: 0.6874\n",
      "Epoch 1275/2000, Train Loss: 0.6254, Test Loss: 0.6857\n",
      "Epoch 1276/2000, Train Loss: 0.6260, Test Loss: 0.6859\n",
      "Epoch 1277/2000, Train Loss: 0.6248, Test Loss: 0.6818\n",
      "Epoch 1278/2000, Train Loss: 0.6249, Test Loss: 0.6873\n",
      "Epoch 1279/2000, Train Loss: 0.6259, Test Loss: 0.6807\n",
      "Epoch 1280/2000, Train Loss: 0.6271, Test Loss: 0.6828\n",
      "Epoch 1281/2000, Train Loss: 0.6249, Test Loss: 0.6837\n",
      "Epoch 1282/2000, Train Loss: 0.6245, Test Loss: 0.6806\n",
      "Epoch 1283/2000, Train Loss: 0.6260, Test Loss: 0.6875\n",
      "Epoch 1284/2000, Train Loss: 0.6259, Test Loss: 0.6800\n",
      "Epoch 1285/2000, Train Loss: 0.6243, Test Loss: 0.6846\n",
      "Epoch 1286/2000, Train Loss: 0.6251, Test Loss: 0.6861\n",
      "Epoch 1287/2000, Train Loss: 0.6254, Test Loss: 0.6822\n",
      "Epoch 1288/2000, Train Loss: 0.6254, Test Loss: 0.6808\n",
      "Epoch 1289/2000, Train Loss: 0.6253, Test Loss: 0.6827\n",
      "Epoch 1290/2000, Train Loss: 0.6252, Test Loss: 0.6816\n",
      "Epoch 1291/2000, Train Loss: 0.6246, Test Loss: 0.6876\n",
      "Epoch 1292/2000, Train Loss: 0.6245, Test Loss: 0.6846\n",
      "Epoch 1293/2000, Train Loss: 0.6257, Test Loss: 0.6989\n",
      "Epoch 1294/2000, Train Loss: 0.6251, Test Loss: 0.6879\n",
      "Epoch 1295/2000, Train Loss: 0.6243, Test Loss: 0.6830\n",
      "Epoch 1296/2000, Train Loss: 0.6247, Test Loss: 0.6819\n",
      "Epoch 1297/2000, Train Loss: 0.6256, Test Loss: 0.6793\n",
      "Epoch 1298/2000, Train Loss: 0.6252, Test Loss: 0.6906\n",
      "Epoch 1299/2000, Train Loss: 0.6252, Test Loss: 0.6806\n",
      "Epoch 1300/2000, Train Loss: 0.6247, Test Loss: 0.6834\n",
      "Epoch 1301/2000, Train Loss: 0.6254, Test Loss: 0.6805\n",
      "Epoch 1302/2000, Train Loss: 0.6246, Test Loss: 0.6847\n",
      "Epoch 1303/2000, Train Loss: 0.6249, Test Loss: 0.6769\n",
      "Epoch 1304/2000, Train Loss: 0.6247, Test Loss: 0.6823\n",
      "Epoch 1305/2000, Train Loss: 0.6262, Test Loss: 0.6828\n",
      "Epoch 1306/2000, Train Loss: 0.6254, Test Loss: 0.6804\n",
      "Epoch 1307/2000, Train Loss: 0.6254, Test Loss: 0.6808\n",
      "Epoch 1308/2000, Train Loss: 0.6250, Test Loss: 0.6869\n",
      "Epoch 1309/2000, Train Loss: 0.6253, Test Loss: 0.6810\n",
      "Epoch 1310/2000, Train Loss: 0.6246, Test Loss: 0.6880\n",
      "Epoch 1311/2000, Train Loss: 0.6253, Test Loss: 0.6794\n",
      "Epoch 1312/2000, Train Loss: 0.6251, Test Loss: 0.6777\n",
      "Epoch 1313/2000, Train Loss: 0.6245, Test Loss: 0.6820\n",
      "Epoch 1314/2000, Train Loss: 0.6246, Test Loss: 0.6799\n",
      "Epoch 1315/2000, Train Loss: 0.6253, Test Loss: 0.6807\n",
      "Epoch 1316/2000, Train Loss: 0.6262, Test Loss: 0.6810\n",
      "Epoch 1317/2000, Train Loss: 0.6250, Test Loss: 0.6872\n",
      "Epoch 1318/2000, Train Loss: 0.6255, Test Loss: 0.6802\n",
      "Epoch 1319/2000, Train Loss: 0.6246, Test Loss: 0.6804\n",
      "Epoch 1320/2000, Train Loss: 0.6238, Test Loss: 0.6770\n",
      "Epoch 1321/2000, Train Loss: 0.6256, Test Loss: 0.6835\n",
      "Epoch 1322/2000, Train Loss: 0.6265, Test Loss: 0.6864\n",
      "Epoch 1323/2000, Train Loss: 0.6257, Test Loss: 0.6869\n",
      "Epoch 1324/2000, Train Loss: 0.6250, Test Loss: 0.6820\n",
      "Epoch 1325/2000, Train Loss: 0.6250, Test Loss: 0.6792\n",
      "Epoch 1326/2000, Train Loss: 0.6242, Test Loss: 0.6818\n",
      "Epoch 1327/2000, Train Loss: 0.6251, Test Loss: 0.6803\n",
      "Epoch 1328/2000, Train Loss: 0.6250, Test Loss: 0.6838\n",
      "Epoch 1329/2000, Train Loss: 0.6250, Test Loss: 0.6811\n",
      "Epoch 1330/2000, Train Loss: 0.6261, Test Loss: 0.6862\n",
      "Epoch 1331/2000, Train Loss: 0.6248, Test Loss: 0.6815\n",
      "Epoch 1332/2000, Train Loss: 0.6255, Test Loss: 0.6794\n",
      "Epoch 1333/2000, Train Loss: 0.6245, Test Loss: 0.6800\n",
      "Epoch 1334/2000, Train Loss: 0.6243, Test Loss: 0.6971\n",
      "Epoch 1335/2000, Train Loss: 0.6242, Test Loss: 0.6845\n",
      "Epoch 1336/2000, Train Loss: 0.6249, Test Loss: 0.6829\n",
      "Epoch 1337/2000, Train Loss: 0.6242, Test Loss: 0.6802\n",
      "Epoch 1338/2000, Train Loss: 0.6246, Test Loss: 0.6811\n",
      "Epoch 1339/2000, Train Loss: 0.6248, Test Loss: 0.6844\n",
      "Epoch 1340/2000, Train Loss: 0.6254, Test Loss: 0.6824\n",
      "Epoch 1341/2000, Train Loss: 0.6245, Test Loss: 0.6829\n",
      "Epoch 1342/2000, Train Loss: 0.6249, Test Loss: 0.6844\n",
      "Epoch 1343/2000, Train Loss: 0.6253, Test Loss: 0.6876\n",
      "Epoch 1344/2000, Train Loss: 0.6246, Test Loss: 0.6795\n",
      "Epoch 1345/2000, Train Loss: 0.6241, Test Loss: 0.6797\n",
      "Epoch 1346/2000, Train Loss: 0.6247, Test Loss: 0.6894\n",
      "Epoch 1347/2000, Train Loss: 0.6249, Test Loss: 0.6798\n",
      "Epoch 1348/2000, Train Loss: 0.6251, Test Loss: 0.6837\n",
      "Epoch 1349/2000, Train Loss: 0.6251, Test Loss: 0.6785\n",
      "Epoch 1350/2000, Train Loss: 0.6243, Test Loss: 0.7092\n",
      "Epoch 1351/2000, Train Loss: 0.6245, Test Loss: 0.6842\n",
      "Epoch 1352/2000, Train Loss: 0.6243, Test Loss: 0.6804\n",
      "Epoch 1353/2000, Train Loss: 0.6248, Test Loss: 0.6832\n",
      "Epoch 1354/2000, Train Loss: 0.6249, Test Loss: 0.6869\n",
      "Epoch 1355/2000, Train Loss: 0.6261, Test Loss: 0.6866\n",
      "Epoch 1356/2000, Train Loss: 0.6243, Test Loss: 0.6873\n",
      "Epoch 1357/2000, Train Loss: 0.6244, Test Loss: 0.6830\n",
      "Epoch 1358/2000, Train Loss: 0.6246, Test Loss: 0.6889\n",
      "Epoch 1359/2000, Train Loss: 0.6241, Test Loss: 0.6857\n",
      "Epoch 1360/2000, Train Loss: 0.6241, Test Loss: 0.6856\n",
      "Epoch 1361/2000, Train Loss: 0.6243, Test Loss: 0.6863\n",
      "Epoch 1362/2000, Train Loss: 0.6251, Test Loss: 0.6804\n",
      "Epoch 1363/2000, Train Loss: 0.6253, Test Loss: 0.6844\n",
      "Epoch 1364/2000, Train Loss: 0.6250, Test Loss: 0.6872\n",
      "Epoch 1365/2000, Train Loss: 0.6241, Test Loss: 0.6830\n",
      "Epoch 1366/2000, Train Loss: 0.6246, Test Loss: 0.6796\n",
      "Epoch 1367/2000, Train Loss: 0.6246, Test Loss: 0.6821\n",
      "Epoch 1368/2000, Train Loss: 0.6251, Test Loss: 0.6872\n",
      "Epoch 1369/2000, Train Loss: 0.6247, Test Loss: 0.6838\n",
      "Epoch 1370/2000, Train Loss: 0.6249, Test Loss: 0.6836\n",
      "Epoch 1371/2000, Train Loss: 0.6244, Test Loss: 0.6854\n",
      "Epoch 1372/2000, Train Loss: 0.6255, Test Loss: 0.6798\n",
      "Epoch 1373/2000, Train Loss: 0.6250, Test Loss: 0.6826\n",
      "Epoch 1374/2000, Train Loss: 0.6237, Test Loss: 0.6852\n",
      "Epoch 1375/2000, Train Loss: 0.6262, Test Loss: 0.6804\n",
      "Epoch 1376/2000, Train Loss: 0.6245, Test Loss: 0.6839\n",
      "Epoch 1377/2000, Train Loss: 0.6244, Test Loss: 0.6926\n",
      "Epoch 1378/2000, Train Loss: 0.6242, Test Loss: 0.6815\n",
      "Epoch 1379/2000, Train Loss: 0.6244, Test Loss: 0.6803\n",
      "Epoch 1380/2000, Train Loss: 0.6250, Test Loss: 0.6805\n",
      "Epoch 1381/2000, Train Loss: 0.6244, Test Loss: 0.6908\n",
      "Epoch 1382/2000, Train Loss: 0.6247, Test Loss: 0.6859\n",
      "Epoch 1383/2000, Train Loss: 0.6240, Test Loss: 0.6826\n",
      "Epoch 1384/2000, Train Loss: 0.6261, Test Loss: 0.6825\n",
      "Epoch 1385/2000, Train Loss: 0.6249, Test Loss: 0.6813\n",
      "Epoch 1386/2000, Train Loss: 0.6244, Test Loss: 0.6853\n",
      "Epoch 1387/2000, Train Loss: 0.6244, Test Loss: 0.6809\n",
      "Epoch 1388/2000, Train Loss: 0.6243, Test Loss: 0.6828\n",
      "Epoch 1389/2000, Train Loss: 0.6244, Test Loss: 0.6801\n",
      "Epoch 1390/2000, Train Loss: 0.6243, Test Loss: 0.6822\n",
      "Epoch 1391/2000, Train Loss: 0.6242, Test Loss: 0.6772\n",
      "Epoch 1392/2000, Train Loss: 0.6247, Test Loss: 0.6785\n",
      "Epoch 1393/2000, Train Loss: 0.6258, Test Loss: 0.6842\n",
      "Epoch 1394/2000, Train Loss: 0.6239, Test Loss: 0.6820\n",
      "Epoch 1395/2000, Train Loss: 0.6240, Test Loss: 0.6828\n",
      "Epoch 1396/2000, Train Loss: 0.6243, Test Loss: 0.6842\n",
      "Epoch 1397/2000, Train Loss: 0.6245, Test Loss: 0.6847\n",
      "Epoch 1398/2000, Train Loss: 0.6247, Test Loss: 0.6840\n",
      "Epoch 1399/2000, Train Loss: 0.6239, Test Loss: 0.6826\n",
      "Epoch 1400/2000, Train Loss: 0.6254, Test Loss: 0.6859\n",
      "Epoch 1401/2000, Train Loss: 0.6244, Test Loss: 0.6904\n",
      "Epoch 1402/2000, Train Loss: 0.6253, Test Loss: 0.6825\n",
      "Epoch 1403/2000, Train Loss: 0.6239, Test Loss: 0.6832\n",
      "Epoch 1404/2000, Train Loss: 0.6250, Test Loss: 0.6854\n",
      "Epoch 1405/2000, Train Loss: 0.6254, Test Loss: 0.6820\n",
      "Epoch 1406/2000, Train Loss: 0.6243, Test Loss: 0.6883\n",
      "Epoch 1407/2000, Train Loss: 0.6240, Test Loss: 0.6811\n",
      "Epoch 1408/2000, Train Loss: 0.6239, Test Loss: 0.6851\n",
      "Epoch 1409/2000, Train Loss: 0.6261, Test Loss: 0.6811\n",
      "Epoch 1410/2000, Train Loss: 0.6241, Test Loss: 0.6929\n",
      "Epoch 1411/2000, Train Loss: 0.6244, Test Loss: 0.6811\n",
      "Epoch 1412/2000, Train Loss: 0.6244, Test Loss: 0.6824\n",
      "Epoch 1413/2000, Train Loss: 0.6255, Test Loss: 0.6877\n",
      "Epoch 1414/2000, Train Loss: 0.6242, Test Loss: 0.6873\n",
      "Epoch 1415/2000, Train Loss: 0.6246, Test Loss: 0.6819\n",
      "Epoch 1416/2000, Train Loss: 0.6240, Test Loss: 0.6846\n",
      "Epoch 1417/2000, Train Loss: 0.6240, Test Loss: 0.6870\n",
      "Epoch 1418/2000, Train Loss: 0.6244, Test Loss: 0.6809\n",
      "Epoch 1419/2000, Train Loss: 0.6251, Test Loss: 0.6857\n",
      "Epoch 1420/2000, Train Loss: 0.6252, Test Loss: 0.6803\n",
      "Epoch 1421/2000, Train Loss: 0.6249, Test Loss: 0.6821\n",
      "Epoch 1422/2000, Train Loss: 0.6243, Test Loss: 0.6848\n",
      "Epoch 1423/2000, Train Loss: 0.6251, Test Loss: 0.6853\n",
      "Epoch 1424/2000, Train Loss: 0.6253, Test Loss: 0.6869\n",
      "Epoch 1425/2000, Train Loss: 0.6237, Test Loss: 0.6866\n",
      "Epoch 1426/2000, Train Loss: 0.6237, Test Loss: 0.6834\n",
      "Epoch 1427/2000, Train Loss: 0.6234, Test Loss: 0.6805\n",
      "Epoch 1428/2000, Train Loss: 0.6247, Test Loss: 0.6835\n",
      "Epoch 1429/2000, Train Loss: 0.6242, Test Loss: 0.6876\n",
      "Epoch 1430/2000, Train Loss: 0.6242, Test Loss: 0.6892\n",
      "Epoch 1431/2000, Train Loss: 0.6243, Test Loss: 0.6807\n",
      "Epoch 1432/2000, Train Loss: 0.6244, Test Loss: 0.6870\n",
      "Epoch 1433/2000, Train Loss: 0.6242, Test Loss: 0.6829\n",
      "Epoch 1434/2000, Train Loss: 0.6251, Test Loss: 0.6780\n",
      "Epoch 1435/2000, Train Loss: 0.6254, Test Loss: 0.6800\n",
      "Epoch 1436/2000, Train Loss: 0.6250, Test Loss: 0.6804\n",
      "Epoch 1437/2000, Train Loss: 0.6260, Test Loss: 0.6872\n",
      "Epoch 1438/2000, Train Loss: 0.6247, Test Loss: 0.6821\n",
      "Epoch 1439/2000, Train Loss: 0.6234, Test Loss: 0.6852\n",
      "Epoch 1440/2000, Train Loss: 0.6244, Test Loss: 0.6781\n",
      "Epoch 1441/2000, Train Loss: 0.6237, Test Loss: 0.6818\n",
      "Epoch 1442/2000, Train Loss: 0.6246, Test Loss: 0.6842\n",
      "Epoch 1443/2000, Train Loss: 0.6254, Test Loss: 0.6908\n",
      "Epoch 1444/2000, Train Loss: 0.6252, Test Loss: 0.6833\n",
      "Epoch 1445/2000, Train Loss: 0.6238, Test Loss: 0.6813\n",
      "Epoch 1446/2000, Train Loss: 0.6242, Test Loss: 0.6835\n",
      "Epoch 1447/2000, Train Loss: 0.6241, Test Loss: 0.6838\n",
      "Epoch 1448/2000, Train Loss: 0.6247, Test Loss: 0.6939\n",
      "Epoch 1449/2000, Train Loss: 0.6237, Test Loss: 0.6839\n",
      "Epoch 1450/2000, Train Loss: 0.6241, Test Loss: 0.6900\n",
      "Epoch 1451/2000, Train Loss: 0.6245, Test Loss: 0.6872\n",
      "Epoch 1452/2000, Train Loss: 0.6248, Test Loss: 0.6846\n",
      "Epoch 1453/2000, Train Loss: 0.6242, Test Loss: 0.6811\n",
      "Epoch 1454/2000, Train Loss: 0.6239, Test Loss: 0.6812\n",
      "Epoch 1455/2000, Train Loss: 0.6243, Test Loss: 0.6853\n",
      "Epoch 1456/2000, Train Loss: 0.6245, Test Loss: 0.6834\n",
      "Epoch 1457/2000, Train Loss: 0.6251, Test Loss: 0.6782\n",
      "Epoch 1458/2000, Train Loss: 0.6241, Test Loss: 0.6817\n",
      "Epoch 1459/2000, Train Loss: 0.6247, Test Loss: 0.6852\n",
      "Epoch 1460/2000, Train Loss: 0.6236, Test Loss: 0.6790\n",
      "Epoch 1461/2000, Train Loss: 0.6246, Test Loss: 0.6807\n",
      "Epoch 1462/2000, Train Loss: 0.6244, Test Loss: 0.6981\n",
      "Epoch 1463/2000, Train Loss: 0.6258, Test Loss: 0.6820\n",
      "Epoch 1464/2000, Train Loss: 0.6240, Test Loss: 0.6812\n",
      "Epoch 1465/2000, Train Loss: 0.6235, Test Loss: 0.6894\n",
      "Epoch 1466/2000, Train Loss: 0.6256, Test Loss: 0.6805\n",
      "Epoch 1467/2000, Train Loss: 0.6249, Test Loss: 0.6837\n",
      "Epoch 1468/2000, Train Loss: 0.6241, Test Loss: 0.6859\n",
      "Epoch 1469/2000, Train Loss: 0.6235, Test Loss: 0.6762\n",
      "Epoch 1470/2000, Train Loss: 0.6252, Test Loss: 0.6850\n",
      "Epoch 1471/2000, Train Loss: 0.6241, Test Loss: 0.6863\n",
      "Epoch 1472/2000, Train Loss: 0.6238, Test Loss: 0.6822\n",
      "Epoch 1473/2000, Train Loss: 0.6238, Test Loss: 0.6810\n",
      "Epoch 1474/2000, Train Loss: 0.6241, Test Loss: 0.6864\n",
      "Epoch 1475/2000, Train Loss: 0.6239, Test Loss: 0.6824\n",
      "Epoch 1476/2000, Train Loss: 0.6235, Test Loss: 0.6881\n",
      "Epoch 1477/2000, Train Loss: 0.6250, Test Loss: 0.6790\n",
      "Epoch 1478/2000, Train Loss: 0.6252, Test Loss: 0.6824\n",
      "Epoch 1479/2000, Train Loss: 0.6239, Test Loss: 0.6795\n",
      "Epoch 1480/2000, Train Loss: 0.6245, Test Loss: 0.6885\n",
      "Epoch 1481/2000, Train Loss: 0.6238, Test Loss: 0.6871\n",
      "Epoch 1482/2000, Train Loss: 0.6243, Test Loss: 0.6786\n",
      "Epoch 1483/2000, Train Loss: 0.6242, Test Loss: 0.6822\n",
      "Epoch 1484/2000, Train Loss: 0.6240, Test Loss: 0.6887\n",
      "Epoch 1485/2000, Train Loss: 0.6238, Test Loss: 0.6815\n",
      "Epoch 1486/2000, Train Loss: 0.6236, Test Loss: 0.6873\n",
      "Epoch 1487/2000, Train Loss: 0.6251, Test Loss: 0.6809\n",
      "Epoch 1488/2000, Train Loss: 0.6244, Test Loss: 0.6865\n",
      "Epoch 1489/2000, Train Loss: 0.6241, Test Loss: 0.6814\n",
      "Epoch 1490/2000, Train Loss: 0.6241, Test Loss: 0.6817\n",
      "Epoch 1491/2000, Train Loss: 0.6246, Test Loss: 0.7012\n",
      "Epoch 1492/2000, Train Loss: 0.6242, Test Loss: 0.6874\n",
      "Epoch 1493/2000, Train Loss: 0.6248, Test Loss: 0.6816\n",
      "Epoch 1494/2000, Train Loss: 0.6244, Test Loss: 0.6902\n",
      "Epoch 1495/2000, Train Loss: 0.6251, Test Loss: 0.6790\n",
      "Epoch 1496/2000, Train Loss: 0.6242, Test Loss: 0.6798\n",
      "Epoch 1497/2000, Train Loss: 0.6238, Test Loss: 0.6828\n",
      "Epoch 1498/2000, Train Loss: 0.6240, Test Loss: 0.6833\n",
      "Epoch 1499/2000, Train Loss: 0.6237, Test Loss: 0.6844\n",
      "Epoch 1500/2000, Train Loss: 0.6245, Test Loss: 0.6761\n",
      "Epoch 1501/2000, Train Loss: 0.6241, Test Loss: 0.6856\n",
      "Epoch 1502/2000, Train Loss: 0.6247, Test Loss: 0.6830\n",
      "Epoch 1503/2000, Train Loss: 0.6245, Test Loss: 0.6843\n",
      "Epoch 1504/2000, Train Loss: 0.6245, Test Loss: 0.6779\n",
      "Epoch 1505/2000, Train Loss: 0.6262, Test Loss: 0.6820\n",
      "Epoch 1506/2000, Train Loss: 0.6241, Test Loss: 0.6853\n",
      "Epoch 1507/2000, Train Loss: 0.6246, Test Loss: 0.6884\n",
      "Epoch 1508/2000, Train Loss: 0.6238, Test Loss: 0.6867\n",
      "Epoch 1509/2000, Train Loss: 0.6250, Test Loss: 0.6780\n",
      "Epoch 1510/2000, Train Loss: 0.6234, Test Loss: 0.6799\n",
      "Epoch 1511/2000, Train Loss: 0.6243, Test Loss: 0.6819\n",
      "Epoch 1512/2000, Train Loss: 0.6239, Test Loss: 0.6871\n",
      "Epoch 1513/2000, Train Loss: 0.6247, Test Loss: 0.6813\n",
      "Epoch 1514/2000, Train Loss: 0.6250, Test Loss: 0.6808\n",
      "Epoch 1515/2000, Train Loss: 0.6244, Test Loss: 0.6929\n",
      "Epoch 1516/2000, Train Loss: 0.6252, Test Loss: 0.6871\n",
      "Epoch 1517/2000, Train Loss: 0.6239, Test Loss: 0.6852\n",
      "Epoch 1518/2000, Train Loss: 0.6238, Test Loss: 0.6921\n",
      "Epoch 1519/2000, Train Loss: 0.6239, Test Loss: 0.6832\n",
      "Epoch 1520/2000, Train Loss: 0.6243, Test Loss: 0.6813\n",
      "Epoch 1521/2000, Train Loss: 0.6236, Test Loss: 0.6852\n",
      "Epoch 1522/2000, Train Loss: 0.6255, Test Loss: 0.6871\n",
      "Epoch 1523/2000, Train Loss: 0.6241, Test Loss: 0.6817\n",
      "Epoch 1524/2000, Train Loss: 0.6251, Test Loss: 0.6750\n",
      "Epoch 1525/2000, Train Loss: 0.6230, Test Loss: 0.6804\n",
      "Epoch 1526/2000, Train Loss: 0.6257, Test Loss: 0.6846\n",
      "Epoch 1527/2000, Train Loss: 0.6243, Test Loss: 0.6831\n",
      "Epoch 1528/2000, Train Loss: 0.6240, Test Loss: 0.6820\n",
      "Epoch 1529/2000, Train Loss: 0.6238, Test Loss: 0.6863\n",
      "Epoch 1530/2000, Train Loss: 0.6236, Test Loss: 0.6809\n",
      "Epoch 1531/2000, Train Loss: 0.6244, Test Loss: 0.6790\n",
      "Epoch 1532/2000, Train Loss: 0.6238, Test Loss: 0.6842\n",
      "Epoch 1533/2000, Train Loss: 0.6243, Test Loss: 0.6832\n",
      "Epoch 1534/2000, Train Loss: 0.6232, Test Loss: 0.6800\n",
      "Epoch 1535/2000, Train Loss: 0.6238, Test Loss: 0.6936\n",
      "Epoch 1536/2000, Train Loss: 0.6246, Test Loss: 0.6835\n",
      "Epoch 1537/2000, Train Loss: 0.6248, Test Loss: 0.6791\n",
      "Epoch 1538/2000, Train Loss: 0.6238, Test Loss: 0.6836\n",
      "Epoch 1539/2000, Train Loss: 0.6240, Test Loss: 0.6802\n",
      "Epoch 1540/2000, Train Loss: 0.6240, Test Loss: 0.6860\n",
      "Epoch 1541/2000, Train Loss: 0.6239, Test Loss: 0.6842\n",
      "Epoch 1542/2000, Train Loss: 0.6247, Test Loss: 0.6861\n",
      "Epoch 1543/2000, Train Loss: 0.6242, Test Loss: 0.6814\n",
      "Epoch 1544/2000, Train Loss: 0.6239, Test Loss: 0.6863\n",
      "Epoch 1545/2000, Train Loss: 0.6248, Test Loss: 0.6797\n",
      "Epoch 1546/2000, Train Loss: 0.6247, Test Loss: 0.6790\n",
      "Epoch 1547/2000, Train Loss: 0.6246, Test Loss: 0.6811\n",
      "Epoch 1548/2000, Train Loss: 0.6243, Test Loss: 0.6838\n",
      "Epoch 1549/2000, Train Loss: 0.6244, Test Loss: 0.6880\n",
      "Epoch 1550/2000, Train Loss: 0.6245, Test Loss: 0.6820\n",
      "Epoch 1551/2000, Train Loss: 0.6243, Test Loss: 0.6810\n",
      "Epoch 1552/2000, Train Loss: 0.6250, Test Loss: 0.6816\n",
      "Epoch 1553/2000, Train Loss: 0.6249, Test Loss: 0.6889\n",
      "Epoch 1554/2000, Train Loss: 0.6248, Test Loss: 0.6956\n",
      "Epoch 1555/2000, Train Loss: 0.6240, Test Loss: 0.6875\n",
      "Epoch 1556/2000, Train Loss: 0.6241, Test Loss: 0.6806\n",
      "Epoch 1557/2000, Train Loss: 0.6241, Test Loss: 0.6872\n",
      "Epoch 1558/2000, Train Loss: 0.6246, Test Loss: 0.6790\n",
      "Epoch 1559/2000, Train Loss: 0.6234, Test Loss: 0.6821\n",
      "Epoch 1560/2000, Train Loss: 0.6234, Test Loss: 0.6846\n",
      "Epoch 1561/2000, Train Loss: 0.6239, Test Loss: 0.6815\n",
      "Epoch 1562/2000, Train Loss: 0.6241, Test Loss: 0.6836\n",
      "Epoch 1563/2000, Train Loss: 0.6262, Test Loss: 0.6891\n",
      "Epoch 1564/2000, Train Loss: 0.6240, Test Loss: 0.6849\n",
      "Epoch 1565/2000, Train Loss: 0.6238, Test Loss: 0.6825\n",
      "Epoch 1566/2000, Train Loss: 0.6239, Test Loss: 0.6845\n",
      "Epoch 1567/2000, Train Loss: 0.6237, Test Loss: 0.6804\n",
      "Epoch 1568/2000, Train Loss: 0.6237, Test Loss: 0.6907\n",
      "Epoch 1569/2000, Train Loss: 0.6236, Test Loss: 0.6796\n",
      "Epoch 1570/2000, Train Loss: 0.6239, Test Loss: 0.6811\n",
      "Epoch 1571/2000, Train Loss: 0.6248, Test Loss: 0.6831\n",
      "Epoch 1572/2000, Train Loss: 0.6241, Test Loss: 0.6820\n",
      "Epoch 1573/2000, Train Loss: 0.6241, Test Loss: 0.6810\n",
      "Epoch 1574/2000, Train Loss: 0.6240, Test Loss: 0.6869\n",
      "Epoch 1575/2000, Train Loss: 0.6231, Test Loss: 0.6814\n",
      "Epoch 1576/2000, Train Loss: 0.6242, Test Loss: 0.6885\n",
      "Epoch 1577/2000, Train Loss: 0.6239, Test Loss: 0.6844\n",
      "Epoch 1578/2000, Train Loss: 0.6252, Test Loss: 0.6939\n",
      "Epoch 1579/2000, Train Loss: 0.6241, Test Loss: 0.6945\n",
      "Epoch 1580/2000, Train Loss: 0.6248, Test Loss: 0.6826\n",
      "Epoch 1581/2000, Train Loss: 0.6236, Test Loss: 0.6819\n",
      "Epoch 1582/2000, Train Loss: 0.6234, Test Loss: 0.6789\n",
      "Epoch 1583/2000, Train Loss: 0.6237, Test Loss: 0.6811\n",
      "Epoch 1584/2000, Train Loss: 0.6241, Test Loss: 0.6896\n",
      "Epoch 1585/2000, Train Loss: 0.6236, Test Loss: 0.6866\n",
      "Epoch 1586/2000, Train Loss: 0.6240, Test Loss: 0.6901\n",
      "Epoch 1587/2000, Train Loss: 0.6234, Test Loss: 0.6774\n",
      "Epoch 1588/2000, Train Loss: 0.6235, Test Loss: 0.6955\n",
      "Epoch 1589/2000, Train Loss: 0.6239, Test Loss: 0.6816\n",
      "Epoch 1590/2000, Train Loss: 0.6233, Test Loss: 0.6831\n",
      "Epoch 1591/2000, Train Loss: 0.6238, Test Loss: 0.6787\n",
      "Epoch 1592/2000, Train Loss: 0.6248, Test Loss: 0.6830\n",
      "Epoch 1593/2000, Train Loss: 0.6237, Test Loss: 0.6786\n",
      "Epoch 1594/2000, Train Loss: 0.6243, Test Loss: 0.6855\n",
      "Epoch 1595/2000, Train Loss: 0.6230, Test Loss: 0.6864\n",
      "Epoch 1596/2000, Train Loss: 0.6238, Test Loss: 0.6858\n",
      "Epoch 1597/2000, Train Loss: 0.6240, Test Loss: 0.6876\n",
      "Epoch 1598/2000, Train Loss: 0.6244, Test Loss: 0.6790\n",
      "Epoch 1599/2000, Train Loss: 0.6241, Test Loss: 0.6787\n",
      "Epoch 1600/2000, Train Loss: 0.6241, Test Loss: 0.6901\n",
      "Epoch 1601/2000, Train Loss: 0.6248, Test Loss: 0.6777\n",
      "Epoch 1602/2000, Train Loss: 0.6242, Test Loss: 0.6837\n",
      "Epoch 1603/2000, Train Loss: 0.6244, Test Loss: 0.6843\n",
      "Epoch 1604/2000, Train Loss: 0.6234, Test Loss: 0.6785\n",
      "Epoch 1605/2000, Train Loss: 0.6232, Test Loss: 0.6812\n",
      "Epoch 1606/2000, Train Loss: 0.6254, Test Loss: 0.6826\n",
      "Epoch 1607/2000, Train Loss: 0.6239, Test Loss: 0.6924\n",
      "Epoch 1608/2000, Train Loss: 0.6234, Test Loss: 0.6860\n",
      "Epoch 1609/2000, Train Loss: 0.6239, Test Loss: 0.6862\n",
      "Epoch 1610/2000, Train Loss: 0.6236, Test Loss: 0.6820\n",
      "Epoch 1611/2000, Train Loss: 0.6240, Test Loss: 0.6809\n",
      "Epoch 1612/2000, Train Loss: 0.6240, Test Loss: 0.6878\n",
      "Epoch 1613/2000, Train Loss: 0.6239, Test Loss: 0.6777\n",
      "Epoch 1614/2000, Train Loss: 0.6234, Test Loss: 0.6777\n",
      "Epoch 1615/2000, Train Loss: 0.6237, Test Loss: 0.6821\n",
      "Epoch 1616/2000, Train Loss: 0.6247, Test Loss: 0.6865\n",
      "Epoch 1617/2000, Train Loss: 0.6237, Test Loss: 0.6882\n",
      "Epoch 1618/2000, Train Loss: 0.6238, Test Loss: 0.6828\n",
      "Epoch 1619/2000, Train Loss: 0.6242, Test Loss: 0.6777\n",
      "Epoch 1620/2000, Train Loss: 0.6240, Test Loss: 0.6823\n",
      "Epoch 1621/2000, Train Loss: 0.6236, Test Loss: 0.6828\n",
      "Epoch 1622/2000, Train Loss: 0.6236, Test Loss: 0.6883\n",
      "Epoch 1623/2000, Train Loss: 0.6245, Test Loss: 0.6813\n",
      "Epoch 1624/2000, Train Loss: 0.6252, Test Loss: 0.6811\n",
      "Epoch 1625/2000, Train Loss: 0.6234, Test Loss: 0.6772\n",
      "Epoch 1626/2000, Train Loss: 0.6235, Test Loss: 0.6799\n",
      "Epoch 1627/2000, Train Loss: 0.6239, Test Loss: 0.6782\n",
      "Epoch 1628/2000, Train Loss: 0.6240, Test Loss: 0.6849\n",
      "Epoch 1629/2000, Train Loss: 0.6241, Test Loss: 0.6944\n",
      "Epoch 1630/2000, Train Loss: 0.6240, Test Loss: 0.6815\n",
      "Epoch 1631/2000, Train Loss: 0.6240, Test Loss: 0.6798\n",
      "Epoch 1632/2000, Train Loss: 0.6233, Test Loss: 0.6830\n",
      "Epoch 1633/2000, Train Loss: 0.6238, Test Loss: 0.6832\n",
      "Epoch 1634/2000, Train Loss: 0.6242, Test Loss: 0.6836\n",
      "Epoch 1635/2000, Train Loss: 0.6237, Test Loss: 0.6879\n",
      "Epoch 1636/2000, Train Loss: 0.6228, Test Loss: 0.6877\n",
      "Epoch 1637/2000, Train Loss: 0.6232, Test Loss: 0.6813\n",
      "Epoch 1638/2000, Train Loss: 0.6241, Test Loss: 0.6827\n",
      "Epoch 1639/2000, Train Loss: 0.6237, Test Loss: 0.6790\n",
      "Epoch 1640/2000, Train Loss: 0.6232, Test Loss: 0.6880\n",
      "Epoch 1641/2000, Train Loss: 0.6236, Test Loss: 0.6833\n",
      "Epoch 1642/2000, Train Loss: 0.6234, Test Loss: 0.6800\n",
      "Epoch 1643/2000, Train Loss: 0.6245, Test Loss: 0.6929\n",
      "Epoch 1644/2000, Train Loss: 0.6245, Test Loss: 0.6816\n",
      "Epoch 1645/2000, Train Loss: 0.6233, Test Loss: 0.6847\n",
      "Epoch 1646/2000, Train Loss: 0.6247, Test Loss: 0.6831\n",
      "Epoch 1647/2000, Train Loss: 0.6238, Test Loss: 0.6812\n",
      "Epoch 1648/2000, Train Loss: 0.6245, Test Loss: 0.6846\n",
      "Epoch 1649/2000, Train Loss: 0.6238, Test Loss: 0.6875\n",
      "Epoch 1650/2000, Train Loss: 0.6226, Test Loss: 0.6908\n",
      "Epoch 1651/2000, Train Loss: 0.6234, Test Loss: 0.6854\n",
      "Epoch 1652/2000, Train Loss: 0.6242, Test Loss: 0.6844\n",
      "Epoch 1653/2000, Train Loss: 0.6238, Test Loss: 0.6802\n",
      "Epoch 1654/2000, Train Loss: 0.6245, Test Loss: 0.6855\n",
      "Epoch 1655/2000, Train Loss: 0.6239, Test Loss: 0.6792\n",
      "Epoch 1656/2000, Train Loss: 0.6229, Test Loss: 0.6841\n",
      "Epoch 1657/2000, Train Loss: 0.6230, Test Loss: 0.7002\n",
      "Epoch 1658/2000, Train Loss: 0.6242, Test Loss: 0.6823\n",
      "Epoch 1659/2000, Train Loss: 0.6232, Test Loss: 0.6834\n",
      "Epoch 1660/2000, Train Loss: 0.6226, Test Loss: 0.6851\n",
      "Epoch 1661/2000, Train Loss: 0.6239, Test Loss: 0.6844\n",
      "Epoch 1662/2000, Train Loss: 0.6237, Test Loss: 0.6934\n",
      "Epoch 1663/2000, Train Loss: 0.6248, Test Loss: 0.6904\n",
      "Epoch 1664/2000, Train Loss: 0.6234, Test Loss: 0.6804\n",
      "Epoch 1665/2000, Train Loss: 0.6231, Test Loss: 0.6816\n",
      "Epoch 1666/2000, Train Loss: 0.6235, Test Loss: 0.6855\n",
      "Epoch 1667/2000, Train Loss: 0.6235, Test Loss: 0.6835\n",
      "Epoch 1668/2000, Train Loss: 0.6229, Test Loss: 0.6936\n",
      "Epoch 1669/2000, Train Loss: 0.6242, Test Loss: 0.6807\n",
      "Epoch 1670/2000, Train Loss: 0.6234, Test Loss: 0.6807\n",
      "Epoch 1671/2000, Train Loss: 0.6242, Test Loss: 0.6883\n",
      "Epoch 1672/2000, Train Loss: 0.6243, Test Loss: 0.6791\n",
      "Epoch 1673/2000, Train Loss: 0.6237, Test Loss: 0.6869\n",
      "Epoch 1674/2000, Train Loss: 0.6227, Test Loss: 0.6827\n",
      "Epoch 1675/2000, Train Loss: 0.6232, Test Loss: 0.6803\n",
      "Epoch 1676/2000, Train Loss: 0.6236, Test Loss: 0.6823\n",
      "Epoch 1677/2000, Train Loss: 0.6231, Test Loss: 0.6792\n",
      "Epoch 1678/2000, Train Loss: 0.6235, Test Loss: 0.6809\n",
      "Epoch 1679/2000, Train Loss: 0.6233, Test Loss: 0.6894\n",
      "Epoch 1680/2000, Train Loss: 0.6236, Test Loss: 0.6857\n",
      "Epoch 1681/2000, Train Loss: 0.6240, Test Loss: 0.6923\n",
      "Epoch 1682/2000, Train Loss: 0.6242, Test Loss: 0.6855\n",
      "Epoch 1683/2000, Train Loss: 0.6240, Test Loss: 0.6830\n",
      "Epoch 1684/2000, Train Loss: 0.6237, Test Loss: 0.6808\n",
      "Epoch 1685/2000, Train Loss: 0.6238, Test Loss: 0.6790\n",
      "Epoch 1686/2000, Train Loss: 0.6235, Test Loss: 0.6846\n",
      "Epoch 1687/2000, Train Loss: 0.6245, Test Loss: 0.6782\n",
      "Epoch 1688/2000, Train Loss: 0.6234, Test Loss: 0.6812\n",
      "Epoch 1689/2000, Train Loss: 0.6239, Test Loss: 0.6873\n",
      "Epoch 1690/2000, Train Loss: 0.6251, Test Loss: 0.6829\n",
      "Epoch 1691/2000, Train Loss: 0.6236, Test Loss: 0.6910\n",
      "Epoch 1692/2000, Train Loss: 0.6235, Test Loss: 0.6821\n",
      "Epoch 1693/2000, Train Loss: 0.6236, Test Loss: 0.6883\n",
      "Epoch 1694/2000, Train Loss: 0.6237, Test Loss: 0.6868\n",
      "Epoch 1695/2000, Train Loss: 0.6233, Test Loss: 0.6800\n",
      "Epoch 1696/2000, Train Loss: 0.6244, Test Loss: 0.6790\n",
      "Epoch 1697/2000, Train Loss: 0.6235, Test Loss: 0.6799\n",
      "Epoch 1698/2000, Train Loss: 0.6240, Test Loss: 0.6789\n",
      "Epoch 1699/2000, Train Loss: 0.6232, Test Loss: 0.6797\n",
      "Epoch 1700/2000, Train Loss: 0.6240, Test Loss: 0.6798\n",
      "Epoch 1701/2000, Train Loss: 0.6238, Test Loss: 0.6828\n",
      "Epoch 1702/2000, Train Loss: 0.6237, Test Loss: 0.6885\n",
      "Epoch 1703/2000, Train Loss: 0.6242, Test Loss: 0.6833\n",
      "Epoch 1704/2000, Train Loss: 0.6231, Test Loss: 0.6870\n",
      "Epoch 1705/2000, Train Loss: 0.6244, Test Loss: 0.6822\n",
      "Epoch 1706/2000, Train Loss: 0.6228, Test Loss: 0.6844\n",
      "Epoch 1707/2000, Train Loss: 0.6234, Test Loss: 0.6875\n",
      "Epoch 1708/2000, Train Loss: 0.6231, Test Loss: 0.6876\n",
      "Epoch 1709/2000, Train Loss: 0.6232, Test Loss: 0.6805\n",
      "Epoch 1710/2000, Train Loss: 0.6242, Test Loss: 0.6806\n",
      "Epoch 1711/2000, Train Loss: 0.6230, Test Loss: 0.6842\n",
      "Epoch 1712/2000, Train Loss: 0.6230, Test Loss: 0.6833\n",
      "Epoch 1713/2000, Train Loss: 0.6242, Test Loss: 0.6807\n",
      "Epoch 1714/2000, Train Loss: 0.6241, Test Loss: 0.6941\n",
      "Epoch 1715/2000, Train Loss: 0.6236, Test Loss: 0.6817\n",
      "Epoch 1716/2000, Train Loss: 0.6231, Test Loss: 0.6801\n",
      "Epoch 1717/2000, Train Loss: 0.6237, Test Loss: 0.6819\n",
      "Epoch 1718/2000, Train Loss: 0.6237, Test Loss: 0.6852\n",
      "Epoch 1719/2000, Train Loss: 0.6237, Test Loss: 0.6800\n",
      "Epoch 1720/2000, Train Loss: 0.6231, Test Loss: 0.6779\n",
      "Epoch 1721/2000, Train Loss: 0.6227, Test Loss: 0.6837\n",
      "Epoch 1722/2000, Train Loss: 0.6230, Test Loss: 0.6788\n",
      "Epoch 1723/2000, Train Loss: 0.6239, Test Loss: 0.6809\n",
      "Epoch 1724/2000, Train Loss: 0.6236, Test Loss: 0.6775\n",
      "Epoch 1725/2000, Train Loss: 0.6231, Test Loss: 0.6794\n",
      "Epoch 1726/2000, Train Loss: 0.6235, Test Loss: 0.6818\n",
      "Epoch 1727/2000, Train Loss: 0.6228, Test Loss: 0.6800\n",
      "Epoch 1728/2000, Train Loss: 0.6236, Test Loss: 0.6809\n",
      "Epoch 1729/2000, Train Loss: 0.6233, Test Loss: 0.6811\n",
      "Epoch 1730/2000, Train Loss: 0.6235, Test Loss: 0.6802\n",
      "Epoch 1731/2000, Train Loss: 0.6234, Test Loss: 0.6885\n",
      "Epoch 1732/2000, Train Loss: 0.6235, Test Loss: 0.6885\n",
      "Epoch 1733/2000, Train Loss: 0.6247, Test Loss: 0.6866\n",
      "Epoch 1734/2000, Train Loss: 0.6231, Test Loss: 0.6868\n",
      "Epoch 1735/2000, Train Loss: 0.6231, Test Loss: 0.6985\n",
      "Epoch 1736/2000, Train Loss: 0.6236, Test Loss: 0.6815\n",
      "Epoch 1737/2000, Train Loss: 0.6241, Test Loss: 0.6800\n",
      "Epoch 1738/2000, Train Loss: 0.6236, Test Loss: 0.6826\n",
      "Epoch 1739/2000, Train Loss: 0.6246, Test Loss: 0.6855\n",
      "Epoch 1740/2000, Train Loss: 0.6233, Test Loss: 0.6815\n",
      "Epoch 1741/2000, Train Loss: 0.6231, Test Loss: 0.6829\n",
      "Epoch 1742/2000, Train Loss: 0.6231, Test Loss: 0.6811\n",
      "Epoch 1743/2000, Train Loss: 0.6227, Test Loss: 0.6825\n",
      "Epoch 1744/2000, Train Loss: 0.6238, Test Loss: 0.6811\n",
      "Epoch 1745/2000, Train Loss: 0.6237, Test Loss: 0.6825\n",
      "Epoch 1746/2000, Train Loss: 0.6227, Test Loss: 0.6811\n",
      "Epoch 1747/2000, Train Loss: 0.6239, Test Loss: 0.6926\n",
      "Epoch 1748/2000, Train Loss: 0.6231, Test Loss: 0.6871\n",
      "Epoch 1749/2000, Train Loss: 0.6241, Test Loss: 0.6932\n",
      "Epoch 1750/2000, Train Loss: 0.6238, Test Loss: 0.6945\n",
      "Epoch 1751/2000, Train Loss: 0.6236, Test Loss: 0.6841\n",
      "Epoch 1752/2000, Train Loss: 0.6240, Test Loss: 0.6819\n",
      "Epoch 1753/2000, Train Loss: 0.6239, Test Loss: 0.6828\n",
      "Epoch 1754/2000, Train Loss: 0.6234, Test Loss: 0.6809\n",
      "Epoch 1755/2000, Train Loss: 0.6231, Test Loss: 0.6870\n",
      "Epoch 1756/2000, Train Loss: 0.6233, Test Loss: 0.6781\n",
      "Epoch 1757/2000, Train Loss: 0.6232, Test Loss: 0.6812\n",
      "Epoch 1758/2000, Train Loss: 0.6234, Test Loss: 0.6802\n",
      "Epoch 1759/2000, Train Loss: 0.6236, Test Loss: 0.6809\n",
      "Epoch 1760/2000, Train Loss: 0.6230, Test Loss: 0.6851\n",
      "Epoch 1761/2000, Train Loss: 0.6229, Test Loss: 0.6820\n",
      "Epoch 1762/2000, Train Loss: 0.6231, Test Loss: 0.6811\n",
      "Epoch 1763/2000, Train Loss: 0.6240, Test Loss: 0.6844\n",
      "Epoch 1764/2000, Train Loss: 0.6230, Test Loss: 0.6909\n",
      "Epoch 1765/2000, Train Loss: 0.6239, Test Loss: 0.6806\n",
      "Epoch 1766/2000, Train Loss: 0.6230, Test Loss: 0.6848\n",
      "Epoch 1767/2000, Train Loss: 0.6241, Test Loss: 0.6902\n",
      "Epoch 1768/2000, Train Loss: 0.6231, Test Loss: 0.6802\n",
      "Epoch 1769/2000, Train Loss: 0.6236, Test Loss: 0.6871\n",
      "Epoch 1770/2000, Train Loss: 0.6228, Test Loss: 0.6866\n",
      "Epoch 1771/2000, Train Loss: 0.6238, Test Loss: 0.6828\n",
      "Epoch 1772/2000, Train Loss: 0.6233, Test Loss: 0.6840\n",
      "Epoch 1773/2000, Train Loss: 0.6234, Test Loss: 0.6827\n",
      "Epoch 1774/2000, Train Loss: 0.6236, Test Loss: 0.6868\n",
      "Epoch 1775/2000, Train Loss: 0.6243, Test Loss: 0.6832\n",
      "Epoch 1776/2000, Train Loss: 0.6238, Test Loss: 0.6899\n",
      "Epoch 1777/2000, Train Loss: 0.6235, Test Loss: 0.6874\n",
      "Epoch 1778/2000, Train Loss: 0.6237, Test Loss: 0.6787\n",
      "Epoch 1779/2000, Train Loss: 0.6233, Test Loss: 0.6800\n",
      "Epoch 1780/2000, Train Loss: 0.6226, Test Loss: 0.6839\n",
      "Epoch 1781/2000, Train Loss: 0.6233, Test Loss: 0.6839\n",
      "Epoch 1782/2000, Train Loss: 0.6241, Test Loss: 0.6858\n",
      "Epoch 1783/2000, Train Loss: 0.6239, Test Loss: 0.6849\n",
      "Epoch 1784/2000, Train Loss: 0.6239, Test Loss: 0.6791\n",
      "Epoch 1785/2000, Train Loss: 0.6225, Test Loss: 0.6919\n",
      "Epoch 1786/2000, Train Loss: 0.6235, Test Loss: 0.6826\n",
      "Epoch 1787/2000, Train Loss: 0.6233, Test Loss: 0.6774\n",
      "Epoch 1788/2000, Train Loss: 0.6227, Test Loss: 0.6802\n",
      "Epoch 1789/2000, Train Loss: 0.6246, Test Loss: 0.6828\n",
      "Epoch 1790/2000, Train Loss: 0.6253, Test Loss: 0.6817\n",
      "Epoch 1791/2000, Train Loss: 0.6234, Test Loss: 0.6812\n",
      "Epoch 1792/2000, Train Loss: 0.6230, Test Loss: 0.6852\n",
      "Epoch 1793/2000, Train Loss: 0.6241, Test Loss: 0.6901\n",
      "Epoch 1794/2000, Train Loss: 0.6232, Test Loss: 0.6817\n",
      "Epoch 1795/2000, Train Loss: 0.6233, Test Loss: 0.6859\n",
      "Epoch 1796/2000, Train Loss: 0.6230, Test Loss: 0.6872\n",
      "Epoch 1797/2000, Train Loss: 0.6227, Test Loss: 0.6872\n",
      "Epoch 1798/2000, Train Loss: 0.6233, Test Loss: 0.6890\n",
      "Epoch 1799/2000, Train Loss: 0.6238, Test Loss: 0.6813\n",
      "Epoch 1800/2000, Train Loss: 0.6240, Test Loss: 0.6809\n",
      "Epoch 1801/2000, Train Loss: 0.6230, Test Loss: 0.6805\n",
      "Epoch 1802/2000, Train Loss: 0.6230, Test Loss: 0.6824\n",
      "Epoch 1803/2000, Train Loss: 0.6231, Test Loss: 0.6826\n",
      "Epoch 1804/2000, Train Loss: 0.6235, Test Loss: 0.6842\n",
      "Epoch 1805/2000, Train Loss: 0.6235, Test Loss: 0.6852\n",
      "Epoch 1806/2000, Train Loss: 0.6245, Test Loss: 0.6861\n",
      "Epoch 1807/2000, Train Loss: 0.6233, Test Loss: 0.6857\n",
      "Epoch 1808/2000, Train Loss: 0.6228, Test Loss: 0.6845\n",
      "Epoch 1809/2000, Train Loss: 0.6228, Test Loss: 0.6850\n",
      "Epoch 1810/2000, Train Loss: 0.6239, Test Loss: 0.6839\n",
      "Epoch 1811/2000, Train Loss: 0.6231, Test Loss: 0.6848\n",
      "Epoch 1812/2000, Train Loss: 0.6234, Test Loss: 0.6852\n",
      "Epoch 1813/2000, Train Loss: 0.6231, Test Loss: 0.6852\n",
      "Epoch 1814/2000, Train Loss: 0.6230, Test Loss: 0.6839\n",
      "Epoch 1815/2000, Train Loss: 0.6233, Test Loss: 0.6805\n",
      "Epoch 1816/2000, Train Loss: 0.6228, Test Loss: 0.6843\n",
      "Epoch 1817/2000, Train Loss: 0.6233, Test Loss: 0.6843\n",
      "Epoch 1818/2000, Train Loss: 0.6236, Test Loss: 0.6814\n",
      "Epoch 1819/2000, Train Loss: 0.6233, Test Loss: 0.6801\n",
      "Epoch 1820/2000, Train Loss: 0.6232, Test Loss: 0.6829\n",
      "Epoch 1821/2000, Train Loss: 0.6228, Test Loss: 0.6860\n",
      "Epoch 1822/2000, Train Loss: 0.6230, Test Loss: 0.6801\n",
      "Epoch 1823/2000, Train Loss: 0.6229, Test Loss: 0.6783\n",
      "Epoch 1824/2000, Train Loss: 0.6234, Test Loss: 0.6787\n",
      "Epoch 1825/2000, Train Loss: 0.6236, Test Loss: 0.6966\n",
      "Epoch 1826/2000, Train Loss: 0.6226, Test Loss: 0.6846\n",
      "Epoch 1827/2000, Train Loss: 0.6235, Test Loss: 0.6824\n",
      "Epoch 1828/2000, Train Loss: 0.6238, Test Loss: 0.6830\n",
      "Epoch 1829/2000, Train Loss: 0.6231, Test Loss: 0.6840\n",
      "Epoch 1830/2000, Train Loss: 0.6227, Test Loss: 0.6781\n",
      "Epoch 1831/2000, Train Loss: 0.6230, Test Loss: 0.6864\n",
      "Epoch 1832/2000, Train Loss: 0.6228, Test Loss: 0.6845\n",
      "Epoch 1833/2000, Train Loss: 0.6241, Test Loss: 0.6835\n",
      "Epoch 1834/2000, Train Loss: 0.6221, Test Loss: 0.6849\n",
      "Epoch 1835/2000, Train Loss: 0.6236, Test Loss: 0.6799\n",
      "Epoch 1836/2000, Train Loss: 0.6232, Test Loss: 0.6801\n",
      "Epoch 1837/2000, Train Loss: 0.6235, Test Loss: 0.6863\n",
      "Epoch 1838/2000, Train Loss: 0.6229, Test Loss: 0.6904\n",
      "Epoch 1839/2000, Train Loss: 0.6238, Test Loss: 0.6812\n",
      "Epoch 1840/2000, Train Loss: 0.6226, Test Loss: 0.6860\n",
      "Epoch 1841/2000, Train Loss: 0.6236, Test Loss: 0.6805\n",
      "Epoch 1842/2000, Train Loss: 0.6226, Test Loss: 0.6774\n",
      "Epoch 1843/2000, Train Loss: 0.6240, Test Loss: 0.6827\n",
      "Epoch 1844/2000, Train Loss: 0.6232, Test Loss: 0.6851\n",
      "Epoch 1845/2000, Train Loss: 0.6241, Test Loss: 0.7016\n",
      "Epoch 1846/2000, Train Loss: 0.6234, Test Loss: 0.6839\n",
      "Epoch 1847/2000, Train Loss: 0.6232, Test Loss: 0.6875\n",
      "Epoch 1848/2000, Train Loss: 0.6235, Test Loss: 0.6815\n",
      "Epoch 1849/2000, Train Loss: 0.6239, Test Loss: 0.6815\n",
      "Epoch 1850/2000, Train Loss: 0.6230, Test Loss: 0.6867\n",
      "Epoch 1851/2000, Train Loss: 0.6229, Test Loss: 0.6885\n",
      "Epoch 1852/2000, Train Loss: 0.6227, Test Loss: 0.6808\n",
      "Epoch 1853/2000, Train Loss: 0.6228, Test Loss: 0.6788\n",
      "Epoch 1854/2000, Train Loss: 0.6231, Test Loss: 0.6811\n",
      "Epoch 1855/2000, Train Loss: 0.6228, Test Loss: 0.6795\n",
      "Epoch 1856/2000, Train Loss: 0.6242, Test Loss: 0.6804\n",
      "Epoch 1857/2000, Train Loss: 0.6238, Test Loss: 0.6840\n",
      "Epoch 1858/2000, Train Loss: 0.6235, Test Loss: 0.6812\n",
      "Epoch 1859/2000, Train Loss: 0.6226, Test Loss: 0.6826\n",
      "Epoch 1860/2000, Train Loss: 0.6238, Test Loss: 0.6845\n",
      "Epoch 1861/2000, Train Loss: 0.6222, Test Loss: 0.6807\n",
      "Epoch 1862/2000, Train Loss: 0.6229, Test Loss: 0.6872\n",
      "Epoch 1863/2000, Train Loss: 0.6232, Test Loss: 0.6833\n",
      "Epoch 1864/2000, Train Loss: 0.6233, Test Loss: 0.6821\n",
      "Epoch 1865/2000, Train Loss: 0.6240, Test Loss: 0.6802\n",
      "Epoch 1866/2000, Train Loss: 0.6242, Test Loss: 0.6822\n",
      "Epoch 1867/2000, Train Loss: 0.6236, Test Loss: 0.6818\n",
      "Epoch 1868/2000, Train Loss: 0.6241, Test Loss: 0.6930\n",
      "Epoch 1869/2000, Train Loss: 0.6228, Test Loss: 0.6815\n",
      "Epoch 1870/2000, Train Loss: 0.6235, Test Loss: 0.6886\n",
      "Epoch 1871/2000, Train Loss: 0.6241, Test Loss: 0.6793\n",
      "Epoch 1872/2000, Train Loss: 0.6225, Test Loss: 0.6901\n",
      "Epoch 1873/2000, Train Loss: 0.6233, Test Loss: 0.6807\n",
      "Epoch 1874/2000, Train Loss: 0.6221, Test Loss: 0.6824\n",
      "Epoch 1875/2000, Train Loss: 0.6234, Test Loss: 0.6858\n",
      "Epoch 1876/2000, Train Loss: 0.6238, Test Loss: 0.6822\n",
      "Epoch 1877/2000, Train Loss: 0.6228, Test Loss: 0.6893\n",
      "Epoch 1878/2000, Train Loss: 0.6233, Test Loss: 0.6859\n",
      "Epoch 1879/2000, Train Loss: 0.6230, Test Loss: 0.6794\n",
      "Epoch 1880/2000, Train Loss: 0.6243, Test Loss: 0.6821\n",
      "Epoch 1881/2000, Train Loss: 0.6239, Test Loss: 0.6936\n",
      "Epoch 1882/2000, Train Loss: 0.6230, Test Loss: 0.6892\n",
      "Epoch 1883/2000, Train Loss: 0.6229, Test Loss: 0.6784\n",
      "Epoch 1884/2000, Train Loss: 0.6225, Test Loss: 0.6840\n",
      "Epoch 1885/2000, Train Loss: 0.6228, Test Loss: 0.6868\n",
      "Epoch 1886/2000, Train Loss: 0.6229, Test Loss: 0.6811\n",
      "Epoch 1887/2000, Train Loss: 0.6222, Test Loss: 0.6805\n",
      "Epoch 1888/2000, Train Loss: 0.6223, Test Loss: 0.6826\n",
      "Epoch 1889/2000, Train Loss: 0.6228, Test Loss: 0.6791\n",
      "Epoch 1890/2000, Train Loss: 0.6241, Test Loss: 0.6771\n",
      "Epoch 1891/2000, Train Loss: 0.6230, Test Loss: 0.6830\n",
      "Epoch 1892/2000, Train Loss: 0.6230, Test Loss: 0.6818\n",
      "Epoch 1893/2000, Train Loss: 0.6226, Test Loss: 0.6818\n",
      "Epoch 1894/2000, Train Loss: 0.6229, Test Loss: 0.6813\n",
      "Epoch 1895/2000, Train Loss: 0.6235, Test Loss: 0.6791\n",
      "Epoch 1896/2000, Train Loss: 0.6228, Test Loss: 0.6878\n",
      "Epoch 1897/2000, Train Loss: 0.6233, Test Loss: 0.6822\n",
      "Epoch 1898/2000, Train Loss: 0.6220, Test Loss: 0.6872\n",
      "Epoch 1899/2000, Train Loss: 0.6230, Test Loss: 0.6787\n",
      "Epoch 1900/2000, Train Loss: 0.6230, Test Loss: 0.6778\n",
      "Epoch 1901/2000, Train Loss: 0.6239, Test Loss: 0.6844\n",
      "Epoch 1902/2000, Train Loss: 0.6223, Test Loss: 0.6913\n",
      "Epoch 1903/2000, Train Loss: 0.6220, Test Loss: 0.6801\n",
      "Epoch 1904/2000, Train Loss: 0.6236, Test Loss: 0.6933\n",
      "Epoch 1905/2000, Train Loss: 0.6241, Test Loss: 0.6779\n",
      "Epoch 1906/2000, Train Loss: 0.6230, Test Loss: 0.6830\n",
      "Epoch 1907/2000, Train Loss: 0.6233, Test Loss: 0.6938\n",
      "Epoch 1908/2000, Train Loss: 0.6230, Test Loss: 0.6891\n",
      "Epoch 1909/2000, Train Loss: 0.6233, Test Loss: 0.6800\n",
      "Epoch 1910/2000, Train Loss: 0.6233, Test Loss: 0.6831\n",
      "Epoch 1911/2000, Train Loss: 0.6224, Test Loss: 0.6841\n",
      "Epoch 1912/2000, Train Loss: 0.6227, Test Loss: 0.6822\n",
      "Epoch 1913/2000, Train Loss: 0.6234, Test Loss: 0.6786\n",
      "Epoch 1914/2000, Train Loss: 0.6223, Test Loss: 0.6879\n",
      "Epoch 1915/2000, Train Loss: 0.6236, Test Loss: 0.6875\n",
      "Epoch 1916/2000, Train Loss: 0.6234, Test Loss: 0.6853\n",
      "Epoch 1917/2000, Train Loss: 0.6237, Test Loss: 0.6829\n",
      "Epoch 1918/2000, Train Loss: 0.6237, Test Loss: 0.6926\n",
      "Epoch 1919/2000, Train Loss: 0.6228, Test Loss: 0.6914\n",
      "Epoch 1920/2000, Train Loss: 0.6222, Test Loss: 0.6830\n",
      "Epoch 1921/2000, Train Loss: 0.6225, Test Loss: 0.6809\n",
      "Epoch 1922/2000, Train Loss: 0.6226, Test Loss: 0.6868\n",
      "Epoch 1923/2000, Train Loss: 0.6226, Test Loss: 0.6804\n",
      "Epoch 1924/2000, Train Loss: 0.6244, Test Loss: 0.6817\n",
      "Epoch 1925/2000, Train Loss: 0.6231, Test Loss: 0.6800\n",
      "Epoch 1926/2000, Train Loss: 0.6226, Test Loss: 0.6851\n",
      "Epoch 1927/2000, Train Loss: 0.6226, Test Loss: 0.6806\n",
      "Epoch 1928/2000, Train Loss: 0.6229, Test Loss: 0.6872\n",
      "Epoch 1929/2000, Train Loss: 0.6229, Test Loss: 0.6835\n",
      "Epoch 1930/2000, Train Loss: 0.6227, Test Loss: 0.6849\n",
      "Epoch 1931/2000, Train Loss: 0.6237, Test Loss: 0.6831\n",
      "Epoch 1932/2000, Train Loss: 0.6228, Test Loss: 0.6822\n",
      "Epoch 1933/2000, Train Loss: 0.6237, Test Loss: 0.6796\n",
      "Epoch 1934/2000, Train Loss: 0.6233, Test Loss: 0.6798\n",
      "Epoch 1935/2000, Train Loss: 0.6231, Test Loss: 0.6827\n",
      "Epoch 1936/2000, Train Loss: 0.6227, Test Loss: 0.6880\n",
      "Epoch 1937/2000, Train Loss: 0.6238, Test Loss: 0.6886\n",
      "Epoch 1938/2000, Train Loss: 0.6230, Test Loss: 0.6898\n",
      "Epoch 1939/2000, Train Loss: 0.6218, Test Loss: 0.6804\n",
      "Epoch 1940/2000, Train Loss: 0.6226, Test Loss: 0.6825\n",
      "Epoch 1941/2000, Train Loss: 0.6239, Test Loss: 0.6881\n",
      "Epoch 1942/2000, Train Loss: 0.6219, Test Loss: 0.6927\n",
      "Epoch 1943/2000, Train Loss: 0.6221, Test Loss: 0.6813\n",
      "Epoch 1944/2000, Train Loss: 0.6239, Test Loss: 0.6836\n",
      "Epoch 1945/2000, Train Loss: 0.6230, Test Loss: 0.6778\n",
      "Epoch 1946/2000, Train Loss: 0.6224, Test Loss: 0.6818\n",
      "Epoch 1947/2000, Train Loss: 0.6229, Test Loss: 0.6823\n",
      "Epoch 1948/2000, Train Loss: 0.6238, Test Loss: 0.6858\n",
      "Epoch 1949/2000, Train Loss: 0.6236, Test Loss: 0.6774\n",
      "Epoch 1950/2000, Train Loss: 0.6250, Test Loss: 0.6851\n",
      "Epoch 1951/2000, Train Loss: 0.6225, Test Loss: 0.6855\n",
      "Epoch 1952/2000, Train Loss: 0.6224, Test Loss: 0.6852\n",
      "Epoch 1953/2000, Train Loss: 0.6236, Test Loss: 0.6931\n",
      "Epoch 1954/2000, Train Loss: 0.6230, Test Loss: 0.6771\n",
      "Epoch 1955/2000, Train Loss: 0.6221, Test Loss: 0.6838\n",
      "Epoch 1956/2000, Train Loss: 0.6225, Test Loss: 0.6881\n",
      "Epoch 1957/2000, Train Loss: 0.6229, Test Loss: 0.6828\n",
      "Epoch 1958/2000, Train Loss: 0.6230, Test Loss: 0.6817\n",
      "Epoch 1959/2000, Train Loss: 0.6232, Test Loss: 0.6798\n",
      "Epoch 1960/2000, Train Loss: 0.6244, Test Loss: 0.6822\n",
      "Epoch 1961/2000, Train Loss: 0.6225, Test Loss: 0.6819\n",
      "Epoch 1962/2000, Train Loss: 0.6232, Test Loss: 0.6861\n",
      "Epoch 1963/2000, Train Loss: 0.6240, Test Loss: 0.6811\n",
      "Epoch 1964/2000, Train Loss: 0.6236, Test Loss: 0.6949\n",
      "Epoch 1965/2000, Train Loss: 0.6228, Test Loss: 0.6888\n",
      "Epoch 1966/2000, Train Loss: 0.6232, Test Loss: 0.6818\n",
      "Epoch 1967/2000, Train Loss: 0.6227, Test Loss: 0.6790\n",
      "Epoch 1968/2000, Train Loss: 0.6234, Test Loss: 0.6817\n",
      "Epoch 1969/2000, Train Loss: 0.6221, Test Loss: 0.6785\n",
      "Epoch 1970/2000, Train Loss: 0.6230, Test Loss: 0.6866\n",
      "Epoch 1971/2000, Train Loss: 0.6229, Test Loss: 0.6854\n",
      "Epoch 1972/2000, Train Loss: 0.6236, Test Loss: 0.6855\n",
      "Epoch 1973/2000, Train Loss: 0.6229, Test Loss: 0.6851\n",
      "Epoch 1974/2000, Train Loss: 0.6234, Test Loss: 0.6805\n",
      "Epoch 1975/2000, Train Loss: 0.6225, Test Loss: 0.6835\n",
      "Epoch 1976/2000, Train Loss: 0.6238, Test Loss: 0.6804\n",
      "Epoch 1977/2000, Train Loss: 0.6225, Test Loss: 0.6808\n",
      "Epoch 1978/2000, Train Loss: 0.6237, Test Loss: 0.6818\n",
      "Epoch 1979/2000, Train Loss: 0.6236, Test Loss: 0.6987\n",
      "Epoch 1980/2000, Train Loss: 0.6231, Test Loss: 0.6847\n",
      "Epoch 1981/2000, Train Loss: 0.6227, Test Loss: 0.6864\n",
      "Epoch 1982/2000, Train Loss: 0.6221, Test Loss: 0.6841\n",
      "Epoch 1983/2000, Train Loss: 0.6226, Test Loss: 0.6802\n",
      "Epoch 1984/2000, Train Loss: 0.6239, Test Loss: 0.6791\n",
      "Epoch 1985/2000, Train Loss: 0.6221, Test Loss: 0.6763\n",
      "Epoch 1986/2000, Train Loss: 0.6232, Test Loss: 0.6997\n",
      "Epoch 1987/2000, Train Loss: 0.6223, Test Loss: 0.6814\n",
      "Epoch 1988/2000, Train Loss: 0.6220, Test Loss: 0.6803\n",
      "Epoch 1989/2000, Train Loss: 0.6227, Test Loss: 0.6854\n",
      "Epoch 1990/2000, Train Loss: 0.6227, Test Loss: 0.6795\n",
      "Epoch 1991/2000, Train Loss: 0.6226, Test Loss: 0.6817\n",
      "Epoch 1992/2000, Train Loss: 0.6236, Test Loss: 0.6830\n",
      "Epoch 1993/2000, Train Loss: 0.6230, Test Loss: 0.6886\n",
      "Epoch 1994/2000, Train Loss: 0.6230, Test Loss: 0.6837\n",
      "Epoch 1995/2000, Train Loss: 0.6224, Test Loss: 0.6805\n",
      "Epoch 1996/2000, Train Loss: 0.6226, Test Loss: 0.6832\n",
      "Epoch 1997/2000, Train Loss: 0.6232, Test Loss: 0.6834\n",
      "Epoch 1998/2000, Train Loss: 0.6236, Test Loss: 0.6848\n",
      "Epoch 1999/2000, Train Loss: 0.6228, Test Loss: 0.6843\n",
      "Epoch 2000/2000, Train Loss: 0.6227, Test Loss: 0.6845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.803</td></tr><tr><td>accuracy/train</td><td>0.8088</td></tr><tr><td>batch_loss</td><td>0.55128</td></tr><tr><td>epoch</td><td>1999</td></tr><tr><td>loss/test</td><td>0.68451</td></tr><tr><td>loss/train</td><td>0.62273</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-music-261</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/49z1ix20' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/49z1ix20</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240312_194128-49z1ix20/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240312_223240-bpm7tt0m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/bpm7tt0m' target=\"_blank\">young-surf-262</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/bpm7tt0m' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/bpm7tt0m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Train Loss: 0.6898, Test Loss: 0.3830\n",
      "Epoch 2/2000, Train Loss: 0.3681, Test Loss: 0.3585\n",
      "Epoch 3/2000, Train Loss: 0.3371, Test Loss: 0.3486\n",
      "Epoch 4/2000, Train Loss: 0.3260, Test Loss: 0.3245\n",
      "Epoch 5/2000, Train Loss: 0.3168, Test Loss: 0.3212\n",
      "Epoch 6/2000, Train Loss: 0.3171, Test Loss: 0.3290\n",
      "Epoch 7/2000, Train Loss: 0.3097, Test Loss: 0.3194\n",
      "Epoch 8/2000, Train Loss: 0.3021, Test Loss: 0.3272\n",
      "Epoch 9/2000, Train Loss: 0.2975, Test Loss: 0.3107\n",
      "Epoch 10/2000, Train Loss: 0.2935, Test Loss: 0.3096\n",
      "Epoch 11/2000, Train Loss: 0.2921, Test Loss: 0.3094\n",
      "Epoch 12/2000, Train Loss: 0.2870, Test Loss: 0.3111\n",
      "Epoch 13/2000, Train Loss: 0.2872, Test Loss: 0.3049\n",
      "Epoch 14/2000, Train Loss: 0.2849, Test Loss: 0.3105\n",
      "Epoch 15/2000, Train Loss: 0.2879, Test Loss: 0.3039\n",
      "Epoch 16/2000, Train Loss: 0.2800, Test Loss: 0.3082\n",
      "Epoch 17/2000, Train Loss: 0.2808, Test Loss: 0.2995\n",
      "Epoch 18/2000, Train Loss: 0.2771, Test Loss: 0.3191\n",
      "Epoch 19/2000, Train Loss: 0.2747, Test Loss: 0.3028\n",
      "Epoch 20/2000, Train Loss: 0.2741, Test Loss: 0.3026\n",
      "Epoch 21/2000, Train Loss: 0.2725, Test Loss: 0.2963\n",
      "Epoch 22/2000, Train Loss: 0.2725, Test Loss: 0.2966\n",
      "Epoch 23/2000, Train Loss: 0.2704, Test Loss: 0.2994\n",
      "Epoch 24/2000, Train Loss: 0.2707, Test Loss: 0.3018\n",
      "Epoch 25/2000, Train Loss: 0.2690, Test Loss: 0.2998\n",
      "Epoch 26/2000, Train Loss: 0.2687, Test Loss: 0.3005\n",
      "Epoch 27/2000, Train Loss: 0.2656, Test Loss: 0.2984\n",
      "Epoch 28/2000, Train Loss: 0.2660, Test Loss: 0.2997\n",
      "Epoch 29/2000, Train Loss: 0.2640, Test Loss: 0.3082\n",
      "Epoch 30/2000, Train Loss: 0.2656, Test Loss: 0.2988\n",
      "Epoch 31/2000, Train Loss: 0.2652, Test Loss: 0.3023\n",
      "Epoch 32/2000, Train Loss: 0.2648, Test Loss: 0.2941\n",
      "Epoch 33/2000, Train Loss: 0.2630, Test Loss: 0.2986\n",
      "Epoch 34/2000, Train Loss: 0.2619, Test Loss: 0.2938\n",
      "Epoch 35/2000, Train Loss: 0.2609, Test Loss: 0.3030\n",
      "Epoch 36/2000, Train Loss: 0.2588, Test Loss: 0.3023\n",
      "Epoch 37/2000, Train Loss: 0.2606, Test Loss: 0.2961\n",
      "Epoch 38/2000, Train Loss: 0.2605, Test Loss: 0.3017\n",
      "Epoch 39/2000, Train Loss: 0.2563, Test Loss: 0.3009\n",
      "Epoch 40/2000, Train Loss: 0.2601, Test Loss: 0.2945\n",
      "Epoch 41/2000, Train Loss: 0.2565, Test Loss: 0.2918\n",
      "Epoch 42/2000, Train Loss: 0.2574, Test Loss: 0.2971\n",
      "Epoch 43/2000, Train Loss: 0.2563, Test Loss: 0.2923\n",
      "Epoch 44/2000, Train Loss: 0.2560, Test Loss: 0.2948\n",
      "Epoch 45/2000, Train Loss: 0.2550, Test Loss: 0.2913\n",
      "Epoch 46/2000, Train Loss: 0.2537, Test Loss: 0.2976\n",
      "Epoch 47/2000, Train Loss: 0.2554, Test Loss: 0.2971\n",
      "Epoch 48/2000, Train Loss: 0.2542, Test Loss: 0.2932\n",
      "Epoch 49/2000, Train Loss: 0.2529, Test Loss: 0.2922\n",
      "Epoch 50/2000, Train Loss: 0.2543, Test Loss: 0.2917\n",
      "Epoch 51/2000, Train Loss: 0.2541, Test Loss: 0.3022\n",
      "Epoch 52/2000, Train Loss: 0.2513, Test Loss: 0.3007\n",
      "Epoch 53/2000, Train Loss: 0.2538, Test Loss: 0.2948\n",
      "Epoch 54/2000, Train Loss: 0.2509, Test Loss: 0.2879\n",
      "Epoch 55/2000, Train Loss: 0.2518, Test Loss: 0.2886\n",
      "Epoch 56/2000, Train Loss: 0.2512, Test Loss: 0.2936\n",
      "Epoch 57/2000, Train Loss: 0.2512, Test Loss: 0.2925\n",
      "Epoch 58/2000, Train Loss: 0.2510, Test Loss: 0.2897\n",
      "Epoch 59/2000, Train Loss: 0.2495, Test Loss: 0.2910\n",
      "Epoch 60/2000, Train Loss: 0.2492, Test Loss: 0.2901\n",
      "Epoch 61/2000, Train Loss: 0.2506, Test Loss: 0.2875\n",
      "Epoch 62/2000, Train Loss: 0.2489, Test Loss: 0.2917\n",
      "Epoch 63/2000, Train Loss: 0.2489, Test Loss: 0.2910\n",
      "Epoch 64/2000, Train Loss: 0.2471, Test Loss: 0.2940\n",
      "Epoch 65/2000, Train Loss: 0.2483, Test Loss: 0.2966\n",
      "Epoch 66/2000, Train Loss: 0.2458, Test Loss: 0.2912\n",
      "Epoch 67/2000, Train Loss: 0.2463, Test Loss: 0.2920\n",
      "Epoch 68/2000, Train Loss: 0.2472, Test Loss: 0.3025\n",
      "Epoch 69/2000, Train Loss: 0.2466, Test Loss: 0.2890\n",
      "Epoch 70/2000, Train Loss: 0.2466, Test Loss: 0.2939\n",
      "Epoch 71/2000, Train Loss: 0.2467, Test Loss: 0.2954\n",
      "Epoch 72/2000, Train Loss: 0.2460, Test Loss: 0.2910\n",
      "Epoch 73/2000, Train Loss: 0.2443, Test Loss: 0.2900\n",
      "Epoch 74/2000, Train Loss: 0.2451, Test Loss: 0.2919\n",
      "Epoch 75/2000, Train Loss: 0.2449, Test Loss: 0.2891\n",
      "Epoch 76/2000, Train Loss: 0.2441, Test Loss: 0.2891\n",
      "Epoch 77/2000, Train Loss: 0.2441, Test Loss: 0.2926\n",
      "Epoch 78/2000, Train Loss: 0.2451, Test Loss: 0.2880\n",
      "Epoch 79/2000, Train Loss: 0.2435, Test Loss: 0.2875\n",
      "Epoch 80/2000, Train Loss: 0.2435, Test Loss: 0.2897\n",
      "Epoch 81/2000, Train Loss: 0.2435, Test Loss: 0.2885\n",
      "Epoch 82/2000, Train Loss: 0.2444, Test Loss: 0.2914\n",
      "Epoch 83/2000, Train Loss: 0.2428, Test Loss: 0.2899\n",
      "Epoch 84/2000, Train Loss: 0.2433, Test Loss: 0.2934\n",
      "Epoch 85/2000, Train Loss: 0.2423, Test Loss: 0.2899\n",
      "Epoch 86/2000, Train Loss: 0.2428, Test Loss: 0.2895\n",
      "Epoch 87/2000, Train Loss: 0.2423, Test Loss: 0.2934\n",
      "Epoch 88/2000, Train Loss: 0.2417, Test Loss: 0.2917\n",
      "Epoch 89/2000, Train Loss: 0.2409, Test Loss: 0.2886\n",
      "Epoch 90/2000, Train Loss: 0.2403, Test Loss: 0.2958\n",
      "Epoch 91/2000, Train Loss: 0.2409, Test Loss: 0.3090\n",
      "Epoch 92/2000, Train Loss: 0.2413, Test Loss: 0.2941\n",
      "Epoch 93/2000, Train Loss: 0.2402, Test Loss: 0.2906\n",
      "Epoch 94/2000, Train Loss: 0.2404, Test Loss: 0.2905\n",
      "Epoch 95/2000, Train Loss: 0.2420, Test Loss: 0.3044\n",
      "Epoch 96/2000, Train Loss: 0.2409, Test Loss: 0.2877\n",
      "Epoch 97/2000, Train Loss: 0.2397, Test Loss: 0.2938\n",
      "Epoch 98/2000, Train Loss: 0.2407, Test Loss: 0.2976\n",
      "Epoch 99/2000, Train Loss: 0.2408, Test Loss: 0.2898\n",
      "Epoch 100/2000, Train Loss: 0.2395, Test Loss: 0.2922\n",
      "Epoch 101/2000, Train Loss: 0.2386, Test Loss: 0.2988\n",
      "Epoch 102/2000, Train Loss: 0.2402, Test Loss: 0.2945\n",
      "Epoch 103/2000, Train Loss: 0.2390, Test Loss: 0.2945\n",
      "Epoch 104/2000, Train Loss: 0.2387, Test Loss: 0.2913\n",
      "Epoch 105/2000, Train Loss: 0.2382, Test Loss: 0.2942\n",
      "Epoch 106/2000, Train Loss: 0.2390, Test Loss: 0.2914\n",
      "Epoch 107/2000, Train Loss: 0.2369, Test Loss: 0.2962\n",
      "Epoch 108/2000, Train Loss: 0.2387, Test Loss: 0.2960\n",
      "Epoch 109/2000, Train Loss: 0.2369, Test Loss: 0.2902\n",
      "Epoch 110/2000, Train Loss: 0.2378, Test Loss: 0.2950\n",
      "Epoch 111/2000, Train Loss: 0.2376, Test Loss: 0.2941\n",
      "Epoch 112/2000, Train Loss: 0.2379, Test Loss: 0.2930\n",
      "Epoch 113/2000, Train Loss: 0.2368, Test Loss: 0.2908\n",
      "Epoch 114/2000, Train Loss: 0.2361, Test Loss: 0.2913\n",
      "Epoch 115/2000, Train Loss: 0.2374, Test Loss: 0.2929\n",
      "Epoch 116/2000, Train Loss: 0.2363, Test Loss: 0.2930\n",
      "Epoch 117/2000, Train Loss: 0.2372, Test Loss: 0.2920\n",
      "Epoch 118/2000, Train Loss: 0.2367, Test Loss: 0.2930\n",
      "Epoch 119/2000, Train Loss: 0.2364, Test Loss: 0.2897\n",
      "Epoch 120/2000, Train Loss: 0.2360, Test Loss: 0.2926\n",
      "Epoch 121/2000, Train Loss: 0.2359, Test Loss: 0.2919\n",
      "Epoch 122/2000, Train Loss: 0.2366, Test Loss: 0.2884\n",
      "Epoch 123/2000, Train Loss: 0.2354, Test Loss: 0.2926\n",
      "Epoch 124/2000, Train Loss: 0.2351, Test Loss: 0.2987\n",
      "Epoch 125/2000, Train Loss: 0.2360, Test Loss: 0.2946\n",
      "Epoch 126/2000, Train Loss: 0.2348, Test Loss: 0.2941\n",
      "Epoch 127/2000, Train Loss: 0.2347, Test Loss: 0.2925\n",
      "Epoch 128/2000, Train Loss: 0.2346, Test Loss: 0.2937\n",
      "Epoch 129/2000, Train Loss: 0.2363, Test Loss: 0.2901\n",
      "Epoch 130/2000, Train Loss: 0.2374, Test Loss: 0.3036\n",
      "Epoch 131/2000, Train Loss: 0.2342, Test Loss: 0.2886\n",
      "Epoch 132/2000, Train Loss: 0.2346, Test Loss: 0.2917\n",
      "Epoch 133/2000, Train Loss: 0.2357, Test Loss: 0.2918\n",
      "Epoch 134/2000, Train Loss: 0.2346, Test Loss: 0.2942\n",
      "Epoch 135/2000, Train Loss: 0.2347, Test Loss: 0.2936\n",
      "Epoch 136/2000, Train Loss: 0.2336, Test Loss: 0.2887\n",
      "Epoch 137/2000, Train Loss: 0.2361, Test Loss: 0.2948\n",
      "Epoch 138/2000, Train Loss: 0.2341, Test Loss: 0.2925\n",
      "Epoch 139/2000, Train Loss: 0.2334, Test Loss: 0.2896\n",
      "Epoch 140/2000, Train Loss: 0.2338, Test Loss: 0.2916\n",
      "Epoch 141/2000, Train Loss: 0.2350, Test Loss: 0.2922\n",
      "Epoch 142/2000, Train Loss: 0.2331, Test Loss: 0.2910\n",
      "Epoch 143/2000, Train Loss: 0.2338, Test Loss: 0.2917\n",
      "Epoch 144/2000, Train Loss: 0.2338, Test Loss: 0.2961\n",
      "Epoch 145/2000, Train Loss: 0.2328, Test Loss: 0.2923\n",
      "Epoch 146/2000, Train Loss: 0.2334, Test Loss: 0.2941\n",
      "Epoch 147/2000, Train Loss: 0.2325, Test Loss: 0.2909\n",
      "Epoch 148/2000, Train Loss: 0.2329, Test Loss: 0.2964\n",
      "Epoch 149/2000, Train Loss: 0.2338, Test Loss: 0.2945\n",
      "Epoch 150/2000, Train Loss: 0.2332, Test Loss: 0.2969\n",
      "Epoch 151/2000, Train Loss: 0.2326, Test Loss: 0.2909\n",
      "Epoch 152/2000, Train Loss: 0.2328, Test Loss: 0.2908\n",
      "Epoch 153/2000, Train Loss: 0.2319, Test Loss: 0.2932\n",
      "Epoch 154/2000, Train Loss: 0.2318, Test Loss: 0.2947\n",
      "Epoch 155/2000, Train Loss: 0.2316, Test Loss: 0.2894\n",
      "Epoch 156/2000, Train Loss: 0.2313, Test Loss: 0.2936\n",
      "Epoch 157/2000, Train Loss: 0.2317, Test Loss: 0.2948\n",
      "Epoch 158/2000, Train Loss: 0.2306, Test Loss: 0.2932\n",
      "Epoch 159/2000, Train Loss: 0.2306, Test Loss: 0.2892\n",
      "Epoch 160/2000, Train Loss: 0.2318, Test Loss: 0.2925\n",
      "Epoch 161/2000, Train Loss: 0.2307, Test Loss: 0.2916\n",
      "Epoch 162/2000, Train Loss: 0.2316, Test Loss: 0.2935\n",
      "Epoch 163/2000, Train Loss: 0.2328, Test Loss: 0.2889\n",
      "Epoch 164/2000, Train Loss: 0.2311, Test Loss: 0.3008\n",
      "Epoch 165/2000, Train Loss: 0.2312, Test Loss: 0.2966\n",
      "Epoch 166/2000, Train Loss: 0.2305, Test Loss: 0.2946\n",
      "Epoch 167/2000, Train Loss: 0.2300, Test Loss: 0.2914\n",
      "Epoch 168/2000, Train Loss: 0.2296, Test Loss: 0.2986\n",
      "Epoch 169/2000, Train Loss: 0.2310, Test Loss: 0.2977\n",
      "Epoch 170/2000, Train Loss: 0.2300, Test Loss: 0.2943\n",
      "Epoch 171/2000, Train Loss: 0.2303, Test Loss: 0.2970\n",
      "Epoch 172/2000, Train Loss: 0.2306, Test Loss: 0.2913\n",
      "Epoch 173/2000, Train Loss: 0.2298, Test Loss: 0.2995\n",
      "Epoch 174/2000, Train Loss: 0.2310, Test Loss: 0.2934\n",
      "Epoch 175/2000, Train Loss: 0.2291, Test Loss: 0.2923\n",
      "Epoch 176/2000, Train Loss: 0.2300, Test Loss: 0.2963\n",
      "Epoch 177/2000, Train Loss: 0.2298, Test Loss: 0.2914\n",
      "Epoch 178/2000, Train Loss: 0.2297, Test Loss: 0.2900\n",
      "Epoch 179/2000, Train Loss: 0.2288, Test Loss: 0.2949\n",
      "Epoch 180/2000, Train Loss: 0.2287, Test Loss: 0.2926\n",
      "Epoch 181/2000, Train Loss: 0.2285, Test Loss: 0.2923\n",
      "Epoch 182/2000, Train Loss: 0.2300, Test Loss: 0.3002\n",
      "Epoch 183/2000, Train Loss: 0.2286, Test Loss: 0.2977\n",
      "Epoch 184/2000, Train Loss: 0.2298, Test Loss: 0.2955\n",
      "Epoch 185/2000, Train Loss: 0.2294, Test Loss: 0.2921\n",
      "Epoch 186/2000, Train Loss: 0.2287, Test Loss: 0.3022\n",
      "Epoch 187/2000, Train Loss: 0.2283, Test Loss: 0.2947\n",
      "Epoch 188/2000, Train Loss: 0.2280, Test Loss: 0.2907\n",
      "Epoch 189/2000, Train Loss: 0.2283, Test Loss: 0.2949\n",
      "Epoch 190/2000, Train Loss: 0.2293, Test Loss: 0.3028\n",
      "Epoch 191/2000, Train Loss: 0.2292, Test Loss: 0.3081\n",
      "Epoch 192/2000, Train Loss: 0.2287, Test Loss: 0.2924\n",
      "Epoch 193/2000, Train Loss: 0.2285, Test Loss: 0.2918\n",
      "Epoch 194/2000, Train Loss: 0.2288, Test Loss: 0.2960\n",
      "Epoch 195/2000, Train Loss: 0.2276, Test Loss: 0.2893\n",
      "Epoch 196/2000, Train Loss: 0.2275, Test Loss: 0.2906\n",
      "Epoch 197/2000, Train Loss: 0.2278, Test Loss: 0.2949\n",
      "Epoch 198/2000, Train Loss: 0.2288, Test Loss: 0.2921\n",
      "Epoch 199/2000, Train Loss: 0.2275, Test Loss: 0.2907\n",
      "Epoch 200/2000, Train Loss: 0.2269, Test Loss: 0.2945\n",
      "Epoch 201/2000, Train Loss: 0.2276, Test Loss: 0.2930\n",
      "Epoch 202/2000, Train Loss: 0.2283, Test Loss: 0.2984\n",
      "Epoch 203/2000, Train Loss: 0.2279, Test Loss: 0.2926\n",
      "Epoch 204/2000, Train Loss: 0.2265, Test Loss: 0.2918\n",
      "Epoch 205/2000, Train Loss: 0.2268, Test Loss: 0.2947\n",
      "Epoch 206/2000, Train Loss: 0.2285, Test Loss: 0.2924\n",
      "Epoch 207/2000, Train Loss: 0.2268, Test Loss: 0.2933\n",
      "Epoch 208/2000, Train Loss: 0.2265, Test Loss: 0.2988\n",
      "Epoch 209/2000, Train Loss: 0.2269, Test Loss: 0.2903\n",
      "Epoch 210/2000, Train Loss: 0.2261, Test Loss: 0.2925\n",
      "Epoch 211/2000, Train Loss: 0.2265, Test Loss: 0.2983\n",
      "Epoch 212/2000, Train Loss: 0.2264, Test Loss: 0.2932\n",
      "Epoch 213/2000, Train Loss: 0.2273, Test Loss: 0.2902\n",
      "Epoch 214/2000, Train Loss: 0.2267, Test Loss: 0.2962\n",
      "Epoch 215/2000, Train Loss: 0.2260, Test Loss: 0.2960\n",
      "Epoch 216/2000, Train Loss: 0.2261, Test Loss: 0.3008\n",
      "Epoch 217/2000, Train Loss: 0.2269, Test Loss: 0.2958\n",
      "Epoch 218/2000, Train Loss: 0.2266, Test Loss: 0.2952\n",
      "Epoch 219/2000, Train Loss: 0.2259, Test Loss: 0.2914\n",
      "Epoch 220/2000, Train Loss: 0.2254, Test Loss: 0.2932\n",
      "Epoch 221/2000, Train Loss: 0.2263, Test Loss: 0.2957\n",
      "Epoch 222/2000, Train Loss: 0.2261, Test Loss: 0.2902\n",
      "Epoch 223/2000, Train Loss: 0.2261, Test Loss: 0.2913\n",
      "Epoch 224/2000, Train Loss: 0.2263, Test Loss: 0.2911\n",
      "Epoch 225/2000, Train Loss: 0.2251, Test Loss: 0.2940\n",
      "Epoch 226/2000, Train Loss: 0.2250, Test Loss: 0.2924\n",
      "Epoch 227/2000, Train Loss: 0.2254, Test Loss: 0.2933\n",
      "Epoch 228/2000, Train Loss: 0.2253, Test Loss: 0.3010\n",
      "Epoch 229/2000, Train Loss: 0.2265, Test Loss: 0.2931\n",
      "Epoch 230/2000, Train Loss: 0.2249, Test Loss: 0.2965\n",
      "Epoch 231/2000, Train Loss: 0.2246, Test Loss: 0.2988\n",
      "Epoch 232/2000, Train Loss: 0.2245, Test Loss: 0.2915\n",
      "Epoch 233/2000, Train Loss: 0.2257, Test Loss: 0.2924\n",
      "Epoch 234/2000, Train Loss: 0.2251, Test Loss: 0.2938\n",
      "Epoch 235/2000, Train Loss: 0.2247, Test Loss: 0.2965\n",
      "Epoch 236/2000, Train Loss: 0.2262, Test Loss: 0.2974\n",
      "Epoch 237/2000, Train Loss: 0.2254, Test Loss: 0.2959\n",
      "Epoch 238/2000, Train Loss: 0.2248, Test Loss: 0.2905\n",
      "Epoch 239/2000, Train Loss: 0.2251, Test Loss: 0.2919\n",
      "Epoch 240/2000, Train Loss: 0.2263, Test Loss: 0.2949\n",
      "Epoch 241/2000, Train Loss: 0.2257, Test Loss: 0.2973\n",
      "Epoch 242/2000, Train Loss: 0.2249, Test Loss: 0.2957\n",
      "Epoch 243/2000, Train Loss: 0.2242, Test Loss: 0.2989\n",
      "Epoch 244/2000, Train Loss: 0.2241, Test Loss: 0.2973\n",
      "Epoch 245/2000, Train Loss: 0.2235, Test Loss: 0.2963\n",
      "Epoch 246/2000, Train Loss: 0.2245, Test Loss: 0.2963\n",
      "Epoch 247/2000, Train Loss: 0.2239, Test Loss: 0.2941\n",
      "Epoch 248/2000, Train Loss: 0.2251, Test Loss: 0.2916\n",
      "Epoch 249/2000, Train Loss: 0.2244, Test Loss: 0.2968\n",
      "Epoch 250/2000, Train Loss: 0.2253, Test Loss: 0.2937\n",
      "Epoch 251/2000, Train Loss: 0.2238, Test Loss: 0.2928\n",
      "Epoch 252/2000, Train Loss: 0.2256, Test Loss: 0.2960\n",
      "Epoch 253/2000, Train Loss: 0.2245, Test Loss: 0.2989\n",
      "Epoch 254/2000, Train Loss: 0.2244, Test Loss: 0.2960\n",
      "Epoch 255/2000, Train Loss: 0.2256, Test Loss: 0.3016\n",
      "Epoch 256/2000, Train Loss: 0.2244, Test Loss: 0.2993\n",
      "Epoch 257/2000, Train Loss: 0.2239, Test Loss: 0.2913\n",
      "Epoch 258/2000, Train Loss: 0.2228, Test Loss: 0.2977\n",
      "Epoch 259/2000, Train Loss: 0.2240, Test Loss: 0.2980\n",
      "Epoch 260/2000, Train Loss: 0.2234, Test Loss: 0.2998\n",
      "Epoch 261/2000, Train Loss: 0.2235, Test Loss: 0.3005\n",
      "Epoch 262/2000, Train Loss: 0.2247, Test Loss: 0.2953\n",
      "Epoch 263/2000, Train Loss: 0.2243, Test Loss: 0.2933\n",
      "Epoch 264/2000, Train Loss: 0.2233, Test Loss: 0.2937\n",
      "Epoch 265/2000, Train Loss: 0.2236, Test Loss: 0.3010\n",
      "Epoch 266/2000, Train Loss: 0.2243, Test Loss: 0.2907\n",
      "Epoch 267/2000, Train Loss: 0.2232, Test Loss: 0.2939\n",
      "Epoch 268/2000, Train Loss: 0.2227, Test Loss: 0.2931\n",
      "Epoch 269/2000, Train Loss: 0.2228, Test Loss: 0.2968\n",
      "Epoch 270/2000, Train Loss: 0.2228, Test Loss: 0.2955\n",
      "Epoch 271/2000, Train Loss: 0.2226, Test Loss: 0.2938\n",
      "Epoch 272/2000, Train Loss: 0.2227, Test Loss: 0.2925\n",
      "Epoch 273/2000, Train Loss: 0.2227, Test Loss: 0.2933\n",
      "Epoch 274/2000, Train Loss: 0.2228, Test Loss: 0.2962\n",
      "Epoch 275/2000, Train Loss: 0.2225, Test Loss: 0.2967\n",
      "Epoch 276/2000, Train Loss: 0.2218, Test Loss: 0.2956\n",
      "Epoch 277/2000, Train Loss: 0.2222, Test Loss: 0.2917\n",
      "Epoch 278/2000, Train Loss: 0.2237, Test Loss: 0.2984\n",
      "Epoch 279/2000, Train Loss: 0.2223, Test Loss: 0.2932\n",
      "Epoch 280/2000, Train Loss: 0.2227, Test Loss: 0.2962\n",
      "Epoch 281/2000, Train Loss: 0.2217, Test Loss: 0.2929\n",
      "Epoch 282/2000, Train Loss: 0.2224, Test Loss: 0.2931\n",
      "Epoch 283/2000, Train Loss: 0.2217, Test Loss: 0.2964\n",
      "Epoch 284/2000, Train Loss: 0.2214, Test Loss: 0.2927\n",
      "Epoch 285/2000, Train Loss: 0.2215, Test Loss: 0.3020\n",
      "Epoch 286/2000, Train Loss: 0.2231, Test Loss: 0.2957\n",
      "Epoch 287/2000, Train Loss: 0.2215, Test Loss: 0.2941\n",
      "Epoch 288/2000, Train Loss: 0.2229, Test Loss: 0.2963\n",
      "Epoch 289/2000, Train Loss: 0.2216, Test Loss: 0.2950\n",
      "Epoch 290/2000, Train Loss: 0.2227, Test Loss: 0.2927\n",
      "Epoch 291/2000, Train Loss: 0.2220, Test Loss: 0.2996\n",
      "Epoch 292/2000, Train Loss: 0.2213, Test Loss: 0.3003\n",
      "Epoch 293/2000, Train Loss: 0.2219, Test Loss: 0.2948\n",
      "Epoch 294/2000, Train Loss: 0.2228, Test Loss: 0.2956\n",
      "Epoch 295/2000, Train Loss: 0.2217, Test Loss: 0.2922\n",
      "Epoch 296/2000, Train Loss: 0.2213, Test Loss: 0.3091\n",
      "Epoch 297/2000, Train Loss: 0.2220, Test Loss: 0.3016\n",
      "Epoch 298/2000, Train Loss: 0.2217, Test Loss: 0.3046\n",
      "Epoch 299/2000, Train Loss: 0.2216, Test Loss: 0.2998\n",
      "Epoch 300/2000, Train Loss: 0.2207, Test Loss: 0.2938\n",
      "Epoch 301/2000, Train Loss: 0.2231, Test Loss: 0.2932\n",
      "Epoch 302/2000, Train Loss: 0.2211, Test Loss: 0.2945\n",
      "Epoch 303/2000, Train Loss: 0.2211, Test Loss: 0.2992\n",
      "Epoch 304/2000, Train Loss: 0.2205, Test Loss: 0.2922\n",
      "Epoch 305/2000, Train Loss: 0.2212, Test Loss: 0.2969\n",
      "Epoch 306/2000, Train Loss: 0.2226, Test Loss: 0.2922\n",
      "Epoch 307/2000, Train Loss: 0.2208, Test Loss: 0.2981\n",
      "Epoch 308/2000, Train Loss: 0.2204, Test Loss: 0.2929\n",
      "Epoch 309/2000, Train Loss: 0.2205, Test Loss: 0.3003\n",
      "Epoch 310/2000, Train Loss: 0.2205, Test Loss: 0.2943\n",
      "Epoch 311/2000, Train Loss: 0.2204, Test Loss: 0.2947\n",
      "Epoch 312/2000, Train Loss: 0.2203, Test Loss: 0.3091\n",
      "Epoch 313/2000, Train Loss: 0.2210, Test Loss: 0.2944\n",
      "Epoch 314/2000, Train Loss: 0.2216, Test Loss: 0.2900\n",
      "Epoch 315/2000, Train Loss: 0.2216, Test Loss: 0.2934\n",
      "Epoch 316/2000, Train Loss: 0.2206, Test Loss: 0.2938\n",
      "Epoch 317/2000, Train Loss: 0.2203, Test Loss: 0.2968\n",
      "Epoch 318/2000, Train Loss: 0.2211, Test Loss: 0.2939\n",
      "Epoch 319/2000, Train Loss: 0.2206, Test Loss: 0.3010\n",
      "Epoch 320/2000, Train Loss: 0.2209, Test Loss: 0.2948\n",
      "Epoch 321/2000, Train Loss: 0.2200, Test Loss: 0.2966\n",
      "Epoch 322/2000, Train Loss: 0.2199, Test Loss: 0.2969\n",
      "Epoch 323/2000, Train Loss: 0.2198, Test Loss: 0.2935\n",
      "Epoch 324/2000, Train Loss: 0.2202, Test Loss: 0.2960\n",
      "Epoch 325/2000, Train Loss: 0.2199, Test Loss: 0.2967\n",
      "Epoch 326/2000, Train Loss: 0.2205, Test Loss: 0.3003\n",
      "Epoch 327/2000, Train Loss: 0.2203, Test Loss: 0.2946\n",
      "Epoch 328/2000, Train Loss: 0.2198, Test Loss: 0.2951\n",
      "Epoch 329/2000, Train Loss: 0.2202, Test Loss: 0.2971\n",
      "Epoch 330/2000, Train Loss: 0.2201, Test Loss: 0.2984\n",
      "Epoch 331/2000, Train Loss: 0.2192, Test Loss: 0.3005\n",
      "Epoch 332/2000, Train Loss: 0.2200, Test Loss: 0.2952\n",
      "Epoch 333/2000, Train Loss: 0.2202, Test Loss: 0.2941\n",
      "Epoch 334/2000, Train Loss: 0.2209, Test Loss: 0.2975\n",
      "Epoch 335/2000, Train Loss: 0.2202, Test Loss: 0.2970\n",
      "Epoch 336/2000, Train Loss: 0.2187, Test Loss: 0.2988\n",
      "Epoch 337/2000, Train Loss: 0.2199, Test Loss: 0.2961\n",
      "Epoch 338/2000, Train Loss: 0.2193, Test Loss: 0.2948\n",
      "Epoch 339/2000, Train Loss: 0.2204, Test Loss: 0.2994\n",
      "Epoch 340/2000, Train Loss: 0.2189, Test Loss: 0.2943\n",
      "Epoch 341/2000, Train Loss: 0.2190, Test Loss: 0.2929\n",
      "Epoch 342/2000, Train Loss: 0.2194, Test Loss: 0.2996\n",
      "Epoch 343/2000, Train Loss: 0.2192, Test Loss: 0.2973\n",
      "Epoch 344/2000, Train Loss: 0.2202, Test Loss: 0.2977\n",
      "Epoch 345/2000, Train Loss: 0.2183, Test Loss: 0.3011\n",
      "Epoch 346/2000, Train Loss: 0.2194, Test Loss: 0.2985\n",
      "Epoch 347/2000, Train Loss: 0.2197, Test Loss: 0.2955\n",
      "Epoch 348/2000, Train Loss: 0.2193, Test Loss: 0.2960\n",
      "Epoch 349/2000, Train Loss: 0.2194, Test Loss: 0.3017\n",
      "Epoch 350/2000, Train Loss: 0.2193, Test Loss: 0.2958\n",
      "Epoch 351/2000, Train Loss: 0.2200, Test Loss: 0.2948\n",
      "Epoch 352/2000, Train Loss: 0.2183, Test Loss: 0.2952\n",
      "Epoch 353/2000, Train Loss: 0.2189, Test Loss: 0.2965\n",
      "Epoch 354/2000, Train Loss: 0.2192, Test Loss: 0.2983\n",
      "Epoch 355/2000, Train Loss: 0.2188, Test Loss: 0.2941\n",
      "Epoch 356/2000, Train Loss: 0.2188, Test Loss: 0.2950\n",
      "Epoch 357/2000, Train Loss: 0.2198, Test Loss: 0.2979\n",
      "Epoch 358/2000, Train Loss: 0.2178, Test Loss: 0.2977\n",
      "Epoch 359/2000, Train Loss: 0.2190, Test Loss: 0.2954\n",
      "Epoch 360/2000, Train Loss: 0.2179, Test Loss: 0.2957\n",
      "Epoch 361/2000, Train Loss: 0.2189, Test Loss: 0.2969\n",
      "Epoch 362/2000, Train Loss: 0.2187, Test Loss: 0.3006\n",
      "Epoch 363/2000, Train Loss: 0.2186, Test Loss: 0.2945\n",
      "Epoch 364/2000, Train Loss: 0.2182, Test Loss: 0.2946\n",
      "Epoch 365/2000, Train Loss: 0.2184, Test Loss: 0.2959\n",
      "Epoch 366/2000, Train Loss: 0.2184, Test Loss: 0.2954\n",
      "Epoch 367/2000, Train Loss: 0.2185, Test Loss: 0.2958\n",
      "Epoch 368/2000, Train Loss: 0.2178, Test Loss: 0.3032\n",
      "Epoch 369/2000, Train Loss: 0.2194, Test Loss: 0.2937\n",
      "Epoch 370/2000, Train Loss: 0.2190, Test Loss: 0.3003\n",
      "Epoch 371/2000, Train Loss: 0.2184, Test Loss: 0.2947\n",
      "Epoch 372/2000, Train Loss: 0.2182, Test Loss: 0.2927\n",
      "Epoch 373/2000, Train Loss: 0.2190, Test Loss: 0.2965\n",
      "Epoch 374/2000, Train Loss: 0.2180, Test Loss: 0.2970\n",
      "Epoch 375/2000, Train Loss: 0.2180, Test Loss: 0.3003\n",
      "Epoch 376/2000, Train Loss: 0.2184, Test Loss: 0.2923\n",
      "Epoch 377/2000, Train Loss: 0.2181, Test Loss: 0.2951\n",
      "Epoch 378/2000, Train Loss: 0.2183, Test Loss: 0.2959\n",
      "Epoch 379/2000, Train Loss: 0.2182, Test Loss: 0.2970\n",
      "Epoch 380/2000, Train Loss: 0.2190, Test Loss: 0.2946\n",
      "Epoch 381/2000, Train Loss: 0.2174, Test Loss: 0.2942\n",
      "Epoch 382/2000, Train Loss: 0.2170, Test Loss: 0.2991\n",
      "Epoch 383/2000, Train Loss: 0.2191, Test Loss: 0.2986\n",
      "Epoch 384/2000, Train Loss: 0.2176, Test Loss: 0.2944\n",
      "Epoch 385/2000, Train Loss: 0.2179, Test Loss: 0.2986\n",
      "Epoch 386/2000, Train Loss: 0.2175, Test Loss: 0.2974\n",
      "Epoch 387/2000, Train Loss: 0.2181, Test Loss: 0.2947\n",
      "Epoch 388/2000, Train Loss: 0.2180, Test Loss: 0.2978\n",
      "Epoch 389/2000, Train Loss: 0.2191, Test Loss: 0.3026\n",
      "Epoch 390/2000, Train Loss: 0.2179, Test Loss: 0.2947\n",
      "Epoch 391/2000, Train Loss: 0.2178, Test Loss: 0.2981\n",
      "Epoch 392/2000, Train Loss: 0.2179, Test Loss: 0.2976\n",
      "Epoch 393/2000, Train Loss: 0.2172, Test Loss: 0.2933\n",
      "Epoch 394/2000, Train Loss: 0.2174, Test Loss: 0.2955\n",
      "Epoch 395/2000, Train Loss: 0.2168, Test Loss: 0.2968\n",
      "Epoch 396/2000, Train Loss: 0.2190, Test Loss: 0.3028\n",
      "Epoch 397/2000, Train Loss: 0.2178, Test Loss: 0.3003\n",
      "Epoch 398/2000, Train Loss: 0.2173, Test Loss: 0.2966\n",
      "Epoch 399/2000, Train Loss: 0.2161, Test Loss: 0.2935\n",
      "Epoch 400/2000, Train Loss: 0.2167, Test Loss: 0.2942\n",
      "Epoch 401/2000, Train Loss: 0.2181, Test Loss: 0.2966\n",
      "Epoch 402/2000, Train Loss: 0.2176, Test Loss: 0.3017\n",
      "Epoch 403/2000, Train Loss: 0.2172, Test Loss: 0.2956\n",
      "Epoch 404/2000, Train Loss: 0.2168, Test Loss: 0.2971\n",
      "Epoch 405/2000, Train Loss: 0.2177, Test Loss: 0.2953\n",
      "Epoch 406/2000, Train Loss: 0.2183, Test Loss: 0.2981\n",
      "Epoch 407/2000, Train Loss: 0.2169, Test Loss: 0.3008\n",
      "Epoch 408/2000, Train Loss: 0.2165, Test Loss: 0.2939\n",
      "Epoch 409/2000, Train Loss: 0.2168, Test Loss: 0.2951\n",
      "Epoch 410/2000, Train Loss: 0.2172, Test Loss: 0.3047\n",
      "Epoch 411/2000, Train Loss: 0.2171, Test Loss: 0.2939\n",
      "Epoch 412/2000, Train Loss: 0.2175, Test Loss: 0.2938\n",
      "Epoch 413/2000, Train Loss: 0.2167, Test Loss: 0.2968\n",
      "Epoch 414/2000, Train Loss: 0.2172, Test Loss: 0.2968\n",
      "Epoch 415/2000, Train Loss: 0.2166, Test Loss: 0.2958\n",
      "Epoch 416/2000, Train Loss: 0.2170, Test Loss: 0.3010\n",
      "Epoch 417/2000, Train Loss: 0.2177, Test Loss: 0.2956\n",
      "Epoch 418/2000, Train Loss: 0.2172, Test Loss: 0.2968\n",
      "Epoch 419/2000, Train Loss: 0.2165, Test Loss: 0.2945\n",
      "Epoch 420/2000, Train Loss: 0.2167, Test Loss: 0.2936\n",
      "Epoch 421/2000, Train Loss: 0.2164, Test Loss: 0.2975\n",
      "Epoch 422/2000, Train Loss: 0.2164, Test Loss: 0.2980\n",
      "Epoch 423/2000, Train Loss: 0.2157, Test Loss: 0.2940\n",
      "Epoch 424/2000, Train Loss: 0.2160, Test Loss: 0.2966\n",
      "Epoch 425/2000, Train Loss: 0.2159, Test Loss: 0.2938\n",
      "Epoch 426/2000, Train Loss: 0.2163, Test Loss: 0.3024\n",
      "Epoch 427/2000, Train Loss: 0.2169, Test Loss: 0.2980\n",
      "Epoch 428/2000, Train Loss: 0.2164, Test Loss: 0.3033\n",
      "Epoch 429/2000, Train Loss: 0.2164, Test Loss: 0.2975\n",
      "Epoch 430/2000, Train Loss: 0.2164, Test Loss: 0.3085\n",
      "Epoch 431/2000, Train Loss: 0.2165, Test Loss: 0.2959\n",
      "Epoch 432/2000, Train Loss: 0.2177, Test Loss: 0.3012\n",
      "Epoch 433/2000, Train Loss: 0.2164, Test Loss: 0.2964\n",
      "Epoch 434/2000, Train Loss: 0.2154, Test Loss: 0.2990\n",
      "Epoch 435/2000, Train Loss: 0.2157, Test Loss: 0.3028\n",
      "Epoch 436/2000, Train Loss: 0.2162, Test Loss: 0.2975\n",
      "Epoch 437/2000, Train Loss: 0.2165, Test Loss: 0.2945\n",
      "Epoch 438/2000, Train Loss: 0.2154, Test Loss: 0.2963\n",
      "Epoch 439/2000, Train Loss: 0.2151, Test Loss: 0.3040\n",
      "Epoch 440/2000, Train Loss: 0.2167, Test Loss: 0.2968\n",
      "Epoch 441/2000, Train Loss: 0.2158, Test Loss: 0.2988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/2000, Train Loss: 0.2156, Test Loss: 0.2978\n",
      "Epoch 443/2000, Train Loss: 0.2157, Test Loss: 0.2961\n",
      "Epoch 444/2000, Train Loss: 0.2155, Test Loss: 0.2943\n",
      "Epoch 445/2000, Train Loss: 0.2161, Test Loss: 0.2951\n",
      "Epoch 446/2000, Train Loss: 0.2152, Test Loss: 0.2944\n",
      "Epoch 447/2000, Train Loss: 0.2156, Test Loss: 0.2990\n",
      "Epoch 448/2000, Train Loss: 0.2157, Test Loss: 0.2989\n",
      "Epoch 449/2000, Train Loss: 0.2152, Test Loss: 0.2981\n",
      "Epoch 450/2000, Train Loss: 0.2159, Test Loss: 0.2947\n",
      "Epoch 451/2000, Train Loss: 0.2159, Test Loss: 0.2959\n",
      "Epoch 452/2000, Train Loss: 0.2147, Test Loss: 0.3061\n",
      "Epoch 453/2000, Train Loss: 0.2167, Test Loss: 0.2987\n",
      "Epoch 454/2000, Train Loss: 0.2164, Test Loss: 0.2994\n",
      "Epoch 455/2000, Train Loss: 0.2159, Test Loss: 0.2953\n",
      "Epoch 456/2000, Train Loss: 0.2160, Test Loss: 0.2948\n",
      "Epoch 457/2000, Train Loss: 0.2154, Test Loss: 0.3042\n",
      "Epoch 458/2000, Train Loss: 0.2154, Test Loss: 0.2945\n",
      "Epoch 459/2000, Train Loss: 0.2146, Test Loss: 0.2964\n",
      "Epoch 460/2000, Train Loss: 0.2139, Test Loss: 0.2961\n",
      "Epoch 461/2000, Train Loss: 0.2146, Test Loss: 0.2935\n",
      "Epoch 462/2000, Train Loss: 0.2151, Test Loss: 0.2954\n",
      "Epoch 463/2000, Train Loss: 0.2146, Test Loss: 0.3020\n",
      "Epoch 464/2000, Train Loss: 0.2146, Test Loss: 0.3029\n",
      "Epoch 465/2000, Train Loss: 0.2149, Test Loss: 0.2968\n",
      "Epoch 466/2000, Train Loss: 0.2152, Test Loss: 0.2995\n",
      "Epoch 467/2000, Train Loss: 0.2150, Test Loss: 0.2974\n",
      "Epoch 468/2000, Train Loss: 0.2155, Test Loss: 0.2971\n",
      "Epoch 469/2000, Train Loss: 0.2156, Test Loss: 0.3056\n",
      "Epoch 470/2000, Train Loss: 0.2153, Test Loss: 0.2969\n",
      "Epoch 471/2000, Train Loss: 0.2154, Test Loss: 0.3017\n",
      "Epoch 472/2000, Train Loss: 0.2155, Test Loss: 0.3023\n",
      "Epoch 473/2000, Train Loss: 0.2158, Test Loss: 0.2982\n",
      "Epoch 474/2000, Train Loss: 0.2143, Test Loss: 0.3038\n",
      "Epoch 475/2000, Train Loss: 0.2158, Test Loss: 0.2994\n",
      "Epoch 476/2000, Train Loss: 0.2145, Test Loss: 0.2971\n",
      "Epoch 477/2000, Train Loss: 0.2158, Test Loss: 0.2936\n",
      "Epoch 478/2000, Train Loss: 0.2142, Test Loss: 0.2966\n",
      "Epoch 479/2000, Train Loss: 0.2143, Test Loss: 0.2963\n",
      "Epoch 480/2000, Train Loss: 0.2154, Test Loss: 0.3004\n",
      "Epoch 481/2000, Train Loss: 0.2145, Test Loss: 0.3066\n",
      "Epoch 482/2000, Train Loss: 0.2151, Test Loss: 0.3061\n",
      "Epoch 483/2000, Train Loss: 0.2152, Test Loss: 0.3020\n",
      "Epoch 484/2000, Train Loss: 0.2142, Test Loss: 0.3011\n",
      "Epoch 485/2000, Train Loss: 0.2140, Test Loss: 0.3002\n",
      "Epoch 486/2000, Train Loss: 0.2150, Test Loss: 0.2951\n",
      "Epoch 487/2000, Train Loss: 0.2147, Test Loss: 0.2945\n",
      "Epoch 488/2000, Train Loss: 0.2146, Test Loss: 0.2967\n",
      "Epoch 489/2000, Train Loss: 0.2142, Test Loss: 0.3022\n",
      "Epoch 490/2000, Train Loss: 0.2140, Test Loss: 0.2997\n",
      "Epoch 491/2000, Train Loss: 0.2145, Test Loss: 0.2969\n",
      "Epoch 492/2000, Train Loss: 0.2142, Test Loss: 0.2982\n",
      "Epoch 493/2000, Train Loss: 0.2144, Test Loss: 0.3006\n",
      "Epoch 494/2000, Train Loss: 0.2140, Test Loss: 0.2960\n",
      "Epoch 495/2000, Train Loss: 0.2140, Test Loss: 0.2954\n",
      "Epoch 496/2000, Train Loss: 0.2136, Test Loss: 0.2965\n",
      "Epoch 497/2000, Train Loss: 0.2143, Test Loss: 0.2953\n",
      "Epoch 498/2000, Train Loss: 0.2140, Test Loss: 0.2979\n",
      "Epoch 499/2000, Train Loss: 0.2137, Test Loss: 0.2956\n",
      "Epoch 500/2000, Train Loss: 0.2143, Test Loss: 0.3008\n",
      "Epoch 501/2000, Train Loss: 0.2134, Test Loss: 0.3006\n",
      "Epoch 502/2000, Train Loss: 0.2138, Test Loss: 0.2986\n",
      "Epoch 503/2000, Train Loss: 0.2141, Test Loss: 0.2959\n",
      "Epoch 504/2000, Train Loss: 0.2147, Test Loss: 0.2956\n",
      "Epoch 505/2000, Train Loss: 0.2135, Test Loss: 0.2984\n",
      "Epoch 506/2000, Train Loss: 0.2136, Test Loss: 0.3054\n",
      "Epoch 507/2000, Train Loss: 0.2137, Test Loss: 0.3002\n",
      "Epoch 508/2000, Train Loss: 0.2138, Test Loss: 0.3027\n",
      "Epoch 509/2000, Train Loss: 0.2141, Test Loss: 0.2990\n",
      "Epoch 510/2000, Train Loss: 0.2138, Test Loss: 0.3017\n",
      "Epoch 511/2000, Train Loss: 0.2134, Test Loss: 0.2962\n",
      "Epoch 512/2000, Train Loss: 0.2142, Test Loss: 0.3006\n",
      "Epoch 513/2000, Train Loss: 0.2138, Test Loss: 0.3018\n",
      "Epoch 514/2000, Train Loss: 0.2147, Test Loss: 0.2993\n",
      "Epoch 515/2000, Train Loss: 0.2144, Test Loss: 0.2957\n",
      "Epoch 516/2000, Train Loss: 0.2133, Test Loss: 0.2994\n",
      "Epoch 517/2000, Train Loss: 0.2137, Test Loss: 0.2961\n",
      "Epoch 518/2000, Train Loss: 0.2135, Test Loss: 0.2962\n",
      "Epoch 519/2000, Train Loss: 0.2130, Test Loss: 0.3011\n",
      "Epoch 520/2000, Train Loss: 0.2136, Test Loss: 0.2996\n",
      "Epoch 521/2000, Train Loss: 0.2132, Test Loss: 0.2968\n",
      "Epoch 522/2000, Train Loss: 0.2131, Test Loss: 0.2950\n",
      "Epoch 523/2000, Train Loss: 0.2132, Test Loss: 0.2969\n",
      "Epoch 524/2000, Train Loss: 0.2136, Test Loss: 0.2983\n",
      "Epoch 525/2000, Train Loss: 0.2136, Test Loss: 0.3027\n",
      "Epoch 526/2000, Train Loss: 0.2134, Test Loss: 0.2969\n",
      "Epoch 527/2000, Train Loss: 0.2137, Test Loss: 0.3066\n",
      "Epoch 528/2000, Train Loss: 0.2132, Test Loss: 0.2980\n",
      "Epoch 529/2000, Train Loss: 0.2137, Test Loss: 0.2982\n",
      "Epoch 530/2000, Train Loss: 0.2130, Test Loss: 0.2969\n",
      "Epoch 531/2000, Train Loss: 0.2134, Test Loss: 0.3038\n",
      "Epoch 532/2000, Train Loss: 0.2135, Test Loss: 0.2971\n",
      "Epoch 533/2000, Train Loss: 0.2136, Test Loss: 0.3002\n",
      "Epoch 534/2000, Train Loss: 0.2127, Test Loss: 0.2954\n",
      "Epoch 535/2000, Train Loss: 0.2138, Test Loss: 0.2979\n",
      "Epoch 536/2000, Train Loss: 0.2138, Test Loss: 0.2975\n",
      "Epoch 537/2000, Train Loss: 0.2139, Test Loss: 0.2978\n",
      "Epoch 538/2000, Train Loss: 0.2141, Test Loss: 0.2967\n",
      "Epoch 539/2000, Train Loss: 0.2128, Test Loss: 0.2984\n",
      "Epoch 540/2000, Train Loss: 0.2130, Test Loss: 0.2962\n",
      "Epoch 541/2000, Train Loss: 0.2130, Test Loss: 0.3035\n",
      "Epoch 542/2000, Train Loss: 0.2124, Test Loss: 0.2953\n",
      "Epoch 543/2000, Train Loss: 0.2135, Test Loss: 0.3005\n",
      "Epoch 544/2000, Train Loss: 0.2137, Test Loss: 0.2990\n",
      "Epoch 545/2000, Train Loss: 0.2134, Test Loss: 0.3139\n",
      "Epoch 546/2000, Train Loss: 0.2125, Test Loss: 0.2982\n",
      "Epoch 547/2000, Train Loss: 0.2136, Test Loss: 0.3001\n",
      "Epoch 548/2000, Train Loss: 0.2132, Test Loss: 0.3059\n",
      "Epoch 549/2000, Train Loss: 0.2131, Test Loss: 0.2996\n",
      "Epoch 550/2000, Train Loss: 0.2128, Test Loss: 0.2999\n",
      "Epoch 551/2000, Train Loss: 0.2132, Test Loss: 0.3002\n",
      "Epoch 552/2000, Train Loss: 0.2132, Test Loss: 0.3042\n",
      "Epoch 553/2000, Train Loss: 0.2128, Test Loss: 0.2981\n",
      "Epoch 554/2000, Train Loss: 0.2125, Test Loss: 0.2999\n",
      "Epoch 555/2000, Train Loss: 0.2125, Test Loss: 0.3034\n",
      "Epoch 556/2000, Train Loss: 0.2127, Test Loss: 0.2965\n",
      "Epoch 557/2000, Train Loss: 0.2127, Test Loss: 0.3001\n",
      "Epoch 558/2000, Train Loss: 0.2127, Test Loss: 0.3010\n",
      "Epoch 559/2000, Train Loss: 0.2123, Test Loss: 0.2952\n",
      "Epoch 560/2000, Train Loss: 0.2117, Test Loss: 0.3014\n",
      "Epoch 561/2000, Train Loss: 0.2126, Test Loss: 0.2961\n",
      "Epoch 562/2000, Train Loss: 0.2122, Test Loss: 0.3026\n",
      "Epoch 563/2000, Train Loss: 0.2144, Test Loss: 0.3042\n",
      "Epoch 564/2000, Train Loss: 0.2118, Test Loss: 0.2978\n",
      "Epoch 565/2000, Train Loss: 0.2119, Test Loss: 0.2982\n",
      "Epoch 566/2000, Train Loss: 0.2130, Test Loss: 0.3020\n",
      "Epoch 567/2000, Train Loss: 0.2123, Test Loss: 0.2939\n",
      "Epoch 568/2000, Train Loss: 0.2124, Test Loss: 0.2992\n",
      "Epoch 569/2000, Train Loss: 0.2127, Test Loss: 0.2964\n",
      "Epoch 570/2000, Train Loss: 0.2122, Test Loss: 0.3010\n",
      "Epoch 571/2000, Train Loss: 0.2129, Test Loss: 0.3000\n",
      "Epoch 572/2000, Train Loss: 0.2121, Test Loss: 0.3025\n",
      "Epoch 573/2000, Train Loss: 0.2125, Test Loss: 0.3041\n",
      "Epoch 574/2000, Train Loss: 0.2120, Test Loss: 0.2976\n",
      "Epoch 575/2000, Train Loss: 0.2121, Test Loss: 0.2977\n",
      "Epoch 576/2000, Train Loss: 0.2121, Test Loss: 0.2987\n",
      "Epoch 577/2000, Train Loss: 0.2116, Test Loss: 0.3009\n",
      "Epoch 578/2000, Train Loss: 0.2125, Test Loss: 0.3036\n",
      "Epoch 579/2000, Train Loss: 0.2138, Test Loss: 0.2966\n",
      "Epoch 580/2000, Train Loss: 0.2123, Test Loss: 0.2955\n",
      "Epoch 581/2000, Train Loss: 0.2115, Test Loss: 0.2991\n",
      "Epoch 582/2000, Train Loss: 0.2117, Test Loss: 0.2998\n",
      "Epoch 583/2000, Train Loss: 0.2122, Test Loss: 0.2970\n",
      "Epoch 584/2000, Train Loss: 0.2117, Test Loss: 0.2966\n",
      "Epoch 585/2000, Train Loss: 0.2124, Test Loss: 0.2967\n",
      "Epoch 586/2000, Train Loss: 0.2122, Test Loss: 0.2994\n",
      "Epoch 587/2000, Train Loss: 0.2119, Test Loss: 0.3083\n",
      "Epoch 588/2000, Train Loss: 0.2115, Test Loss: 0.3034\n",
      "Epoch 589/2000, Train Loss: 0.2119, Test Loss: 0.2991\n",
      "Epoch 590/2000, Train Loss: 0.2118, Test Loss: 0.3059\n",
      "Epoch 591/2000, Train Loss: 0.2121, Test Loss: 0.2977\n",
      "Epoch 592/2000, Train Loss: 0.2111, Test Loss: 0.3050\n",
      "Epoch 593/2000, Train Loss: 0.2117, Test Loss: 0.3044\n",
      "Epoch 594/2000, Train Loss: 0.2122, Test Loss: 0.3073\n",
      "Epoch 595/2000, Train Loss: 0.2118, Test Loss: 0.2980\n",
      "Epoch 596/2000, Train Loss: 0.2120, Test Loss: 0.3018\n",
      "Epoch 597/2000, Train Loss: 0.2115, Test Loss: 0.3000\n",
      "Epoch 598/2000, Train Loss: 0.2118, Test Loss: 0.2983\n",
      "Epoch 599/2000, Train Loss: 0.2118, Test Loss: 0.2975\n",
      "Epoch 600/2000, Train Loss: 0.2119, Test Loss: 0.3015\n",
      "Epoch 601/2000, Train Loss: 0.2124, Test Loss: 0.3068\n",
      "Epoch 602/2000, Train Loss: 0.2112, Test Loss: 0.2984\n",
      "Epoch 603/2000, Train Loss: 0.2121, Test Loss: 0.2988\n",
      "Epoch 604/2000, Train Loss: 0.2117, Test Loss: 0.2974\n",
      "Epoch 605/2000, Train Loss: 0.2112, Test Loss: 0.3012\n",
      "Epoch 606/2000, Train Loss: 0.2114, Test Loss: 0.3006\n",
      "Epoch 607/2000, Train Loss: 0.2117, Test Loss: 0.2986\n",
      "Epoch 608/2000, Train Loss: 0.2109, Test Loss: 0.3043\n",
      "Epoch 609/2000, Train Loss: 0.2116, Test Loss: 0.2985\n",
      "Epoch 610/2000, Train Loss: 0.2109, Test Loss: 0.2991\n",
      "Epoch 611/2000, Train Loss: 0.2116, Test Loss: 0.3035\n",
      "Epoch 612/2000, Train Loss: 0.2112, Test Loss: 0.2965\n",
      "Epoch 613/2000, Train Loss: 0.2125, Test Loss: 0.2961\n",
      "Epoch 614/2000, Train Loss: 0.2110, Test Loss: 0.2965\n",
      "Epoch 615/2000, Train Loss: 0.2109, Test Loss: 0.3002\n",
      "Epoch 616/2000, Train Loss: 0.2112, Test Loss: 0.3006\n",
      "Epoch 617/2000, Train Loss: 0.2110, Test Loss: 0.3002\n",
      "Epoch 618/2000, Train Loss: 0.2116, Test Loss: 0.2967\n",
      "Epoch 619/2000, Train Loss: 0.2109, Test Loss: 0.2974\n",
      "Epoch 620/2000, Train Loss: 0.2112, Test Loss: 0.2976\n",
      "Epoch 621/2000, Train Loss: 0.2112, Test Loss: 0.3065\n",
      "Epoch 622/2000, Train Loss: 0.2108, Test Loss: 0.2987\n",
      "Epoch 623/2000, Train Loss: 0.2123, Test Loss: 0.2977\n",
      "Epoch 624/2000, Train Loss: 0.2097, Test Loss: 0.2977\n",
      "Epoch 625/2000, Train Loss: 0.2109, Test Loss: 0.2977\n",
      "Epoch 626/2000, Train Loss: 0.2106, Test Loss: 0.2969\n",
      "Epoch 627/2000, Train Loss: 0.2122, Test Loss: 0.3042\n",
      "Epoch 628/2000, Train Loss: 0.2110, Test Loss: 0.3025\n",
      "Epoch 629/2000, Train Loss: 0.2101, Test Loss: 0.2979\n",
      "Epoch 630/2000, Train Loss: 0.2120, Test Loss: 0.2996\n",
      "Epoch 631/2000, Train Loss: 0.2108, Test Loss: 0.2961\n",
      "Epoch 632/2000, Train Loss: 0.2110, Test Loss: 0.2973\n",
      "Epoch 633/2000, Train Loss: 0.2113, Test Loss: 0.2993\n",
      "Epoch 634/2000, Train Loss: 0.2102, Test Loss: 0.3060\n",
      "Epoch 635/2000, Train Loss: 0.2110, Test Loss: 0.3028\n",
      "Epoch 636/2000, Train Loss: 0.2105, Test Loss: 0.2963\n",
      "Epoch 637/2000, Train Loss: 0.2117, Test Loss: 0.3017\n",
      "Epoch 638/2000, Train Loss: 0.2117, Test Loss: 0.3088\n",
      "Epoch 639/2000, Train Loss: 0.2108, Test Loss: 0.3027\n",
      "Epoch 640/2000, Train Loss: 0.2101, Test Loss: 0.3030\n",
      "Epoch 641/2000, Train Loss: 0.2104, Test Loss: 0.3029\n",
      "Epoch 642/2000, Train Loss: 0.2106, Test Loss: 0.3022\n",
      "Epoch 643/2000, Train Loss: 0.2104, Test Loss: 0.3057\n",
      "Epoch 644/2000, Train Loss: 0.2106, Test Loss: 0.2986\n",
      "Epoch 645/2000, Train Loss: 0.2108, Test Loss: 0.2965\n",
      "Epoch 646/2000, Train Loss: 0.2104, Test Loss: 0.2953\n",
      "Epoch 647/2000, Train Loss: 0.2104, Test Loss: 0.2995\n",
      "Epoch 648/2000, Train Loss: 0.2103, Test Loss: 0.2999\n",
      "Epoch 649/2000, Train Loss: 0.2097, Test Loss: 0.2977\n",
      "Epoch 650/2000, Train Loss: 0.2104, Test Loss: 0.2970\n",
      "Epoch 651/2000, Train Loss: 0.2096, Test Loss: 0.3012\n",
      "Epoch 652/2000, Train Loss: 0.2104, Test Loss: 0.2977\n",
      "Epoch 653/2000, Train Loss: 0.2113, Test Loss: 0.3034\n",
      "Epoch 654/2000, Train Loss: 0.2108, Test Loss: 0.3023\n",
      "Epoch 655/2000, Train Loss: 0.2105, Test Loss: 0.3031\n",
      "Epoch 656/2000, Train Loss: 0.2106, Test Loss: 0.3004\n",
      "Epoch 657/2000, Train Loss: 0.2106, Test Loss: 0.2991\n",
      "Epoch 658/2000, Train Loss: 0.2105, Test Loss: 0.2997\n",
      "Epoch 659/2000, Train Loss: 0.2101, Test Loss: 0.2993\n",
      "Epoch 660/2000, Train Loss: 0.2111, Test Loss: 0.2999\n",
      "Epoch 661/2000, Train Loss: 0.2109, Test Loss: 0.2986\n",
      "Epoch 662/2000, Train Loss: 0.2098, Test Loss: 0.2984\n",
      "Epoch 663/2000, Train Loss: 0.2098, Test Loss: 0.2983\n",
      "Epoch 664/2000, Train Loss: 0.2097, Test Loss: 0.3017\n",
      "Epoch 665/2000, Train Loss: 0.2107, Test Loss: 0.2991\n",
      "Epoch 666/2000, Train Loss: 0.2095, Test Loss: 0.3025\n",
      "Epoch 667/2000, Train Loss: 0.2109, Test Loss: 0.3037\n",
      "Epoch 668/2000, Train Loss: 0.2101, Test Loss: 0.2974\n",
      "Epoch 669/2000, Train Loss: 0.2114, Test Loss: 0.3010\n",
      "Epoch 670/2000, Train Loss: 0.2100, Test Loss: 0.2990\n",
      "Epoch 671/2000, Train Loss: 0.2099, Test Loss: 0.2985\n",
      "Epoch 672/2000, Train Loss: 0.2103, Test Loss: 0.3001\n",
      "Epoch 673/2000, Train Loss: 0.2095, Test Loss: 0.3017\n",
      "Epoch 674/2000, Train Loss: 0.2111, Test Loss: 0.3052\n",
      "Epoch 675/2000, Train Loss: 0.2106, Test Loss: 0.3080\n",
      "Epoch 676/2000, Train Loss: 0.2110, Test Loss: 0.2990\n",
      "Epoch 677/2000, Train Loss: 0.2095, Test Loss: 0.2971\n",
      "Epoch 678/2000, Train Loss: 0.2101, Test Loss: 0.3026\n",
      "Epoch 679/2000, Train Loss: 0.2094, Test Loss: 0.2997\n",
      "Epoch 680/2000, Train Loss: 0.2099, Test Loss: 0.2985\n",
      "Epoch 681/2000, Train Loss: 0.2106, Test Loss: 0.2992\n",
      "Epoch 682/2000, Train Loss: 0.2091, Test Loss: 0.2966\n",
      "Epoch 683/2000, Train Loss: 0.2101, Test Loss: 0.2982\n",
      "Epoch 684/2000, Train Loss: 0.2108, Test Loss: 0.3064\n",
      "Epoch 685/2000, Train Loss: 0.2101, Test Loss: 0.3004\n",
      "Epoch 686/2000, Train Loss: 0.2113, Test Loss: 0.2994\n",
      "Epoch 687/2000, Train Loss: 0.2095, Test Loss: 0.3130\n",
      "Epoch 688/2000, Train Loss: 0.2097, Test Loss: 0.3010\n",
      "Epoch 689/2000, Train Loss: 0.2100, Test Loss: 0.3004\n",
      "Epoch 690/2000, Train Loss: 0.2102, Test Loss: 0.3006\n",
      "Epoch 691/2000, Train Loss: 0.2102, Test Loss: 0.3033\n",
      "Epoch 692/2000, Train Loss: 0.2093, Test Loss: 0.2970\n",
      "Epoch 693/2000, Train Loss: 0.2100, Test Loss: 0.2969\n",
      "Epoch 694/2000, Train Loss: 0.2103, Test Loss: 0.2983\n",
      "Epoch 695/2000, Train Loss: 0.2095, Test Loss: 0.2982\n",
      "Epoch 696/2000, Train Loss: 0.2104, Test Loss: 0.2996\n",
      "Epoch 697/2000, Train Loss: 0.2100, Test Loss: 0.3015\n",
      "Epoch 698/2000, Train Loss: 0.2091, Test Loss: 0.2996\n",
      "Epoch 699/2000, Train Loss: 0.2095, Test Loss: 0.3036\n",
      "Epoch 700/2000, Train Loss: 0.2094, Test Loss: 0.3054\n",
      "Epoch 701/2000, Train Loss: 0.2093, Test Loss: 0.3063\n",
      "Epoch 702/2000, Train Loss: 0.2093, Test Loss: 0.2982\n",
      "Epoch 703/2000, Train Loss: 0.2093, Test Loss: 0.3013\n",
      "Epoch 704/2000, Train Loss: 0.2100, Test Loss: 0.3007\n",
      "Epoch 705/2000, Train Loss: 0.2089, Test Loss: 0.3021\n",
      "Epoch 706/2000, Train Loss: 0.2089, Test Loss: 0.3045\n",
      "Epoch 707/2000, Train Loss: 0.2090, Test Loss: 0.3081\n",
      "Epoch 708/2000, Train Loss: 0.2087, Test Loss: 0.2974\n",
      "Epoch 709/2000, Train Loss: 0.2096, Test Loss: 0.3005\n",
      "Epoch 710/2000, Train Loss: 0.2095, Test Loss: 0.2988\n",
      "Epoch 711/2000, Train Loss: 0.2093, Test Loss: 0.2996\n",
      "Epoch 712/2000, Train Loss: 0.2092, Test Loss: 0.3093\n",
      "Epoch 713/2000, Train Loss: 0.2090, Test Loss: 0.2976\n",
      "Epoch 714/2000, Train Loss: 0.2086, Test Loss: 0.3001\n",
      "Epoch 715/2000, Train Loss: 0.2088, Test Loss: 0.3149\n",
      "Epoch 716/2000, Train Loss: 0.2096, Test Loss: 0.3000\n",
      "Epoch 717/2000, Train Loss: 0.2102, Test Loss: 0.2976\n",
      "Epoch 718/2000, Train Loss: 0.2091, Test Loss: 0.3095\n",
      "Epoch 719/2000, Train Loss: 0.2095, Test Loss: 0.3051\n",
      "Epoch 720/2000, Train Loss: 0.2095, Test Loss: 0.3000\n",
      "Epoch 721/2000, Train Loss: 0.2095, Test Loss: 0.3004\n",
      "Epoch 722/2000, Train Loss: 0.2090, Test Loss: 0.3001\n",
      "Epoch 723/2000, Train Loss: 0.2090, Test Loss: 0.3033\n",
      "Epoch 724/2000, Train Loss: 0.2098, Test Loss: 0.2994\n",
      "Epoch 725/2000, Train Loss: 0.2092, Test Loss: 0.3054\n",
      "Epoch 726/2000, Train Loss: 0.2090, Test Loss: 0.2983\n",
      "Epoch 727/2000, Train Loss: 0.2099, Test Loss: 0.3084\n",
      "Epoch 728/2000, Train Loss: 0.2092, Test Loss: 0.3011\n",
      "Epoch 729/2000, Train Loss: 0.2087, Test Loss: 0.3056\n",
      "Epoch 730/2000, Train Loss: 0.2088, Test Loss: 0.3003\n",
      "Epoch 731/2000, Train Loss: 0.2089, Test Loss: 0.2990\n",
      "Epoch 732/2000, Train Loss: 0.2092, Test Loss: 0.3025\n",
      "Epoch 733/2000, Train Loss: 0.2090, Test Loss: 0.3039\n",
      "Epoch 734/2000, Train Loss: 0.2084, Test Loss: 0.2979\n",
      "Epoch 735/2000, Train Loss: 0.2090, Test Loss: 0.3000\n",
      "Epoch 736/2000, Train Loss: 0.2083, Test Loss: 0.3004\n",
      "Epoch 737/2000, Train Loss: 0.2082, Test Loss: 0.3041\n",
      "Epoch 738/2000, Train Loss: 0.2097, Test Loss: 0.3009\n",
      "Epoch 739/2000, Train Loss: 0.2092, Test Loss: 0.3007\n",
      "Epoch 740/2000, Train Loss: 0.2087, Test Loss: 0.3122\n",
      "Epoch 741/2000, Train Loss: 0.2087, Test Loss: 0.3017\n",
      "Epoch 742/2000, Train Loss: 0.2084, Test Loss: 0.3013\n",
      "Epoch 743/2000, Train Loss: 0.2089, Test Loss: 0.2995\n",
      "Epoch 744/2000, Train Loss: 0.2084, Test Loss: 0.3018\n",
      "Epoch 745/2000, Train Loss: 0.2089, Test Loss: 0.3059\n",
      "Epoch 746/2000, Train Loss: 0.2080, Test Loss: 0.2997\n",
      "Epoch 747/2000, Train Loss: 0.2092, Test Loss: 0.2991\n",
      "Epoch 748/2000, Train Loss: 0.2084, Test Loss: 0.2972\n",
      "Epoch 749/2000, Train Loss: 0.2089, Test Loss: 0.2992\n",
      "Epoch 750/2000, Train Loss: 0.2087, Test Loss: 0.2975\n",
      "Epoch 751/2000, Train Loss: 0.2083, Test Loss: 0.2994\n",
      "Epoch 752/2000, Train Loss: 0.2082, Test Loss: 0.3017\n",
      "Epoch 753/2000, Train Loss: 0.2080, Test Loss: 0.2979\n",
      "Epoch 754/2000, Train Loss: 0.2091, Test Loss: 0.3010\n",
      "Epoch 755/2000, Train Loss: 0.2085, Test Loss: 0.3029\n",
      "Epoch 756/2000, Train Loss: 0.2087, Test Loss: 0.3015\n",
      "Epoch 757/2000, Train Loss: 0.2085, Test Loss: 0.3019\n",
      "Epoch 758/2000, Train Loss: 0.2085, Test Loss: 0.3060\n",
      "Epoch 759/2000, Train Loss: 0.2083, Test Loss: 0.3014\n",
      "Epoch 760/2000, Train Loss: 0.2088, Test Loss: 0.3135\n",
      "Epoch 761/2000, Train Loss: 0.2080, Test Loss: 0.3036\n",
      "Epoch 762/2000, Train Loss: 0.2076, Test Loss: 0.3121\n",
      "Epoch 763/2000, Train Loss: 0.2079, Test Loss: 0.3012\n",
      "Epoch 764/2000, Train Loss: 0.2078, Test Loss: 0.2989\n",
      "Epoch 765/2000, Train Loss: 0.2085, Test Loss: 0.2989\n",
      "Epoch 766/2000, Train Loss: 0.2084, Test Loss: 0.3020\n",
      "Epoch 767/2000, Train Loss: 0.2087, Test Loss: 0.3081\n",
      "Epoch 768/2000, Train Loss: 0.2079, Test Loss: 0.2988\n",
      "Epoch 769/2000, Train Loss: 0.2079, Test Loss: 0.2997\n",
      "Epoch 770/2000, Train Loss: 0.2083, Test Loss: 0.3012\n",
      "Epoch 771/2000, Train Loss: 0.2080, Test Loss: 0.3105\n",
      "Epoch 772/2000, Train Loss: 0.2085, Test Loss: 0.2993\n",
      "Epoch 773/2000, Train Loss: 0.2083, Test Loss: 0.3116\n",
      "Epoch 774/2000, Train Loss: 0.2078, Test Loss: 0.3131\n",
      "Epoch 775/2000, Train Loss: 0.2082, Test Loss: 0.3017\n",
      "Epoch 776/2000, Train Loss: 0.2075, Test Loss: 0.3030\n",
      "Epoch 777/2000, Train Loss: 0.2078, Test Loss: 0.3085\n",
      "Epoch 778/2000, Train Loss: 0.2084, Test Loss: 0.3057\n",
      "Epoch 779/2000, Train Loss: 0.2086, Test Loss: 0.3082\n",
      "Epoch 780/2000, Train Loss: 0.2079, Test Loss: 0.3023\n",
      "Epoch 781/2000, Train Loss: 0.2080, Test Loss: 0.3037\n",
      "Epoch 782/2000, Train Loss: 0.2078, Test Loss: 0.3077\n",
      "Epoch 783/2000, Train Loss: 0.2083, Test Loss: 0.3041\n",
      "Epoch 784/2000, Train Loss: 0.2080, Test Loss: 0.3030\n",
      "Epoch 785/2000, Train Loss: 0.2073, Test Loss: 0.3002\n",
      "Epoch 786/2000, Train Loss: 0.2074, Test Loss: 0.3028\n",
      "Epoch 787/2000, Train Loss: 0.2077, Test Loss: 0.2992\n",
      "Epoch 788/2000, Train Loss: 0.2086, Test Loss: 0.3092\n",
      "Epoch 789/2000, Train Loss: 0.2077, Test Loss: 0.3005\n",
      "Epoch 790/2000, Train Loss: 0.2073, Test Loss: 0.3035\n",
      "Epoch 791/2000, Train Loss: 0.2074, Test Loss: 0.2996\n",
      "Epoch 792/2000, Train Loss: 0.2081, Test Loss: 0.3062\n",
      "Epoch 793/2000, Train Loss: 0.2077, Test Loss: 0.3028\n",
      "Epoch 794/2000, Train Loss: 0.2081, Test Loss: 0.2993\n",
      "Epoch 795/2000, Train Loss: 0.2084, Test Loss: 0.3036\n",
      "Epoch 796/2000, Train Loss: 0.2075, Test Loss: 0.3075\n",
      "Epoch 797/2000, Train Loss: 0.2075, Test Loss: 0.3005\n",
      "Epoch 798/2000, Train Loss: 0.2085, Test Loss: 0.3055\n",
      "Epoch 799/2000, Train Loss: 0.2074, Test Loss: 0.3004\n",
      "Epoch 800/2000, Train Loss: 0.2086, Test Loss: 0.3039\n",
      "Epoch 801/2000, Train Loss: 0.2082, Test Loss: 0.3083\n",
      "Epoch 802/2000, Train Loss: 0.2076, Test Loss: 0.3007\n",
      "Epoch 803/2000, Train Loss: 0.2082, Test Loss: 0.3054\n",
      "Epoch 804/2000, Train Loss: 0.2079, Test Loss: 0.3053\n",
      "Epoch 805/2000, Train Loss: 0.2092, Test Loss: 0.3029\n",
      "Epoch 806/2000, Train Loss: 0.2074, Test Loss: 0.3002\n",
      "Epoch 807/2000, Train Loss: 0.2076, Test Loss: 0.3036\n",
      "Epoch 808/2000, Train Loss: 0.2077, Test Loss: 0.2979\n",
      "Epoch 809/2000, Train Loss: 0.2070, Test Loss: 0.3016\n",
      "Epoch 810/2000, Train Loss: 0.2071, Test Loss: 0.3013\n",
      "Epoch 811/2000, Train Loss: 0.2075, Test Loss: 0.2989\n",
      "Epoch 812/2000, Train Loss: 0.2076, Test Loss: 0.3051\n",
      "Epoch 813/2000, Train Loss: 0.2067, Test Loss: 0.3033\n",
      "Epoch 814/2000, Train Loss: 0.2074, Test Loss: 0.3003\n",
      "Epoch 815/2000, Train Loss: 0.2073, Test Loss: 0.2991\n",
      "Epoch 816/2000, Train Loss: 0.2078, Test Loss: 0.3027\n",
      "Epoch 817/2000, Train Loss: 0.2067, Test Loss: 0.3024\n",
      "Epoch 818/2000, Train Loss: 0.2072, Test Loss: 0.3019\n",
      "Epoch 819/2000, Train Loss: 0.2069, Test Loss: 0.3035\n",
      "Epoch 820/2000, Train Loss: 0.2070, Test Loss: 0.3075\n",
      "Epoch 821/2000, Train Loss: 0.2080, Test Loss: 0.3055\n",
      "Epoch 822/2000, Train Loss: 0.2075, Test Loss: 0.2984\n",
      "Epoch 823/2000, Train Loss: 0.2076, Test Loss: 0.3012\n",
      "Epoch 824/2000, Train Loss: 0.2077, Test Loss: 0.3070\n",
      "Epoch 825/2000, Train Loss: 0.2067, Test Loss: 0.3026\n",
      "Epoch 826/2000, Train Loss: 0.2079, Test Loss: 0.3007\n",
      "Epoch 827/2000, Train Loss: 0.2083, Test Loss: 0.3008\n",
      "Epoch 828/2000, Train Loss: 0.2076, Test Loss: 0.3012\n",
      "Epoch 829/2000, Train Loss: 0.2075, Test Loss: 0.3047\n",
      "Epoch 830/2000, Train Loss: 0.2071, Test Loss: 0.3010\n",
      "Epoch 831/2000, Train Loss: 0.2070, Test Loss: 0.2994\n",
      "Epoch 832/2000, Train Loss: 0.2070, Test Loss: 0.3022\n",
      "Epoch 833/2000, Train Loss: 0.2070, Test Loss: 0.3007\n",
      "Epoch 834/2000, Train Loss: 0.2077, Test Loss: 0.3016\n",
      "Epoch 835/2000, Train Loss: 0.2066, Test Loss: 0.3050\n",
      "Epoch 836/2000, Train Loss: 0.2073, Test Loss: 0.3023\n",
      "Epoch 837/2000, Train Loss: 0.2079, Test Loss: 0.3068\n",
      "Epoch 838/2000, Train Loss: 0.2069, Test Loss: 0.3014\n",
      "Epoch 839/2000, Train Loss: 0.2076, Test Loss: 0.3006\n",
      "Epoch 840/2000, Train Loss: 0.2070, Test Loss: 0.3060\n",
      "Epoch 841/2000, Train Loss: 0.2072, Test Loss: 0.3057\n",
      "Epoch 842/2000, Train Loss: 0.2072, Test Loss: 0.3011\n",
      "Epoch 843/2000, Train Loss: 0.2082, Test Loss: 0.3079\n",
      "Epoch 844/2000, Train Loss: 0.2067, Test Loss: 0.3000\n",
      "Epoch 845/2000, Train Loss: 0.2066, Test Loss: 0.3022\n",
      "Epoch 846/2000, Train Loss: 0.2069, Test Loss: 0.3009\n",
      "Epoch 847/2000, Train Loss: 0.2072, Test Loss: 0.3034\n",
      "Epoch 848/2000, Train Loss: 0.2071, Test Loss: 0.3030\n",
      "Epoch 849/2000, Train Loss: 0.2074, Test Loss: 0.3026\n",
      "Epoch 850/2000, Train Loss: 0.2082, Test Loss: 0.3011\n",
      "Epoch 851/2000, Train Loss: 0.2076, Test Loss: 0.3064\n",
      "Epoch 852/2000, Train Loss: 0.2069, Test Loss: 0.3053\n",
      "Epoch 853/2000, Train Loss: 0.2070, Test Loss: 0.3071\n",
      "Epoch 854/2000, Train Loss: 0.2063, Test Loss: 0.3066\n",
      "Epoch 855/2000, Train Loss: 0.2072, Test Loss: 0.2997\n",
      "Epoch 856/2000, Train Loss: 0.2064, Test Loss: 0.3005\n",
      "Epoch 857/2000, Train Loss: 0.2073, Test Loss: 0.3028\n",
      "Epoch 858/2000, Train Loss: 0.2066, Test Loss: 0.3012\n",
      "Epoch 859/2000, Train Loss: 0.2072, Test Loss: 0.3052\n",
      "Epoch 860/2000, Train Loss: 0.2069, Test Loss: 0.3001\n",
      "Epoch 861/2000, Train Loss: 0.2064, Test Loss: 0.3012\n",
      "Epoch 862/2000, Train Loss: 0.2073, Test Loss: 0.3020\n",
      "Epoch 863/2000, Train Loss: 0.2069, Test Loss: 0.3025\n",
      "Epoch 864/2000, Train Loss: 0.2072, Test Loss: 0.2994\n",
      "Epoch 865/2000, Train Loss: 0.2061, Test Loss: 0.3022\n",
      "Epoch 866/2000, Train Loss: 0.2065, Test Loss: 0.3087\n",
      "Epoch 867/2000, Train Loss: 0.2065, Test Loss: 0.3062\n",
      "Epoch 868/2000, Train Loss: 0.2064, Test Loss: 0.3045\n",
      "Epoch 869/2000, Train Loss: 0.2070, Test Loss: 0.3027\n",
      "Epoch 870/2000, Train Loss: 0.2068, Test Loss: 0.3029\n",
      "Epoch 871/2000, Train Loss: 0.2066, Test Loss: 0.3071\n",
      "Epoch 872/2000, Train Loss: 0.2081, Test Loss: 0.3066\n",
      "Epoch 873/2000, Train Loss: 0.2067, Test Loss: 0.3117\n",
      "Epoch 874/2000, Train Loss: 0.2064, Test Loss: 0.3058\n",
      "Epoch 875/2000, Train Loss: 0.2062, Test Loss: 0.3061\n",
      "Epoch 876/2000, Train Loss: 0.2060, Test Loss: 0.3013\n",
      "Epoch 877/2000, Train Loss: 0.2067, Test Loss: 0.3024\n",
      "Epoch 878/2000, Train Loss: 0.2066, Test Loss: 0.3007\n",
      "Epoch 879/2000, Train Loss: 0.2059, Test Loss: 0.3024\n",
      "Epoch 880/2000, Train Loss: 0.2066, Test Loss: 0.3018\n",
      "Epoch 881/2000, Train Loss: 0.2059, Test Loss: 0.3076\n",
      "Epoch 882/2000, Train Loss: 0.2067, Test Loss: 0.3112\n",
      "Epoch 883/2000, Train Loss: 0.2059, Test Loss: 0.3174\n",
      "Epoch 884/2000, Train Loss: 0.2069, Test Loss: 0.3019\n",
      "Epoch 885/2000, Train Loss: 0.2063, Test Loss: 0.3024\n",
      "Epoch 886/2000, Train Loss: 0.2066, Test Loss: 0.3012\n",
      "Epoch 887/2000, Train Loss: 0.2062, Test Loss: 0.3075\n",
      "Epoch 888/2000, Train Loss: 0.2058, Test Loss: 0.3043\n",
      "Epoch 889/2000, Train Loss: 0.2063, Test Loss: 0.3037\n",
      "Epoch 890/2000, Train Loss: 0.2064, Test Loss: 0.3100\n",
      "Epoch 891/2000, Train Loss: 0.2060, Test Loss: 0.3063\n",
      "Epoch 892/2000, Train Loss: 0.2066, Test Loss: 0.3029\n",
      "Epoch 893/2000, Train Loss: 0.2071, Test Loss: 0.3163\n",
      "Epoch 894/2000, Train Loss: 0.2061, Test Loss: 0.3002\n",
      "Epoch 895/2000, Train Loss: 0.2065, Test Loss: 0.3042\n",
      "Epoch 896/2000, Train Loss: 0.2069, Test Loss: 0.3043\n",
      "Epoch 897/2000, Train Loss: 0.2063, Test Loss: 0.3068\n",
      "Epoch 898/2000, Train Loss: 0.2064, Test Loss: 0.3050\n",
      "Epoch 899/2000, Train Loss: 0.2060, Test Loss: 0.3070\n",
      "Epoch 900/2000, Train Loss: 0.2064, Test Loss: 0.3028\n",
      "Epoch 901/2000, Train Loss: 0.2056, Test Loss: 0.3056\n",
      "Epoch 902/2000, Train Loss: 0.2054, Test Loss: 0.3002\n",
      "Epoch 903/2000, Train Loss: 0.2059, Test Loss: 0.3072\n",
      "Epoch 904/2000, Train Loss: 0.2066, Test Loss: 0.3038\n",
      "Epoch 905/2000, Train Loss: 0.2066, Test Loss: 0.3030\n",
      "Epoch 906/2000, Train Loss: 0.2061, Test Loss: 0.3030\n",
      "Epoch 907/2000, Train Loss: 0.2063, Test Loss: 0.3084\n",
      "Epoch 908/2000, Train Loss: 0.2057, Test Loss: 0.3075\n",
      "Epoch 909/2000, Train Loss: 0.2062, Test Loss: 0.3017\n",
      "Epoch 910/2000, Train Loss: 0.2052, Test Loss: 0.3143\n",
      "Epoch 911/2000, Train Loss: 0.2066, Test Loss: 0.3015\n",
      "Epoch 912/2000, Train Loss: 0.2057, Test Loss: 0.3037\n",
      "Epoch 913/2000, Train Loss: 0.2062, Test Loss: 0.3236\n",
      "Epoch 914/2000, Train Loss: 0.2062, Test Loss: 0.3028\n",
      "Epoch 915/2000, Train Loss: 0.2062, Test Loss: 0.3029\n",
      "Epoch 916/2000, Train Loss: 0.2063, Test Loss: 0.3012\n",
      "Epoch 917/2000, Train Loss: 0.2063, Test Loss: 0.3059\n",
      "Epoch 918/2000, Train Loss: 0.2055, Test Loss: 0.2999\n",
      "Epoch 919/2000, Train Loss: 0.2064, Test Loss: 0.3046\n",
      "Epoch 920/2000, Train Loss: 0.2064, Test Loss: 0.3071\n",
      "Epoch 921/2000, Train Loss: 0.2061, Test Loss: 0.3035\n",
      "Epoch 922/2000, Train Loss: 0.2058, Test Loss: 0.3062\n",
      "Epoch 923/2000, Train Loss: 0.2066, Test Loss: 0.3059\n",
      "Epoch 924/2000, Train Loss: 0.2060, Test Loss: 0.3015\n",
      "Epoch 925/2000, Train Loss: 0.2055, Test Loss: 0.3340\n",
      "Epoch 926/2000, Train Loss: 0.2049, Test Loss: 0.3006\n",
      "Epoch 927/2000, Train Loss: 0.2057, Test Loss: 0.3042\n",
      "Epoch 928/2000, Train Loss: 0.2058, Test Loss: 0.3047\n",
      "Epoch 929/2000, Train Loss: 0.2058, Test Loss: 0.3069\n",
      "Epoch 930/2000, Train Loss: 0.2059, Test Loss: 0.3148\n",
      "Epoch 931/2000, Train Loss: 0.2061, Test Loss: 0.3070\n",
      "Epoch 932/2000, Train Loss: 0.2054, Test Loss: 0.3077\n",
      "Epoch 933/2000, Train Loss: 0.2058, Test Loss: 0.3043\n",
      "Epoch 934/2000, Train Loss: 0.2059, Test Loss: 0.3016\n",
      "Epoch 935/2000, Train Loss: 0.2068, Test Loss: 0.3021\n",
      "Epoch 936/2000, Train Loss: 0.2056, Test Loss: 0.3066\n",
      "Epoch 937/2000, Train Loss: 0.2059, Test Loss: 0.3057\n",
      "Epoch 938/2000, Train Loss: 0.2063, Test Loss: 0.3065\n",
      "Epoch 939/2000, Train Loss: 0.2053, Test Loss: 0.3047\n",
      "Epoch 940/2000, Train Loss: 0.2055, Test Loss: 0.3047\n",
      "Epoch 941/2000, Train Loss: 0.2053, Test Loss: 0.3055\n",
      "Epoch 942/2000, Train Loss: 0.2057, Test Loss: 0.3017\n",
      "Epoch 943/2000, Train Loss: 0.2056, Test Loss: 0.3029\n",
      "Epoch 944/2000, Train Loss: 0.2060, Test Loss: 0.3009\n",
      "Epoch 945/2000, Train Loss: 0.2055, Test Loss: 0.3052\n",
      "Epoch 946/2000, Train Loss: 0.2054, Test Loss: 0.3079\n",
      "Epoch 947/2000, Train Loss: 0.2054, Test Loss: 0.3016\n",
      "Epoch 948/2000, Train Loss: 0.2060, Test Loss: 0.3064\n",
      "Epoch 949/2000, Train Loss: 0.2051, Test Loss: 0.3015\n",
      "Epoch 950/2000, Train Loss: 0.2047, Test Loss: 0.3034\n",
      "Epoch 951/2000, Train Loss: 0.2058, Test Loss: 0.3031\n",
      "Epoch 952/2000, Train Loss: 0.2055, Test Loss: 0.3054\n",
      "Epoch 953/2000, Train Loss: 0.2058, Test Loss: 0.3016\n",
      "Epoch 954/2000, Train Loss: 0.2054, Test Loss: 0.3057\n",
      "Epoch 955/2000, Train Loss: 0.2050, Test Loss: 0.3014\n",
      "Epoch 956/2000, Train Loss: 0.2053, Test Loss: 0.3087\n",
      "Epoch 957/2000, Train Loss: 0.2051, Test Loss: 0.3062\n",
      "Epoch 958/2000, Train Loss: 0.2053, Test Loss: 0.3012\n",
      "Epoch 959/2000, Train Loss: 0.2057, Test Loss: 0.3090\n",
      "Epoch 960/2000, Train Loss: 0.2049, Test Loss: 0.3053\n",
      "Epoch 961/2000, Train Loss: 0.2053, Test Loss: 0.3083\n",
      "Epoch 962/2000, Train Loss: 0.2050, Test Loss: 0.3072\n",
      "Epoch 963/2000, Train Loss: 0.2061, Test Loss: 0.3014\n",
      "Epoch 964/2000, Train Loss: 0.2051, Test Loss: 0.3040\n",
      "Epoch 965/2000, Train Loss: 0.2053, Test Loss: 0.3115\n",
      "Epoch 966/2000, Train Loss: 0.2049, Test Loss: 0.3079\n",
      "Epoch 967/2000, Train Loss: 0.2056, Test Loss: 0.3033\n",
      "Epoch 968/2000, Train Loss: 0.2054, Test Loss: 0.3024\n",
      "Epoch 969/2000, Train Loss: 0.2048, Test Loss: 0.3008\n",
      "Epoch 970/2000, Train Loss: 0.2055, Test Loss: 0.3036\n",
      "Epoch 971/2000, Train Loss: 0.2057, Test Loss: 0.3021\n",
      "Epoch 972/2000, Train Loss: 0.2051, Test Loss: 0.3010\n",
      "Epoch 973/2000, Train Loss: 0.2052, Test Loss: 0.3112\n",
      "Epoch 974/2000, Train Loss: 0.2048, Test Loss: 0.3051\n",
      "Epoch 975/2000, Train Loss: 0.2046, Test Loss: 0.3018\n",
      "Epoch 976/2000, Train Loss: 0.2050, Test Loss: 0.3004\n",
      "Epoch 977/2000, Train Loss: 0.2050, Test Loss: 0.3056\n",
      "Epoch 978/2000, Train Loss: 0.2056, Test Loss: 0.3021\n",
      "Epoch 979/2000, Train Loss: 0.2053, Test Loss: 0.3015\n",
      "Epoch 980/2000, Train Loss: 0.2049, Test Loss: 0.3075\n",
      "Epoch 981/2000, Train Loss: 0.2050, Test Loss: 0.3052\n",
      "Epoch 982/2000, Train Loss: 0.2057, Test Loss: 0.3022\n",
      "Epoch 983/2000, Train Loss: 0.2054, Test Loss: 0.3072\n",
      "Epoch 984/2000, Train Loss: 0.2053, Test Loss: 0.3040\n",
      "Epoch 985/2000, Train Loss: 0.2043, Test Loss: 0.3047\n",
      "Epoch 986/2000, Train Loss: 0.2049, Test Loss: 0.3126\n",
      "Epoch 987/2000, Train Loss: 0.2050, Test Loss: 0.3026\n",
      "Epoch 988/2000, Train Loss: 0.2053, Test Loss: 0.3046\n",
      "Epoch 989/2000, Train Loss: 0.2047, Test Loss: 0.3071\n",
      "Epoch 990/2000, Train Loss: 0.2055, Test Loss: 0.3033\n",
      "Epoch 991/2000, Train Loss: 0.2040, Test Loss: 0.3044\n",
      "Epoch 992/2000, Train Loss: 0.2049, Test Loss: 0.3103\n",
      "Epoch 993/2000, Train Loss: 0.2050, Test Loss: 0.3118\n",
      "Epoch 994/2000, Train Loss: 0.2050, Test Loss: 0.3112\n",
      "Epoch 995/2000, Train Loss: 0.2048, Test Loss: 0.3037\n",
      "Epoch 996/2000, Train Loss: 0.2051, Test Loss: 0.3039\n",
      "Epoch 997/2000, Train Loss: 0.2050, Test Loss: 0.3068\n",
      "Epoch 998/2000, Train Loss: 0.2056, Test Loss: 0.3058\n",
      "Epoch 999/2000, Train Loss: 0.2040, Test Loss: 0.3134\n",
      "Epoch 1000/2000, Train Loss: 0.2049, Test Loss: 0.3025\n",
      "Epoch 1001/2000, Train Loss: 0.2049, Test Loss: 0.3018\n",
      "Epoch 1002/2000, Train Loss: 0.2050, Test Loss: 0.3048\n",
      "Epoch 1003/2000, Train Loss: 0.2056, Test Loss: 0.3044\n",
      "Epoch 1004/2000, Train Loss: 0.2050, Test Loss: 0.3031\n",
      "Epoch 1005/2000, Train Loss: 0.2047, Test Loss: 0.3093\n",
      "Epoch 1006/2000, Train Loss: 0.2047, Test Loss: 0.3064\n",
      "Epoch 1007/2000, Train Loss: 0.2052, Test Loss: 0.3027\n",
      "Epoch 1008/2000, Train Loss: 0.2049, Test Loss: 0.3124\n",
      "Epoch 1009/2000, Train Loss: 0.2051, Test Loss: 0.3085\n",
      "Epoch 1010/2000, Train Loss: 0.2050, Test Loss: 0.3068\n",
      "Epoch 1011/2000, Train Loss: 0.2041, Test Loss: 0.3084\n",
      "Epoch 1012/2000, Train Loss: 0.2049, Test Loss: 0.3087\n",
      "Epoch 1013/2000, Train Loss: 0.2048, Test Loss: 0.3041\n",
      "Epoch 1014/2000, Train Loss: 0.2047, Test Loss: 0.3039\n",
      "Epoch 1015/2000, Train Loss: 0.2052, Test Loss: 0.3100\n",
      "Epoch 1016/2000, Train Loss: 0.2048, Test Loss: 0.3022\n",
      "Epoch 1017/2000, Train Loss: 0.2048, Test Loss: 0.3033\n",
      "Epoch 1018/2000, Train Loss: 0.2042, Test Loss: 0.3053\n",
      "Epoch 1019/2000, Train Loss: 0.2049, Test Loss: 0.3074\n",
      "Epoch 1020/2000, Train Loss: 0.2046, Test Loss: 0.3068\n",
      "Epoch 1021/2000, Train Loss: 0.2038, Test Loss: 0.3078\n",
      "Epoch 1022/2000, Train Loss: 0.2049, Test Loss: 0.3070\n",
      "Epoch 1023/2000, Train Loss: 0.2045, Test Loss: 0.3032\n",
      "Epoch 1024/2000, Train Loss: 0.2043, Test Loss: 0.3043\n",
      "Epoch 1025/2000, Train Loss: 0.2047, Test Loss: 0.3025\n",
      "Epoch 1026/2000, Train Loss: 0.2046, Test Loss: 0.3067\n",
      "Epoch 1027/2000, Train Loss: 0.2048, Test Loss: 0.3078\n",
      "Epoch 1028/2000, Train Loss: 0.2048, Test Loss: 0.3043\n",
      "Epoch 1029/2000, Train Loss: 0.2045, Test Loss: 0.3072\n",
      "Epoch 1030/2000, Train Loss: 0.2039, Test Loss: 0.3036\n",
      "Epoch 1031/2000, Train Loss: 0.2045, Test Loss: 0.3058\n",
      "Epoch 1032/2000, Train Loss: 0.2041, Test Loss: 0.3046\n",
      "Epoch 1033/2000, Train Loss: 0.2050, Test Loss: 0.3016\n",
      "Epoch 1034/2000, Train Loss: 0.2044, Test Loss: 0.3056\n",
      "Epoch 1035/2000, Train Loss: 0.2044, Test Loss: 0.3032\n",
      "Epoch 1036/2000, Train Loss: 0.2048, Test Loss: 0.3052\n",
      "Epoch 1037/2000, Train Loss: 0.2040, Test Loss: 0.3019\n",
      "Epoch 1038/2000, Train Loss: 0.2046, Test Loss: 0.3052\n",
      "Epoch 1039/2000, Train Loss: 0.2042, Test Loss: 0.3097\n",
      "Epoch 1040/2000, Train Loss: 0.2049, Test Loss: 0.3118\n",
      "Epoch 1041/2000, Train Loss: 0.2050, Test Loss: 0.3041\n",
      "Epoch 1042/2000, Train Loss: 0.2041, Test Loss: 0.3065\n",
      "Epoch 1043/2000, Train Loss: 0.2044, Test Loss: 0.3042\n",
      "Epoch 1044/2000, Train Loss: 0.2043, Test Loss: 0.3097\n",
      "Epoch 1045/2000, Train Loss: 0.2047, Test Loss: 0.3031\n",
      "Epoch 1046/2000, Train Loss: 0.2047, Test Loss: 0.3074\n",
      "Epoch 1047/2000, Train Loss: 0.2044, Test Loss: 0.3023\n",
      "Epoch 1048/2000, Train Loss: 0.2046, Test Loss: 0.3041\n",
      "Epoch 1049/2000, Train Loss: 0.2040, Test Loss: 0.3039\n",
      "Epoch 1050/2000, Train Loss: 0.2041, Test Loss: 0.3038\n",
      "Epoch 1051/2000, Train Loss: 0.2052, Test Loss: 0.3022\n",
      "Epoch 1052/2000, Train Loss: 0.2042, Test Loss: 0.3035\n",
      "Epoch 1053/2000, Train Loss: 0.2044, Test Loss: 0.3032\n",
      "Epoch 1054/2000, Train Loss: 0.2040, Test Loss: 0.3090\n",
      "Epoch 1055/2000, Train Loss: 0.2041, Test Loss: 0.3062\n",
      "Epoch 1056/2000, Train Loss: 0.2044, Test Loss: 0.3059\n",
      "Epoch 1057/2000, Train Loss: 0.2039, Test Loss: 0.3187\n",
      "Epoch 1058/2000, Train Loss: 0.2048, Test Loss: 0.3062\n",
      "Epoch 1059/2000, Train Loss: 0.2044, Test Loss: 0.3072\n",
      "Epoch 1060/2000, Train Loss: 0.2031, Test Loss: 0.3050\n",
      "Epoch 1061/2000, Train Loss: 0.2041, Test Loss: 0.3085\n",
      "Epoch 1062/2000, Train Loss: 0.2050, Test Loss: 0.3036\n",
      "Epoch 1063/2000, Train Loss: 0.2041, Test Loss: 0.3033\n",
      "Epoch 1064/2000, Train Loss: 0.2031, Test Loss: 0.3034\n",
      "Epoch 1065/2000, Train Loss: 0.2036, Test Loss: 0.3064\n",
      "Epoch 1066/2000, Train Loss: 0.2041, Test Loss: 0.3051\n",
      "Epoch 1067/2000, Train Loss: 0.2050, Test Loss: 0.3051\n",
      "Epoch 1068/2000, Train Loss: 0.2040, Test Loss: 0.3066\n",
      "Epoch 1069/2000, Train Loss: 0.2038, Test Loss: 0.3040\n",
      "Epoch 1070/2000, Train Loss: 0.2041, Test Loss: 0.3033\n",
      "Epoch 1071/2000, Train Loss: 0.2046, Test Loss: 0.3045\n",
      "Epoch 1072/2000, Train Loss: 0.2040, Test Loss: 0.3077\n",
      "Epoch 1073/2000, Train Loss: 0.2040, Test Loss: 0.3104\n",
      "Epoch 1074/2000, Train Loss: 0.2038, Test Loss: 0.3050\n",
      "Epoch 1075/2000, Train Loss: 0.2035, Test Loss: 0.3053\n",
      "Epoch 1076/2000, Train Loss: 0.2039, Test Loss: 0.3052\n",
      "Epoch 1077/2000, Train Loss: 0.2045, Test Loss: 0.3053\n",
      "Epoch 1078/2000, Train Loss: 0.2038, Test Loss: 0.3056\n",
      "Epoch 1079/2000, Train Loss: 0.2043, Test Loss: 0.3080\n",
      "Epoch 1080/2000, Train Loss: 0.2035, Test Loss: 0.3016\n",
      "Epoch 1081/2000, Train Loss: 0.2036, Test Loss: 0.3093\n",
      "Epoch 1082/2000, Train Loss: 0.2038, Test Loss: 0.3042\n",
      "Epoch 1083/2000, Train Loss: 0.2039, Test Loss: 0.3078\n",
      "Epoch 1084/2000, Train Loss: 0.2036, Test Loss: 0.3069\n",
      "Epoch 1085/2000, Train Loss: 0.2043, Test Loss: 0.3030\n",
      "Epoch 1086/2000, Train Loss: 0.2036, Test Loss: 0.3072\n",
      "Epoch 1087/2000, Train Loss: 0.2044, Test Loss: 0.3153\n",
      "Epoch 1088/2000, Train Loss: 0.2040, Test Loss: 0.3064\n",
      "Epoch 1089/2000, Train Loss: 0.2045, Test Loss: 0.3056\n",
      "Epoch 1090/2000, Train Loss: 0.2039, Test Loss: 0.3134\n",
      "Epoch 1091/2000, Train Loss: 0.2038, Test Loss: 0.3079\n",
      "Epoch 1092/2000, Train Loss: 0.2037, Test Loss: 0.3028\n",
      "Epoch 1093/2000, Train Loss: 0.2036, Test Loss: 0.3039\n",
      "Epoch 1094/2000, Train Loss: 0.2038, Test Loss: 0.3091\n",
      "Epoch 1095/2000, Train Loss: 0.2043, Test Loss: 0.3096\n",
      "Epoch 1096/2000, Train Loss: 0.2036, Test Loss: 0.3060\n",
      "Epoch 1097/2000, Train Loss: 0.2038, Test Loss: 0.3046\n",
      "Epoch 1098/2000, Train Loss: 0.2032, Test Loss: 0.3026\n",
      "Epoch 1099/2000, Train Loss: 0.2040, Test Loss: 0.3091\n",
      "Epoch 1100/2000, Train Loss: 0.2042, Test Loss: 0.3034\n",
      "Epoch 1101/2000, Train Loss: 0.2034, Test Loss: 0.3048\n",
      "Epoch 1102/2000, Train Loss: 0.2036, Test Loss: 0.3056\n",
      "Epoch 1103/2000, Train Loss: 0.2036, Test Loss: 0.3026\n",
      "Epoch 1104/2000, Train Loss: 0.2038, Test Loss: 0.3038\n",
      "Epoch 1105/2000, Train Loss: 0.2041, Test Loss: 0.3057\n",
      "Epoch 1106/2000, Train Loss: 0.2033, Test Loss: 0.3105\n",
      "Epoch 1107/2000, Train Loss: 0.2035, Test Loss: 0.3089\n",
      "Epoch 1108/2000, Train Loss: 0.2040, Test Loss: 0.3068\n",
      "Epoch 1109/2000, Train Loss: 0.2039, Test Loss: 0.3045\n",
      "Epoch 1110/2000, Train Loss: 0.2038, Test Loss: 0.3044\n",
      "Epoch 1111/2000, Train Loss: 0.2032, Test Loss: 0.3031\n",
      "Epoch 1112/2000, Train Loss: 0.2029, Test Loss: 0.3061\n",
      "Epoch 1113/2000, Train Loss: 0.2039, Test Loss: 0.3076\n",
      "Epoch 1114/2000, Train Loss: 0.2046, Test Loss: 0.3044\n",
      "Epoch 1115/2000, Train Loss: 0.2030, Test Loss: 0.3103\n",
      "Epoch 1116/2000, Train Loss: 0.2038, Test Loss: 0.3082\n",
      "Epoch 1117/2000, Train Loss: 0.2032, Test Loss: 0.3073\n",
      "Epoch 1118/2000, Train Loss: 0.2042, Test Loss: 0.3051\n",
      "Epoch 1119/2000, Train Loss: 0.2035, Test Loss: 0.3051\n",
      "Epoch 1120/2000, Train Loss: 0.2032, Test Loss: 0.3060\n",
      "Epoch 1121/2000, Train Loss: 0.2032, Test Loss: 0.3070\n",
      "Epoch 1122/2000, Train Loss: 0.2035, Test Loss: 0.3051\n",
      "Epoch 1123/2000, Train Loss: 0.2028, Test Loss: 0.3036\n",
      "Epoch 1124/2000, Train Loss: 0.2030, Test Loss: 0.3085\n",
      "Epoch 1125/2000, Train Loss: 0.2035, Test Loss: 0.3045\n",
      "Epoch 1126/2000, Train Loss: 0.2037, Test Loss: 0.3050\n",
      "Epoch 1127/2000, Train Loss: 0.2033, Test Loss: 0.3139\n",
      "Epoch 1128/2000, Train Loss: 0.2029, Test Loss: 0.3044\n",
      "Epoch 1129/2000, Train Loss: 0.2029, Test Loss: 0.3090\n",
      "Epoch 1130/2000, Train Loss: 0.2033, Test Loss: 0.3065\n",
      "Epoch 1131/2000, Train Loss: 0.2030, Test Loss: 0.3102\n",
      "Epoch 1132/2000, Train Loss: 0.2034, Test Loss: 0.3048\n",
      "Epoch 1133/2000, Train Loss: 0.2034, Test Loss: 0.3087\n",
      "Epoch 1134/2000, Train Loss: 0.2051, Test Loss: 0.3062\n",
      "Epoch 1135/2000, Train Loss: 0.2027, Test Loss: 0.3040\n",
      "Epoch 1136/2000, Train Loss: 0.2036, Test Loss: 0.3064\n",
      "Epoch 1137/2000, Train Loss: 0.2031, Test Loss: 0.3070\n",
      "Epoch 1138/2000, Train Loss: 0.2030, Test Loss: 0.3159\n",
      "Epoch 1139/2000, Train Loss: 0.2036, Test Loss: 0.3104\n",
      "Epoch 1140/2000, Train Loss: 0.2028, Test Loss: 0.3044\n",
      "Epoch 1141/2000, Train Loss: 0.2033, Test Loss: 0.3056\n",
      "Epoch 1142/2000, Train Loss: 0.2032, Test Loss: 0.3061\n",
      "Epoch 1143/2000, Train Loss: 0.2023, Test Loss: 0.3061\n",
      "Epoch 1144/2000, Train Loss: 0.2033, Test Loss: 0.3068\n",
      "Epoch 1145/2000, Train Loss: 0.2036, Test Loss: 0.3040\n",
      "Epoch 1146/2000, Train Loss: 0.2031, Test Loss: 0.3070\n",
      "Epoch 1147/2000, Train Loss: 0.2037, Test Loss: 0.3097\n",
      "Epoch 1148/2000, Train Loss: 0.2027, Test Loss: 0.3069\n",
      "Epoch 1149/2000, Train Loss: 0.2031, Test Loss: 0.3042\n",
      "Epoch 1150/2000, Train Loss: 0.2029, Test Loss: 0.3107\n",
      "Epoch 1151/2000, Train Loss: 0.2027, Test Loss: 0.3103\n",
      "Epoch 1152/2000, Train Loss: 0.2030, Test Loss: 0.3073\n",
      "Epoch 1153/2000, Train Loss: 0.2033, Test Loss: 0.3129\n",
      "Epoch 1154/2000, Train Loss: 0.2035, Test Loss: 0.3044\n",
      "Epoch 1155/2000, Train Loss: 0.2029, Test Loss: 0.3085\n",
      "Epoch 1156/2000, Train Loss: 0.2033, Test Loss: 0.3063\n",
      "Epoch 1157/2000, Train Loss: 0.2029, Test Loss: 0.3063\n",
      "Epoch 1158/2000, Train Loss: 0.2031, Test Loss: 0.3064\n",
      "Epoch 1159/2000, Train Loss: 0.2040, Test Loss: 0.3055\n",
      "Epoch 1160/2000, Train Loss: 0.2032, Test Loss: 0.3077\n",
      "Epoch 1161/2000, Train Loss: 0.2028, Test Loss: 0.3073\n",
      "Epoch 1162/2000, Train Loss: 0.2028, Test Loss: 0.3074\n",
      "Epoch 1163/2000, Train Loss: 0.2035, Test Loss: 0.3083\n",
      "Epoch 1164/2000, Train Loss: 0.2022, Test Loss: 0.3067\n",
      "Epoch 1165/2000, Train Loss: 0.2032, Test Loss: 0.3064\n",
      "Epoch 1166/2000, Train Loss: 0.2023, Test Loss: 0.3061\n",
      "Epoch 1167/2000, Train Loss: 0.2025, Test Loss: 0.3082\n",
      "Epoch 1168/2000, Train Loss: 0.2037, Test Loss: 0.3075\n",
      "Epoch 1169/2000, Train Loss: 0.2028, Test Loss: 0.3052\n",
      "Epoch 1170/2000, Train Loss: 0.2030, Test Loss: 0.3076\n",
      "Epoch 1171/2000, Train Loss: 0.2028, Test Loss: 0.3037\n",
      "Epoch 1172/2000, Train Loss: 0.2025, Test Loss: 0.3071\n",
      "Epoch 1173/2000, Train Loss: 0.2027, Test Loss: 0.3113\n",
      "Epoch 1174/2000, Train Loss: 0.2029, Test Loss: 0.3066\n",
      "Epoch 1175/2000, Train Loss: 0.2026, Test Loss: 0.3075\n",
      "Epoch 1176/2000, Train Loss: 0.2031, Test Loss: 0.3111\n",
      "Epoch 1177/2000, Train Loss: 0.2025, Test Loss: 0.3057\n",
      "Epoch 1178/2000, Train Loss: 0.2028, Test Loss: 0.3089\n",
      "Epoch 1179/2000, Train Loss: 0.2026, Test Loss: 0.3141\n",
      "Epoch 1180/2000, Train Loss: 0.2036, Test Loss: 0.3047\n",
      "Epoch 1181/2000, Train Loss: 0.2030, Test Loss: 0.3103\n",
      "Epoch 1182/2000, Train Loss: 0.2031, Test Loss: 0.3060\n",
      "Epoch 1183/2000, Train Loss: 0.2025, Test Loss: 0.3070\n",
      "Epoch 1184/2000, Train Loss: 0.2027, Test Loss: 0.3081\n",
      "Epoch 1185/2000, Train Loss: 0.2026, Test Loss: 0.3054\n",
      "Epoch 1186/2000, Train Loss: 0.2028, Test Loss: 0.3068\n",
      "Epoch 1187/2000, Train Loss: 0.2029, Test Loss: 0.3065\n",
      "Epoch 1188/2000, Train Loss: 0.2024, Test Loss: 0.3083\n",
      "Epoch 1189/2000, Train Loss: 0.2023, Test Loss: 0.3057\n",
      "Epoch 1190/2000, Train Loss: 0.2025, Test Loss: 0.3101\n",
      "Epoch 1191/2000, Train Loss: 0.2032, Test Loss: 0.3144\n",
      "Epoch 1192/2000, Train Loss: 0.2029, Test Loss: 0.3094\n",
      "Epoch 1193/2000, Train Loss: 0.2026, Test Loss: 0.3141\n",
      "Epoch 1194/2000, Train Loss: 0.2025, Test Loss: 0.3084\n",
      "Epoch 1195/2000, Train Loss: 0.2030, Test Loss: 0.3098\n",
      "Epoch 1196/2000, Train Loss: 0.2030, Test Loss: 0.3071\n",
      "Epoch 1197/2000, Train Loss: 0.2022, Test Loss: 0.3059\n",
      "Epoch 1198/2000, Train Loss: 0.2022, Test Loss: 0.3124\n",
      "Epoch 1199/2000, Train Loss: 0.2030, Test Loss: 0.3097\n",
      "Epoch 1200/2000, Train Loss: 0.2023, Test Loss: 0.3146\n",
      "Epoch 1201/2000, Train Loss: 0.2026, Test Loss: 0.3047\n",
      "Epoch 1202/2000, Train Loss: 0.2031, Test Loss: 0.3118\n",
      "Epoch 1203/2000, Train Loss: 0.2024, Test Loss: 0.3094\n",
      "Epoch 1204/2000, Train Loss: 0.2030, Test Loss: 0.3161\n",
      "Epoch 1205/2000, Train Loss: 0.2021, Test Loss: 0.3089\n",
      "Epoch 1206/2000, Train Loss: 0.2021, Test Loss: 0.3134\n",
      "Epoch 1207/2000, Train Loss: 0.2015, Test Loss: 0.3055\n",
      "Epoch 1208/2000, Train Loss: 0.2022, Test Loss: 0.3102\n",
      "Epoch 1209/2000, Train Loss: 0.2025, Test Loss: 0.3160\n",
      "Epoch 1210/2000, Train Loss: 0.2024, Test Loss: 0.3104\n",
      "Epoch 1211/2000, Train Loss: 0.2025, Test Loss: 0.3053\n",
      "Epoch 1212/2000, Train Loss: 0.2032, Test Loss: 0.3087\n",
      "Epoch 1213/2000, Train Loss: 0.2023, Test Loss: 0.3123\n",
      "Epoch 1214/2000, Train Loss: 0.2023, Test Loss: 0.3338\n",
      "Epoch 1215/2000, Train Loss: 0.2033, Test Loss: 0.3181\n",
      "Epoch 1216/2000, Train Loss: 0.2029, Test Loss: 0.3099\n",
      "Epoch 1217/2000, Train Loss: 0.2017, Test Loss: 0.3067\n",
      "Epoch 1218/2000, Train Loss: 0.2018, Test Loss: 0.3110\n",
      "Epoch 1219/2000, Train Loss: 0.2031, Test Loss: 0.3040\n",
      "Epoch 1220/2000, Train Loss: 0.2034, Test Loss: 0.3155\n",
      "Epoch 1221/2000, Train Loss: 0.2033, Test Loss: 0.3057\n",
      "Epoch 1222/2000, Train Loss: 0.2022, Test Loss: 0.3054\n",
      "Epoch 1223/2000, Train Loss: 0.2023, Test Loss: 0.3067\n",
      "Epoch 1224/2000, Train Loss: 0.2028, Test Loss: 0.3094\n",
      "Epoch 1225/2000, Train Loss: 0.2025, Test Loss: 0.3062\n",
      "Epoch 1226/2000, Train Loss: 0.2021, Test Loss: 0.3058\n",
      "Epoch 1227/2000, Train Loss: 0.2023, Test Loss: 0.3120\n",
      "Epoch 1228/2000, Train Loss: 0.2020, Test Loss: 0.3076\n",
      "Epoch 1229/2000, Train Loss: 0.2023, Test Loss: 0.3060\n",
      "Epoch 1230/2000, Train Loss: 0.2021, Test Loss: 0.3052\n",
      "Epoch 1231/2000, Train Loss: 0.2021, Test Loss: 0.3190\n",
      "Epoch 1232/2000, Train Loss: 0.2020, Test Loss: 0.3114\n",
      "Epoch 1233/2000, Train Loss: 0.2027, Test Loss: 0.3117\n",
      "Epoch 1234/2000, Train Loss: 0.2024, Test Loss: 0.3080\n",
      "Epoch 1235/2000, Train Loss: 0.2025, Test Loss: 0.3104\n",
      "Epoch 1236/2000, Train Loss: 0.2021, Test Loss: 0.3063\n",
      "Epoch 1237/2000, Train Loss: 0.2028, Test Loss: 0.3076\n",
      "Epoch 1238/2000, Train Loss: 0.2023, Test Loss: 0.3080\n",
      "Epoch 1239/2000, Train Loss: 0.2027, Test Loss: 0.3070\n",
      "Epoch 1240/2000, Train Loss: 0.2020, Test Loss: 0.3052\n",
      "Epoch 1241/2000, Train Loss: 0.2017, Test Loss: 0.3069\n",
      "Epoch 1242/2000, Train Loss: 0.2017, Test Loss: 0.3065\n",
      "Epoch 1243/2000, Train Loss: 0.2022, Test Loss: 0.3083\n",
      "Epoch 1244/2000, Train Loss: 0.2027, Test Loss: 0.3135\n",
      "Epoch 1245/2000, Train Loss: 0.2014, Test Loss: 0.3054\n",
      "Epoch 1246/2000, Train Loss: 0.2022, Test Loss: 0.3124\n",
      "Epoch 1247/2000, Train Loss: 0.2028, Test Loss: 0.3063\n",
      "Epoch 1248/2000, Train Loss: 0.2019, Test Loss: 0.3097\n",
      "Epoch 1249/2000, Train Loss: 0.2023, Test Loss: 0.3099\n",
      "Epoch 1250/2000, Train Loss: 0.2019, Test Loss: 0.3125\n",
      "Epoch 1251/2000, Train Loss: 0.2017, Test Loss: 0.3067\n",
      "Epoch 1252/2000, Train Loss: 0.2015, Test Loss: 0.3133\n",
      "Epoch 1253/2000, Train Loss: 0.2019, Test Loss: 0.3082\n",
      "Epoch 1254/2000, Train Loss: 0.2022, Test Loss: 0.3131\n",
      "Epoch 1255/2000, Train Loss: 0.2017, Test Loss: 0.3090\n",
      "Epoch 1256/2000, Train Loss: 0.2022, Test Loss: 0.3066\n",
      "Epoch 1257/2000, Train Loss: 0.2020, Test Loss: 0.3084\n",
      "Epoch 1258/2000, Train Loss: 0.2020, Test Loss: 0.3063\n",
      "Epoch 1259/2000, Train Loss: 0.2021, Test Loss: 0.3066\n",
      "Epoch 1260/2000, Train Loss: 0.2018, Test Loss: 0.3095\n",
      "Epoch 1261/2000, Train Loss: 0.2020, Test Loss: 0.3054\n",
      "Epoch 1262/2000, Train Loss: 0.2014, Test Loss: 0.3058\n",
      "Epoch 1263/2000, Train Loss: 0.2025, Test Loss: 0.3055\n",
      "Epoch 1264/2000, Train Loss: 0.2015, Test Loss: 0.3134\n",
      "Epoch 1265/2000, Train Loss: 0.2029, Test Loss: 0.3090\n",
      "Epoch 1266/2000, Train Loss: 0.2021, Test Loss: 0.3065\n",
      "Epoch 1267/2000, Train Loss: 0.2019, Test Loss: 0.3176\n",
      "Epoch 1268/2000, Train Loss: 0.2022, Test Loss: 0.3058\n",
      "Epoch 1269/2000, Train Loss: 0.2012, Test Loss: 0.3132\n",
      "Epoch 1270/2000, Train Loss: 0.2019, Test Loss: 0.3154\n",
      "Epoch 1271/2000, Train Loss: 0.2025, Test Loss: 0.3125\n",
      "Epoch 1272/2000, Train Loss: 0.2017, Test Loss: 0.3154\n",
      "Epoch 1273/2000, Train Loss: 0.2013, Test Loss: 0.3102\n",
      "Epoch 1274/2000, Train Loss: 0.2013, Test Loss: 0.3106\n",
      "Epoch 1275/2000, Train Loss: 0.2020, Test Loss: 0.3115\n",
      "Epoch 1276/2000, Train Loss: 0.2025, Test Loss: 0.3082\n",
      "Epoch 1277/2000, Train Loss: 0.2015, Test Loss: 0.3084\n",
      "Epoch 1278/2000, Train Loss: 0.2021, Test Loss: 0.3115\n",
      "Epoch 1279/2000, Train Loss: 0.2018, Test Loss: 0.3275\n",
      "Epoch 1280/2000, Train Loss: 0.2024, Test Loss: 0.3058\n",
      "Epoch 1281/2000, Train Loss: 0.2015, Test Loss: 0.3072\n",
      "Epoch 1282/2000, Train Loss: 0.2014, Test Loss: 0.3162\n",
      "Epoch 1283/2000, Train Loss: 0.2022, Test Loss: 0.3154\n",
      "Epoch 1284/2000, Train Loss: 0.2019, Test Loss: 0.3121\n",
      "Epoch 1285/2000, Train Loss: 0.2017, Test Loss: 0.3084\n",
      "Epoch 1286/2000, Train Loss: 0.2012, Test Loss: 0.3121\n",
      "Epoch 1287/2000, Train Loss: 0.2015, Test Loss: 0.3108\n",
      "Epoch 1288/2000, Train Loss: 0.2017, Test Loss: 0.3109\n",
      "Epoch 1289/2000, Train Loss: 0.2022, Test Loss: 0.3084\n",
      "Epoch 1290/2000, Train Loss: 0.2010, Test Loss: 0.3075\n",
      "Epoch 1291/2000, Train Loss: 0.2012, Test Loss: 0.3088\n",
      "Epoch 1292/2000, Train Loss: 0.2021, Test Loss: 0.3075\n",
      "Epoch 1293/2000, Train Loss: 0.2009, Test Loss: 0.3142\n",
      "Epoch 1294/2000, Train Loss: 0.2019, Test Loss: 0.3139\n",
      "Epoch 1295/2000, Train Loss: 0.2019, Test Loss: 0.3069\n",
      "Epoch 1296/2000, Train Loss: 0.2019, Test Loss: 0.3056\n",
      "Epoch 1297/2000, Train Loss: 0.2013, Test Loss: 0.3142\n",
      "Epoch 1298/2000, Train Loss: 0.2020, Test Loss: 0.3067\n",
      "Epoch 1299/2000, Train Loss: 0.2016, Test Loss: 0.3132\n",
      "Epoch 1300/2000, Train Loss: 0.2019, Test Loss: 0.3118\n",
      "Epoch 1301/2000, Train Loss: 0.2015, Test Loss: 0.3069\n",
      "Epoch 1302/2000, Train Loss: 0.2015, Test Loss: 0.3061\n",
      "Epoch 1303/2000, Train Loss: 0.2017, Test Loss: 0.3092\n",
      "Epoch 1304/2000, Train Loss: 0.2014, Test Loss: 0.3108\n",
      "Epoch 1305/2000, Train Loss: 0.2011, Test Loss: 0.3090\n",
      "Epoch 1306/2000, Train Loss: 0.2016, Test Loss: 0.3161\n",
      "Epoch 1307/2000, Train Loss: 0.2019, Test Loss: 0.3070\n",
      "Epoch 1308/2000, Train Loss: 0.2016, Test Loss: 0.3132\n",
      "Epoch 1309/2000, Train Loss: 0.2023, Test Loss: 0.3072\n",
      "Epoch 1310/2000, Train Loss: 0.2016, Test Loss: 0.3103\n",
      "Epoch 1311/2000, Train Loss: 0.2007, Test Loss: 0.3056\n",
      "Epoch 1312/2000, Train Loss: 0.2014, Test Loss: 0.3104\n",
      "Epoch 1313/2000, Train Loss: 0.2012, Test Loss: 0.3086\n",
      "Epoch 1314/2000, Train Loss: 0.2019, Test Loss: 0.3067\n",
      "Epoch 1315/2000, Train Loss: 0.2008, Test Loss: 0.3110\n",
      "Epoch 1316/2000, Train Loss: 0.2023, Test Loss: 0.3072\n",
      "Epoch 1317/2000, Train Loss: 0.2016, Test Loss: 0.3092\n",
      "Epoch 1318/2000, Train Loss: 0.2008, Test Loss: 0.3065\n",
      "Epoch 1319/2000, Train Loss: 0.2013, Test Loss: 0.3131\n",
      "Epoch 1320/2000, Train Loss: 0.2009, Test Loss: 0.3064\n",
      "Epoch 1321/2000, Train Loss: 0.2015, Test Loss: 0.3158\n",
      "Epoch 1322/2000, Train Loss: 0.2020, Test Loss: 0.3100\n",
      "Epoch 1323/2000, Train Loss: 0.2015, Test Loss: 0.3137\n",
      "Epoch 1324/2000, Train Loss: 0.2019, Test Loss: 0.3063\n",
      "Epoch 1325/2000, Train Loss: 0.2018, Test Loss: 0.3061\n",
      "Epoch 1326/2000, Train Loss: 0.2010, Test Loss: 0.3085\n",
      "Epoch 1327/2000, Train Loss: 0.2019, Test Loss: 0.3145\n",
      "Epoch 1328/2000, Train Loss: 0.2018, Test Loss: 0.3076\n",
      "Epoch 1329/2000, Train Loss: 0.2013, Test Loss: 0.3076\n",
      "Epoch 1330/2000, Train Loss: 0.2007, Test Loss: 0.3088\n",
      "Epoch 1331/2000, Train Loss: 0.2012, Test Loss: 0.3116\n",
      "Epoch 1332/2000, Train Loss: 0.2018, Test Loss: 0.3111\n",
      "Epoch 1333/2000, Train Loss: 0.2022, Test Loss: 0.3079\n",
      "Epoch 1334/2000, Train Loss: 0.2013, Test Loss: 0.3103\n",
      "Epoch 1335/2000, Train Loss: 0.2012, Test Loss: 0.3100\n",
      "Epoch 1336/2000, Train Loss: 0.2018, Test Loss: 0.3082\n",
      "Epoch 1337/2000, Train Loss: 0.2010, Test Loss: 0.3070\n",
      "Epoch 1338/2000, Train Loss: 0.2010, Test Loss: 0.3077\n",
      "Epoch 1339/2000, Train Loss: 0.2007, Test Loss: 0.3068\n",
      "Epoch 1340/2000, Train Loss: 0.2014, Test Loss: 0.3102\n",
      "Epoch 1341/2000, Train Loss: 0.2017, Test Loss: 0.3122\n",
      "Epoch 1342/2000, Train Loss: 0.2013, Test Loss: 0.3077\n",
      "Epoch 1343/2000, Train Loss: 0.2011, Test Loss: 0.3066\n",
      "Epoch 1344/2000, Train Loss: 0.2006, Test Loss: 0.3086\n",
      "Epoch 1345/2000, Train Loss: 0.2008, Test Loss: 0.3096\n",
      "Epoch 1346/2000, Train Loss: 0.2012, Test Loss: 0.3068\n",
      "Epoch 1347/2000, Train Loss: 0.2013, Test Loss: 0.3096\n",
      "Epoch 1348/2000, Train Loss: 0.2014, Test Loss: 0.3131\n",
      "Epoch 1349/2000, Train Loss: 0.2018, Test Loss: 0.3071\n",
      "Epoch 1350/2000, Train Loss: 0.2014, Test Loss: 0.3092\n",
      "Epoch 1351/2000, Train Loss: 0.2014, Test Loss: 0.3104\n",
      "Epoch 1352/2000, Train Loss: 0.2011, Test Loss: 0.3075\n",
      "Epoch 1353/2000, Train Loss: 0.2011, Test Loss: 0.3085\n",
      "Epoch 1354/2000, Train Loss: 0.2014, Test Loss: 0.3081\n",
      "Epoch 1355/2000, Train Loss: 0.2016, Test Loss: 0.3098\n",
      "Epoch 1356/2000, Train Loss: 0.2007, Test Loss: 0.3136\n",
      "Epoch 1357/2000, Train Loss: 0.2008, Test Loss: 0.3070\n",
      "Epoch 1358/2000, Train Loss: 0.2012, Test Loss: 0.3115\n",
      "Epoch 1359/2000, Train Loss: 0.2017, Test Loss: 0.3094\n",
      "Epoch 1360/2000, Train Loss: 0.2013, Test Loss: 0.3145\n",
      "Epoch 1361/2000, Train Loss: 0.2014, Test Loss: 0.3151\n",
      "Epoch 1362/2000, Train Loss: 0.2020, Test Loss: 0.3183\n",
      "Epoch 1363/2000, Train Loss: 0.2017, Test Loss: 0.3147\n",
      "Epoch 1364/2000, Train Loss: 0.2018, Test Loss: 0.3088\n",
      "Epoch 1365/2000, Train Loss: 0.2016, Test Loss: 0.3079\n",
      "Epoch 1366/2000, Train Loss: 0.2012, Test Loss: 0.3083\n",
      "Epoch 1367/2000, Train Loss: 0.2011, Test Loss: 0.3086\n",
      "Epoch 1368/2000, Train Loss: 0.2012, Test Loss: 0.3109\n",
      "Epoch 1369/2000, Train Loss: 0.2011, Test Loss: 0.3129\n",
      "Epoch 1370/2000, Train Loss: 0.2015, Test Loss: 0.3117\n",
      "Epoch 1371/2000, Train Loss: 0.2011, Test Loss: 0.3073\n",
      "Epoch 1372/2000, Train Loss: 0.2012, Test Loss: 0.3104\n",
      "Epoch 1373/2000, Train Loss: 0.2011, Test Loss: 0.3160\n",
      "Epoch 1374/2000, Train Loss: 0.2016, Test Loss: 0.3126\n",
      "Epoch 1375/2000, Train Loss: 0.2002, Test Loss: 0.3138\n",
      "Epoch 1376/2000, Train Loss: 0.2009, Test Loss: 0.3123\n",
      "Epoch 1377/2000, Train Loss: 0.2009, Test Loss: 0.3089\n",
      "Epoch 1378/2000, Train Loss: 0.2013, Test Loss: 0.3090\n",
      "Epoch 1379/2000, Train Loss: 0.2013, Test Loss: 0.3097\n",
      "Epoch 1380/2000, Train Loss: 0.2008, Test Loss: 0.3082\n",
      "Epoch 1381/2000, Train Loss: 0.2016, Test Loss: 0.3074\n",
      "Epoch 1382/2000, Train Loss: 0.2012, Test Loss: 0.3107\n",
      "Epoch 1383/2000, Train Loss: 0.2004, Test Loss: 0.3086\n",
      "Epoch 1384/2000, Train Loss: 0.2006, Test Loss: 0.3075\n",
      "Epoch 1385/2000, Train Loss: 0.2006, Test Loss: 0.3080\n",
      "Epoch 1386/2000, Train Loss: 0.2013, Test Loss: 0.3173\n",
      "Epoch 1387/2000, Train Loss: 0.2012, Test Loss: 0.3094\n",
      "Epoch 1388/2000, Train Loss: 0.2007, Test Loss: 0.3138\n",
      "Epoch 1389/2000, Train Loss: 0.2005, Test Loss: 0.3101\n",
      "Epoch 1390/2000, Train Loss: 0.2013, Test Loss: 0.3081\n",
      "Epoch 1391/2000, Train Loss: 0.2007, Test Loss: 0.3074\n",
      "Epoch 1392/2000, Train Loss: 0.2008, Test Loss: 0.3073\n",
      "Epoch 1393/2000, Train Loss: 0.2006, Test Loss: 0.3279\n",
      "Epoch 1394/2000, Train Loss: 0.2008, Test Loss: 0.3103\n",
      "Epoch 1395/2000, Train Loss: 0.2014, Test Loss: 0.3084\n",
      "Epoch 1396/2000, Train Loss: 0.2002, Test Loss: 0.3107\n",
      "Epoch 1397/2000, Train Loss: 0.2005, Test Loss: 0.3077\n",
      "Epoch 1398/2000, Train Loss: 0.2004, Test Loss: 0.3130\n",
      "Epoch 1399/2000, Train Loss: 0.2009, Test Loss: 0.3108\n",
      "Epoch 1400/2000, Train Loss: 0.2004, Test Loss: 0.3138\n",
      "Epoch 1401/2000, Train Loss: 0.2006, Test Loss: 0.3079\n",
      "Epoch 1402/2000, Train Loss: 0.2006, Test Loss: 0.3091\n",
      "Epoch 1403/2000, Train Loss: 0.2005, Test Loss: 0.3107\n",
      "Epoch 1404/2000, Train Loss: 0.2011, Test Loss: 0.3132\n",
      "Epoch 1405/2000, Train Loss: 0.2010, Test Loss: 0.3086\n",
      "Epoch 1406/2000, Train Loss: 0.2016, Test Loss: 0.3088\n",
      "Epoch 1407/2000, Train Loss: 0.2012, Test Loss: 0.3108\n",
      "Epoch 1408/2000, Train Loss: 0.2000, Test Loss: 0.3145\n",
      "Epoch 1409/2000, Train Loss: 0.2011, Test Loss: 0.3173\n",
      "Epoch 1410/2000, Train Loss: 0.2010, Test Loss: 0.3170\n",
      "Epoch 1411/2000, Train Loss: 0.2015, Test Loss: 0.3123\n",
      "Epoch 1412/2000, Train Loss: 0.2008, Test Loss: 0.3143\n",
      "Epoch 1413/2000, Train Loss: 0.2003, Test Loss: 0.3120\n",
      "Epoch 1414/2000, Train Loss: 0.2002, Test Loss: 0.3145\n",
      "Epoch 1415/2000, Train Loss: 0.2005, Test Loss: 0.3100\n",
      "Epoch 1416/2000, Train Loss: 0.2005, Test Loss: 0.3120\n",
      "Epoch 1417/2000, Train Loss: 0.2010, Test Loss: 0.3140\n",
      "Epoch 1418/2000, Train Loss: 0.2011, Test Loss: 0.3095\n",
      "Epoch 1419/2000, Train Loss: 0.2008, Test Loss: 0.3123\n",
      "Epoch 1420/2000, Train Loss: 0.2007, Test Loss: 0.3077\n",
      "Epoch 1421/2000, Train Loss: 0.2002, Test Loss: 0.3086\n",
      "Epoch 1422/2000, Train Loss: 0.2008, Test Loss: 0.3074\n",
      "Epoch 1423/2000, Train Loss: 0.1998, Test Loss: 0.3153\n",
      "Epoch 1424/2000, Train Loss: 0.2003, Test Loss: 0.3105\n",
      "Epoch 1425/2000, Train Loss: 0.2013, Test Loss: 0.3191\n",
      "Epoch 1426/2000, Train Loss: 0.2010, Test Loss: 0.3211\n",
      "Epoch 1427/2000, Train Loss: 0.2003, Test Loss: 0.3114\n",
      "Epoch 1428/2000, Train Loss: 0.2002, Test Loss: 0.3102\n",
      "Epoch 1429/2000, Train Loss: 0.2009, Test Loss: 0.3107\n",
      "Epoch 1430/2000, Train Loss: 0.2006, Test Loss: 0.3159\n",
      "Epoch 1431/2000, Train Loss: 0.2007, Test Loss: 0.3092\n",
      "Epoch 1432/2000, Train Loss: 0.2003, Test Loss: 0.3122\n",
      "Epoch 1433/2000, Train Loss: 0.2001, Test Loss: 0.3233\n",
      "Epoch 1434/2000, Train Loss: 0.2003, Test Loss: 0.3099\n",
      "Epoch 1435/2000, Train Loss: 0.2001, Test Loss: 0.3216\n",
      "Epoch 1436/2000, Train Loss: 0.2003, Test Loss: 0.3100\n",
      "Epoch 1437/2000, Train Loss: 0.2011, Test Loss: 0.3089\n",
      "Epoch 1438/2000, Train Loss: 0.2002, Test Loss: 0.3077\n",
      "Epoch 1439/2000, Train Loss: 0.2006, Test Loss: 0.3082\n",
      "Epoch 1440/2000, Train Loss: 0.2003, Test Loss: 0.3101\n",
      "Epoch 1441/2000, Train Loss: 0.2003, Test Loss: 0.3190\n",
      "Epoch 1442/2000, Train Loss: 0.2004, Test Loss: 0.3112\n",
      "Epoch 1443/2000, Train Loss: 0.2007, Test Loss: 0.3104\n",
      "Epoch 1444/2000, Train Loss: 0.2013, Test Loss: 0.3100\n",
      "Epoch 1445/2000, Train Loss: 0.2007, Test Loss: 0.3084\n",
      "Epoch 1446/2000, Train Loss: 0.2004, Test Loss: 0.3112\n",
      "Epoch 1447/2000, Train Loss: 0.1997, Test Loss: 0.3091\n",
      "Epoch 1448/2000, Train Loss: 0.2002, Test Loss: 0.3193\n",
      "Epoch 1449/2000, Train Loss: 0.2006, Test Loss: 0.3087\n",
      "Epoch 1450/2000, Train Loss: 0.2001, Test Loss: 0.3136\n",
      "Epoch 1451/2000, Train Loss: 0.2005, Test Loss: 0.3135\n",
      "Epoch 1452/2000, Train Loss: 0.2010, Test Loss: 0.3121\n",
      "Epoch 1453/2000, Train Loss: 0.2000, Test Loss: 0.3139\n",
      "Epoch 1454/2000, Train Loss: 0.2000, Test Loss: 0.3091\n",
      "Epoch 1455/2000, Train Loss: 0.1996, Test Loss: 0.3101\n",
      "Epoch 1456/2000, Train Loss: 0.1998, Test Loss: 0.3112\n",
      "Epoch 1457/2000, Train Loss: 0.1999, Test Loss: 0.3108\n",
      "Epoch 1458/2000, Train Loss: 0.2001, Test Loss: 0.3131\n",
      "Epoch 1459/2000, Train Loss: 0.2004, Test Loss: 0.3135\n",
      "Epoch 1460/2000, Train Loss: 0.2004, Test Loss: 0.3103\n",
      "Epoch 1461/2000, Train Loss: 0.2000, Test Loss: 0.3094\n",
      "Epoch 1462/2000, Train Loss: 0.2002, Test Loss: 0.3098\n",
      "Epoch 1463/2000, Train Loss: 0.2000, Test Loss: 0.3116\n",
      "Epoch 1464/2000, Train Loss: 0.2006, Test Loss: 0.3144\n",
      "Epoch 1465/2000, Train Loss: 0.2006, Test Loss: 0.3093\n",
      "Epoch 1466/2000, Train Loss: 0.2001, Test Loss: 0.3079\n",
      "Epoch 1467/2000, Train Loss: 0.2001, Test Loss: 0.3129\n",
      "Epoch 1468/2000, Train Loss: 0.2001, Test Loss: 0.3164\n",
      "Epoch 1469/2000, Train Loss: 0.1997, Test Loss: 0.3129\n",
      "Epoch 1470/2000, Train Loss: 0.2004, Test Loss: 0.3133\n",
      "Epoch 1471/2000, Train Loss: 0.2000, Test Loss: 0.3135\n",
      "Epoch 1472/2000, Train Loss: 0.1999, Test Loss: 0.3157\n",
      "Epoch 1473/2000, Train Loss: 0.2002, Test Loss: 0.3109\n",
      "Epoch 1474/2000, Train Loss: 0.2005, Test Loss: 0.3158\n",
      "Epoch 1475/2000, Train Loss: 0.1995, Test Loss: 0.3083\n",
      "Epoch 1476/2000, Train Loss: 0.2009, Test Loss: 0.3120\n",
      "Epoch 1477/2000, Train Loss: 0.2002, Test Loss: 0.3096\n",
      "Epoch 1478/2000, Train Loss: 0.2001, Test Loss: 0.3117\n",
      "Epoch 1479/2000, Train Loss: 0.2002, Test Loss: 0.3134\n",
      "Epoch 1480/2000, Train Loss: 0.2002, Test Loss: 0.3098\n",
      "Epoch 1481/2000, Train Loss: 0.2002, Test Loss: 0.3089\n",
      "Epoch 1482/2000, Train Loss: 0.2009, Test Loss: 0.3151\n",
      "Epoch 1483/2000, Train Loss: 0.2005, Test Loss: 0.3129\n",
      "Epoch 1484/2000, Train Loss: 0.2004, Test Loss: 0.3122\n",
      "Epoch 1485/2000, Train Loss: 0.1998, Test Loss: 0.3081\n",
      "Epoch 1486/2000, Train Loss: 0.2001, Test Loss: 0.3144\n",
      "Epoch 1487/2000, Train Loss: 0.1995, Test Loss: 0.3080\n",
      "Epoch 1488/2000, Train Loss: 0.1999, Test Loss: 0.3103\n",
      "Epoch 1489/2000, Train Loss: 0.2004, Test Loss: 0.3094\n",
      "Epoch 1490/2000, Train Loss: 0.2003, Test Loss: 0.3107\n",
      "Epoch 1491/2000, Train Loss: 0.2003, Test Loss: 0.3198\n",
      "Epoch 1492/2000, Train Loss: 0.2002, Test Loss: 0.3104\n",
      "Epoch 1493/2000, Train Loss: 0.1993, Test Loss: 0.3155\n",
      "Epoch 1494/2000, Train Loss: 0.1994, Test Loss: 0.3099\n",
      "Epoch 1495/2000, Train Loss: 0.1997, Test Loss: 0.3117\n",
      "Epoch 1496/2000, Train Loss: 0.2000, Test Loss: 0.3131\n",
      "Epoch 1497/2000, Train Loss: 0.2003, Test Loss: 0.3089\n",
      "Epoch 1498/2000, Train Loss: 0.2001, Test Loss: 0.3092\n",
      "Epoch 1499/2000, Train Loss: 0.1999, Test Loss: 0.3131\n",
      "Epoch 1500/2000, Train Loss: 0.2002, Test Loss: 0.3117\n",
      "Epoch 1501/2000, Train Loss: 0.1997, Test Loss: 0.3103\n",
      "Epoch 1502/2000, Train Loss: 0.1994, Test Loss: 0.3135\n",
      "Epoch 1503/2000, Train Loss: 0.2002, Test Loss: 0.3125\n",
      "Epoch 1504/2000, Train Loss: 0.2001, Test Loss: 0.3161\n",
      "Epoch 1505/2000, Train Loss: 0.1995, Test Loss: 0.3146\n",
      "Epoch 1506/2000, Train Loss: 0.1999, Test Loss: 0.3175\n",
      "Epoch 1507/2000, Train Loss: 0.2000, Test Loss: 0.3098\n",
      "Epoch 1508/2000, Train Loss: 0.1997, Test Loss: 0.3168\n",
      "Epoch 1509/2000, Train Loss: 0.2006, Test Loss: 0.3236\n",
      "Epoch 1510/2000, Train Loss: 0.2000, Test Loss: 0.3119\n",
      "Epoch 1511/2000, Train Loss: 0.1997, Test Loss: 0.3217\n",
      "Epoch 1512/2000, Train Loss: 0.2000, Test Loss: 0.3152\n",
      "Epoch 1513/2000, Train Loss: 0.1997, Test Loss: 0.3116\n",
      "Epoch 1514/2000, Train Loss: 0.1997, Test Loss: 0.3110\n",
      "Epoch 1515/2000, Train Loss: 0.1995, Test Loss: 0.3127\n",
      "Epoch 1516/2000, Train Loss: 0.1995, Test Loss: 0.3096\n",
      "Epoch 1517/2000, Train Loss: 0.2000, Test Loss: 0.3203\n",
      "Epoch 1518/2000, Train Loss: 0.2000, Test Loss: 0.3117\n",
      "Epoch 1519/2000, Train Loss: 0.1996, Test Loss: 0.3147\n",
      "Epoch 1520/2000, Train Loss: 0.1996, Test Loss: 0.3113\n",
      "Epoch 1521/2000, Train Loss: 0.1998, Test Loss: 0.3087\n",
      "Epoch 1522/2000, Train Loss: 0.1999, Test Loss: 0.3120\n",
      "Epoch 1523/2000, Train Loss: 0.1999, Test Loss: 0.3110\n",
      "Epoch 1524/2000, Train Loss: 0.1992, Test Loss: 0.3170\n",
      "Epoch 1525/2000, Train Loss: 0.1995, Test Loss: 0.3183\n",
      "Epoch 1526/2000, Train Loss: 0.1996, Test Loss: 0.3105\n",
      "Epoch 1527/2000, Train Loss: 0.2002, Test Loss: 0.3118\n",
      "Epoch 1528/2000, Train Loss: 0.1998, Test Loss: 0.3151\n",
      "Epoch 1529/2000, Train Loss: 0.1996, Test Loss: 0.3095\n",
      "Epoch 1530/2000, Train Loss: 0.1996, Test Loss: 0.3224\n",
      "Epoch 1531/2000, Train Loss: 0.1992, Test Loss: 0.3104\n",
      "Epoch 1532/2000, Train Loss: 0.1995, Test Loss: 0.3107\n",
      "Epoch 1533/2000, Train Loss: 0.1994, Test Loss: 0.3130\n",
      "Epoch 1534/2000, Train Loss: 0.1993, Test Loss: 0.3111\n",
      "Epoch 1535/2000, Train Loss: 0.1990, Test Loss: 0.3135\n",
      "Epoch 1536/2000, Train Loss: 0.2004, Test Loss: 0.3102\n",
      "Epoch 1537/2000, Train Loss: 0.1994, Test Loss: 0.3095\n",
      "Epoch 1538/2000, Train Loss: 0.2000, Test Loss: 0.3140\n",
      "Epoch 1539/2000, Train Loss: 0.1993, Test Loss: 0.3111\n",
      "Epoch 1540/2000, Train Loss: 0.2004, Test Loss: 0.3124\n",
      "Epoch 1541/2000, Train Loss: 0.1994, Test Loss: 0.3098\n",
      "Epoch 1542/2000, Train Loss: 0.1991, Test Loss: 0.3147\n",
      "Epoch 1543/2000, Train Loss: 0.2003, Test Loss: 0.3128\n",
      "Epoch 1544/2000, Train Loss: 0.1998, Test Loss: 0.3091\n",
      "Epoch 1545/2000, Train Loss: 0.2001, Test Loss: 0.3130\n",
      "Epoch 1546/2000, Train Loss: 0.1999, Test Loss: 0.3116\n",
      "Epoch 1547/2000, Train Loss: 0.1994, Test Loss: 0.3110\n",
      "Epoch 1548/2000, Train Loss: 0.1996, Test Loss: 0.3134\n",
      "Epoch 1549/2000, Train Loss: 0.1993, Test Loss: 0.3153\n",
      "Epoch 1550/2000, Train Loss: 0.1994, Test Loss: 0.3141\n",
      "Epoch 1551/2000, Train Loss: 0.1995, Test Loss: 0.3108\n",
      "Epoch 1552/2000, Train Loss: 0.1991, Test Loss: 0.3205\n",
      "Epoch 1553/2000, Train Loss: 0.1998, Test Loss: 0.3116\n",
      "Epoch 1554/2000, Train Loss: 0.1995, Test Loss: 0.3124\n",
      "Epoch 1555/2000, Train Loss: 0.1994, Test Loss: 0.3115\n",
      "Epoch 1556/2000, Train Loss: 0.1999, Test Loss: 0.3128\n",
      "Epoch 1557/2000, Train Loss: 0.1994, Test Loss: 0.3160\n",
      "Epoch 1558/2000, Train Loss: 0.1995, Test Loss: 0.3126\n",
      "Epoch 1559/2000, Train Loss: 0.1995, Test Loss: 0.3114\n",
      "Epoch 1560/2000, Train Loss: 0.1992, Test Loss: 0.3106\n",
      "Epoch 1561/2000, Train Loss: 0.1988, Test Loss: 0.3116\n",
      "Epoch 1562/2000, Train Loss: 0.1991, Test Loss: 0.3104\n",
      "Epoch 1563/2000, Train Loss: 0.1997, Test Loss: 0.3135\n",
      "Epoch 1564/2000, Train Loss: 0.1992, Test Loss: 0.3110\n",
      "Epoch 1565/2000, Train Loss: 0.2000, Test Loss: 0.3137\n",
      "Epoch 1566/2000, Train Loss: 0.1990, Test Loss: 0.3093\n",
      "Epoch 1567/2000, Train Loss: 0.1991, Test Loss: 0.3119\n",
      "Epoch 1568/2000, Train Loss: 0.1992, Test Loss: 0.3113\n",
      "Epoch 1569/2000, Train Loss: 0.1995, Test Loss: 0.3101\n",
      "Epoch 1570/2000, Train Loss: 0.1995, Test Loss: 0.3116\n",
      "Epoch 1571/2000, Train Loss: 0.1990, Test Loss: 0.3162\n",
      "Epoch 1572/2000, Train Loss: 0.1995, Test Loss: 0.3151\n",
      "Epoch 1573/2000, Train Loss: 0.2001, Test Loss: 0.3107\n",
      "Epoch 1574/2000, Train Loss: 0.1997, Test Loss: 0.3131\n",
      "Epoch 1575/2000, Train Loss: 0.1996, Test Loss: 0.3118\n",
      "Epoch 1576/2000, Train Loss: 0.1991, Test Loss: 0.3125\n",
      "Epoch 1577/2000, Train Loss: 0.1994, Test Loss: 0.3135\n",
      "Epoch 1578/2000, Train Loss: 0.1992, Test Loss: 0.3327\n",
      "Epoch 1579/2000, Train Loss: 0.1996, Test Loss: 0.3134\n",
      "Epoch 1580/2000, Train Loss: 0.1994, Test Loss: 0.3155\n",
      "Epoch 1581/2000, Train Loss: 0.2001, Test Loss: 0.3099\n",
      "Epoch 1582/2000, Train Loss: 0.1990, Test Loss: 0.3138\n",
      "Epoch 1583/2000, Train Loss: 0.1992, Test Loss: 0.3179\n",
      "Epoch 1584/2000, Train Loss: 0.1999, Test Loss: 0.3219\n",
      "Epoch 1585/2000, Train Loss: 0.1994, Test Loss: 0.3130\n",
      "Epoch 1586/2000, Train Loss: 0.1991, Test Loss: 0.3146\n",
      "Epoch 1587/2000, Train Loss: 0.1989, Test Loss: 0.3152\n",
      "Epoch 1588/2000, Train Loss: 0.1988, Test Loss: 0.3118\n",
      "Epoch 1589/2000, Train Loss: 0.1995, Test Loss: 0.3156\n",
      "Epoch 1590/2000, Train Loss: 0.1991, Test Loss: 0.3134\n",
      "Epoch 1591/2000, Train Loss: 0.1997, Test Loss: 0.3159\n",
      "Epoch 1592/2000, Train Loss: 0.1989, Test Loss: 0.3112\n",
      "Epoch 1593/2000, Train Loss: 0.1990, Test Loss: 0.3189\n",
      "Epoch 1594/2000, Train Loss: 0.1994, Test Loss: 0.3105\n",
      "Epoch 1595/2000, Train Loss: 0.1990, Test Loss: 0.3135\n",
      "Epoch 1596/2000, Train Loss: 0.1993, Test Loss: 0.3121\n",
      "Epoch 1597/2000, Train Loss: 0.1991, Test Loss: 0.3120\n",
      "Epoch 1598/2000, Train Loss: 0.1996, Test Loss: 0.3145\n",
      "Epoch 1599/2000, Train Loss: 0.1996, Test Loss: 0.3162\n",
      "Epoch 1600/2000, Train Loss: 0.1995, Test Loss: 0.3154\n",
      "Epoch 1601/2000, Train Loss: 0.1990, Test Loss: 0.3146\n",
      "Epoch 1602/2000, Train Loss: 0.1997, Test Loss: 0.3155\n",
      "Epoch 1603/2000, Train Loss: 0.1991, Test Loss: 0.3120\n",
      "Epoch 1604/2000, Train Loss: 0.1992, Test Loss: 0.3146\n",
      "Epoch 1605/2000, Train Loss: 0.1989, Test Loss: 0.3218\n",
      "Epoch 1606/2000, Train Loss: 0.1996, Test Loss: 0.3113\n",
      "Epoch 1607/2000, Train Loss: 0.1990, Test Loss: 0.3114\n",
      "Epoch 1608/2000, Train Loss: 0.1987, Test Loss: 0.3144\n",
      "Epoch 1609/2000, Train Loss: 0.1990, Test Loss: 0.3112\n",
      "Epoch 1610/2000, Train Loss: 0.1988, Test Loss: 0.3114\n",
      "Epoch 1611/2000, Train Loss: 0.1983, Test Loss: 0.3163\n",
      "Epoch 1612/2000, Train Loss: 0.1991, Test Loss: 0.3124\n",
      "Epoch 1613/2000, Train Loss: 0.1986, Test Loss: 0.3138\n",
      "Epoch 1614/2000, Train Loss: 0.1987, Test Loss: 0.3110\n",
      "Epoch 1615/2000, Train Loss: 0.1992, Test Loss: 0.3132\n",
      "Epoch 1616/2000, Train Loss: 0.1992, Test Loss: 0.3134\n",
      "Epoch 1617/2000, Train Loss: 0.1997, Test Loss: 0.3133\n",
      "Epoch 1618/2000, Train Loss: 0.1989, Test Loss: 0.3140\n",
      "Epoch 1619/2000, Train Loss: 0.1993, Test Loss: 0.3123\n",
      "Epoch 1620/2000, Train Loss: 0.1991, Test Loss: 0.3124\n",
      "Epoch 1621/2000, Train Loss: 0.1989, Test Loss: 0.3103\n",
      "Epoch 1622/2000, Train Loss: 0.1990, Test Loss: 0.3121\n",
      "Epoch 1623/2000, Train Loss: 0.1998, Test Loss: 0.3222\n",
      "Epoch 1624/2000, Train Loss: 0.1993, Test Loss: 0.3160\n",
      "Epoch 1625/2000, Train Loss: 0.1996, Test Loss: 0.3129\n",
      "Epoch 1626/2000, Train Loss: 0.1990, Test Loss: 0.3104\n",
      "Epoch 1627/2000, Train Loss: 0.1983, Test Loss: 0.3120\n",
      "Epoch 1628/2000, Train Loss: 0.1985, Test Loss: 0.3116\n",
      "Epoch 1629/2000, Train Loss: 0.1990, Test Loss: 0.3105\n",
      "Epoch 1630/2000, Train Loss: 0.1991, Test Loss: 0.3165\n",
      "Epoch 1631/2000, Train Loss: 0.1989, Test Loss: 0.3129\n",
      "Epoch 1632/2000, Train Loss: 0.1989, Test Loss: 0.3154\n",
      "Epoch 1633/2000, Train Loss: 0.1987, Test Loss: 0.3158\n",
      "Epoch 1634/2000, Train Loss: 0.1987, Test Loss: 0.3131\n",
      "Epoch 1635/2000, Train Loss: 0.1986, Test Loss: 0.3115\n",
      "Epoch 1636/2000, Train Loss: 0.1988, Test Loss: 0.3108\n",
      "Epoch 1637/2000, Train Loss: 0.1991, Test Loss: 0.3120\n",
      "Epoch 1638/2000, Train Loss: 0.1980, Test Loss: 0.3253\n",
      "Epoch 1639/2000, Train Loss: 0.1989, Test Loss: 0.3102\n",
      "Epoch 1640/2000, Train Loss: 0.1989, Test Loss: 0.3150\n",
      "Epoch 1641/2000, Train Loss: 0.1985, Test Loss: 0.3183\n",
      "Epoch 1642/2000, Train Loss: 0.1988, Test Loss: 0.3159\n",
      "Epoch 1643/2000, Train Loss: 0.1988, Test Loss: 0.3129\n",
      "Epoch 1644/2000, Train Loss: 0.1990, Test Loss: 0.3164\n",
      "Epoch 1645/2000, Train Loss: 0.1990, Test Loss: 0.3137\n",
      "Epoch 1646/2000, Train Loss: 0.1996, Test Loss: 0.3118\n",
      "Epoch 1647/2000, Train Loss: 0.1992, Test Loss: 0.3206\n",
      "Epoch 1648/2000, Train Loss: 0.1988, Test Loss: 0.3138\n",
      "Epoch 1649/2000, Train Loss: 0.1991, Test Loss: 0.3105\n",
      "Epoch 1650/2000, Train Loss: 0.1990, Test Loss: 0.3125\n",
      "Epoch 1651/2000, Train Loss: 0.1982, Test Loss: 0.3178\n",
      "Epoch 1652/2000, Train Loss: 0.1994, Test Loss: 0.3203\n",
      "Epoch 1653/2000, Train Loss: 0.1990, Test Loss: 0.3145\n",
      "Epoch 1654/2000, Train Loss: 0.1987, Test Loss: 0.3144\n",
      "Epoch 1655/2000, Train Loss: 0.1987, Test Loss: 0.3137\n",
      "Epoch 1656/2000, Train Loss: 0.1985, Test Loss: 0.3135\n",
      "Epoch 1657/2000, Train Loss: 0.1992, Test Loss: 0.3114\n",
      "Epoch 1658/2000, Train Loss: 0.1988, Test Loss: 0.3158\n",
      "Epoch 1659/2000, Train Loss: 0.1990, Test Loss: 0.3203\n",
      "Epoch 1660/2000, Train Loss: 0.1990, Test Loss: 0.3148\n",
      "Epoch 1661/2000, Train Loss: 0.1986, Test Loss: 0.3150\n",
      "Epoch 1662/2000, Train Loss: 0.1991, Test Loss: 0.3130\n",
      "Epoch 1663/2000, Train Loss: 0.1984, Test Loss: 0.3141\n",
      "Epoch 1664/2000, Train Loss: 0.1989, Test Loss: 0.3363\n",
      "Epoch 1665/2000, Train Loss: 0.1986, Test Loss: 0.3114\n",
      "Epoch 1666/2000, Train Loss: 0.1988, Test Loss: 0.3103\n",
      "Epoch 1667/2000, Train Loss: 0.1993, Test Loss: 0.3150\n",
      "Epoch 1668/2000, Train Loss: 0.1992, Test Loss: 0.3124\n",
      "Epoch 1669/2000, Train Loss: 0.1988, Test Loss: 0.3151\n",
      "Epoch 1670/2000, Train Loss: 0.1990, Test Loss: 0.3132\n",
      "Epoch 1671/2000, Train Loss: 0.1989, Test Loss: 0.3105\n",
      "Epoch 1672/2000, Train Loss: 0.1980, Test Loss: 0.3156\n",
      "Epoch 1673/2000, Train Loss: 0.1986, Test Loss: 0.3167\n",
      "Epoch 1674/2000, Train Loss: 0.1991, Test Loss: 0.3177\n",
      "Epoch 1675/2000, Train Loss: 0.1987, Test Loss: 0.3122\n",
      "Epoch 1676/2000, Train Loss: 0.1987, Test Loss: 0.3253\n",
      "Epoch 1677/2000, Train Loss: 0.1988, Test Loss: 0.3149\n",
      "Epoch 1678/2000, Train Loss: 0.1984, Test Loss: 0.3195\n",
      "Epoch 1679/2000, Train Loss: 0.1991, Test Loss: 0.3168\n",
      "Epoch 1680/2000, Train Loss: 0.1988, Test Loss: 0.3113\n",
      "Epoch 1681/2000, Train Loss: 0.1985, Test Loss: 0.3230\n",
      "Epoch 1682/2000, Train Loss: 0.1988, Test Loss: 0.3110\n",
      "Epoch 1683/2000, Train Loss: 0.1983, Test Loss: 0.3135\n",
      "Epoch 1684/2000, Train Loss: 0.1990, Test Loss: 0.3147\n",
      "Epoch 1685/2000, Train Loss: 0.1987, Test Loss: 0.3176\n",
      "Epoch 1686/2000, Train Loss: 0.1990, Test Loss: 0.3129\n",
      "Epoch 1687/2000, Train Loss: 0.1988, Test Loss: 0.3173\n",
      "Epoch 1688/2000, Train Loss: 0.1986, Test Loss: 0.3204\n",
      "Epoch 1689/2000, Train Loss: 0.1991, Test Loss: 0.3135\n",
      "Epoch 1690/2000, Train Loss: 0.1980, Test Loss: 0.3137\n",
      "Epoch 1691/2000, Train Loss: 0.1985, Test Loss: 0.3184\n",
      "Epoch 1692/2000, Train Loss: 0.1988, Test Loss: 0.3137\n",
      "Epoch 1693/2000, Train Loss: 0.1986, Test Loss: 0.3117\n",
      "Epoch 1694/2000, Train Loss: 0.1986, Test Loss: 0.3246\n",
      "Epoch 1695/2000, Train Loss: 0.1985, Test Loss: 0.3162\n",
      "Epoch 1696/2000, Train Loss: 0.1983, Test Loss: 0.3140\n",
      "Epoch 1697/2000, Train Loss: 0.1983, Test Loss: 0.3122\n",
      "Epoch 1698/2000, Train Loss: 0.1985, Test Loss: 0.3134\n",
      "Epoch 1699/2000, Train Loss: 0.1986, Test Loss: 0.3131\n",
      "Epoch 1700/2000, Train Loss: 0.1989, Test Loss: 0.3125\n",
      "Epoch 1701/2000, Train Loss: 0.1980, Test Loss: 0.3120\n",
      "Epoch 1702/2000, Train Loss: 0.1981, Test Loss: 0.3134\n",
      "Epoch 1703/2000, Train Loss: 0.1983, Test Loss: 0.3113\n",
      "Epoch 1704/2000, Train Loss: 0.1980, Test Loss: 0.3165\n",
      "Epoch 1705/2000, Train Loss: 0.1991, Test Loss: 0.3150\n",
      "Epoch 1706/2000, Train Loss: 0.1985, Test Loss: 0.3234\n",
      "Epoch 1707/2000, Train Loss: 0.1977, Test Loss: 0.3128\n",
      "Epoch 1708/2000, Train Loss: 0.1983, Test Loss: 0.3158\n",
      "Epoch 1709/2000, Train Loss: 0.1987, Test Loss: 0.3162\n",
      "Epoch 1710/2000, Train Loss: 0.1983, Test Loss: 0.3200\n",
      "Epoch 1711/2000, Train Loss: 0.1980, Test Loss: 0.3101\n",
      "Epoch 1712/2000, Train Loss: 0.1981, Test Loss: 0.3179\n",
      "Epoch 1713/2000, Train Loss: 0.1984, Test Loss: 0.3132\n",
      "Epoch 1714/2000, Train Loss: 0.1980, Test Loss: 0.3158\n",
      "Epoch 1715/2000, Train Loss: 0.1988, Test Loss: 0.3130\n",
      "Epoch 1716/2000, Train Loss: 0.1982, Test Loss: 0.3175\n",
      "Epoch 1717/2000, Train Loss: 0.1991, Test Loss: 0.3156\n",
      "Epoch 1718/2000, Train Loss: 0.1988, Test Loss: 0.3166\n",
      "Epoch 1719/2000, Train Loss: 0.1988, Test Loss: 0.3137\n",
      "Epoch 1720/2000, Train Loss: 0.1975, Test Loss: 0.3128\n",
      "Epoch 1721/2000, Train Loss: 0.1987, Test Loss: 0.3126\n",
      "Epoch 1722/2000, Train Loss: 0.1980, Test Loss: 0.3108\n",
      "Epoch 1723/2000, Train Loss: 0.1981, Test Loss: 0.3148\n",
      "Epoch 1724/2000, Train Loss: 0.1983, Test Loss: 0.3172\n",
      "Epoch 1725/2000, Train Loss: 0.1979, Test Loss: 0.3189\n",
      "Epoch 1726/2000, Train Loss: 0.1987, Test Loss: 0.3143\n",
      "Epoch 1727/2000, Train Loss: 0.1982, Test Loss: 0.3130\n",
      "Epoch 1728/2000, Train Loss: 0.1989, Test Loss: 0.3138\n",
      "Epoch 1729/2000, Train Loss: 0.1982, Test Loss: 0.3124\n",
      "Epoch 1730/2000, Train Loss: 0.1985, Test Loss: 0.3174\n",
      "Epoch 1731/2000, Train Loss: 0.1981, Test Loss: 0.3152\n",
      "Epoch 1732/2000, Train Loss: 0.1982, Test Loss: 0.3222\n",
      "Epoch 1733/2000, Train Loss: 0.1984, Test Loss: 0.3115\n",
      "Epoch 1734/2000, Train Loss: 0.1979, Test Loss: 0.3198\n",
      "Epoch 1735/2000, Train Loss: 0.1986, Test Loss: 0.3134\n",
      "Epoch 1736/2000, Train Loss: 0.1977, Test Loss: 0.3160\n",
      "Epoch 1737/2000, Train Loss: 0.1981, Test Loss: 0.3161\n",
      "Epoch 1738/2000, Train Loss: 0.1985, Test Loss: 0.3153\n",
      "Epoch 1739/2000, Train Loss: 0.1981, Test Loss: 0.3141\n",
      "Epoch 1740/2000, Train Loss: 0.1992, Test Loss: 0.3122\n",
      "Epoch 1741/2000, Train Loss: 0.1978, Test Loss: 0.3170\n",
      "Epoch 1742/2000, Train Loss: 0.1979, Test Loss: 0.3119\n",
      "Epoch 1743/2000, Train Loss: 0.1982, Test Loss: 0.3160\n",
      "Epoch 1744/2000, Train Loss: 0.1979, Test Loss: 0.3153\n",
      "Epoch 1745/2000, Train Loss: 0.1982, Test Loss: 0.3155\n",
      "Epoch 1746/2000, Train Loss: 0.1984, Test Loss: 0.3186\n",
      "Epoch 1747/2000, Train Loss: 0.1980, Test Loss: 0.3210\n",
      "Epoch 1748/2000, Train Loss: 0.1981, Test Loss: 0.3220\n",
      "Epoch 1749/2000, Train Loss: 0.1984, Test Loss: 0.3179\n",
      "Epoch 1750/2000, Train Loss: 0.1980, Test Loss: 0.3140\n",
      "Epoch 1751/2000, Train Loss: 0.1976, Test Loss: 0.3137\n",
      "Epoch 1752/2000, Train Loss: 0.1979, Test Loss: 0.3121\n",
      "Epoch 1753/2000, Train Loss: 0.1978, Test Loss: 0.3145\n",
      "Epoch 1754/2000, Train Loss: 0.1984, Test Loss: 0.3184\n",
      "Epoch 1755/2000, Train Loss: 0.1989, Test Loss: 0.3158\n",
      "Epoch 1756/2000, Train Loss: 0.1982, Test Loss: 0.3183\n",
      "Epoch 1757/2000, Train Loss: 0.1984, Test Loss: 0.3126\n",
      "Epoch 1758/2000, Train Loss: 0.1987, Test Loss: 0.3106\n",
      "Epoch 1759/2000, Train Loss: 0.1976, Test Loss: 0.3228\n",
      "Epoch 1760/2000, Train Loss: 0.1980, Test Loss: 0.3111\n",
      "Epoch 1761/2000, Train Loss: 0.1982, Test Loss: 0.3199\n",
      "Epoch 1762/2000, Train Loss: 0.1983, Test Loss: 0.3125\n",
      "Epoch 1763/2000, Train Loss: 0.1980, Test Loss: 0.3158\n",
      "Epoch 1764/2000, Train Loss: 0.1977, Test Loss: 0.3176\n",
      "Epoch 1765/2000, Train Loss: 0.1993, Test Loss: 0.3173\n",
      "Epoch 1766/2000, Train Loss: 0.1986, Test Loss: 0.3178\n",
      "Epoch 1767/2000, Train Loss: 0.1987, Test Loss: 0.3149\n",
      "Epoch 1768/2000, Train Loss: 0.1983, Test Loss: 0.3125\n",
      "Epoch 1769/2000, Train Loss: 0.1991, Test Loss: 0.3171\n",
      "Epoch 1770/2000, Train Loss: 0.1975, Test Loss: 0.3120\n",
      "Epoch 1771/2000, Train Loss: 0.1980, Test Loss: 0.3169\n",
      "Epoch 1772/2000, Train Loss: 0.1979, Test Loss: 0.3219\n",
      "Epoch 1773/2000, Train Loss: 0.1979, Test Loss: 0.3124\n",
      "Epoch 1774/2000, Train Loss: 0.1980, Test Loss: 0.3167\n",
      "Epoch 1775/2000, Train Loss: 0.1978, Test Loss: 0.3164\n",
      "Epoch 1776/2000, Train Loss: 0.1981, Test Loss: 0.3176\n",
      "Epoch 1777/2000, Train Loss: 0.1984, Test Loss: 0.3193\n",
      "Epoch 1778/2000, Train Loss: 0.1981, Test Loss: 0.3181\n",
      "Epoch 1779/2000, Train Loss: 0.1979, Test Loss: 0.3152\n",
      "Epoch 1780/2000, Train Loss: 0.1981, Test Loss: 0.3145\n",
      "Epoch 1781/2000, Train Loss: 0.1983, Test Loss: 0.3185\n",
      "Epoch 1782/2000, Train Loss: 0.1978, Test Loss: 0.3239\n",
      "Epoch 1783/2000, Train Loss: 0.1980, Test Loss: 0.3118\n",
      "Epoch 1784/2000, Train Loss: 0.1978, Test Loss: 0.3122\n",
      "Epoch 1785/2000, Train Loss: 0.1983, Test Loss: 0.3167\n",
      "Epoch 1786/2000, Train Loss: 0.1982, Test Loss: 0.3150\n",
      "Epoch 1787/2000, Train Loss: 0.1983, Test Loss: 0.3298\n",
      "Epoch 1788/2000, Train Loss: 0.1983, Test Loss: 0.3144\n",
      "Epoch 1789/2000, Train Loss: 0.1983, Test Loss: 0.3130\n",
      "Epoch 1790/2000, Train Loss: 0.1974, Test Loss: 0.3125\n",
      "Epoch 1791/2000, Train Loss: 0.1982, Test Loss: 0.3201\n",
      "Epoch 1792/2000, Train Loss: 0.1980, Test Loss: 0.3165\n",
      "Epoch 1793/2000, Train Loss: 0.1977, Test Loss: 0.3147\n",
      "Epoch 1794/2000, Train Loss: 0.1972, Test Loss: 0.3163\n",
      "Epoch 1795/2000, Train Loss: 0.1976, Test Loss: 0.3166\n",
      "Epoch 1796/2000, Train Loss: 0.1975, Test Loss: 0.3228\n",
      "Epoch 1797/2000, Train Loss: 0.1981, Test Loss: 0.3130\n",
      "Epoch 1798/2000, Train Loss: 0.1978, Test Loss: 0.3138\n",
      "Epoch 1799/2000, Train Loss: 0.1978, Test Loss: 0.3220\n",
      "Epoch 1800/2000, Train Loss: 0.1982, Test Loss: 0.3158\n",
      "Epoch 1801/2000, Train Loss: 0.1982, Test Loss: 0.3147\n",
      "Epoch 1802/2000, Train Loss: 0.1976, Test Loss: 0.3213\n",
      "Epoch 1803/2000, Train Loss: 0.1982, Test Loss: 0.3166\n",
      "Epoch 1804/2000, Train Loss: 0.1975, Test Loss: 0.3153\n",
      "Epoch 1805/2000, Train Loss: 0.1980, Test Loss: 0.3141\n",
      "Epoch 1806/2000, Train Loss: 0.1981, Test Loss: 0.3169\n",
      "Epoch 1807/2000, Train Loss: 0.1978, Test Loss: 0.3222\n",
      "Epoch 1808/2000, Train Loss: 0.1976, Test Loss: 0.3138\n",
      "Epoch 1809/2000, Train Loss: 0.1973, Test Loss: 0.3119\n",
      "Epoch 1810/2000, Train Loss: 0.1976, Test Loss: 0.3150\n",
      "Epoch 1811/2000, Train Loss: 0.1978, Test Loss: 0.3183\n",
      "Epoch 1812/2000, Train Loss: 0.1972, Test Loss: 0.3155\n",
      "Epoch 1813/2000, Train Loss: 0.1978, Test Loss: 0.3157\n",
      "Epoch 1814/2000, Train Loss: 0.1971, Test Loss: 0.3216\n",
      "Epoch 1815/2000, Train Loss: 0.1977, Test Loss: 0.3132\n",
      "Epoch 1816/2000, Train Loss: 0.1972, Test Loss: 0.3160\n",
      "Epoch 1817/2000, Train Loss: 0.1972, Test Loss: 0.3162\n",
      "Epoch 1818/2000, Train Loss: 0.1978, Test Loss: 0.3139\n",
      "Epoch 1819/2000, Train Loss: 0.1976, Test Loss: 0.3130\n",
      "Epoch 1820/2000, Train Loss: 0.1982, Test Loss: 0.3179\n",
      "Epoch 1821/2000, Train Loss: 0.1976, Test Loss: 0.3209\n",
      "Epoch 1822/2000, Train Loss: 0.1978, Test Loss: 0.3147\n",
      "Epoch 1823/2000, Train Loss: 0.1973, Test Loss: 0.3197\n",
      "Epoch 1824/2000, Train Loss: 0.1977, Test Loss: 0.3220\n",
      "Epoch 1825/2000, Train Loss: 0.1976, Test Loss: 0.3226\n",
      "Epoch 1826/2000, Train Loss: 0.1979, Test Loss: 0.3216\n",
      "Epoch 1827/2000, Train Loss: 0.1987, Test Loss: 0.3176\n",
      "Epoch 1828/2000, Train Loss: 0.1978, Test Loss: 0.3168\n",
      "Epoch 1829/2000, Train Loss: 0.1980, Test Loss: 0.3240\n",
      "Epoch 1830/2000, Train Loss: 0.1986, Test Loss: 0.3169\n",
      "Epoch 1831/2000, Train Loss: 0.1972, Test Loss: 0.3252\n",
      "Epoch 1832/2000, Train Loss: 0.1976, Test Loss: 0.3184\n",
      "Epoch 1833/2000, Train Loss: 0.1974, Test Loss: 0.3179\n",
      "Epoch 1834/2000, Train Loss: 0.1975, Test Loss: 0.3127\n",
      "Epoch 1835/2000, Train Loss: 0.1978, Test Loss: 0.3152\n",
      "Epoch 1836/2000, Train Loss: 0.1971, Test Loss: 0.3135\n",
      "Epoch 1837/2000, Train Loss: 0.1976, Test Loss: 0.3175\n",
      "Epoch 1838/2000, Train Loss: 0.1973, Test Loss: 0.3203\n",
      "Epoch 1839/2000, Train Loss: 0.1981, Test Loss: 0.3155\n",
      "Epoch 1840/2000, Train Loss: 0.1975, Test Loss: 0.3194\n",
      "Epoch 1841/2000, Train Loss: 0.1972, Test Loss: 0.3131\n",
      "Epoch 1842/2000, Train Loss: 0.1976, Test Loss: 0.3210\n",
      "Epoch 1843/2000, Train Loss: 0.1981, Test Loss: 0.3143\n",
      "Epoch 1844/2000, Train Loss: 0.1975, Test Loss: 0.3137\n",
      "Epoch 1845/2000, Train Loss: 0.1976, Test Loss: 0.3134\n",
      "Epoch 1846/2000, Train Loss: 0.1973, Test Loss: 0.3137\n",
      "Epoch 1847/2000, Train Loss: 0.1983, Test Loss: 0.3166\n",
      "Epoch 1848/2000, Train Loss: 0.1974, Test Loss: 0.3136\n",
      "Epoch 1849/2000, Train Loss: 0.1978, Test Loss: 0.3174\n",
      "Epoch 1850/2000, Train Loss: 0.1978, Test Loss: 0.3142\n",
      "Epoch 1851/2000, Train Loss: 0.1977, Test Loss: 0.3189\n",
      "Epoch 1852/2000, Train Loss: 0.1977, Test Loss: 0.3214\n",
      "Epoch 1853/2000, Train Loss: 0.1978, Test Loss: 0.3121\n",
      "Epoch 1854/2000, Train Loss: 0.1971, Test Loss: 0.3135\n",
      "Epoch 1855/2000, Train Loss: 0.1976, Test Loss: 0.3156\n",
      "Epoch 1856/2000, Train Loss: 0.1973, Test Loss: 0.3154\n",
      "Epoch 1857/2000, Train Loss: 0.1980, Test Loss: 0.3161\n",
      "Epoch 1858/2000, Train Loss: 0.1980, Test Loss: 0.3180\n",
      "Epoch 1859/2000, Train Loss: 0.1976, Test Loss: 0.3217\n",
      "Epoch 1860/2000, Train Loss: 0.1976, Test Loss: 0.3174\n",
      "Epoch 1861/2000, Train Loss: 0.1973, Test Loss: 0.3171\n",
      "Epoch 1862/2000, Train Loss: 0.1977, Test Loss: 0.3189\n",
      "Epoch 1863/2000, Train Loss: 0.1974, Test Loss: 0.3165\n",
      "Epoch 1864/2000, Train Loss: 0.1973, Test Loss: 0.3155\n",
      "Epoch 1865/2000, Train Loss: 0.1970, Test Loss: 0.3141\n",
      "Epoch 1866/2000, Train Loss: 0.1972, Test Loss: 0.3120\n",
      "Epoch 1867/2000, Train Loss: 0.1973, Test Loss: 0.3158\n",
      "Epoch 1868/2000, Train Loss: 0.1973, Test Loss: 0.3158\n",
      "Epoch 1869/2000, Train Loss: 0.1975, Test Loss: 0.3178\n",
      "Epoch 1870/2000, Train Loss: 0.1971, Test Loss: 0.3134\n",
      "Epoch 1871/2000, Train Loss: 0.1978, Test Loss: 0.3171\n",
      "Epoch 1872/2000, Train Loss: 0.1979, Test Loss: 0.3205\n",
      "Epoch 1873/2000, Train Loss: 0.1972, Test Loss: 0.3148\n",
      "Epoch 1874/2000, Train Loss: 0.1976, Test Loss: 0.3186\n",
      "Epoch 1875/2000, Train Loss: 0.1971, Test Loss: 0.3163\n",
      "Epoch 1876/2000, Train Loss: 0.1982, Test Loss: 0.3207\n",
      "Epoch 1877/2000, Train Loss: 0.1970, Test Loss: 0.3137\n",
      "Epoch 1878/2000, Train Loss: 0.1977, Test Loss: 0.3158\n",
      "Epoch 1879/2000, Train Loss: 0.1970, Test Loss: 0.3198\n",
      "Epoch 1880/2000, Train Loss: 0.1972, Test Loss: 0.3143\n",
      "Epoch 1881/2000, Train Loss: 0.1967, Test Loss: 0.3165\n",
      "Epoch 1882/2000, Train Loss: 0.1969, Test Loss: 0.3173\n",
      "Epoch 1883/2000, Train Loss: 0.1970, Test Loss: 0.3188\n",
      "Epoch 1884/2000, Train Loss: 0.1973, Test Loss: 0.3137\n",
      "Epoch 1885/2000, Train Loss: 0.1974, Test Loss: 0.3164\n",
      "Epoch 1886/2000, Train Loss: 0.1972, Test Loss: 0.3153\n",
      "Epoch 1887/2000, Train Loss: 0.1979, Test Loss: 0.3167\n",
      "Epoch 1888/2000, Train Loss: 0.1972, Test Loss: 0.3134\n",
      "Epoch 1889/2000, Train Loss: 0.1971, Test Loss: 0.3175\n",
      "Epoch 1890/2000, Train Loss: 0.1974, Test Loss: 0.3158\n",
      "Epoch 1891/2000, Train Loss: 0.1977, Test Loss: 0.3173\n",
      "Epoch 1892/2000, Train Loss: 0.1976, Test Loss: 0.3151\n",
      "Epoch 1893/2000, Train Loss: 0.1967, Test Loss: 0.3159\n",
      "Epoch 1894/2000, Train Loss: 0.1974, Test Loss: 0.3171\n",
      "Epoch 1895/2000, Train Loss: 0.1978, Test Loss: 0.3205\n",
      "Epoch 1896/2000, Train Loss: 0.1967, Test Loss: 0.3128\n",
      "Epoch 1897/2000, Train Loss: 0.1970, Test Loss: 0.3164\n",
      "Epoch 1898/2000, Train Loss: 0.1979, Test Loss: 0.3150\n",
      "Epoch 1899/2000, Train Loss: 0.1973, Test Loss: 0.3150\n",
      "Epoch 1900/2000, Train Loss: 0.1980, Test Loss: 0.3144\n",
      "Epoch 1901/2000, Train Loss: 0.1972, Test Loss: 0.3161\n",
      "Epoch 1902/2000, Train Loss: 0.1974, Test Loss: 0.3172\n",
      "Epoch 1903/2000, Train Loss: 0.1975, Test Loss: 0.3161\n",
      "Epoch 1904/2000, Train Loss: 0.1973, Test Loss: 0.3156\n",
      "Epoch 1905/2000, Train Loss: 0.1972, Test Loss: 0.3158\n",
      "Epoch 1906/2000, Train Loss: 0.1981, Test Loss: 0.3156\n",
      "Epoch 1907/2000, Train Loss: 0.1970, Test Loss: 0.3142\n",
      "Epoch 1908/2000, Train Loss: 0.1976, Test Loss: 0.3161\n",
      "Epoch 1909/2000, Train Loss: 0.1970, Test Loss: 0.3191\n",
      "Epoch 1910/2000, Train Loss: 0.1980, Test Loss: 0.3215\n",
      "Epoch 1911/2000, Train Loss: 0.1975, Test Loss: 0.3206\n",
      "Epoch 1912/2000, Train Loss: 0.1973, Test Loss: 0.3138\n",
      "Epoch 1913/2000, Train Loss: 0.1971, Test Loss: 0.3241\n",
      "Epoch 1914/2000, Train Loss: 0.1970, Test Loss: 0.3145\n",
      "Epoch 1915/2000, Train Loss: 0.1974, Test Loss: 0.3193\n",
      "Epoch 1916/2000, Train Loss: 0.1971, Test Loss: 0.3166\n",
      "Epoch 1917/2000, Train Loss: 0.1979, Test Loss: 0.3133\n",
      "Epoch 1918/2000, Train Loss: 0.1973, Test Loss: 0.3155\n",
      "Epoch 1919/2000, Train Loss: 0.1977, Test Loss: 0.3214\n",
      "Epoch 1920/2000, Train Loss: 0.1977, Test Loss: 0.3183\n",
      "Epoch 1921/2000, Train Loss: 0.1970, Test Loss: 0.3167\n",
      "Epoch 1922/2000, Train Loss: 0.1974, Test Loss: 0.3172\n",
      "Epoch 1923/2000, Train Loss: 0.1965, Test Loss: 0.3237\n",
      "Epoch 1924/2000, Train Loss: 0.1975, Test Loss: 0.3171\n",
      "Epoch 1925/2000, Train Loss: 0.1972, Test Loss: 0.3154\n",
      "Epoch 1926/2000, Train Loss: 0.1970, Test Loss: 0.3262\n",
      "Epoch 1927/2000, Train Loss: 0.1971, Test Loss: 0.3171\n",
      "Epoch 1928/2000, Train Loss: 0.1970, Test Loss: 0.3189\n",
      "Epoch 1929/2000, Train Loss: 0.1972, Test Loss: 0.3155\n",
      "Epoch 1930/2000, Train Loss: 0.1969, Test Loss: 0.3223\n",
      "Epoch 1931/2000, Train Loss: 0.1973, Test Loss: 0.3159\n",
      "Epoch 1932/2000, Train Loss: 0.1969, Test Loss: 0.3182\n",
      "Epoch 1933/2000, Train Loss: 0.1971, Test Loss: 0.3198\n",
      "Epoch 1934/2000, Train Loss: 0.1978, Test Loss: 0.3132\n",
      "Epoch 1935/2000, Train Loss: 0.1967, Test Loss: 0.3179\n",
      "Epoch 1936/2000, Train Loss: 0.1967, Test Loss: 0.3142\n",
      "Epoch 1937/2000, Train Loss: 0.1972, Test Loss: 0.3170\n",
      "Epoch 1938/2000, Train Loss: 0.1971, Test Loss: 0.3175\n",
      "Epoch 1939/2000, Train Loss: 0.1966, Test Loss: 0.3189\n",
      "Epoch 1940/2000, Train Loss: 0.1973, Test Loss: 0.3155\n",
      "Epoch 1941/2000, Train Loss: 0.1967, Test Loss: 0.3184\n",
      "Epoch 1942/2000, Train Loss: 0.1967, Test Loss: 0.3139\n",
      "Epoch 1943/2000, Train Loss: 0.1968, Test Loss: 0.3136\n",
      "Epoch 1944/2000, Train Loss: 0.1972, Test Loss: 0.3140\n",
      "Epoch 1945/2000, Train Loss: 0.1968, Test Loss: 0.3193\n",
      "Epoch 1946/2000, Train Loss: 0.1970, Test Loss: 0.3154\n",
      "Epoch 1947/2000, Train Loss: 0.1968, Test Loss: 0.3146\n",
      "Epoch 1948/2000, Train Loss: 0.1976, Test Loss: 0.3249\n",
      "Epoch 1949/2000, Train Loss: 0.1968, Test Loss: 0.3152\n",
      "Epoch 1950/2000, Train Loss: 0.1966, Test Loss: 0.3169\n",
      "Epoch 1951/2000, Train Loss: 0.1970, Test Loss: 0.3152\n",
      "Epoch 1952/2000, Train Loss: 0.1965, Test Loss: 0.3147\n",
      "Epoch 1953/2000, Train Loss: 0.1970, Test Loss: 0.3154\n",
      "Epoch 1954/2000, Train Loss: 0.1971, Test Loss: 0.3228\n",
      "Epoch 1955/2000, Train Loss: 0.1972, Test Loss: 0.3220\n",
      "Epoch 1956/2000, Train Loss: 0.1966, Test Loss: 0.3146\n",
      "Epoch 1957/2000, Train Loss: 0.1970, Test Loss: 0.3190\n",
      "Epoch 1958/2000, Train Loss: 0.1971, Test Loss: 0.3153\n",
      "Epoch 1959/2000, Train Loss: 0.1968, Test Loss: 0.3169\n",
      "Epoch 1960/2000, Train Loss: 0.1981, Test Loss: 0.3144\n",
      "Epoch 1961/2000, Train Loss: 0.1966, Test Loss: 0.3165\n",
      "Epoch 1962/2000, Train Loss: 0.1970, Test Loss: 0.3136\n",
      "Epoch 1963/2000, Train Loss: 0.1966, Test Loss: 0.3191\n",
      "Epoch 1964/2000, Train Loss: 0.1967, Test Loss: 0.3162\n",
      "Epoch 1965/2000, Train Loss: 0.1964, Test Loss: 0.3235\n",
      "Epoch 1966/2000, Train Loss: 0.1970, Test Loss: 0.3164\n",
      "Epoch 1967/2000, Train Loss: 0.1973, Test Loss: 0.3189\n",
      "Epoch 1968/2000, Train Loss: 0.1967, Test Loss: 0.3175\n",
      "Epoch 1969/2000, Train Loss: 0.1966, Test Loss: 0.3196\n",
      "Epoch 1970/2000, Train Loss: 0.1966, Test Loss: 0.3146\n",
      "Epoch 1971/2000, Train Loss: 0.1967, Test Loss: 0.3270\n",
      "Epoch 1972/2000, Train Loss: 0.1969, Test Loss: 0.3226\n",
      "Epoch 1973/2000, Train Loss: 0.1971, Test Loss: 0.3164\n",
      "Epoch 1974/2000, Train Loss: 0.1967, Test Loss: 0.3233\n",
      "Epoch 1975/2000, Train Loss: 0.1963, Test Loss: 0.3160\n",
      "Epoch 1976/2000, Train Loss: 0.1968, Test Loss: 0.3175\n",
      "Epoch 1977/2000, Train Loss: 0.1970, Test Loss: 0.3147\n",
      "Epoch 1978/2000, Train Loss: 0.1968, Test Loss: 0.3190\n",
      "Epoch 1979/2000, Train Loss: 0.1969, Test Loss: 0.3177\n",
      "Epoch 1980/2000, Train Loss: 0.1966, Test Loss: 0.3137\n",
      "Epoch 1981/2000, Train Loss: 0.1973, Test Loss: 0.3163\n",
      "Epoch 1982/2000, Train Loss: 0.1968, Test Loss: 0.3162\n",
      "Epoch 1983/2000, Train Loss: 0.1962, Test Loss: 0.3190\n",
      "Epoch 1984/2000, Train Loss: 0.1971, Test Loss: 0.3153\n",
      "Epoch 1985/2000, Train Loss: 0.1968, Test Loss: 0.3168\n",
      "Epoch 1986/2000, Train Loss: 0.1968, Test Loss: 0.3199\n",
      "Epoch 1987/2000, Train Loss: 0.1973, Test Loss: 0.3169\n",
      "Epoch 1988/2000, Train Loss: 0.1969, Test Loss: 0.3201\n",
      "Epoch 1989/2000, Train Loss: 0.1971, Test Loss: 0.3137\n",
      "Epoch 1990/2000, Train Loss: 0.1969, Test Loss: 0.3167\n",
      "Epoch 1991/2000, Train Loss: 0.1971, Test Loss: 0.3166\n",
      "Epoch 1992/2000, Train Loss: 0.1967, Test Loss: 0.3275\n",
      "Epoch 1993/2000, Train Loss: 0.1970, Test Loss: 0.3148\n",
      "Epoch 1994/2000, Train Loss: 0.1971, Test Loss: 0.3206\n",
      "Epoch 1995/2000, Train Loss: 0.1969, Test Loss: 0.3165\n",
      "Epoch 1996/2000, Train Loss: 0.1970, Test Loss: 0.3197\n",
      "Epoch 1997/2000, Train Loss: 0.1973, Test Loss: 0.3166\n",
      "Epoch 1998/2000, Train Loss: 0.1965, Test Loss: 0.3206\n",
      "Epoch 1999/2000, Train Loss: 0.1967, Test Loss: 0.3167\n",
      "Epoch 2000/2000, Train Loss: 0.1969, Test Loss: 0.3198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.9153</td></tr><tr><td>accuracy/train</td><td>0.94303</td></tr><tr><td>batch_loss</td><td>0.11634</td></tr><tr><td>epoch</td><td>1999</td></tr><tr><td>loss/test</td><td>0.31979</td></tr><tr><td>loss/train</td><td>0.19693</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">young-surf-262</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/bpm7tt0m' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/bpm7tt0m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240312_223240-bpm7tt0m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240313_102210-mw7z41vh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/mw7z41vh' target=\"_blank\">serene-microwave-263</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/mw7z41vh' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/mw7z41vh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Train Loss: 0.5556, Test Loss: 0.3415\n",
      "Epoch 2/2000, Train Loss: 0.3032, Test Loss: 0.2748\n",
      "Epoch 3/2000, Train Loss: 0.2733, Test Loss: 0.2669\n",
      "Epoch 4/2000, Train Loss: 0.2506, Test Loss: 0.2606\n",
      "Epoch 5/2000, Train Loss: 0.2418, Test Loss: 0.2386\n",
      "Epoch 6/2000, Train Loss: 0.2316, Test Loss: 0.2492\n",
      "Epoch 7/2000, Train Loss: 0.2252, Test Loss: 0.2351\n",
      "Epoch 8/2000, Train Loss: 0.2169, Test Loss: 0.2309\n",
      "Epoch 9/2000, Train Loss: 0.2132, Test Loss: 0.2329\n",
      "Epoch 10/2000, Train Loss: 0.2067, Test Loss: 0.2350\n",
      "Epoch 11/2000, Train Loss: 0.2016, Test Loss: 0.2365\n",
      "Epoch 12/2000, Train Loss: 0.1978, Test Loss: 0.2110\n",
      "Epoch 13/2000, Train Loss: 0.1935, Test Loss: 0.2140\n",
      "Epoch 14/2000, Train Loss: 0.1911, Test Loss: 0.2132\n",
      "Epoch 15/2000, Train Loss: 0.1876, Test Loss: 0.2075\n",
      "Epoch 16/2000, Train Loss: 0.1857, Test Loss: 0.2107\n",
      "Epoch 17/2000, Train Loss: 0.1848, Test Loss: 0.2140\n",
      "Epoch 18/2000, Train Loss: 0.1801, Test Loss: 0.2069\n",
      "Epoch 19/2000, Train Loss: 0.1779, Test Loss: 0.2069\n",
      "Epoch 20/2000, Train Loss: 0.1771, Test Loss: 0.2148\n",
      "Epoch 21/2000, Train Loss: 0.1752, Test Loss: 0.2150\n",
      "Epoch 22/2000, Train Loss: 0.1738, Test Loss: 0.2085\n",
      "Epoch 23/2000, Train Loss: 0.1717, Test Loss: 0.2082\n",
      "Epoch 24/2000, Train Loss: 0.1699, Test Loss: 0.2051\n",
      "Epoch 25/2000, Train Loss: 0.1693, Test Loss: 0.2053\n",
      "Epoch 26/2000, Train Loss: 0.1684, Test Loss: 0.2086\n",
      "Epoch 27/2000, Train Loss: 0.1659, Test Loss: 0.2053\n",
      "Epoch 28/2000, Train Loss: 0.1651, Test Loss: 0.1975\n",
      "Epoch 29/2000, Train Loss: 0.1631, Test Loss: 0.2034\n",
      "Epoch 30/2000, Train Loss: 0.1624, Test Loss: 0.2044\n",
      "Epoch 31/2000, Train Loss: 0.1617, Test Loss: 0.1993\n",
      "Epoch 32/2000, Train Loss: 0.1593, Test Loss: 0.1962\n",
      "Epoch 33/2000, Train Loss: 0.1606, Test Loss: 0.1988\n",
      "Epoch 34/2000, Train Loss: 0.1591, Test Loss: 0.2015\n",
      "Epoch 35/2000, Train Loss: 0.1573, Test Loss: 0.2023\n",
      "Epoch 36/2000, Train Loss: 0.1554, Test Loss: 0.1964\n",
      "Epoch 37/2000, Train Loss: 0.1555, Test Loss: 0.1993\n",
      "Epoch 38/2000, Train Loss: 0.1540, Test Loss: 0.2023\n",
      "Epoch 39/2000, Train Loss: 0.1546, Test Loss: 0.1989\n",
      "Epoch 40/2000, Train Loss: 0.1530, Test Loss: 0.1983\n",
      "Epoch 41/2000, Train Loss: 0.1516, Test Loss: 0.2019\n",
      "Epoch 42/2000, Train Loss: 0.1527, Test Loss: 0.1974\n",
      "Epoch 43/2000, Train Loss: 0.1524, Test Loss: 0.1970\n",
      "Epoch 44/2000, Train Loss: 0.1494, Test Loss: 0.1977\n",
      "Epoch 45/2000, Train Loss: 0.1505, Test Loss: 0.1999\n",
      "Epoch 46/2000, Train Loss: 0.1484, Test Loss: 0.1966\n",
      "Epoch 47/2000, Train Loss: 0.1484, Test Loss: 0.2027\n",
      "Epoch 48/2000, Train Loss: 0.1478, Test Loss: 0.1961\n",
      "Epoch 49/2000, Train Loss: 0.1466, Test Loss: 0.1971\n",
      "Epoch 50/2000, Train Loss: 0.1453, Test Loss: 0.2010\n",
      "Epoch 51/2000, Train Loss: 0.1453, Test Loss: 0.2002\n",
      "Epoch 52/2000, Train Loss: 0.1462, Test Loss: 0.1942\n",
      "Epoch 53/2000, Train Loss: 0.1449, Test Loss: 0.1963\n",
      "Epoch 54/2000, Train Loss: 0.1440, Test Loss: 0.1948\n",
      "Epoch 55/2000, Train Loss: 0.1424, Test Loss: 0.1961\n",
      "Epoch 56/2000, Train Loss: 0.1422, Test Loss: 0.1925\n",
      "Epoch 57/2000, Train Loss: 0.1428, Test Loss: 0.1976\n",
      "Epoch 58/2000, Train Loss: 0.1417, Test Loss: 0.1972\n",
      "Epoch 59/2000, Train Loss: 0.1412, Test Loss: 0.1959\n",
      "Epoch 60/2000, Train Loss: 0.1416, Test Loss: 0.1928\n",
      "Epoch 61/2000, Train Loss: 0.1396, Test Loss: 0.1947\n",
      "Epoch 62/2000, Train Loss: 0.1396, Test Loss: 0.1963\n",
      "Epoch 63/2000, Train Loss: 0.1389, Test Loss: 0.2015\n",
      "Epoch 64/2000, Train Loss: 0.1395, Test Loss: 0.1952\n",
      "Epoch 65/2000, Train Loss: 0.1379, Test Loss: 0.1977\n",
      "Epoch 66/2000, Train Loss: 0.1377, Test Loss: 0.1947\n",
      "Epoch 67/2000, Train Loss: 0.1380, Test Loss: 0.1980\n",
      "Epoch 68/2000, Train Loss: 0.1370, Test Loss: 0.1982\n",
      "Epoch 69/2000, Train Loss: 0.1369, Test Loss: 0.2104\n",
      "Epoch 70/2000, Train Loss: 0.1367, Test Loss: 0.1926\n",
      "Epoch 71/2000, Train Loss: 0.1366, Test Loss: 0.2003\n",
      "Epoch 72/2000, Train Loss: 0.1354, Test Loss: 0.1981\n",
      "Epoch 73/2000, Train Loss: 0.1348, Test Loss: 0.1954\n",
      "Epoch 74/2000, Train Loss: 0.1349, Test Loss: 0.1943\n",
      "Epoch 75/2000, Train Loss: 0.1331, Test Loss: 0.1965\n",
      "Epoch 76/2000, Train Loss: 0.1348, Test Loss: 0.1959\n",
      "Epoch 77/2000, Train Loss: 0.1342, Test Loss: 0.1944\n",
      "Epoch 78/2000, Train Loss: 0.1325, Test Loss: 0.1960\n",
      "Epoch 79/2000, Train Loss: 0.1332, Test Loss: 0.1943\n",
      "Epoch 80/2000, Train Loss: 0.1321, Test Loss: 0.1949\n",
      "Epoch 81/2000, Train Loss: 0.1323, Test Loss: 0.1967\n",
      "Epoch 82/2000, Train Loss: 0.1306, Test Loss: 0.1969\n",
      "Epoch 83/2000, Train Loss: 0.1308, Test Loss: 0.1961\n",
      "Epoch 84/2000, Train Loss: 0.1303, Test Loss: 0.1935\n",
      "Epoch 85/2000, Train Loss: 0.1303, Test Loss: 0.1966\n",
      "Epoch 86/2000, Train Loss: 0.1304, Test Loss: 0.1947\n",
      "Epoch 87/2000, Train Loss: 0.1297, Test Loss: 0.1986\n",
      "Epoch 88/2000, Train Loss: 0.1298, Test Loss: 0.1983\n",
      "Epoch 89/2000, Train Loss: 0.1299, Test Loss: 0.1909\n",
      "Epoch 90/2000, Train Loss: 0.1289, Test Loss: 0.1936\n",
      "Epoch 91/2000, Train Loss: 0.1278, Test Loss: 0.1958\n",
      "Epoch 92/2000, Train Loss: 0.1292, Test Loss: 0.1959\n",
      "Epoch 93/2000, Train Loss: 0.1280, Test Loss: 0.1955\n",
      "Epoch 94/2000, Train Loss: 0.1273, Test Loss: 0.1995\n",
      "Epoch 95/2000, Train Loss: 0.1289, Test Loss: 0.1938\n",
      "Epoch 96/2000, Train Loss: 0.1268, Test Loss: 0.1978\n",
      "Epoch 97/2000, Train Loss: 0.1268, Test Loss: 0.1972\n",
      "Epoch 98/2000, Train Loss: 0.1266, Test Loss: 0.1918\n",
      "Epoch 99/2000, Train Loss: 0.1262, Test Loss: 0.1945\n",
      "Epoch 100/2000, Train Loss: 0.1252, Test Loss: 0.1950\n",
      "Epoch 101/2000, Train Loss: 0.1257, Test Loss: 0.1950\n",
      "Epoch 102/2000, Train Loss: 0.1256, Test Loss: 0.1983\n",
      "Epoch 103/2000, Train Loss: 0.1260, Test Loss: 0.1977\n",
      "Epoch 104/2000, Train Loss: 0.1251, Test Loss: 0.1946\n",
      "Epoch 105/2000, Train Loss: 0.1242, Test Loss: 0.1915\n",
      "Epoch 106/2000, Train Loss: 0.1246, Test Loss: 0.1928\n",
      "Epoch 107/2000, Train Loss: 0.1234, Test Loss: 0.1921\n",
      "Epoch 108/2000, Train Loss: 0.1243, Test Loss: 0.2013\n",
      "Epoch 109/2000, Train Loss: 0.1236, Test Loss: 0.2018\n",
      "Epoch 110/2000, Train Loss: 0.1237, Test Loss: 0.2015\n",
      "Epoch 111/2000, Train Loss: 0.1236, Test Loss: 0.1945\n",
      "Epoch 112/2000, Train Loss: 0.1228, Test Loss: 0.1959\n",
      "Epoch 113/2000, Train Loss: 0.1228, Test Loss: 0.1974\n",
      "Epoch 114/2000, Train Loss: 0.1226, Test Loss: 0.1987\n",
      "Epoch 115/2000, Train Loss: 0.1220, Test Loss: 0.1950\n",
      "Epoch 116/2000, Train Loss: 0.1213, Test Loss: 0.1947\n",
      "Epoch 117/2000, Train Loss: 0.1215, Test Loss: 0.1933\n",
      "Epoch 118/2000, Train Loss: 0.1211, Test Loss: 0.1943\n",
      "Epoch 119/2000, Train Loss: 0.1210, Test Loss: 0.1952\n",
      "Epoch 120/2000, Train Loss: 0.1218, Test Loss: 0.1976\n",
      "Epoch 121/2000, Train Loss: 0.1205, Test Loss: 0.1948\n",
      "Epoch 122/2000, Train Loss: 0.1200, Test Loss: 0.1945\n",
      "Epoch 123/2000, Train Loss: 0.1209, Test Loss: 0.1943\n",
      "Epoch 124/2000, Train Loss: 0.1194, Test Loss: 0.1922\n",
      "Epoch 125/2000, Train Loss: 0.1202, Test Loss: 0.1925\n",
      "Epoch 126/2000, Train Loss: 0.1195, Test Loss: 0.1967\n",
      "Epoch 127/2000, Train Loss: 0.1202, Test Loss: 0.2007\n",
      "Epoch 128/2000, Train Loss: 0.1186, Test Loss: 0.1926\n",
      "Epoch 129/2000, Train Loss: 0.1183, Test Loss: 0.1993\n",
      "Epoch 130/2000, Train Loss: 0.1188, Test Loss: 0.1970\n",
      "Epoch 131/2000, Train Loss: 0.1190, Test Loss: 0.1927\n",
      "Epoch 132/2000, Train Loss: 0.1178, Test Loss: 0.1996\n",
      "Epoch 133/2000, Train Loss: 0.1181, Test Loss: 0.1962\n",
      "Epoch 134/2000, Train Loss: 0.1184, Test Loss: 0.1955\n",
      "Epoch 135/2000, Train Loss: 0.1175, Test Loss: 0.1959\n",
      "Epoch 136/2000, Train Loss: 0.1192, Test Loss: 0.1985\n",
      "Epoch 137/2000, Train Loss: 0.1172, Test Loss: 0.1969\n",
      "Epoch 138/2000, Train Loss: 0.1175, Test Loss: 0.1966\n",
      "Epoch 139/2000, Train Loss: 0.1177, Test Loss: 0.1943\n",
      "Epoch 140/2000, Train Loss: 0.1172, Test Loss: 0.1992\n",
      "Epoch 141/2000, Train Loss: 0.1170, Test Loss: 0.2031\n",
      "Epoch 142/2000, Train Loss: 0.1165, Test Loss: 0.1963\n",
      "Epoch 143/2000, Train Loss: 0.1164, Test Loss: 0.1983\n",
      "Epoch 144/2000, Train Loss: 0.1164, Test Loss: 0.1988\n",
      "Epoch 145/2000, Train Loss: 0.1165, Test Loss: 0.2020\n",
      "Epoch 146/2000, Train Loss: 0.1150, Test Loss: 0.1962\n",
      "Epoch 147/2000, Train Loss: 0.1154, Test Loss: 0.1955\n",
      "Epoch 148/2000, Train Loss: 0.1158, Test Loss: 0.1959\n",
      "Epoch 149/2000, Train Loss: 0.1151, Test Loss: 0.1950\n",
      "Epoch 150/2000, Train Loss: 0.1157, Test Loss: 0.1943\n",
      "Epoch 151/2000, Train Loss: 0.1158, Test Loss: 0.1985\n",
      "Epoch 152/2000, Train Loss: 0.1153, Test Loss: 0.2006\n",
      "Epoch 153/2000, Train Loss: 0.1152, Test Loss: 0.1984\n",
      "Epoch 154/2000, Train Loss: 0.1150, Test Loss: 0.1966\n",
      "Epoch 155/2000, Train Loss: 0.1143, Test Loss: 0.2010\n",
      "Epoch 156/2000, Train Loss: 0.1144, Test Loss: 0.1964\n",
      "Epoch 157/2000, Train Loss: 0.1137, Test Loss: 0.1984\n",
      "Epoch 158/2000, Train Loss: 0.1134, Test Loss: 0.1985\n",
      "Epoch 159/2000, Train Loss: 0.1135, Test Loss: 0.1968\n",
      "Epoch 160/2000, Train Loss: 0.1133, Test Loss: 0.2010\n",
      "Epoch 161/2000, Train Loss: 0.1130, Test Loss: 0.2045\n",
      "Epoch 162/2000, Train Loss: 0.1133, Test Loss: 0.2023\n",
      "Epoch 163/2000, Train Loss: 0.1131, Test Loss: 0.1991\n",
      "Epoch 164/2000, Train Loss: 0.1129, Test Loss: 0.1980\n",
      "Epoch 165/2000, Train Loss: 0.1124, Test Loss: 0.1974\n",
      "Epoch 166/2000, Train Loss: 0.1131, Test Loss: 0.1978\n",
      "Epoch 167/2000, Train Loss: 0.1133, Test Loss: 0.1969\n",
      "Epoch 168/2000, Train Loss: 0.1125, Test Loss: 0.1991\n",
      "Epoch 169/2000, Train Loss: 0.1118, Test Loss: 0.2017\n",
      "Epoch 170/2000, Train Loss: 0.1129, Test Loss: 0.2002\n",
      "Epoch 171/2000, Train Loss: 0.1123, Test Loss: 0.2009\n",
      "Epoch 172/2000, Train Loss: 0.1118, Test Loss: 0.2005\n",
      "Epoch 173/2000, Train Loss: 0.1126, Test Loss: 0.2014\n",
      "Epoch 174/2000, Train Loss: 0.1115, Test Loss: 0.1967\n",
      "Epoch 175/2000, Train Loss: 0.1118, Test Loss: 0.1976\n",
      "Epoch 176/2000, Train Loss: 0.1111, Test Loss: 0.2023\n",
      "Epoch 177/2000, Train Loss: 0.1106, Test Loss: 0.2091\n",
      "Epoch 178/2000, Train Loss: 0.1116, Test Loss: 0.2002\n",
      "Epoch 179/2000, Train Loss: 0.1111, Test Loss: 0.2079\n",
      "Epoch 180/2000, Train Loss: 0.1114, Test Loss: 0.1961\n",
      "Epoch 181/2000, Train Loss: 0.1108, Test Loss: 0.1997\n",
      "Epoch 182/2000, Train Loss: 0.1103, Test Loss: 0.1958\n",
      "Epoch 183/2000, Train Loss: 0.1101, Test Loss: 0.1964\n",
      "Epoch 184/2000, Train Loss: 0.1100, Test Loss: 0.2011\n",
      "Epoch 185/2000, Train Loss: 0.1101, Test Loss: 0.1991\n",
      "Epoch 186/2000, Train Loss: 0.1100, Test Loss: 0.1996\n",
      "Epoch 187/2000, Train Loss: 0.1095, Test Loss: 0.2029\n",
      "Epoch 188/2000, Train Loss: 0.1098, Test Loss: 0.2024\n",
      "Epoch 189/2000, Train Loss: 0.1096, Test Loss: 0.2000\n",
      "Epoch 190/2000, Train Loss: 0.1098, Test Loss: 0.1984\n",
      "Epoch 191/2000, Train Loss: 0.1097, Test Loss: 0.2069\n",
      "Epoch 192/2000, Train Loss: 0.1096, Test Loss: 0.2018\n",
      "Epoch 193/2000, Train Loss: 0.1096, Test Loss: 0.2045\n",
      "Epoch 194/2000, Train Loss: 0.1087, Test Loss: 0.1999\n",
      "Epoch 195/2000, Train Loss: 0.1093, Test Loss: 0.1985\n",
      "Epoch 196/2000, Train Loss: 0.1083, Test Loss: 0.2138\n",
      "Epoch 197/2000, Train Loss: 0.1091, Test Loss: 0.2074\n",
      "Epoch 198/2000, Train Loss: 0.1088, Test Loss: 0.1984\n",
      "Epoch 199/2000, Train Loss: 0.1083, Test Loss: 0.2024\n",
      "Epoch 200/2000, Train Loss: 0.1082, Test Loss: 0.1994\n",
      "Epoch 201/2000, Train Loss: 0.1088, Test Loss: 0.1981\n",
      "Epoch 202/2000, Train Loss: 0.1078, Test Loss: 0.2003\n",
      "Epoch 203/2000, Train Loss: 0.1077, Test Loss: 0.2035\n",
      "Epoch 204/2000, Train Loss: 0.1080, Test Loss: 0.1984\n",
      "Epoch 205/2000, Train Loss: 0.1077, Test Loss: 0.2043\n",
      "Epoch 206/2000, Train Loss: 0.1079, Test Loss: 0.2025\n",
      "Epoch 207/2000, Train Loss: 0.1078, Test Loss: 0.2090\n",
      "Epoch 208/2000, Train Loss: 0.1078, Test Loss: 0.2012\n",
      "Epoch 209/2000, Train Loss: 0.1072, Test Loss: 0.2026\n",
      "Epoch 210/2000, Train Loss: 0.1072, Test Loss: 0.2035\n",
      "Epoch 211/2000, Train Loss: 0.1078, Test Loss: 0.2083\n",
      "Epoch 212/2000, Train Loss: 0.1073, Test Loss: 0.2047\n",
      "Epoch 213/2000, Train Loss: 0.1068, Test Loss: 0.2007\n",
      "Epoch 214/2000, Train Loss: 0.1067, Test Loss: 0.2033\n",
      "Epoch 215/2000, Train Loss: 0.1066, Test Loss: 0.2002\n",
      "Epoch 216/2000, Train Loss: 0.1076, Test Loss: 0.2025\n",
      "Epoch 217/2000, Train Loss: 0.1062, Test Loss: 0.2022\n",
      "Epoch 218/2000, Train Loss: 0.1064, Test Loss: 0.2040\n",
      "Epoch 219/2000, Train Loss: 0.1068, Test Loss: 0.2017\n",
      "Epoch 220/2000, Train Loss: 0.1066, Test Loss: 0.2085\n",
      "Epoch 221/2000, Train Loss: 0.1065, Test Loss: 0.2042\n",
      "Epoch 222/2000, Train Loss: 0.1067, Test Loss: 0.2017\n",
      "Epoch 223/2000, Train Loss: 0.1066, Test Loss: 0.2051\n",
      "Epoch 224/2000, Train Loss: 0.1051, Test Loss: 0.2050\n",
      "Epoch 225/2000, Train Loss: 0.1058, Test Loss: 0.2085\n",
      "Epoch 226/2000, Train Loss: 0.1070, Test Loss: 0.2049\n",
      "Epoch 227/2000, Train Loss: 0.1054, Test Loss: 0.2019\n",
      "Epoch 228/2000, Train Loss: 0.1057, Test Loss: 0.2004\n",
      "Epoch 229/2000, Train Loss: 0.1055, Test Loss: 0.2038\n",
      "Epoch 230/2000, Train Loss: 0.1050, Test Loss: 0.2020\n",
      "Epoch 231/2000, Train Loss: 0.1056, Test Loss: 0.2039\n",
      "Epoch 232/2000, Train Loss: 0.1054, Test Loss: 0.2047\n",
      "Epoch 233/2000, Train Loss: 0.1044, Test Loss: 0.2026\n",
      "Epoch 234/2000, Train Loss: 0.1053, Test Loss: 0.2058\n",
      "Epoch 235/2000, Train Loss: 0.1052, Test Loss: 0.2058\n",
      "Epoch 236/2000, Train Loss: 0.1048, Test Loss: 0.2035\n",
      "Epoch 237/2000, Train Loss: 0.1043, Test Loss: 0.2039\n",
      "Epoch 238/2000, Train Loss: 0.1039, Test Loss: 0.2024\n",
      "Epoch 239/2000, Train Loss: 0.1045, Test Loss: 0.2025\n",
      "Epoch 240/2000, Train Loss: 0.1037, Test Loss: 0.2043\n",
      "Epoch 241/2000, Train Loss: 0.1050, Test Loss: 0.2039\n",
      "Epoch 242/2000, Train Loss: 0.1046, Test Loss: 0.2095\n",
      "Epoch 243/2000, Train Loss: 0.1045, Test Loss: 0.2039\n",
      "Epoch 244/2000, Train Loss: 0.1040, Test Loss: 0.2039\n",
      "Epoch 245/2000, Train Loss: 0.1031, Test Loss: 0.2034\n",
      "Epoch 246/2000, Train Loss: 0.1038, Test Loss: 0.2010\n",
      "Epoch 247/2000, Train Loss: 0.1036, Test Loss: 0.2086\n",
      "Epoch 248/2000, Train Loss: 0.1044, Test Loss: 0.2061\n",
      "Epoch 249/2000, Train Loss: 0.1043, Test Loss: 0.2035\n",
      "Epoch 250/2000, Train Loss: 0.1037, Test Loss: 0.2094\n",
      "Epoch 251/2000, Train Loss: 0.1039, Test Loss: 0.2097\n",
      "Epoch 252/2000, Train Loss: 0.1035, Test Loss: 0.2020\n",
      "Epoch 253/2000, Train Loss: 0.1034, Test Loss: 0.2052\n",
      "Epoch 254/2000, Train Loss: 0.1034, Test Loss: 0.2062\n",
      "Epoch 255/2000, Train Loss: 0.1030, Test Loss: 0.2061\n",
      "Epoch 256/2000, Train Loss: 0.1030, Test Loss: 0.2057\n",
      "Epoch 257/2000, Train Loss: 0.1032, Test Loss: 0.2077\n",
      "Epoch 258/2000, Train Loss: 0.1032, Test Loss: 0.2036\n",
      "Epoch 259/2000, Train Loss: 0.1031, Test Loss: 0.2133\n",
      "Epoch 260/2000, Train Loss: 0.1027, Test Loss: 0.2099\n",
      "Epoch 261/2000, Train Loss: 0.1024, Test Loss: 0.2115\n",
      "Epoch 262/2000, Train Loss: 0.1026, Test Loss: 0.2077\n",
      "Epoch 263/2000, Train Loss: 0.1021, Test Loss: 0.2062\n",
      "Epoch 264/2000, Train Loss: 0.1020, Test Loss: 0.2065\n",
      "Epoch 265/2000, Train Loss: 0.1023, Test Loss: 0.2059\n",
      "Epoch 266/2000, Train Loss: 0.1019, Test Loss: 0.2205\n",
      "Epoch 267/2000, Train Loss: 0.1017, Test Loss: 0.2050\n",
      "Epoch 268/2000, Train Loss: 0.1023, Test Loss: 0.2052\n",
      "Epoch 269/2000, Train Loss: 0.1023, Test Loss: 0.2072\n",
      "Epoch 270/2000, Train Loss: 0.1019, Test Loss: 0.2068\n",
      "Epoch 271/2000, Train Loss: 0.1015, Test Loss: 0.2052\n",
      "Epoch 272/2000, Train Loss: 0.1013, Test Loss: 0.2078\n",
      "Epoch 273/2000, Train Loss: 0.1015, Test Loss: 0.2053\n",
      "Epoch 274/2000, Train Loss: 0.1009, Test Loss: 0.2050\n",
      "Epoch 275/2000, Train Loss: 0.1020, Test Loss: 0.2050\n",
      "Epoch 276/2000, Train Loss: 0.1011, Test Loss: 0.2059\n",
      "Epoch 277/2000, Train Loss: 0.1020, Test Loss: 0.2075\n",
      "Epoch 278/2000, Train Loss: 0.1008, Test Loss: 0.2074\n",
      "Epoch 279/2000, Train Loss: 0.1015, Test Loss: 0.2079\n",
      "Epoch 280/2000, Train Loss: 0.1011, Test Loss: 0.2079\n",
      "Epoch 281/2000, Train Loss: 0.1020, Test Loss: 0.2064\n",
      "Epoch 282/2000, Train Loss: 0.1008, Test Loss: 0.2093\n",
      "Epoch 283/2000, Train Loss: 0.1020, Test Loss: 0.2073\n",
      "Epoch 284/2000, Train Loss: 0.1015, Test Loss: 0.2074\n",
      "Epoch 285/2000, Train Loss: 0.1002, Test Loss: 0.2055\n",
      "Epoch 286/2000, Train Loss: 0.1007, Test Loss: 0.2052\n",
      "Epoch 287/2000, Train Loss: 0.1004, Test Loss: 0.2101\n",
      "Epoch 288/2000, Train Loss: 0.1003, Test Loss: 0.2062\n",
      "Epoch 289/2000, Train Loss: 0.0998, Test Loss: 0.2047\n",
      "Epoch 290/2000, Train Loss: 0.1001, Test Loss: 0.2137\n",
      "Epoch 291/2000, Train Loss: 0.0998, Test Loss: 0.2075\n",
      "Epoch 292/2000, Train Loss: 0.0999, Test Loss: 0.2080\n",
      "Epoch 293/2000, Train Loss: 0.1003, Test Loss: 0.2088\n",
      "Epoch 294/2000, Train Loss: 0.0998, Test Loss: 0.2122\n",
      "Epoch 295/2000, Train Loss: 0.0998, Test Loss: 0.2078\n",
      "Epoch 296/2000, Train Loss: 0.0997, Test Loss: 0.2093\n",
      "Epoch 297/2000, Train Loss: 0.0994, Test Loss: 0.2064\n",
      "Epoch 298/2000, Train Loss: 0.1000, Test Loss: 0.2070\n",
      "Epoch 299/2000, Train Loss: 0.1000, Test Loss: 0.2087\n",
      "Epoch 300/2000, Train Loss: 0.0996, Test Loss: 0.2179\n",
      "Epoch 301/2000, Train Loss: 0.0992, Test Loss: 0.2083\n",
      "Epoch 302/2000, Train Loss: 0.0997, Test Loss: 0.2069\n",
      "Epoch 303/2000, Train Loss: 0.0993, Test Loss: 0.2079\n",
      "Epoch 304/2000, Train Loss: 0.0995, Test Loss: 0.2130\n",
      "Epoch 305/2000, Train Loss: 0.0989, Test Loss: 0.2095\n",
      "Epoch 306/2000, Train Loss: 0.0985, Test Loss: 0.2101\n",
      "Epoch 307/2000, Train Loss: 0.0990, Test Loss: 0.2094\n",
      "Epoch 308/2000, Train Loss: 0.0992, Test Loss: 0.2084\n",
      "Epoch 309/2000, Train Loss: 0.0987, Test Loss: 0.2117\n",
      "Epoch 310/2000, Train Loss: 0.0989, Test Loss: 0.2088\n",
      "Epoch 311/2000, Train Loss: 0.0987, Test Loss: 0.2081\n",
      "Epoch 312/2000, Train Loss: 0.0984, Test Loss: 0.2126\n",
      "Epoch 313/2000, Train Loss: 0.0986, Test Loss: 0.2139\n",
      "Epoch 314/2000, Train Loss: 0.0993, Test Loss: 0.2159\n",
      "Epoch 315/2000, Train Loss: 0.0984, Test Loss: 0.2160\n",
      "Epoch 316/2000, Train Loss: 0.0986, Test Loss: 0.2116\n",
      "Epoch 317/2000, Train Loss: 0.0986, Test Loss: 0.2104\n",
      "Epoch 318/2000, Train Loss: 0.0987, Test Loss: 0.2075\n",
      "Epoch 319/2000, Train Loss: 0.0984, Test Loss: 0.2097\n",
      "Epoch 320/2000, Train Loss: 0.0982, Test Loss: 0.2107\n",
      "Epoch 321/2000, Train Loss: 0.0980, Test Loss: 0.2088\n",
      "Epoch 322/2000, Train Loss: 0.0992, Test Loss: 0.2105\n",
      "Epoch 323/2000, Train Loss: 0.0979, Test Loss: 0.2115\n",
      "Epoch 324/2000, Train Loss: 0.0981, Test Loss: 0.2111\n",
      "Epoch 325/2000, Train Loss: 0.0980, Test Loss: 0.2097\n",
      "Epoch 326/2000, Train Loss: 0.0978, Test Loss: 0.2104\n",
      "Epoch 327/2000, Train Loss: 0.0985, Test Loss: 0.2101\n",
      "Epoch 328/2000, Train Loss: 0.0988, Test Loss: 0.2170\n",
      "Epoch 329/2000, Train Loss: 0.0974, Test Loss: 0.2097\n",
      "Epoch 330/2000, Train Loss: 0.0974, Test Loss: 0.2116\n",
      "Epoch 331/2000, Train Loss: 0.0974, Test Loss: 0.2101\n",
      "Epoch 332/2000, Train Loss: 0.0969, Test Loss: 0.2124\n",
      "Epoch 333/2000, Train Loss: 0.0978, Test Loss: 0.2127\n",
      "Epoch 334/2000, Train Loss: 0.0978, Test Loss: 0.2104\n",
      "Epoch 335/2000, Train Loss: 0.0971, Test Loss: 0.2117\n",
      "Epoch 336/2000, Train Loss: 0.0973, Test Loss: 0.2132\n",
      "Epoch 337/2000, Train Loss: 0.0971, Test Loss: 0.2090\n",
      "Epoch 338/2000, Train Loss: 0.0968, Test Loss: 0.2127\n",
      "Epoch 339/2000, Train Loss: 0.0965, Test Loss: 0.2128\n",
      "Epoch 340/2000, Train Loss: 0.0972, Test Loss: 0.2127\n",
      "Epoch 341/2000, Train Loss: 0.0966, Test Loss: 0.2144\n",
      "Epoch 342/2000, Train Loss: 0.0970, Test Loss: 0.2116\n",
      "Epoch 343/2000, Train Loss: 0.0962, Test Loss: 0.2128\n",
      "Epoch 344/2000, Train Loss: 0.0963, Test Loss: 0.2194\n",
      "Epoch 345/2000, Train Loss: 0.0964, Test Loss: 0.2138\n",
      "Epoch 346/2000, Train Loss: 0.0966, Test Loss: 0.2106\n",
      "Epoch 347/2000, Train Loss: 0.0967, Test Loss: 0.2143\n",
      "Epoch 348/2000, Train Loss: 0.0968, Test Loss: 0.2127\n",
      "Epoch 349/2000, Train Loss: 0.0963, Test Loss: 0.2150\n",
      "Epoch 350/2000, Train Loss: 0.0962, Test Loss: 0.2293\n",
      "Epoch 351/2000, Train Loss: 0.0966, Test Loss: 0.2168\n",
      "Epoch 352/2000, Train Loss: 0.0967, Test Loss: 0.2207\n",
      "Epoch 353/2000, Train Loss: 0.0962, Test Loss: 0.2220\n",
      "Epoch 354/2000, Train Loss: 0.0961, Test Loss: 0.2140\n",
      "Epoch 355/2000, Train Loss: 0.0960, Test Loss: 0.2105\n",
      "Epoch 356/2000, Train Loss: 0.0969, Test Loss: 0.2108\n",
      "Epoch 357/2000, Train Loss: 0.0956, Test Loss: 0.2125\n",
      "Epoch 358/2000, Train Loss: 0.0952, Test Loss: 0.2113\n",
      "Epoch 359/2000, Train Loss: 0.0955, Test Loss: 0.2188\n",
      "Epoch 360/2000, Train Loss: 0.0954, Test Loss: 0.2123\n",
      "Epoch 361/2000, Train Loss: 0.0952, Test Loss: 0.2118\n",
      "Epoch 362/2000, Train Loss: 0.0961, Test Loss: 0.2128\n",
      "Epoch 363/2000, Train Loss: 0.0959, Test Loss: 0.2122\n",
      "Epoch 364/2000, Train Loss: 0.0954, Test Loss: 0.2121\n",
      "Epoch 365/2000, Train Loss: 0.0950, Test Loss: 0.2157\n",
      "Epoch 366/2000, Train Loss: 0.0950, Test Loss: 0.2124\n",
      "Epoch 367/2000, Train Loss: 0.0951, Test Loss: 0.2143\n",
      "Epoch 368/2000, Train Loss: 0.0955, Test Loss: 0.2156\n",
      "Epoch 369/2000, Train Loss: 0.0954, Test Loss: 0.2143\n",
      "Epoch 370/2000, Train Loss: 0.0952, Test Loss: 0.2118\n",
      "Epoch 371/2000, Train Loss: 0.0952, Test Loss: 0.2124\n",
      "Epoch 372/2000, Train Loss: 0.0950, Test Loss: 0.2147\n",
      "Epoch 373/2000, Train Loss: 0.0946, Test Loss: 0.2129\n",
      "Epoch 374/2000, Train Loss: 0.0949, Test Loss: 0.2256\n",
      "Epoch 375/2000, Train Loss: 0.0946, Test Loss: 0.2134\n",
      "Epoch 376/2000, Train Loss: 0.0947, Test Loss: 0.2171\n",
      "Epoch 377/2000, Train Loss: 0.0950, Test Loss: 0.2123\n",
      "Epoch 378/2000, Train Loss: 0.0942, Test Loss: 0.2168\n",
      "Epoch 379/2000, Train Loss: 0.0941, Test Loss: 0.2153\n",
      "Epoch 380/2000, Train Loss: 0.0942, Test Loss: 0.2165\n",
      "Epoch 381/2000, Train Loss: 0.0944, Test Loss: 0.2183\n",
      "Epoch 382/2000, Train Loss: 0.0939, Test Loss: 0.2136\n",
      "Epoch 383/2000, Train Loss: 0.0942, Test Loss: 0.2145\n",
      "Epoch 384/2000, Train Loss: 0.0943, Test Loss: 0.2134\n",
      "Epoch 385/2000, Train Loss: 0.0940, Test Loss: 0.2160\n",
      "Epoch 386/2000, Train Loss: 0.0945, Test Loss: 0.2168\n",
      "Epoch 387/2000, Train Loss: 0.0944, Test Loss: 0.2152\n",
      "Epoch 388/2000, Train Loss: 0.0939, Test Loss: 0.2136\n",
      "Epoch 389/2000, Train Loss: 0.0943, Test Loss: 0.2139\n",
      "Epoch 390/2000, Train Loss: 0.0939, Test Loss: 0.2137\n",
      "Epoch 391/2000, Train Loss: 0.0938, Test Loss: 0.2156\n",
      "Epoch 392/2000, Train Loss: 0.0949, Test Loss: 0.2158\n",
      "Epoch 393/2000, Train Loss: 0.0940, Test Loss: 0.2161\n",
      "Epoch 394/2000, Train Loss: 0.0940, Test Loss: 0.2142\n",
      "Epoch 395/2000, Train Loss: 0.0944, Test Loss: 0.2151\n",
      "Epoch 396/2000, Train Loss: 0.0939, Test Loss: 0.2208\n",
      "Epoch 397/2000, Train Loss: 0.0940, Test Loss: 0.2166\n",
      "Epoch 398/2000, Train Loss: 0.0935, Test Loss: 0.2162\n",
      "Epoch 399/2000, Train Loss: 0.0934, Test Loss: 0.2158\n",
      "Epoch 400/2000, Train Loss: 0.0934, Test Loss: 0.2144\n",
      "Epoch 401/2000, Train Loss: 0.0928, Test Loss: 0.2181\n",
      "Epoch 402/2000, Train Loss: 0.0939, Test Loss: 0.2175\n",
      "Epoch 403/2000, Train Loss: 0.0933, Test Loss: 0.2158\n",
      "Epoch 404/2000, Train Loss: 0.0930, Test Loss: 0.2173\n",
      "Epoch 405/2000, Train Loss: 0.0927, Test Loss: 0.2165\n",
      "Epoch 406/2000, Train Loss: 0.0931, Test Loss: 0.2156\n",
      "Epoch 407/2000, Train Loss: 0.0932, Test Loss: 0.2161\n",
      "Epoch 408/2000, Train Loss: 0.0924, Test Loss: 0.2243\n",
      "Epoch 409/2000, Train Loss: 0.0927, Test Loss: 0.2186\n",
      "Epoch 410/2000, Train Loss: 0.0927, Test Loss: 0.2163\n",
      "Epoch 411/2000, Train Loss: 0.0931, Test Loss: 0.2217\n",
      "Epoch 412/2000, Train Loss: 0.0932, Test Loss: 0.2160\n",
      "Epoch 413/2000, Train Loss: 0.0925, Test Loss: 0.2154\n",
      "Epoch 414/2000, Train Loss: 0.0929, Test Loss: 0.2165\n",
      "Epoch 415/2000, Train Loss: 0.0927, Test Loss: 0.2167\n",
      "Epoch 416/2000, Train Loss: 0.0923, Test Loss: 0.2167\n",
      "Epoch 417/2000, Train Loss: 0.0925, Test Loss: 0.2197\n",
      "Epoch 418/2000, Train Loss: 0.0923, Test Loss: 0.2206\n",
      "Epoch 419/2000, Train Loss: 0.0923, Test Loss: 0.2182\n",
      "Epoch 420/2000, Train Loss: 0.0926, Test Loss: 0.2182\n",
      "Epoch 421/2000, Train Loss: 0.0926, Test Loss: 0.2166\n",
      "Epoch 422/2000, Train Loss: 0.0921, Test Loss: 0.2180\n",
      "Epoch 423/2000, Train Loss: 0.0922, Test Loss: 0.2210\n",
      "Epoch 424/2000, Train Loss: 0.0924, Test Loss: 0.2174\n",
      "Epoch 425/2000, Train Loss: 0.0924, Test Loss: 0.2175\n",
      "Epoch 426/2000, Train Loss: 0.0922, Test Loss: 0.2187\n",
      "Epoch 427/2000, Train Loss: 0.0922, Test Loss: 0.2172\n",
      "Epoch 428/2000, Train Loss: 0.0917, Test Loss: 0.2173\n",
      "Epoch 429/2000, Train Loss: 0.0918, Test Loss: 0.2166\n",
      "Epoch 430/2000, Train Loss: 0.0925, Test Loss: 0.2167\n",
      "Epoch 431/2000, Train Loss: 0.0919, Test Loss: 0.2167\n",
      "Epoch 432/2000, Train Loss: 0.0919, Test Loss: 0.2172\n",
      "Epoch 433/2000, Train Loss: 0.0917, Test Loss: 0.2193\n",
      "Epoch 434/2000, Train Loss: 0.0915, Test Loss: 0.2223\n",
      "Epoch 435/2000, Train Loss: 0.0918, Test Loss: 0.2162\n",
      "Epoch 436/2000, Train Loss: 0.0908, Test Loss: 0.2197\n",
      "Epoch 437/2000, Train Loss: 0.0921, Test Loss: 0.2215\n",
      "Epoch 438/2000, Train Loss: 0.0917, Test Loss: 0.2214\n",
      "Epoch 439/2000, Train Loss: 0.0919, Test Loss: 0.2216\n",
      "Epoch 440/2000, Train Loss: 0.0915, Test Loss: 0.2179\n",
      "Epoch 441/2000, Train Loss: 0.0914, Test Loss: 0.2180\n",
      "Epoch 442/2000, Train Loss: 0.0916, Test Loss: 0.2302\n",
      "Epoch 443/2000, Train Loss: 0.0913, Test Loss: 0.2227\n",
      "Epoch 444/2000, Train Loss: 0.0909, Test Loss: 0.2173\n",
      "Epoch 445/2000, Train Loss: 0.0916, Test Loss: 0.2187\n",
      "Epoch 446/2000, Train Loss: 0.0915, Test Loss: 0.2267\n",
      "Epoch 447/2000, Train Loss: 0.0910, Test Loss: 0.2253\n",
      "Epoch 448/2000, Train Loss: 0.0911, Test Loss: 0.2219\n",
      "Epoch 449/2000, Train Loss: 0.0919, Test Loss: 0.2195\n",
      "Epoch 450/2000, Train Loss: 0.0904, Test Loss: 0.2220\n",
      "Epoch 451/2000, Train Loss: 0.0908, Test Loss: 0.2263\n",
      "Epoch 452/2000, Train Loss: 0.0913, Test Loss: 0.2246\n",
      "Epoch 453/2000, Train Loss: 0.0909, Test Loss: 0.2218\n",
      "Epoch 454/2000, Train Loss: 0.0911, Test Loss: 0.2204\n",
      "Epoch 455/2000, Train Loss: 0.0908, Test Loss: 0.2220\n",
      "Epoch 456/2000, Train Loss: 0.0902, Test Loss: 0.2225\n",
      "Epoch 457/2000, Train Loss: 0.0906, Test Loss: 0.2195\n",
      "Epoch 458/2000, Train Loss: 0.0906, Test Loss: 0.2206\n",
      "Epoch 459/2000, Train Loss: 0.0907, Test Loss: 0.2229\n",
      "Epoch 460/2000, Train Loss: 0.0907, Test Loss: 0.2257\n",
      "Epoch 461/2000, Train Loss: 0.0904, Test Loss: 0.2184\n",
      "Epoch 462/2000, Train Loss: 0.0902, Test Loss: 0.2214\n",
      "Epoch 463/2000, Train Loss: 0.0908, Test Loss: 0.2241\n",
      "Epoch 464/2000, Train Loss: 0.0904, Test Loss: 0.2257\n",
      "Epoch 465/2000, Train Loss: 0.0906, Test Loss: 0.2210\n",
      "Epoch 466/2000, Train Loss: 0.0904, Test Loss: 0.2250\n",
      "Epoch 467/2000, Train Loss: 0.0900, Test Loss: 0.2216\n",
      "Epoch 468/2000, Train Loss: 0.0901, Test Loss: 0.2238\n",
      "Epoch 469/2000, Train Loss: 0.0903, Test Loss: 0.2198\n",
      "Epoch 470/2000, Train Loss: 0.0904, Test Loss: 0.2242\n",
      "Epoch 471/2000, Train Loss: 0.0904, Test Loss: 0.2190\n",
      "Epoch 472/2000, Train Loss: 0.0902, Test Loss: 0.2244\n",
      "Epoch 473/2000, Train Loss: 0.0903, Test Loss: 0.2280\n",
      "Epoch 474/2000, Train Loss: 0.0899, Test Loss: 0.2220\n",
      "Epoch 475/2000, Train Loss: 0.0898, Test Loss: 0.2212\n",
      "Epoch 476/2000, Train Loss: 0.0897, Test Loss: 0.2237\n",
      "Epoch 477/2000, Train Loss: 0.0903, Test Loss: 0.2220\n",
      "Epoch 478/2000, Train Loss: 0.0904, Test Loss: 0.2292\n",
      "Epoch 479/2000, Train Loss: 0.0898, Test Loss: 0.2211\n",
      "Epoch 480/2000, Train Loss: 0.0891, Test Loss: 0.2207\n",
      "Epoch 481/2000, Train Loss: 0.0899, Test Loss: 0.2210\n",
      "Epoch 482/2000, Train Loss: 0.0898, Test Loss: 0.2226\n",
      "Epoch 483/2000, Train Loss: 0.0896, Test Loss: 0.2228\n",
      "Epoch 484/2000, Train Loss: 0.0892, Test Loss: 0.2217\n",
      "Epoch 485/2000, Train Loss: 0.0897, Test Loss: 0.2218\n",
      "Epoch 486/2000, Train Loss: 0.0900, Test Loss: 0.2219\n",
      "Epoch 487/2000, Train Loss: 0.0891, Test Loss: 0.2208\n",
      "Epoch 488/2000, Train Loss: 0.0891, Test Loss: 0.2199\n",
      "Epoch 489/2000, Train Loss: 0.0886, Test Loss: 0.2269\n",
      "Epoch 490/2000, Train Loss: 0.0897, Test Loss: 0.2216\n",
      "Epoch 491/2000, Train Loss: 0.0891, Test Loss: 0.2256\n",
      "Epoch 492/2000, Train Loss: 0.0889, Test Loss: 0.2249\n",
      "Epoch 493/2000, Train Loss: 0.0890, Test Loss: 0.2210\n",
      "Epoch 494/2000, Train Loss: 0.0888, Test Loss: 0.2217\n",
      "Epoch 495/2000, Train Loss: 0.0885, Test Loss: 0.2253\n",
      "Epoch 496/2000, Train Loss: 0.0892, Test Loss: 0.2300\n",
      "Epoch 497/2000, Train Loss: 0.0898, Test Loss: 0.2321\n",
      "Epoch 498/2000, Train Loss: 0.0887, Test Loss: 0.2280\n",
      "Epoch 499/2000, Train Loss: 0.0888, Test Loss: 0.2241\n",
      "Epoch 500/2000, Train Loss: 0.0885, Test Loss: 0.2254\n",
      "Epoch 501/2000, Train Loss: 0.0887, Test Loss: 0.2282\n",
      "Epoch 502/2000, Train Loss: 0.0891, Test Loss: 0.2211\n",
      "Epoch 503/2000, Train Loss: 0.0883, Test Loss: 0.2215\n",
      "Epoch 504/2000, Train Loss: 0.0886, Test Loss: 0.2250\n",
      "Epoch 505/2000, Train Loss: 0.0889, Test Loss: 0.2253\n",
      "Epoch 506/2000, Train Loss: 0.0887, Test Loss: 0.2346\n",
      "Epoch 507/2000, Train Loss: 0.0886, Test Loss: 0.2266\n",
      "Epoch 508/2000, Train Loss: 0.0888, Test Loss: 0.2248\n",
      "Epoch 509/2000, Train Loss: 0.0881, Test Loss: 0.2241\n",
      "Epoch 510/2000, Train Loss: 0.0887, Test Loss: 0.2251\n",
      "Epoch 511/2000, Train Loss: 0.0879, Test Loss: 0.2278\n",
      "Epoch 512/2000, Train Loss: 0.0881, Test Loss: 0.2304\n",
      "Epoch 513/2000, Train Loss: 0.0883, Test Loss: 0.2241\n",
      "Epoch 514/2000, Train Loss: 0.0883, Test Loss: 0.2271\n",
      "Epoch 515/2000, Train Loss: 0.0887, Test Loss: 0.2319\n",
      "Epoch 516/2000, Train Loss: 0.0880, Test Loss: 0.2234\n",
      "Epoch 517/2000, Train Loss: 0.0878, Test Loss: 0.2325\n",
      "Epoch 518/2000, Train Loss: 0.0880, Test Loss: 0.2276\n",
      "Epoch 519/2000, Train Loss: 0.0880, Test Loss: 0.2247\n",
      "Epoch 520/2000, Train Loss: 0.0876, Test Loss: 0.2232\n",
      "Epoch 521/2000, Train Loss: 0.0881, Test Loss: 0.2267\n",
      "Epoch 522/2000, Train Loss: 0.0878, Test Loss: 0.2234\n",
      "Epoch 523/2000, Train Loss: 0.0884, Test Loss: 0.2236\n",
      "Epoch 524/2000, Train Loss: 0.0879, Test Loss: 0.2234\n",
      "Epoch 525/2000, Train Loss: 0.0877, Test Loss: 0.2263\n",
      "Epoch 526/2000, Train Loss: 0.0878, Test Loss: 0.2230\n",
      "Epoch 527/2000, Train Loss: 0.0878, Test Loss: 0.2238\n",
      "Epoch 528/2000, Train Loss: 0.0876, Test Loss: 0.2267\n",
      "Epoch 529/2000, Train Loss: 0.0880, Test Loss: 0.2355\n",
      "Epoch 530/2000, Train Loss: 0.0881, Test Loss: 0.2249\n",
      "Epoch 531/2000, Train Loss: 0.0878, Test Loss: 0.2257\n",
      "Epoch 532/2000, Train Loss: 0.0878, Test Loss: 0.2307\n",
      "Epoch 533/2000, Train Loss: 0.0875, Test Loss: 0.2280\n",
      "Epoch 534/2000, Train Loss: 0.0874, Test Loss: 0.2255\n",
      "Epoch 535/2000, Train Loss: 0.0873, Test Loss: 0.2265\n",
      "Epoch 536/2000, Train Loss: 0.0875, Test Loss: 0.2257\n",
      "Epoch 537/2000, Train Loss: 0.0872, Test Loss: 0.2354\n",
      "Epoch 538/2000, Train Loss: 0.0877, Test Loss: 0.2262\n",
      "Epoch 539/2000, Train Loss: 0.0873, Test Loss: 0.2281\n",
      "Epoch 540/2000, Train Loss: 0.0872, Test Loss: 0.2381\n",
      "Epoch 541/2000, Train Loss: 0.0876, Test Loss: 0.2299\n",
      "Epoch 542/2000, Train Loss: 0.0868, Test Loss: 0.2419\n",
      "Epoch 543/2000, Train Loss: 0.0871, Test Loss: 0.2276\n",
      "Epoch 544/2000, Train Loss: 0.0869, Test Loss: 0.2250\n",
      "Epoch 545/2000, Train Loss: 0.0875, Test Loss: 0.2258\n",
      "Epoch 546/2000, Train Loss: 0.0874, Test Loss: 0.2300\n",
      "Epoch 547/2000, Train Loss: 0.0872, Test Loss: 0.2391\n",
      "Epoch 548/2000, Train Loss: 0.0867, Test Loss: 0.2265\n",
      "Epoch 549/2000, Train Loss: 0.0870, Test Loss: 0.2267\n",
      "Epoch 550/2000, Train Loss: 0.0867, Test Loss: 0.2249\n",
      "Epoch 551/2000, Train Loss: 0.0868, Test Loss: 0.2269\n",
      "Epoch 552/2000, Train Loss: 0.0872, Test Loss: 0.2330\n",
      "Epoch 553/2000, Train Loss: 0.0872, Test Loss: 0.2274\n",
      "Epoch 554/2000, Train Loss: 0.0863, Test Loss: 0.2275\n",
      "Epoch 555/2000, Train Loss: 0.0869, Test Loss: 0.2293\n",
      "Epoch 556/2000, Train Loss: 0.0864, Test Loss: 0.2270\n",
      "Epoch 557/2000, Train Loss: 0.0868, Test Loss: 0.2290\n",
      "Epoch 558/2000, Train Loss: 0.0869, Test Loss: 0.2254\n",
      "Epoch 559/2000, Train Loss: 0.0866, Test Loss: 0.2269\n",
      "Epoch 560/2000, Train Loss: 0.0869, Test Loss: 0.2317\n",
      "Epoch 561/2000, Train Loss: 0.0865, Test Loss: 0.2316\n",
      "Epoch 562/2000, Train Loss: 0.0868, Test Loss: 0.2265\n",
      "Epoch 563/2000, Train Loss: 0.0863, Test Loss: 0.2335\n",
      "Epoch 564/2000, Train Loss: 0.0863, Test Loss: 0.2268\n",
      "Epoch 565/2000, Train Loss: 0.0863, Test Loss: 0.2266\n",
      "Epoch 566/2000, Train Loss: 0.0864, Test Loss: 0.2310\n",
      "Epoch 567/2000, Train Loss: 0.0862, Test Loss: 0.2274\n",
      "Epoch 568/2000, Train Loss: 0.0862, Test Loss: 0.2303\n",
      "Epoch 569/2000, Train Loss: 0.0867, Test Loss: 0.2275\n",
      "Epoch 570/2000, Train Loss: 0.0867, Test Loss: 0.2278\n",
      "Epoch 571/2000, Train Loss: 0.0863, Test Loss: 0.2270\n",
      "Epoch 572/2000, Train Loss: 0.0868, Test Loss: 0.2263\n",
      "Epoch 573/2000, Train Loss: 0.0864, Test Loss: 0.2289\n",
      "Epoch 574/2000, Train Loss: 0.0861, Test Loss: 0.2311\n",
      "Epoch 575/2000, Train Loss: 0.0861, Test Loss: 0.2273\n",
      "Epoch 576/2000, Train Loss: 0.0861, Test Loss: 0.2291\n",
      "Epoch 577/2000, Train Loss: 0.0861, Test Loss: 0.2270\n",
      "Epoch 578/2000, Train Loss: 0.0862, Test Loss: 0.2309\n",
      "Epoch 579/2000, Train Loss: 0.0860, Test Loss: 0.2298\n",
      "Epoch 580/2000, Train Loss: 0.0858, Test Loss: 0.2295\n",
      "Epoch 581/2000, Train Loss: 0.0857, Test Loss: 0.2339\n",
      "Epoch 582/2000, Train Loss: 0.0855, Test Loss: 0.2293\n",
      "Epoch 583/2000, Train Loss: 0.0858, Test Loss: 0.2297\n",
      "Epoch 584/2000, Train Loss: 0.0859, Test Loss: 0.2314\n",
      "Epoch 585/2000, Train Loss: 0.0856, Test Loss: 0.2336\n",
      "Epoch 586/2000, Train Loss: 0.0852, Test Loss: 0.2312\n",
      "Epoch 587/2000, Train Loss: 0.0855, Test Loss: 0.2269\n",
      "Epoch 588/2000, Train Loss: 0.0854, Test Loss: 0.2293\n",
      "Epoch 589/2000, Train Loss: 0.0856, Test Loss: 0.2276\n",
      "Epoch 590/2000, Train Loss: 0.0852, Test Loss: 0.2274\n",
      "Epoch 591/2000, Train Loss: 0.0852, Test Loss: 0.2305\n",
      "Epoch 592/2000, Train Loss: 0.0849, Test Loss: 0.2347\n",
      "Epoch 593/2000, Train Loss: 0.0852, Test Loss: 0.2337\n",
      "Epoch 594/2000, Train Loss: 0.0847, Test Loss: 0.2291\n",
      "Epoch 595/2000, Train Loss: 0.0850, Test Loss: 0.2342\n",
      "Epoch 596/2000, Train Loss: 0.0847, Test Loss: 0.2297\n",
      "Epoch 597/2000, Train Loss: 0.0851, Test Loss: 0.2286\n",
      "Epoch 598/2000, Train Loss: 0.0852, Test Loss: 0.2315\n",
      "Epoch 599/2000, Train Loss: 0.0855, Test Loss: 0.2357\n",
      "Epoch 600/2000, Train Loss: 0.0847, Test Loss: 0.2380\n",
      "Epoch 601/2000, Train Loss: 0.0849, Test Loss: 0.2346\n",
      "Epoch 602/2000, Train Loss: 0.0851, Test Loss: 0.2297\n",
      "Epoch 603/2000, Train Loss: 0.0857, Test Loss: 0.2316\n",
      "Epoch 604/2000, Train Loss: 0.0852, Test Loss: 0.2303\n",
      "Epoch 605/2000, Train Loss: 0.0849, Test Loss: 0.2287\n",
      "Epoch 606/2000, Train Loss: 0.0843, Test Loss: 0.2312\n",
      "Epoch 607/2000, Train Loss: 0.0851, Test Loss: 0.2326\n",
      "Epoch 608/2000, Train Loss: 0.0849, Test Loss: 0.2347\n",
      "Epoch 609/2000, Train Loss: 0.0846, Test Loss: 0.2303\n",
      "Epoch 610/2000, Train Loss: 0.0850, Test Loss: 0.2303\n",
      "Epoch 611/2000, Train Loss: 0.0850, Test Loss: 0.2362\n",
      "Epoch 612/2000, Train Loss: 0.0855, Test Loss: 0.2284\n",
      "Epoch 613/2000, Train Loss: 0.0847, Test Loss: 0.2304\n",
      "Epoch 614/2000, Train Loss: 0.0845, Test Loss: 0.2333\n",
      "Epoch 615/2000, Train Loss: 0.0847, Test Loss: 0.2350\n",
      "Epoch 616/2000, Train Loss: 0.0849, Test Loss: 0.2324\n",
      "Epoch 617/2000, Train Loss: 0.0843, Test Loss: 0.2311\n",
      "Epoch 618/2000, Train Loss: 0.0850, Test Loss: 0.2316\n",
      "Epoch 619/2000, Train Loss: 0.0845, Test Loss: 0.2338\n",
      "Epoch 620/2000, Train Loss: 0.0842, Test Loss: 0.2340\n",
      "Epoch 621/2000, Train Loss: 0.0842, Test Loss: 0.2416\n",
      "Epoch 622/2000, Train Loss: 0.0848, Test Loss: 0.2317\n",
      "Epoch 623/2000, Train Loss: 0.0843, Test Loss: 0.2310\n",
      "Epoch 624/2000, Train Loss: 0.0847, Test Loss: 0.2335\n",
      "Epoch 625/2000, Train Loss: 0.0848, Test Loss: 0.2404\n",
      "Epoch 626/2000, Train Loss: 0.0839, Test Loss: 0.2379\n",
      "Epoch 627/2000, Train Loss: 0.0842, Test Loss: 0.2314\n",
      "Epoch 628/2000, Train Loss: 0.0843, Test Loss: 0.2325\n",
      "Epoch 629/2000, Train Loss: 0.0839, Test Loss: 0.2320\n",
      "Epoch 630/2000, Train Loss: 0.0842, Test Loss: 0.2322\n",
      "Epoch 631/2000, Train Loss: 0.0843, Test Loss: 0.2334\n",
      "Epoch 632/2000, Train Loss: 0.0839, Test Loss: 0.2314\n",
      "Epoch 633/2000, Train Loss: 0.0837, Test Loss: 0.2326\n",
      "Epoch 634/2000, Train Loss: 0.0841, Test Loss: 0.2402\n",
      "Epoch 635/2000, Train Loss: 0.0844, Test Loss: 0.2345\n",
      "Epoch 636/2000, Train Loss: 0.0842, Test Loss: 0.2315\n",
      "Epoch 637/2000, Train Loss: 0.0838, Test Loss: 0.2328\n",
      "Epoch 638/2000, Train Loss: 0.0840, Test Loss: 0.2362\n",
      "Epoch 639/2000, Train Loss: 0.0838, Test Loss: 0.2350\n",
      "Epoch 640/2000, Train Loss: 0.0840, Test Loss: 0.2490\n",
      "Epoch 641/2000, Train Loss: 0.0845, Test Loss: 0.2342\n",
      "Epoch 642/2000, Train Loss: 0.0835, Test Loss: 0.2338\n",
      "Epoch 643/2000, Train Loss: 0.0836, Test Loss: 0.2360\n",
      "Epoch 644/2000, Train Loss: 0.0843, Test Loss: 0.2367\n",
      "Epoch 645/2000, Train Loss: 0.0840, Test Loss: 0.2412\n",
      "Epoch 646/2000, Train Loss: 0.0837, Test Loss: 0.2360\n",
      "Epoch 647/2000, Train Loss: 0.0840, Test Loss: 0.2337\n",
      "Epoch 648/2000, Train Loss: 0.0839, Test Loss: 0.2362\n",
      "Epoch 649/2000, Train Loss: 0.0832, Test Loss: 0.2402\n",
      "Epoch 650/2000, Train Loss: 0.0844, Test Loss: 0.2355\n",
      "Epoch 651/2000, Train Loss: 0.0841, Test Loss: 0.2328\n",
      "Epoch 652/2000, Train Loss: 0.0834, Test Loss: 0.2418\n",
      "Epoch 653/2000, Train Loss: 0.0835, Test Loss: 0.2333\n",
      "Epoch 654/2000, Train Loss: 0.0837, Test Loss: 0.2319\n",
      "Epoch 655/2000, Train Loss: 0.0837, Test Loss: 0.2328\n",
      "Epoch 656/2000, Train Loss: 0.0832, Test Loss: 0.2393\n",
      "Epoch 657/2000, Train Loss: 0.0836, Test Loss: 0.2421\n",
      "Epoch 658/2000, Train Loss: 0.0835, Test Loss: 0.2364\n",
      "Epoch 659/2000, Train Loss: 0.0834, Test Loss: 0.2337\n",
      "Epoch 660/2000, Train Loss: 0.0831, Test Loss: 0.2420\n",
      "Epoch 661/2000, Train Loss: 0.0833, Test Loss: 0.2364\n",
      "Epoch 662/2000, Train Loss: 0.0832, Test Loss: 0.2368\n",
      "Epoch 663/2000, Train Loss: 0.0834, Test Loss: 0.2410\n",
      "Epoch 664/2000, Train Loss: 0.0834, Test Loss: 0.2345\n",
      "Epoch 665/2000, Train Loss: 0.0828, Test Loss: 0.2355\n",
      "Epoch 666/2000, Train Loss: 0.0828, Test Loss: 0.2333\n",
      "Epoch 667/2000, Train Loss: 0.0835, Test Loss: 0.2379\n",
      "Epoch 668/2000, Train Loss: 0.0839, Test Loss: 0.2339\n",
      "Epoch 669/2000, Train Loss: 0.0831, Test Loss: 0.2415\n",
      "Epoch 670/2000, Train Loss: 0.0828, Test Loss: 0.2364\n",
      "Epoch 671/2000, Train Loss: 0.0830, Test Loss: 0.2405\n",
      "Epoch 672/2000, Train Loss: 0.0826, Test Loss: 0.2342\n",
      "Epoch 673/2000, Train Loss: 0.0828, Test Loss: 0.2332\n",
      "Epoch 674/2000, Train Loss: 0.0825, Test Loss: 0.2372\n",
      "Epoch 675/2000, Train Loss: 0.0827, Test Loss: 0.2429\n",
      "Epoch 676/2000, Train Loss: 0.0830, Test Loss: 0.2360\n",
      "Epoch 677/2000, Train Loss: 0.0829, Test Loss: 0.2378\n",
      "Epoch 678/2000, Train Loss: 0.0827, Test Loss: 0.2342\n",
      "Epoch 679/2000, Train Loss: 0.0821, Test Loss: 0.2356\n",
      "Epoch 680/2000, Train Loss: 0.0826, Test Loss: 0.2383\n",
      "Epoch 681/2000, Train Loss: 0.0826, Test Loss: 0.2343\n",
      "Epoch 682/2000, Train Loss: 0.0822, Test Loss: 0.2434\n",
      "Epoch 683/2000, Train Loss: 0.0829, Test Loss: 0.2342\n",
      "Epoch 684/2000, Train Loss: 0.0827, Test Loss: 0.2337\n",
      "Epoch 685/2000, Train Loss: 0.0828, Test Loss: 0.2356\n",
      "Epoch 686/2000, Train Loss: 0.0822, Test Loss: 0.2387\n",
      "Epoch 687/2000, Train Loss: 0.0821, Test Loss: 0.2374\n",
      "Epoch 688/2000, Train Loss: 0.0824, Test Loss: 0.2358\n",
      "Epoch 689/2000, Train Loss: 0.0823, Test Loss: 0.2499\n",
      "Epoch 690/2000, Train Loss: 0.0822, Test Loss: 0.2351\n",
      "Epoch 691/2000, Train Loss: 0.0822, Test Loss: 0.2354\n",
      "Epoch 692/2000, Train Loss: 0.0821, Test Loss: 0.2347\n",
      "Epoch 693/2000, Train Loss: 0.0819, Test Loss: 0.2379\n",
      "Epoch 694/2000, Train Loss: 0.0821, Test Loss: 0.2355\n",
      "Epoch 695/2000, Train Loss: 0.0822, Test Loss: 0.2360\n",
      "Epoch 696/2000, Train Loss: 0.0825, Test Loss: 0.2375\n",
      "Epoch 697/2000, Train Loss: 0.0825, Test Loss: 0.2413\n",
      "Epoch 698/2000, Train Loss: 0.0828, Test Loss: 0.2402\n",
      "Epoch 699/2000, Train Loss: 0.0822, Test Loss: 0.2395\n",
      "Epoch 700/2000, Train Loss: 0.0816, Test Loss: 0.2366\n",
      "Epoch 701/2000, Train Loss: 0.0824, Test Loss: 0.2364\n",
      "Epoch 702/2000, Train Loss: 0.0821, Test Loss: 0.2436\n",
      "Epoch 703/2000, Train Loss: 0.0819, Test Loss: 0.2364\n",
      "Epoch 704/2000, Train Loss: 0.0822, Test Loss: 0.2384\n",
      "Epoch 705/2000, Train Loss: 0.0816, Test Loss: 0.2400\n",
      "Epoch 706/2000, Train Loss: 0.0818, Test Loss: 0.2376\n",
      "Epoch 707/2000, Train Loss: 0.0815, Test Loss: 0.2418\n",
      "Epoch 708/2000, Train Loss: 0.0821, Test Loss: 0.2438\n",
      "Epoch 709/2000, Train Loss: 0.0819, Test Loss: 0.2346\n",
      "Epoch 710/2000, Train Loss: 0.0815, Test Loss: 0.2377\n",
      "Epoch 711/2000, Train Loss: 0.0816, Test Loss: 0.2400\n",
      "Epoch 712/2000, Train Loss: 0.0818, Test Loss: 0.2457\n",
      "Epoch 713/2000, Train Loss: 0.0817, Test Loss: 0.2396\n",
      "Epoch 714/2000, Train Loss: 0.0814, Test Loss: 0.2380\n",
      "Epoch 715/2000, Train Loss: 0.0820, Test Loss: 0.2368\n",
      "Epoch 716/2000, Train Loss: 0.0809, Test Loss: 0.2399\n",
      "Epoch 717/2000, Train Loss: 0.0821, Test Loss: 0.2377\n",
      "Epoch 718/2000, Train Loss: 0.0811, Test Loss: 0.2393\n",
      "Epoch 719/2000, Train Loss: 0.0818, Test Loss: 0.2427\n",
      "Epoch 720/2000, Train Loss: 0.0812, Test Loss: 0.2373\n",
      "Epoch 721/2000, Train Loss: 0.0815, Test Loss: 0.2377\n",
      "Epoch 722/2000, Train Loss: 0.0811, Test Loss: 0.2364\n",
      "Epoch 723/2000, Train Loss: 0.0812, Test Loss: 0.2389\n",
      "Epoch 724/2000, Train Loss: 0.0809, Test Loss: 0.2471\n",
      "Epoch 725/2000, Train Loss: 0.0813, Test Loss: 0.2397\n",
      "Epoch 726/2000, Train Loss: 0.0812, Test Loss: 0.2374\n",
      "Epoch 727/2000, Train Loss: 0.0813, Test Loss: 0.2367\n",
      "Epoch 728/2000, Train Loss: 0.0813, Test Loss: 0.2388\n",
      "Epoch 729/2000, Train Loss: 0.0810, Test Loss: 0.2419\n",
      "Epoch 730/2000, Train Loss: 0.0810, Test Loss: 0.2377\n",
      "Epoch 731/2000, Train Loss: 0.0808, Test Loss: 0.2402\n",
      "Epoch 732/2000, Train Loss: 0.0810, Test Loss: 0.2365\n",
      "Epoch 733/2000, Train Loss: 0.0814, Test Loss: 0.2389\n",
      "Epoch 734/2000, Train Loss: 0.0811, Test Loss: 0.2462\n",
      "Epoch 735/2000, Train Loss: 0.0810, Test Loss: 0.2385\n",
      "Epoch 736/2000, Train Loss: 0.0812, Test Loss: 0.2453\n",
      "Epoch 737/2000, Train Loss: 0.0810, Test Loss: 0.2443\n",
      "Epoch 738/2000, Train Loss: 0.0807, Test Loss: 0.2383\n",
      "Epoch 739/2000, Train Loss: 0.0816, Test Loss: 0.2375\n",
      "Epoch 740/2000, Train Loss: 0.0809, Test Loss: 0.2409\n",
      "Epoch 741/2000, Train Loss: 0.0817, Test Loss: 0.2402\n",
      "Epoch 742/2000, Train Loss: 0.0808, Test Loss: 0.2381\n",
      "Epoch 743/2000, Train Loss: 0.0809, Test Loss: 0.2406\n",
      "Epoch 744/2000, Train Loss: 0.0808, Test Loss: 0.2392\n",
      "Epoch 745/2000, Train Loss: 0.0807, Test Loss: 0.2416\n",
      "Epoch 746/2000, Train Loss: 0.0811, Test Loss: 0.2408\n",
      "Epoch 747/2000, Train Loss: 0.0810, Test Loss: 0.2391\n",
      "Epoch 748/2000, Train Loss: 0.0812, Test Loss: 0.2450\n",
      "Epoch 749/2000, Train Loss: 0.0807, Test Loss: 0.2402\n",
      "Epoch 750/2000, Train Loss: 0.0806, Test Loss: 0.2399\n",
      "Epoch 751/2000, Train Loss: 0.0805, Test Loss: 0.2399\n",
      "Epoch 752/2000, Train Loss: 0.0804, Test Loss: 0.2391\n",
      "Epoch 753/2000, Train Loss: 0.0805, Test Loss: 0.2396\n",
      "Epoch 754/2000, Train Loss: 0.0805, Test Loss: 0.2404\n",
      "Epoch 755/2000, Train Loss: 0.0810, Test Loss: 0.2413\n",
      "Epoch 756/2000, Train Loss: 0.0801, Test Loss: 0.2491\n",
      "Epoch 757/2000, Train Loss: 0.0806, Test Loss: 0.2407\n",
      "Epoch 758/2000, Train Loss: 0.0804, Test Loss: 0.2397\n",
      "Epoch 759/2000, Train Loss: 0.0803, Test Loss: 0.2405\n",
      "Epoch 760/2000, Train Loss: 0.0801, Test Loss: 0.2407\n",
      "Epoch 761/2000, Train Loss: 0.0804, Test Loss: 0.2409\n",
      "Epoch 762/2000, Train Loss: 0.0805, Test Loss: 0.2458\n",
      "Epoch 763/2000, Train Loss: 0.0806, Test Loss: 0.2410\n",
      "Epoch 764/2000, Train Loss: 0.0809, Test Loss: 0.2422\n",
      "Epoch 765/2000, Train Loss: 0.0804, Test Loss: 0.2402\n",
      "Epoch 766/2000, Train Loss: 0.0804, Test Loss: 0.2427\n",
      "Epoch 767/2000, Train Loss: 0.0801, Test Loss: 0.2467\n",
      "Epoch 768/2000, Train Loss: 0.0802, Test Loss: 0.2414\n",
      "Epoch 769/2000, Train Loss: 0.0803, Test Loss: 0.2446\n",
      "Epoch 770/2000, Train Loss: 0.0801, Test Loss: 0.2432\n",
      "Epoch 771/2000, Train Loss: 0.0804, Test Loss: 0.2420\n",
      "Epoch 772/2000, Train Loss: 0.0802, Test Loss: 0.2391\n",
      "Epoch 773/2000, Train Loss: 0.0805, Test Loss: 0.2425\n",
      "Epoch 774/2000, Train Loss: 0.0798, Test Loss: 0.2509\n",
      "Epoch 775/2000, Train Loss: 0.0803, Test Loss: 0.2420\n",
      "Epoch 776/2000, Train Loss: 0.0800, Test Loss: 0.2436\n",
      "Epoch 777/2000, Train Loss: 0.0795, Test Loss: 0.2446\n",
      "Epoch 778/2000, Train Loss: 0.0801, Test Loss: 0.2441\n",
      "Epoch 779/2000, Train Loss: 0.0797, Test Loss: 0.2416\n",
      "Epoch 780/2000, Train Loss: 0.0798, Test Loss: 0.2448\n",
      "Epoch 781/2000, Train Loss: 0.0798, Test Loss: 0.2437\n",
      "Epoch 782/2000, Train Loss: 0.0803, Test Loss: 0.2428\n",
      "Epoch 783/2000, Train Loss: 0.0807, Test Loss: 0.2407\n",
      "Epoch 784/2000, Train Loss: 0.0801, Test Loss: 0.2426\n",
      "Epoch 785/2000, Train Loss: 0.0800, Test Loss: 0.2510\n",
      "Epoch 786/2000, Train Loss: 0.0797, Test Loss: 0.2460\n",
      "Epoch 787/2000, Train Loss: 0.0794, Test Loss: 0.2462\n",
      "Epoch 788/2000, Train Loss: 0.0791, Test Loss: 0.2463\n",
      "Epoch 789/2000, Train Loss: 0.0795, Test Loss: 0.2423\n",
      "Epoch 790/2000, Train Loss: 0.0804, Test Loss: 0.2439\n",
      "Epoch 791/2000, Train Loss: 0.0794, Test Loss: 0.2459\n",
      "Epoch 792/2000, Train Loss: 0.0797, Test Loss: 0.2431\n",
      "Epoch 793/2000, Train Loss: 0.0794, Test Loss: 0.2510\n",
      "Epoch 794/2000, Train Loss: 0.0795, Test Loss: 0.2534\n",
      "Epoch 795/2000, Train Loss: 0.0796, Test Loss: 0.2444\n",
      "Epoch 796/2000, Train Loss: 0.0795, Test Loss: 0.2531\n",
      "Epoch 797/2000, Train Loss: 0.0796, Test Loss: 0.2446\n",
      "Epoch 798/2000, Train Loss: 0.0797, Test Loss: 0.2408\n",
      "Epoch 799/2000, Train Loss: 0.0794, Test Loss: 0.2422\n",
      "Epoch 800/2000, Train Loss: 0.0795, Test Loss: 0.2420\n",
      "Epoch 801/2000, Train Loss: 0.0794, Test Loss: 0.2416\n",
      "Epoch 802/2000, Train Loss: 0.0791, Test Loss: 0.2428\n",
      "Epoch 803/2000, Train Loss: 0.0796, Test Loss: 0.2435\n",
      "Epoch 804/2000, Train Loss: 0.0793, Test Loss: 0.2428\n",
      "Epoch 805/2000, Train Loss: 0.0789, Test Loss: 0.2492\n",
      "Epoch 806/2000, Train Loss: 0.0793, Test Loss: 0.2460\n",
      "Epoch 807/2000, Train Loss: 0.0795, Test Loss: 0.2515\n",
      "Epoch 808/2000, Train Loss: 0.0792, Test Loss: 0.2471\n",
      "Epoch 809/2000, Train Loss: 0.0791, Test Loss: 0.2424\n",
      "Epoch 810/2000, Train Loss: 0.0791, Test Loss: 0.2408\n",
      "Epoch 811/2000, Train Loss: 0.0789, Test Loss: 0.2434\n",
      "Epoch 812/2000, Train Loss: 0.0795, Test Loss: 0.2484\n",
      "Epoch 813/2000, Train Loss: 0.0788, Test Loss: 0.2465\n",
      "Epoch 814/2000, Train Loss: 0.0790, Test Loss: 0.2420\n",
      "Epoch 815/2000, Train Loss: 0.0794, Test Loss: 0.2448\n",
      "Epoch 816/2000, Train Loss: 0.0789, Test Loss: 0.2445\n",
      "Epoch 817/2000, Train Loss: 0.0793, Test Loss: 0.2431\n",
      "Epoch 818/2000, Train Loss: 0.0787, Test Loss: 0.2435\n",
      "Epoch 819/2000, Train Loss: 0.0788, Test Loss: 0.2503\n",
      "Epoch 820/2000, Train Loss: 0.0788, Test Loss: 0.2461\n",
      "Epoch 821/2000, Train Loss: 0.0788, Test Loss: 0.2428\n",
      "Epoch 822/2000, Train Loss: 0.0793, Test Loss: 0.2424\n",
      "Epoch 823/2000, Train Loss: 0.0786, Test Loss: 0.2463\n",
      "Epoch 824/2000, Train Loss: 0.0789, Test Loss: 0.2519\n",
      "Epoch 825/2000, Train Loss: 0.0788, Test Loss: 0.2448\n",
      "Epoch 826/2000, Train Loss: 0.0785, Test Loss: 0.2419\n",
      "Epoch 827/2000, Train Loss: 0.0785, Test Loss: 0.2429\n",
      "Epoch 828/2000, Train Loss: 0.0783, Test Loss: 0.2489\n",
      "Epoch 829/2000, Train Loss: 0.0784, Test Loss: 0.2425\n",
      "Epoch 830/2000, Train Loss: 0.0788, Test Loss: 0.2475\n",
      "Epoch 831/2000, Train Loss: 0.0785, Test Loss: 0.2488\n",
      "Epoch 832/2000, Train Loss: 0.0784, Test Loss: 0.2443\n",
      "Epoch 833/2000, Train Loss: 0.0790, Test Loss: 0.2485\n",
      "Epoch 834/2000, Train Loss: 0.0781, Test Loss: 0.2436\n",
      "Epoch 835/2000, Train Loss: 0.0784, Test Loss: 0.2499\n",
      "Epoch 836/2000, Train Loss: 0.0787, Test Loss: 0.2432\n",
      "Epoch 837/2000, Train Loss: 0.0780, Test Loss: 0.2463\n",
      "Epoch 838/2000, Train Loss: 0.0782, Test Loss: 0.2453\n",
      "Epoch 839/2000, Train Loss: 0.0779, Test Loss: 0.2438\n",
      "Epoch 840/2000, Train Loss: 0.0783, Test Loss: 0.2440\n",
      "Epoch 841/2000, Train Loss: 0.0782, Test Loss: 0.2462\n",
      "Epoch 842/2000, Train Loss: 0.0783, Test Loss: 0.2447\n",
      "Epoch 843/2000, Train Loss: 0.0783, Test Loss: 0.2485\n",
      "Epoch 844/2000, Train Loss: 0.0780, Test Loss: 0.2484\n",
      "Epoch 845/2000, Train Loss: 0.0779, Test Loss: 0.2469\n",
      "Epoch 846/2000, Train Loss: 0.0785, Test Loss: 0.2476\n",
      "Epoch 847/2000, Train Loss: 0.0782, Test Loss: 0.2466\n",
      "Epoch 848/2000, Train Loss: 0.0778, Test Loss: 0.2506\n",
      "Epoch 849/2000, Train Loss: 0.0786, Test Loss: 0.2456\n",
      "Epoch 850/2000, Train Loss: 0.0780, Test Loss: 0.2458\n",
      "Epoch 851/2000, Train Loss: 0.0782, Test Loss: 0.2470\n",
      "Epoch 852/2000, Train Loss: 0.0783, Test Loss: 0.2462\n",
      "Epoch 853/2000, Train Loss: 0.0780, Test Loss: 0.2518\n",
      "Epoch 854/2000, Train Loss: 0.0783, Test Loss: 0.2481\n",
      "Epoch 855/2000, Train Loss: 0.0783, Test Loss: 0.2447\n",
      "Epoch 856/2000, Train Loss: 0.0782, Test Loss: 0.2469\n",
      "Epoch 857/2000, Train Loss: 0.0779, Test Loss: 0.2584\n",
      "Epoch 858/2000, Train Loss: 0.0780, Test Loss: 0.2460\n",
      "Epoch 859/2000, Train Loss: 0.0785, Test Loss: 0.2566\n",
      "Epoch 860/2000, Train Loss: 0.0779, Test Loss: 0.2470\n",
      "Epoch 861/2000, Train Loss: 0.0778, Test Loss: 0.2481\n",
      "Epoch 862/2000, Train Loss: 0.0782, Test Loss: 0.2440\n",
      "Epoch 863/2000, Train Loss: 0.0782, Test Loss: 0.2462\n",
      "Epoch 864/2000, Train Loss: 0.0780, Test Loss: 0.2510\n",
      "Epoch 865/2000, Train Loss: 0.0780, Test Loss: 0.2460\n",
      "Epoch 866/2000, Train Loss: 0.0776, Test Loss: 0.2448\n",
      "Epoch 867/2000, Train Loss: 0.0775, Test Loss: 0.2485\n",
      "Epoch 868/2000, Train Loss: 0.0778, Test Loss: 0.2494\n",
      "Epoch 869/2000, Train Loss: 0.0776, Test Loss: 0.2453\n",
      "Epoch 870/2000, Train Loss: 0.0777, Test Loss: 0.2532\n",
      "Epoch 871/2000, Train Loss: 0.0773, Test Loss: 0.2506\n",
      "Epoch 872/2000, Train Loss: 0.0775, Test Loss: 0.2499\n",
      "Epoch 873/2000, Train Loss: 0.0781, Test Loss: 0.2473\n",
      "Epoch 874/2000, Train Loss: 0.0774, Test Loss: 0.2509\n",
      "Epoch 875/2000, Train Loss: 0.0772, Test Loss: 0.2539\n",
      "Epoch 876/2000, Train Loss: 0.0780, Test Loss: 0.2455\n",
      "Epoch 877/2000, Train Loss: 0.0770, Test Loss: 0.2456\n",
      "Epoch 878/2000, Train Loss: 0.0775, Test Loss: 0.2576\n",
      "Epoch 879/2000, Train Loss: 0.0774, Test Loss: 0.2471\n",
      "Epoch 880/2000, Train Loss: 0.0773, Test Loss: 0.2523\n",
      "Epoch 881/2000, Train Loss: 0.0773, Test Loss: 0.2488\n",
      "Epoch 882/2000, Train Loss: 0.0774, Test Loss: 0.2508\n",
      "Epoch 883/2000, Train Loss: 0.0771, Test Loss: 0.2477\n",
      "Epoch 884/2000, Train Loss: 0.0775, Test Loss: 0.2487\n",
      "Epoch 885/2000, Train Loss: 0.0776, Test Loss: 0.2516\n",
      "Epoch 886/2000, Train Loss: 0.0774, Test Loss: 0.2482\n",
      "Epoch 887/2000, Train Loss: 0.0770, Test Loss: 0.2543\n",
      "Epoch 888/2000, Train Loss: 0.0772, Test Loss: 0.2526\n",
      "Epoch 889/2000, Train Loss: 0.0770, Test Loss: 0.2465\n",
      "Epoch 890/2000, Train Loss: 0.0772, Test Loss: 0.2495\n",
      "Epoch 891/2000, Train Loss: 0.0771, Test Loss: 0.2473\n",
      "Epoch 892/2000, Train Loss: 0.0767, Test Loss: 0.2488\n",
      "Epoch 893/2000, Train Loss: 0.0772, Test Loss: 0.2478\n",
      "Epoch 894/2000, Train Loss: 0.0770, Test Loss: 0.2493\n",
      "Epoch 895/2000, Train Loss: 0.0773, Test Loss: 0.2470\n",
      "Epoch 896/2000, Train Loss: 0.0774, Test Loss: 0.2536\n",
      "Epoch 897/2000, Train Loss: 0.0770, Test Loss: 0.2491\n",
      "Epoch 898/2000, Train Loss: 0.0773, Test Loss: 0.2489\n",
      "Epoch 899/2000, Train Loss: 0.0770, Test Loss: 0.2470\n",
      "Epoch 900/2000, Train Loss: 0.0769, Test Loss: 0.2505\n",
      "Epoch 901/2000, Train Loss: 0.0768, Test Loss: 0.2499\n",
      "Epoch 902/2000, Train Loss: 0.0768, Test Loss: 0.2517\n",
      "Epoch 903/2000, Train Loss: 0.0769, Test Loss: 0.2501\n",
      "Epoch 904/2000, Train Loss: 0.0771, Test Loss: 0.2547\n",
      "Epoch 905/2000, Train Loss: 0.0764, Test Loss: 0.2486\n",
      "Epoch 906/2000, Train Loss: 0.0774, Test Loss: 0.2499\n",
      "Epoch 907/2000, Train Loss: 0.0767, Test Loss: 0.2594\n",
      "Epoch 908/2000, Train Loss: 0.0763, Test Loss: 0.2523\n",
      "Epoch 909/2000, Train Loss: 0.0765, Test Loss: 0.2536\n",
      "Epoch 910/2000, Train Loss: 0.0771, Test Loss: 0.2518\n",
      "Epoch 911/2000, Train Loss: 0.0767, Test Loss: 0.2477\n",
      "Epoch 912/2000, Train Loss: 0.0764, Test Loss: 0.2479\n",
      "Epoch 913/2000, Train Loss: 0.0762, Test Loss: 0.2504\n",
      "Epoch 914/2000, Train Loss: 0.0766, Test Loss: 0.2537\n",
      "Epoch 915/2000, Train Loss: 0.0769, Test Loss: 0.2535\n",
      "Epoch 916/2000, Train Loss: 0.0766, Test Loss: 0.2658\n",
      "Epoch 917/2000, Train Loss: 0.0764, Test Loss: 0.2490\n",
      "Epoch 918/2000, Train Loss: 0.0770, Test Loss: 0.2518\n",
      "Epoch 919/2000, Train Loss: 0.0767, Test Loss: 0.2488\n",
      "Epoch 920/2000, Train Loss: 0.0767, Test Loss: 0.2536\n",
      "Epoch 921/2000, Train Loss: 0.0768, Test Loss: 0.2502\n",
      "Epoch 922/2000, Train Loss: 0.0765, Test Loss: 0.2537\n",
      "Epoch 923/2000, Train Loss: 0.0767, Test Loss: 0.2505\n",
      "Epoch 924/2000, Train Loss: 0.0766, Test Loss: 0.2489\n",
      "Epoch 925/2000, Train Loss: 0.0769, Test Loss: 0.2558\n",
      "Epoch 926/2000, Train Loss: 0.0762, Test Loss: 0.2494\n",
      "Epoch 927/2000, Train Loss: 0.0761, Test Loss: 0.2561\n",
      "Epoch 928/2000, Train Loss: 0.0760, Test Loss: 0.2500\n",
      "Epoch 929/2000, Train Loss: 0.0770, Test Loss: 0.2606\n",
      "Epoch 930/2000, Train Loss: 0.0761, Test Loss: 0.2509\n",
      "Epoch 931/2000, Train Loss: 0.0762, Test Loss: 0.2508\n",
      "Epoch 932/2000, Train Loss: 0.0761, Test Loss: 0.2532\n",
      "Epoch 933/2000, Train Loss: 0.0770, Test Loss: 0.2575\n",
      "Epoch 934/2000, Train Loss: 0.0765, Test Loss: 0.2545\n",
      "Epoch 935/2000, Train Loss: 0.0763, Test Loss: 0.2501\n",
      "Epoch 936/2000, Train Loss: 0.0766, Test Loss: 0.2505\n",
      "Epoch 937/2000, Train Loss: 0.0762, Test Loss: 0.2505\n",
      "Epoch 938/2000, Train Loss: 0.0763, Test Loss: 0.2551\n",
      "Epoch 939/2000, Train Loss: 0.0761, Test Loss: 0.2517\n",
      "Epoch 940/2000, Train Loss: 0.0761, Test Loss: 0.2511\n",
      "Epoch 941/2000, Train Loss: 0.0759, Test Loss: 0.2566\n",
      "Epoch 942/2000, Train Loss: 0.0757, Test Loss: 0.2507\n",
      "Epoch 943/2000, Train Loss: 0.0759, Test Loss: 0.2519\n",
      "Epoch 944/2000, Train Loss: 0.0760, Test Loss: 0.2529\n",
      "Epoch 945/2000, Train Loss: 0.0760, Test Loss: 0.2591\n",
      "Epoch 946/2000, Train Loss: 0.0761, Test Loss: 0.2500\n",
      "Epoch 947/2000, Train Loss: 0.0763, Test Loss: 0.2532\n",
      "Epoch 948/2000, Train Loss: 0.0760, Test Loss: 0.2581\n",
      "Epoch 949/2000, Train Loss: 0.0763, Test Loss: 0.2591\n",
      "Epoch 950/2000, Train Loss: 0.0757, Test Loss: 0.2523\n",
      "Epoch 951/2000, Train Loss: 0.0761, Test Loss: 0.2511\n",
      "Epoch 952/2000, Train Loss: 0.0764, Test Loss: 0.2592\n",
      "Epoch 953/2000, Train Loss: 0.0762, Test Loss: 0.2525\n",
      "Epoch 954/2000, Train Loss: 0.0756, Test Loss: 0.2529\n",
      "Epoch 955/2000, Train Loss: 0.0761, Test Loss: 0.2517\n",
      "Epoch 956/2000, Train Loss: 0.0756, Test Loss: 0.2577\n",
      "Epoch 957/2000, Train Loss: 0.0757, Test Loss: 0.2520\n",
      "Epoch 958/2000, Train Loss: 0.0755, Test Loss: 0.2577\n",
      "Epoch 959/2000, Train Loss: 0.0756, Test Loss: 0.2498\n",
      "Epoch 960/2000, Train Loss: 0.0756, Test Loss: 0.2518\n",
      "Epoch 961/2000, Train Loss: 0.0758, Test Loss: 0.2518\n",
      "Epoch 962/2000, Train Loss: 0.0759, Test Loss: 0.2522\n",
      "Epoch 963/2000, Train Loss: 0.0753, Test Loss: 0.2524\n",
      "Epoch 964/2000, Train Loss: 0.0758, Test Loss: 0.2505\n",
      "Epoch 965/2000, Train Loss: 0.0754, Test Loss: 0.2509\n",
      "Epoch 966/2000, Train Loss: 0.0754, Test Loss: 0.2511\n",
      "Epoch 967/2000, Train Loss: 0.0758, Test Loss: 0.2557\n",
      "Epoch 968/2000, Train Loss: 0.0753, Test Loss: 0.2552\n",
      "Epoch 969/2000, Train Loss: 0.0755, Test Loss: 0.2527\n",
      "Epoch 970/2000, Train Loss: 0.0756, Test Loss: 0.2514\n",
      "Epoch 971/2000, Train Loss: 0.0750, Test Loss: 0.2520\n",
      "Epoch 972/2000, Train Loss: 0.0752, Test Loss: 0.2548\n",
      "Epoch 973/2000, Train Loss: 0.0755, Test Loss: 0.2588\n",
      "Epoch 974/2000, Train Loss: 0.0754, Test Loss: 0.2589\n",
      "Epoch 975/2000, Train Loss: 0.0752, Test Loss: 0.2583\n",
      "Epoch 976/2000, Train Loss: 0.0754, Test Loss: 0.2525\n",
      "Epoch 977/2000, Train Loss: 0.0754, Test Loss: 0.2539\n",
      "Epoch 978/2000, Train Loss: 0.0761, Test Loss: 0.2597\n",
      "Epoch 979/2000, Train Loss: 0.0752, Test Loss: 0.2616\n",
      "Epoch 980/2000, Train Loss: 0.0752, Test Loss: 0.2595\n",
      "Epoch 981/2000, Train Loss: 0.0754, Test Loss: 0.2576\n",
      "Epoch 982/2000, Train Loss: 0.0748, Test Loss: 0.2520\n",
      "Epoch 983/2000, Train Loss: 0.0755, Test Loss: 0.2539\n",
      "Epoch 984/2000, Train Loss: 0.0754, Test Loss: 0.2583\n",
      "Epoch 985/2000, Train Loss: 0.0751, Test Loss: 0.2555\n",
      "Epoch 986/2000, Train Loss: 0.0758, Test Loss: 0.2564\n",
      "Epoch 987/2000, Train Loss: 0.0752, Test Loss: 0.2519\n",
      "Epoch 988/2000, Train Loss: 0.0751, Test Loss: 0.2554\n",
      "Epoch 989/2000, Train Loss: 0.0755, Test Loss: 0.2625\n",
      "Epoch 990/2000, Train Loss: 0.0752, Test Loss: 0.2524\n",
      "Epoch 991/2000, Train Loss: 0.0752, Test Loss: 0.2549\n",
      "Epoch 992/2000, Train Loss: 0.0754, Test Loss: 0.2537\n",
      "Epoch 993/2000, Train Loss: 0.0752, Test Loss: 0.2589\n",
      "Epoch 994/2000, Train Loss: 0.0752, Test Loss: 0.2587\n",
      "Epoch 995/2000, Train Loss: 0.0747, Test Loss: 0.2639\n",
      "Epoch 996/2000, Train Loss: 0.0753, Test Loss: 0.2532\n",
      "Epoch 997/2000, Train Loss: 0.0749, Test Loss: 0.2588\n",
      "Epoch 998/2000, Train Loss: 0.0746, Test Loss: 0.2569\n",
      "Epoch 999/2000, Train Loss: 0.0748, Test Loss: 0.2532\n",
      "Epoch 1000/2000, Train Loss: 0.0749, Test Loss: 0.2598\n",
      "Epoch 1001/2000, Train Loss: 0.0749, Test Loss: 0.2533\n",
      "Epoch 1002/2000, Train Loss: 0.0752, Test Loss: 0.2544\n",
      "Epoch 1003/2000, Train Loss: 0.0747, Test Loss: 0.2541\n",
      "Epoch 1004/2000, Train Loss: 0.0746, Test Loss: 0.2549\n",
      "Epoch 1005/2000, Train Loss: 0.0746, Test Loss: 0.2614\n",
      "Epoch 1006/2000, Train Loss: 0.0747, Test Loss: 0.2582\n",
      "Epoch 1007/2000, Train Loss: 0.0749, Test Loss: 0.2547\n",
      "Epoch 1008/2000, Train Loss: 0.0746, Test Loss: 0.2536\n",
      "Epoch 1009/2000, Train Loss: 0.0744, Test Loss: 0.2535\n",
      "Epoch 1010/2000, Train Loss: 0.0743, Test Loss: 0.2619\n",
      "Epoch 1011/2000, Train Loss: 0.0746, Test Loss: 0.2545\n",
      "Epoch 1012/2000, Train Loss: 0.0750, Test Loss: 0.2550\n",
      "Epoch 1013/2000, Train Loss: 0.0746, Test Loss: 0.2613\n",
      "Epoch 1014/2000, Train Loss: 0.0749, Test Loss: 0.2556\n",
      "Epoch 1015/2000, Train Loss: 0.0747, Test Loss: 0.2537\n",
      "Epoch 1016/2000, Train Loss: 0.0747, Test Loss: 0.2624\n",
      "Epoch 1017/2000, Train Loss: 0.0747, Test Loss: 0.2568\n",
      "Epoch 1018/2000, Train Loss: 0.0744, Test Loss: 0.2543\n",
      "Epoch 1019/2000, Train Loss: 0.0743, Test Loss: 0.2555\n",
      "Epoch 1020/2000, Train Loss: 0.0746, Test Loss: 0.2542\n",
      "Epoch 1021/2000, Train Loss: 0.0744, Test Loss: 0.2536\n",
      "Epoch 1022/2000, Train Loss: 0.0748, Test Loss: 0.2681\n",
      "Epoch 1023/2000, Train Loss: 0.0745, Test Loss: 0.2589\n",
      "Epoch 1024/2000, Train Loss: 0.0743, Test Loss: 0.2565\n",
      "Epoch 1025/2000, Train Loss: 0.0741, Test Loss: 0.2531\n",
      "Epoch 1026/2000, Train Loss: 0.0742, Test Loss: 0.2551\n",
      "Epoch 1027/2000, Train Loss: 0.0744, Test Loss: 0.2596\n",
      "Epoch 1028/2000, Train Loss: 0.0745, Test Loss: 0.2579\n",
      "Epoch 1029/2000, Train Loss: 0.0744, Test Loss: 0.2602\n",
      "Epoch 1030/2000, Train Loss: 0.0745, Test Loss: 0.2561\n",
      "Epoch 1031/2000, Train Loss: 0.0740, Test Loss: 0.2734\n",
      "Epoch 1032/2000, Train Loss: 0.0744, Test Loss: 0.2565\n",
      "Epoch 1033/2000, Train Loss: 0.0742, Test Loss: 0.2545\n",
      "Epoch 1034/2000, Train Loss: 0.0738, Test Loss: 0.2663\n",
      "Epoch 1035/2000, Train Loss: 0.0745, Test Loss: 0.2565\n",
      "Epoch 1036/2000, Train Loss: 0.0744, Test Loss: 0.2569\n",
      "Epoch 1037/2000, Train Loss: 0.0742, Test Loss: 0.2544\n",
      "Epoch 1038/2000, Train Loss: 0.0744, Test Loss: 0.2612\n",
      "Epoch 1039/2000, Train Loss: 0.0741, Test Loss: 0.2550\n",
      "Epoch 1040/2000, Train Loss: 0.0742, Test Loss: 0.2608\n",
      "Epoch 1041/2000, Train Loss: 0.0735, Test Loss: 0.2600\n",
      "Epoch 1042/2000, Train Loss: 0.0738, Test Loss: 0.2560\n",
      "Epoch 1043/2000, Train Loss: 0.0743, Test Loss: 0.2555\n",
      "Epoch 1044/2000, Train Loss: 0.0740, Test Loss: 0.2537\n",
      "Epoch 1045/2000, Train Loss: 0.0739, Test Loss: 0.2552\n",
      "Epoch 1046/2000, Train Loss: 0.0738, Test Loss: 0.2585\n",
      "Epoch 1047/2000, Train Loss: 0.0738, Test Loss: 0.2570\n",
      "Epoch 1048/2000, Train Loss: 0.0744, Test Loss: 0.2574\n",
      "Epoch 1049/2000, Train Loss: 0.0742, Test Loss: 0.2593\n",
      "Epoch 1050/2000, Train Loss: 0.0739, Test Loss: 0.2554\n",
      "Epoch 1051/2000, Train Loss: 0.0743, Test Loss: 0.2647\n",
      "Epoch 1052/2000, Train Loss: 0.0745, Test Loss: 0.2566\n",
      "Epoch 1053/2000, Train Loss: 0.0742, Test Loss: 0.2579\n",
      "Epoch 1054/2000, Train Loss: 0.0737, Test Loss: 0.2575\n",
      "Epoch 1055/2000, Train Loss: 0.0742, Test Loss: 0.2567\n",
      "Epoch 1056/2000, Train Loss: 0.0735, Test Loss: 0.2553\n",
      "Epoch 1057/2000, Train Loss: 0.0742, Test Loss: 0.2649\n",
      "Epoch 1058/2000, Train Loss: 0.0743, Test Loss: 0.2557\n",
      "Epoch 1059/2000, Train Loss: 0.0740, Test Loss: 0.2566\n",
      "Epoch 1060/2000, Train Loss: 0.0738, Test Loss: 0.2587\n",
      "Epoch 1061/2000, Train Loss: 0.0737, Test Loss: 0.2635\n",
      "Epoch 1062/2000, Train Loss: 0.0737, Test Loss: 0.2564\n",
      "Epoch 1063/2000, Train Loss: 0.0738, Test Loss: 0.2615\n",
      "Epoch 1064/2000, Train Loss: 0.0739, Test Loss: 0.2608\n",
      "Epoch 1065/2000, Train Loss: 0.0742, Test Loss: 0.2600\n",
      "Epoch 1066/2000, Train Loss: 0.0734, Test Loss: 0.2599\n",
      "Epoch 1067/2000, Train Loss: 0.0737, Test Loss: 0.2657\n",
      "Epoch 1068/2000, Train Loss: 0.0739, Test Loss: 0.2587\n",
      "Epoch 1069/2000, Train Loss: 0.0733, Test Loss: 0.2561\n",
      "Epoch 1070/2000, Train Loss: 0.0734, Test Loss: 0.2630\n",
      "Epoch 1071/2000, Train Loss: 0.0738, Test Loss: 0.2548\n",
      "Epoch 1072/2000, Train Loss: 0.0733, Test Loss: 0.2584\n",
      "Epoch 1073/2000, Train Loss: 0.0740, Test Loss: 0.2616\n",
      "Epoch 1074/2000, Train Loss: 0.0737, Test Loss: 0.2614\n",
      "Epoch 1075/2000, Train Loss: 0.0733, Test Loss: 0.2579\n",
      "Epoch 1076/2000, Train Loss: 0.0734, Test Loss: 0.2594\n",
      "Epoch 1077/2000, Train Loss: 0.0734, Test Loss: 0.2604\n",
      "Epoch 1078/2000, Train Loss: 0.0740, Test Loss: 0.2581\n",
      "Epoch 1079/2000, Train Loss: 0.0739, Test Loss: 0.2583\n",
      "Epoch 1080/2000, Train Loss: 0.0739, Test Loss: 0.2590\n",
      "Epoch 1081/2000, Train Loss: 0.0728, Test Loss: 0.2601\n",
      "Epoch 1082/2000, Train Loss: 0.0733, Test Loss: 0.2646\n",
      "Epoch 1083/2000, Train Loss: 0.0737, Test Loss: 0.2633\n",
      "Epoch 1084/2000, Train Loss: 0.0737, Test Loss: 0.2558\n",
      "Epoch 1085/2000, Train Loss: 0.0730, Test Loss: 0.2570\n",
      "Epoch 1086/2000, Train Loss: 0.0736, Test Loss: 0.2581\n",
      "Epoch 1087/2000, Train Loss: 0.0736, Test Loss: 0.2556\n",
      "Epoch 1088/2000, Train Loss: 0.0735, Test Loss: 0.2617\n",
      "Epoch 1089/2000, Train Loss: 0.0730, Test Loss: 0.2636\n",
      "Epoch 1090/2000, Train Loss: 0.0735, Test Loss: 0.2575\n",
      "Epoch 1091/2000, Train Loss: 0.0735, Test Loss: 0.2602\n",
      "Epoch 1092/2000, Train Loss: 0.0728, Test Loss: 0.2598\n",
      "Epoch 1093/2000, Train Loss: 0.0739, Test Loss: 0.2599\n",
      "Epoch 1094/2000, Train Loss: 0.0734, Test Loss: 0.2574\n",
      "Epoch 1095/2000, Train Loss: 0.0731, Test Loss: 0.2597\n",
      "Epoch 1096/2000, Train Loss: 0.0729, Test Loss: 0.2562\n",
      "Epoch 1097/2000, Train Loss: 0.0730, Test Loss: 0.2612\n",
      "Epoch 1098/2000, Train Loss: 0.0732, Test Loss: 0.2599\n",
      "Epoch 1099/2000, Train Loss: 0.0729, Test Loss: 0.2574\n",
      "Epoch 1100/2000, Train Loss: 0.0728, Test Loss: 0.2581\n",
      "Epoch 1101/2000, Train Loss: 0.0731, Test Loss: 0.2621\n",
      "Epoch 1102/2000, Train Loss: 0.0733, Test Loss: 0.2603\n",
      "Epoch 1103/2000, Train Loss: 0.0738, Test Loss: 0.2601\n",
      "Epoch 1104/2000, Train Loss: 0.0725, Test Loss: 0.2615\n",
      "Epoch 1105/2000, Train Loss: 0.0730, Test Loss: 0.2630\n",
      "Epoch 1106/2000, Train Loss: 0.0728, Test Loss: 0.2585\n",
      "Epoch 1107/2000, Train Loss: 0.0727, Test Loss: 0.2607\n",
      "Epoch 1108/2000, Train Loss: 0.0734, Test Loss: 0.2584\n",
      "Epoch 1109/2000, Train Loss: 0.0732, Test Loss: 0.2634\n",
      "Epoch 1110/2000, Train Loss: 0.0734, Test Loss: 0.2579\n",
      "Epoch 1111/2000, Train Loss: 0.0726, Test Loss: 0.2586\n",
      "Epoch 1112/2000, Train Loss: 0.0734, Test Loss: 0.2583\n",
      "Epoch 1113/2000, Train Loss: 0.0725, Test Loss: 0.2649\n",
      "Epoch 1114/2000, Train Loss: 0.0727, Test Loss: 0.2627\n",
      "Epoch 1115/2000, Train Loss: 0.0729, Test Loss: 0.2577\n",
      "Epoch 1116/2000, Train Loss: 0.0732, Test Loss: 0.2615\n",
      "Epoch 1117/2000, Train Loss: 0.0727, Test Loss: 0.2693\n",
      "Epoch 1118/2000, Train Loss: 0.0721, Test Loss: 0.2674\n",
      "Epoch 1119/2000, Train Loss: 0.0733, Test Loss: 0.2629\n",
      "Epoch 1120/2000, Train Loss: 0.0724, Test Loss: 0.2684\n",
      "Epoch 1121/2000, Train Loss: 0.0726, Test Loss: 0.2596\n",
      "Epoch 1122/2000, Train Loss: 0.0724, Test Loss: 0.2598\n",
      "Epoch 1123/2000, Train Loss: 0.0727, Test Loss: 0.2640\n",
      "Epoch 1124/2000, Train Loss: 0.0727, Test Loss: 0.2682\n",
      "Epoch 1125/2000, Train Loss: 0.0726, Test Loss: 0.2628\n",
      "Epoch 1126/2000, Train Loss: 0.0729, Test Loss: 0.2613\n",
      "Epoch 1127/2000, Train Loss: 0.0727, Test Loss: 0.2646\n",
      "Epoch 1128/2000, Train Loss: 0.0725, Test Loss: 0.2607\n",
      "Epoch 1129/2000, Train Loss: 0.0723, Test Loss: 0.2604\n",
      "Epoch 1130/2000, Train Loss: 0.0730, Test Loss: 0.2601\n",
      "Epoch 1131/2000, Train Loss: 0.0726, Test Loss: 0.2600\n",
      "Epoch 1132/2000, Train Loss: 0.0728, Test Loss: 0.2689\n",
      "Epoch 1133/2000, Train Loss: 0.0726, Test Loss: 0.2597\n",
      "Epoch 1134/2000, Train Loss: 0.0724, Test Loss: 0.2691\n",
      "Epoch 1135/2000, Train Loss: 0.0728, Test Loss: 0.2582\n",
      "Epoch 1136/2000, Train Loss: 0.0722, Test Loss: 0.2617\n",
      "Epoch 1137/2000, Train Loss: 0.0726, Test Loss: 0.2702\n",
      "Epoch 1138/2000, Train Loss: 0.0725, Test Loss: 0.2595\n",
      "Epoch 1139/2000, Train Loss: 0.0721, Test Loss: 0.2672\n",
      "Epoch 1140/2000, Train Loss: 0.0724, Test Loss: 0.2624\n",
      "Epoch 1141/2000, Train Loss: 0.0724, Test Loss: 0.2604\n",
      "Epoch 1142/2000, Train Loss: 0.0724, Test Loss: 0.2632\n",
      "Epoch 1143/2000, Train Loss: 0.0721, Test Loss: 0.2603\n",
      "Epoch 1144/2000, Train Loss: 0.0722, Test Loss: 0.2808\n",
      "Epoch 1145/2000, Train Loss: 0.0720, Test Loss: 0.2617\n",
      "Epoch 1146/2000, Train Loss: 0.0723, Test Loss: 0.2632\n",
      "Epoch 1147/2000, Train Loss: 0.0723, Test Loss: 0.2630\n",
      "Epoch 1148/2000, Train Loss: 0.0720, Test Loss: 0.2672\n",
      "Epoch 1149/2000, Train Loss: 0.0724, Test Loss: 0.2615\n",
      "Epoch 1150/2000, Train Loss: 0.0725, Test Loss: 0.2690\n",
      "Epoch 1151/2000, Train Loss: 0.0718, Test Loss: 0.2603\n",
      "Epoch 1152/2000, Train Loss: 0.0726, Test Loss: 0.2684\n",
      "Epoch 1153/2000, Train Loss: 0.0722, Test Loss: 0.2613\n",
      "Epoch 1154/2000, Train Loss: 0.0718, Test Loss: 0.2618\n",
      "Epoch 1155/2000, Train Loss: 0.0720, Test Loss: 0.2650\n",
      "Epoch 1156/2000, Train Loss: 0.0726, Test Loss: 0.2620\n",
      "Epoch 1157/2000, Train Loss: 0.0721, Test Loss: 0.2627\n",
      "Epoch 1158/2000, Train Loss: 0.0722, Test Loss: 0.2609\n",
      "Epoch 1159/2000, Train Loss: 0.0719, Test Loss: 0.2651\n",
      "Epoch 1160/2000, Train Loss: 0.0724, Test Loss: 0.2631\n",
      "Epoch 1161/2000, Train Loss: 0.0721, Test Loss: 0.2616\n",
      "Epoch 1162/2000, Train Loss: 0.0720, Test Loss: 0.2601\n",
      "Epoch 1163/2000, Train Loss: 0.0719, Test Loss: 0.2614\n",
      "Epoch 1164/2000, Train Loss: 0.0720, Test Loss: 0.2616\n",
      "Epoch 1165/2000, Train Loss: 0.0719, Test Loss: 0.2626\n",
      "Epoch 1166/2000, Train Loss: 0.0719, Test Loss: 0.2624\n",
      "Epoch 1167/2000, Train Loss: 0.0718, Test Loss: 0.2619\n",
      "Epoch 1168/2000, Train Loss: 0.0717, Test Loss: 0.2613\n",
      "Epoch 1169/2000, Train Loss: 0.0717, Test Loss: 0.2628\n",
      "Epoch 1170/2000, Train Loss: 0.0716, Test Loss: 0.2610\n",
      "Epoch 1171/2000, Train Loss: 0.0716, Test Loss: 0.2809\n",
      "Epoch 1172/2000, Train Loss: 0.0718, Test Loss: 0.2636\n",
      "Epoch 1173/2000, Train Loss: 0.0719, Test Loss: 0.2615\n",
      "Epoch 1174/2000, Train Loss: 0.0719, Test Loss: 0.2616\n",
      "Epoch 1175/2000, Train Loss: 0.0719, Test Loss: 0.2623\n",
      "Epoch 1176/2000, Train Loss: 0.0715, Test Loss: 0.2654\n",
      "Epoch 1177/2000, Train Loss: 0.0717, Test Loss: 0.2635\n",
      "Epoch 1178/2000, Train Loss: 0.0718, Test Loss: 0.2657\n",
      "Epoch 1179/2000, Train Loss: 0.0716, Test Loss: 0.2686\n",
      "Epoch 1180/2000, Train Loss: 0.0721, Test Loss: 0.2617\n",
      "Epoch 1181/2000, Train Loss: 0.0717, Test Loss: 0.2670\n",
      "Epoch 1182/2000, Train Loss: 0.0715, Test Loss: 0.2619\n",
      "Epoch 1183/2000, Train Loss: 0.0714, Test Loss: 0.2711\n",
      "Epoch 1184/2000, Train Loss: 0.0719, Test Loss: 0.2648\n",
      "Epoch 1185/2000, Train Loss: 0.0719, Test Loss: 0.2753\n",
      "Epoch 1186/2000, Train Loss: 0.0715, Test Loss: 0.2632\n",
      "Epoch 1187/2000, Train Loss: 0.0715, Test Loss: 0.2631\n",
      "Epoch 1188/2000, Train Loss: 0.0715, Test Loss: 0.2624\n",
      "Epoch 1189/2000, Train Loss: 0.0718, Test Loss: 0.2740\n",
      "Epoch 1190/2000, Train Loss: 0.0715, Test Loss: 0.2663\n",
      "Epoch 1191/2000, Train Loss: 0.0721, Test Loss: 0.2662\n",
      "Epoch 1192/2000, Train Loss: 0.0716, Test Loss: 0.2659\n",
      "Epoch 1193/2000, Train Loss: 0.0711, Test Loss: 0.2651\n",
      "Epoch 1194/2000, Train Loss: 0.0715, Test Loss: 0.2654\n",
      "Epoch 1195/2000, Train Loss: 0.0715, Test Loss: 0.2641\n",
      "Epoch 1196/2000, Train Loss: 0.0715, Test Loss: 0.2748\n",
      "Epoch 1197/2000, Train Loss: 0.0715, Test Loss: 0.2674\n",
      "Epoch 1198/2000, Train Loss: 0.0715, Test Loss: 0.2635\n",
      "Epoch 1199/2000, Train Loss: 0.0714, Test Loss: 0.2628\n",
      "Epoch 1200/2000, Train Loss: 0.0716, Test Loss: 0.2623\n",
      "Epoch 1201/2000, Train Loss: 0.0713, Test Loss: 0.2628\n",
      "Epoch 1202/2000, Train Loss: 0.0715, Test Loss: 0.2671\n",
      "Epoch 1203/2000, Train Loss: 0.0718, Test Loss: 0.2662\n",
      "Epoch 1204/2000, Train Loss: 0.0713, Test Loss: 0.2629\n",
      "Epoch 1205/2000, Train Loss: 0.0713, Test Loss: 0.2760\n",
      "Epoch 1206/2000, Train Loss: 0.0710, Test Loss: 0.2634\n",
      "Epoch 1207/2000, Train Loss: 0.0715, Test Loss: 0.2645\n",
      "Epoch 1208/2000, Train Loss: 0.0713, Test Loss: 0.2622\n",
      "Epoch 1209/2000, Train Loss: 0.0713, Test Loss: 0.2640\n",
      "Epoch 1210/2000, Train Loss: 0.0713, Test Loss: 0.2631\n",
      "Epoch 1211/2000, Train Loss: 0.0711, Test Loss: 0.2749\n",
      "Epoch 1212/2000, Train Loss: 0.0715, Test Loss: 0.2717\n",
      "Epoch 1213/2000, Train Loss: 0.0710, Test Loss: 0.2648\n",
      "Epoch 1214/2000, Train Loss: 0.0715, Test Loss: 0.2651\n",
      "Epoch 1215/2000, Train Loss: 0.0711, Test Loss: 0.2640\n",
      "Epoch 1216/2000, Train Loss: 0.0715, Test Loss: 0.2698\n",
      "Epoch 1217/2000, Train Loss: 0.0714, Test Loss: 0.2644\n",
      "Epoch 1218/2000, Train Loss: 0.0718, Test Loss: 0.2653\n",
      "Epoch 1219/2000, Train Loss: 0.0705, Test Loss: 0.2697\n",
      "Epoch 1220/2000, Train Loss: 0.0712, Test Loss: 0.2649\n",
      "Epoch 1221/2000, Train Loss: 0.0712, Test Loss: 0.2645\n",
      "Epoch 1222/2000, Train Loss: 0.0708, Test Loss: 0.2644\n",
      "Epoch 1223/2000, Train Loss: 0.0708, Test Loss: 0.2678\n",
      "Epoch 1224/2000, Train Loss: 0.0710, Test Loss: 0.2679\n",
      "Epoch 1225/2000, Train Loss: 0.0711, Test Loss: 0.2637\n",
      "Epoch 1226/2000, Train Loss: 0.0711, Test Loss: 0.2657\n",
      "Epoch 1227/2000, Train Loss: 0.0710, Test Loss: 0.2804\n",
      "Epoch 1228/2000, Train Loss: 0.0711, Test Loss: 0.2647\n",
      "Epoch 1229/2000, Train Loss: 0.0706, Test Loss: 0.2724\n",
      "Epoch 1230/2000, Train Loss: 0.0707, Test Loss: 0.2708\n",
      "Epoch 1231/2000, Train Loss: 0.0716, Test Loss: 0.2659\n",
      "Epoch 1232/2000, Train Loss: 0.0708, Test Loss: 0.2678\n",
      "Epoch 1233/2000, Train Loss: 0.0707, Test Loss: 0.2720\n",
      "Epoch 1234/2000, Train Loss: 0.0707, Test Loss: 0.2641\n",
      "Epoch 1235/2000, Train Loss: 0.0710, Test Loss: 0.2644\n",
      "Epoch 1236/2000, Train Loss: 0.0705, Test Loss: 0.2684\n",
      "Epoch 1237/2000, Train Loss: 0.0710, Test Loss: 0.2655\n",
      "Epoch 1238/2000, Train Loss: 0.0705, Test Loss: 0.2631\n",
      "Epoch 1239/2000, Train Loss: 0.0707, Test Loss: 0.2665\n",
      "Epoch 1240/2000, Train Loss: 0.0704, Test Loss: 0.2681\n",
      "Epoch 1241/2000, Train Loss: 0.0712, Test Loss: 0.2678\n",
      "Epoch 1242/2000, Train Loss: 0.0707, Test Loss: 0.2662\n",
      "Epoch 1243/2000, Train Loss: 0.0702, Test Loss: 0.2709\n",
      "Epoch 1244/2000, Train Loss: 0.0711, Test Loss: 0.2657\n",
      "Epoch 1245/2000, Train Loss: 0.0707, Test Loss: 0.2723\n",
      "Epoch 1246/2000, Train Loss: 0.0704, Test Loss: 0.2651\n",
      "Epoch 1247/2000, Train Loss: 0.0703, Test Loss: 0.2704\n",
      "Epoch 1248/2000, Train Loss: 0.0711, Test Loss: 0.2643\n",
      "Epoch 1249/2000, Train Loss: 0.0707, Test Loss: 0.2642\n",
      "Epoch 1250/2000, Train Loss: 0.0709, Test Loss: 0.2659\n",
      "Epoch 1251/2000, Train Loss: 0.0705, Test Loss: 0.2695\n",
      "Epoch 1252/2000, Train Loss: 0.0708, Test Loss: 0.2700\n",
      "Epoch 1253/2000, Train Loss: 0.0703, Test Loss: 0.2655\n",
      "Epoch 1254/2000, Train Loss: 0.0702, Test Loss: 0.2658\n",
      "Epoch 1255/2000, Train Loss: 0.0706, Test Loss: 0.2696\n",
      "Epoch 1256/2000, Train Loss: 0.0709, Test Loss: 0.2775\n",
      "Epoch 1257/2000, Train Loss: 0.0707, Test Loss: 0.2711\n",
      "Epoch 1258/2000, Train Loss: 0.0710, Test Loss: 0.2658\n",
      "Epoch 1259/2000, Train Loss: 0.0699, Test Loss: 0.2745\n",
      "Epoch 1260/2000, Train Loss: 0.0707, Test Loss: 0.2760\n",
      "Epoch 1261/2000, Train Loss: 0.0703, Test Loss: 0.2665\n",
      "Epoch 1262/2000, Train Loss: 0.0701, Test Loss: 0.2713\n",
      "Epoch 1263/2000, Train Loss: 0.0704, Test Loss: 0.2704\n",
      "Epoch 1264/2000, Train Loss: 0.0703, Test Loss: 0.2744\n",
      "Epoch 1265/2000, Train Loss: 0.0706, Test Loss: 0.2756\n",
      "Epoch 1266/2000, Train Loss: 0.0703, Test Loss: 0.2666\n",
      "Epoch 1267/2000, Train Loss: 0.0705, Test Loss: 0.2664\n",
      "Epoch 1268/2000, Train Loss: 0.0706, Test Loss: 0.2734\n",
      "Epoch 1269/2000, Train Loss: 0.0707, Test Loss: 0.2665\n",
      "Epoch 1270/2000, Train Loss: 0.0705, Test Loss: 0.2706\n",
      "Epoch 1271/2000, Train Loss: 0.0706, Test Loss: 0.2671\n",
      "Epoch 1272/2000, Train Loss: 0.0704, Test Loss: 0.2717\n",
      "Epoch 1273/2000, Train Loss: 0.0701, Test Loss: 0.2709\n",
      "Epoch 1274/2000, Train Loss: 0.0701, Test Loss: 0.2714\n",
      "Epoch 1275/2000, Train Loss: 0.0702, Test Loss: 0.2661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1276/2000, Train Loss: 0.0702, Test Loss: 0.2743\n",
      "Epoch 1277/2000, Train Loss: 0.0703, Test Loss: 0.2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:16.631944, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1278/2000, Train Loss: 0.0703, Test Loss: 0.2682\n",
      "Epoch 1279/2000, Train Loss: 0.0705, Test Loss: 0.2687\n",
      "Epoch 1280/2000, Train Loss: 0.0702, Test Loss: 0.2740\n",
      "Epoch 1281/2000, Train Loss: 0.0706, Test Loss: 0.2669\n",
      "Epoch 1282/2000, Train Loss: 0.0704, Test Loss: 0.2718\n",
      "Epoch 1283/2000, Train Loss: 0.0703, Test Loss: 0.2663\n",
      "Epoch 1284/2000, Train Loss: 0.0703, Test Loss: 0.2663\n",
      "Epoch 1285/2000, Train Loss: 0.0698, Test Loss: 0.2692\n",
      "Epoch 1286/2000, Train Loss: 0.0697, Test Loss: 0.2709\n",
      "Epoch 1287/2000, Train Loss: 0.0696, Test Loss: 0.2750\n",
      "Epoch 1288/2000, Train Loss: 0.0702, Test Loss: 0.2666\n",
      "Epoch 1289/2000, Train Loss: 0.0701, Test Loss: 0.2687\n",
      "Epoch 1290/2000, Train Loss: 0.0699, Test Loss: 0.2679\n",
      "Epoch 1291/2000, Train Loss: 0.0705, Test Loss: 0.2679\n",
      "Epoch 1292/2000, Train Loss: 0.0706, Test Loss: 0.2673\n",
      "Epoch 1293/2000, Train Loss: 0.0698, Test Loss: 0.2704\n",
      "Epoch 1294/2000, Train Loss: 0.0698, Test Loss: 0.2683\n",
      "Epoch 1295/2000, Train Loss: 0.0703, Test Loss: 0.2803\n",
      "Epoch 1296/2000, Train Loss: 0.0700, Test Loss: 0.2762\n",
      "Epoch 1297/2000, Train Loss: 0.0704, Test Loss: 0.2676\n",
      "Epoch 1298/2000, Train Loss: 0.0700, Test Loss: 0.2707\n",
      "Epoch 1299/2000, Train Loss: 0.0698, Test Loss: 0.2685\n",
      "Epoch 1300/2000, Train Loss: 0.0706, Test Loss: 0.2678\n",
      "Epoch 1301/2000, Train Loss: 0.0695, Test Loss: 0.2688\n",
      "Epoch 1302/2000, Train Loss: 0.0699, Test Loss: 0.2677\n",
      "Epoch 1303/2000, Train Loss: 0.0698, Test Loss: 0.2740\n",
      "Epoch 1304/2000, Train Loss: 0.0695, Test Loss: 0.2690\n",
      "Epoch 1305/2000, Train Loss: 0.0695, Test Loss: 0.2680\n",
      "Epoch 1306/2000, Train Loss: 0.0702, Test Loss: 0.2672\n",
      "Epoch 1307/2000, Train Loss: 0.0699, Test Loss: 0.2775\n",
      "Epoch 1308/2000, Train Loss: 0.0699, Test Loss: 0.2666\n",
      "Epoch 1309/2000, Train Loss: 0.0694, Test Loss: 0.2686\n",
      "Epoch 1310/2000, Train Loss: 0.0700, Test Loss: 0.2724\n",
      "Epoch 1311/2000, Train Loss: 0.0694, Test Loss: 0.2734\n",
      "Epoch 1312/2000, Train Loss: 0.0693, Test Loss: 0.2693\n",
      "Epoch 1313/2000, Train Loss: 0.0697, Test Loss: 0.2668\n",
      "Epoch 1314/2000, Train Loss: 0.0701, Test Loss: 0.2673\n",
      "Epoch 1315/2000, Train Loss: 0.0699, Test Loss: 0.2684\n",
      "Epoch 1316/2000, Train Loss: 0.0694, Test Loss: 0.2735\n",
      "Epoch 1317/2000, Train Loss: 0.0699, Test Loss: 0.2687\n",
      "Epoch 1318/2000, Train Loss: 0.0693, Test Loss: 0.2702\n",
      "Epoch 1319/2000, Train Loss: 0.0697, Test Loss: 0.2730\n",
      "Epoch 1320/2000, Train Loss: 0.0695, Test Loss: 0.2692\n",
      "Epoch 1321/2000, Train Loss: 0.0697, Test Loss: 0.2686\n",
      "Epoch 1322/2000, Train Loss: 0.0694, Test Loss: 0.2704\n",
      "Epoch 1323/2000, Train Loss: 0.0696, Test Loss: 0.2692\n",
      "Epoch 1324/2000, Train Loss: 0.0696, Test Loss: 0.2720\n",
      "Epoch 1325/2000, Train Loss: 0.0700, Test Loss: 0.2770\n",
      "Epoch 1326/2000, Train Loss: 0.0694, Test Loss: 0.2708\n",
      "Epoch 1327/2000, Train Loss: 0.0699, Test Loss: 0.2748\n",
      "Epoch 1328/2000, Train Loss: 0.0694, Test Loss: 0.2883\n",
      "Epoch 1329/2000, Train Loss: 0.0695, Test Loss: 0.2703\n",
      "Epoch 1330/2000, Train Loss: 0.0695, Test Loss: 0.2746\n",
      "Epoch 1331/2000, Train Loss: 0.0695, Test Loss: 0.2820\n",
      "Epoch 1332/2000, Train Loss: 0.0692, Test Loss: 0.2702\n",
      "Epoch 1333/2000, Train Loss: 0.0694, Test Loss: 0.2833\n",
      "Epoch 1334/2000, Train Loss: 0.0696, Test Loss: 0.2694\n",
      "Epoch 1335/2000, Train Loss: 0.0689, Test Loss: 0.2709\n",
      "Epoch 1336/2000, Train Loss: 0.0692, Test Loss: 0.2704\n",
      "Epoch 1337/2000, Train Loss: 0.0694, Test Loss: 0.2686\n",
      "Epoch 1338/2000, Train Loss: 0.0691, Test Loss: 0.2764\n",
      "Epoch 1339/2000, Train Loss: 0.0693, Test Loss: 0.2754\n",
      "Epoch 1340/2000, Train Loss: 0.0692, Test Loss: 0.2708\n",
      "Epoch 1341/2000, Train Loss: 0.0695, Test Loss: 0.2734\n",
      "Epoch 1342/2000, Train Loss: 0.0692, Test Loss: 0.2683\n",
      "Epoch 1343/2000, Train Loss: 0.0695, Test Loss: 0.2758\n",
      "Epoch 1344/2000, Train Loss: 0.0690, Test Loss: 0.2706\n",
      "Epoch 1345/2000, Train Loss: 0.0695, Test Loss: 0.2719\n",
      "Epoch 1346/2000, Train Loss: 0.0699, Test Loss: 0.2708\n",
      "Epoch 1347/2000, Train Loss: 0.0692, Test Loss: 0.2737\n",
      "Epoch 1348/2000, Train Loss: 0.0690, Test Loss: 0.2686\n",
      "Epoch 1349/2000, Train Loss: 0.0692, Test Loss: 0.2800\n",
      "Epoch 1350/2000, Train Loss: 0.0693, Test Loss: 0.2791\n",
      "Epoch 1351/2000, Train Loss: 0.0687, Test Loss: 0.2701\n",
      "Epoch 1352/2000, Train Loss: 0.0689, Test Loss: 0.2695\n",
      "Epoch 1353/2000, Train Loss: 0.0689, Test Loss: 0.2787\n",
      "Epoch 1354/2000, Train Loss: 0.0693, Test Loss: 0.2710\n",
      "Epoch 1355/2000, Train Loss: 0.0691, Test Loss: 0.2697\n",
      "Epoch 1356/2000, Train Loss: 0.0694, Test Loss: 0.2702\n",
      "Epoch 1357/2000, Train Loss: 0.0688, Test Loss: 0.2741\n",
      "Epoch 1358/2000, Train Loss: 0.0692, Test Loss: 0.2803\n",
      "Epoch 1359/2000, Train Loss: 0.0690, Test Loss: 0.2710\n",
      "Epoch 1360/2000, Train Loss: 0.0689, Test Loss: 0.2768\n",
      "Epoch 1361/2000, Train Loss: 0.0691, Test Loss: 0.2734\n",
      "Epoch 1362/2000, Train Loss: 0.0690, Test Loss: 0.2785\n",
      "Epoch 1363/2000, Train Loss: 0.0690, Test Loss: 0.2712\n",
      "Epoch 1364/2000, Train Loss: 0.0691, Test Loss: 0.2739\n",
      "Epoch 1365/2000, Train Loss: 0.0689, Test Loss: 0.2685\n",
      "Epoch 1366/2000, Train Loss: 0.0687, Test Loss: 0.2751\n",
      "Epoch 1367/2000, Train Loss: 0.0694, Test Loss: 0.2721\n",
      "Epoch 1368/2000, Train Loss: 0.0689, Test Loss: 0.2703\n",
      "Epoch 1369/2000, Train Loss: 0.0693, Test Loss: 0.2752\n",
      "Epoch 1370/2000, Train Loss: 0.0688, Test Loss: 0.2876\n",
      "Epoch 1371/2000, Train Loss: 0.0692, Test Loss: 0.2758\n",
      "Epoch 1372/2000, Train Loss: 0.0695, Test Loss: 0.2715\n",
      "Epoch 1373/2000, Train Loss: 0.0690, Test Loss: 0.2717\n",
      "Epoch 1374/2000, Train Loss: 0.0689, Test Loss: 0.2698\n",
      "Epoch 1375/2000, Train Loss: 0.0689, Test Loss: 0.2759\n",
      "Epoch 1376/2000, Train Loss: 0.0693, Test Loss: 0.2743\n",
      "Epoch 1377/2000, Train Loss: 0.0690, Test Loss: 0.2697\n",
      "Epoch 1378/2000, Train Loss: 0.0689, Test Loss: 0.2737\n",
      "Epoch 1379/2000, Train Loss: 0.0686, Test Loss: 0.2715\n",
      "Epoch 1380/2000, Train Loss: 0.0689, Test Loss: 0.2735\n",
      "Epoch 1381/2000, Train Loss: 0.0689, Test Loss: 0.2802\n",
      "Epoch 1382/2000, Train Loss: 0.0686, Test Loss: 0.2733\n",
      "Epoch 1383/2000, Train Loss: 0.0688, Test Loss: 0.2833\n",
      "Epoch 1384/2000, Train Loss: 0.0697, Test Loss: 0.2751\n",
      "Epoch 1385/2000, Train Loss: 0.0686, Test Loss: 0.2723\n",
      "Epoch 1386/2000, Train Loss: 0.0688, Test Loss: 0.2749\n",
      "Epoch 1387/2000, Train Loss: 0.0689, Test Loss: 0.2745\n",
      "Epoch 1388/2000, Train Loss: 0.0689, Test Loss: 0.2717\n",
      "Epoch 1389/2000, Train Loss: 0.0685, Test Loss: 0.2707\n",
      "Epoch 1390/2000, Train Loss: 0.0685, Test Loss: 0.2767\n",
      "Epoch 1391/2000, Train Loss: 0.0687, Test Loss: 0.2847\n",
      "Epoch 1392/2000, Train Loss: 0.0689, Test Loss: 0.2712\n",
      "Epoch 1393/2000, Train Loss: 0.0689, Test Loss: 0.2697\n",
      "Epoch 1394/2000, Train Loss: 0.0692, Test Loss: 0.2783\n",
      "Epoch 1395/2000, Train Loss: 0.0689, Test Loss: 0.2832\n",
      "Epoch 1396/2000, Train Loss: 0.0684, Test Loss: 0.2754\n",
      "Epoch 1397/2000, Train Loss: 0.0681, Test Loss: 0.2746\n",
      "Epoch 1398/2000, Train Loss: 0.0684, Test Loss: 0.2773\n",
      "Epoch 1399/2000, Train Loss: 0.0683, Test Loss: 0.2747\n",
      "Epoch 1400/2000, Train Loss: 0.0688, Test Loss: 0.2723\n",
      "Epoch 1401/2000, Train Loss: 0.0683, Test Loss: 0.2774\n",
      "Epoch 1402/2000, Train Loss: 0.0687, Test Loss: 0.2723\n",
      "Epoch 1403/2000, Train Loss: 0.0682, Test Loss: 0.2717\n",
      "Epoch 1404/2000, Train Loss: 0.0683, Test Loss: 0.2748\n",
      "Epoch 1405/2000, Train Loss: 0.0684, Test Loss: 0.2733\n",
      "Epoch 1406/2000, Train Loss: 0.0684, Test Loss: 0.2770\n",
      "Epoch 1407/2000, Train Loss: 0.0683, Test Loss: 0.2719\n",
      "Epoch 1408/2000, Train Loss: 0.0682, Test Loss: 0.2722\n",
      "Epoch 1409/2000, Train Loss: 0.0682, Test Loss: 0.2747\n",
      "Epoch 1410/2000, Train Loss: 0.0690, Test Loss: 0.2785\n",
      "Epoch 1411/2000, Train Loss: 0.0681, Test Loss: 0.2725\n",
      "Epoch 1412/2000, Train Loss: 0.0684, Test Loss: 0.2739\n",
      "Epoch 1413/2000, Train Loss: 0.0683, Test Loss: 0.2737\n",
      "Epoch 1414/2000, Train Loss: 0.0687, Test Loss: 0.2758\n",
      "Epoch 1415/2000, Train Loss: 0.0684, Test Loss: 0.2788\n",
      "Epoch 1416/2000, Train Loss: 0.0684, Test Loss: 0.2729\n",
      "Epoch 1417/2000, Train Loss: 0.0683, Test Loss: 0.2725\n",
      "Epoch 1418/2000, Train Loss: 0.0683, Test Loss: 0.2843\n",
      "Epoch 1419/2000, Train Loss: 0.0687, Test Loss: 0.2735\n",
      "Epoch 1420/2000, Train Loss: 0.0683, Test Loss: 0.2879\n",
      "Epoch 1421/2000, Train Loss: 0.0685, Test Loss: 0.2722\n",
      "Epoch 1422/2000, Train Loss: 0.0686, Test Loss: 0.2728\n",
      "Epoch 1423/2000, Train Loss: 0.0681, Test Loss: 0.2773\n",
      "Epoch 1424/2000, Train Loss: 0.0681, Test Loss: 0.2728\n",
      "Epoch 1425/2000, Train Loss: 0.0681, Test Loss: 0.2782\n",
      "Epoch 1426/2000, Train Loss: 0.0684, Test Loss: 0.2796\n",
      "Epoch 1427/2000, Train Loss: 0.0680, Test Loss: 0.2757\n",
      "Epoch 1428/2000, Train Loss: 0.0681, Test Loss: 0.2726\n",
      "Epoch 1429/2000, Train Loss: 0.0681, Test Loss: 0.2771\n",
      "Epoch 1430/2000, Train Loss: 0.0682, Test Loss: 0.2768\n",
      "Epoch 1431/2000, Train Loss: 0.0684, Test Loss: 0.2769\n",
      "Epoch 1432/2000, Train Loss: 0.0687, Test Loss: 0.2737\n",
      "Epoch 1433/2000, Train Loss: 0.0685, Test Loss: 0.2751\n",
      "Epoch 1434/2000, Train Loss: 0.0683, Test Loss: 0.2783\n",
      "Epoch 1435/2000, Train Loss: 0.0682, Test Loss: 0.2774\n",
      "Epoch 1436/2000, Train Loss: 0.0682, Test Loss: 0.2748\n",
      "Epoch 1437/2000, Train Loss: 0.0685, Test Loss: 0.2778\n",
      "Epoch 1438/2000, Train Loss: 0.0682, Test Loss: 0.2722\n",
      "Epoch 1439/2000, Train Loss: 0.0679, Test Loss: 0.2750\n",
      "Epoch 1440/2000, Train Loss: 0.0676, Test Loss: 0.2877\n",
      "Epoch 1441/2000, Train Loss: 0.0678, Test Loss: 0.2738\n",
      "Epoch 1442/2000, Train Loss: 0.0678, Test Loss: 0.2832\n",
      "Epoch 1443/2000, Train Loss: 0.0683, Test Loss: 0.2775\n",
      "Epoch 1444/2000, Train Loss: 0.0676, Test Loss: 0.2876\n",
      "Epoch 1445/2000, Train Loss: 0.0681, Test Loss: 0.2751\n",
      "Epoch 1446/2000, Train Loss: 0.0680, Test Loss: 0.2832\n",
      "Epoch 1447/2000, Train Loss: 0.0677, Test Loss: 0.2747\n",
      "Epoch 1448/2000, Train Loss: 0.0681, Test Loss: 0.2747\n",
      "Epoch 1449/2000, Train Loss: 0.0677, Test Loss: 0.2739\n",
      "Epoch 1450/2000, Train Loss: 0.0676, Test Loss: 0.2745\n",
      "Epoch 1451/2000, Train Loss: 0.0683, Test Loss: 0.2723\n",
      "Epoch 1452/2000, Train Loss: 0.0678, Test Loss: 0.2790\n",
      "Epoch 1453/2000, Train Loss: 0.0679, Test Loss: 0.2755\n",
      "Epoch 1454/2000, Train Loss: 0.0678, Test Loss: 0.2758\n",
      "Epoch 1455/2000, Train Loss: 0.0679, Test Loss: 0.2816\n",
      "Epoch 1456/2000, Train Loss: 0.0682, Test Loss: 0.2757\n",
      "Epoch 1457/2000, Train Loss: 0.0677, Test Loss: 0.2750\n",
      "Epoch 1458/2000, Train Loss: 0.0678, Test Loss: 0.2739\n",
      "Epoch 1459/2000, Train Loss: 0.0678, Test Loss: 0.2759\n",
      "Epoch 1460/2000, Train Loss: 0.0677, Test Loss: 0.2792\n",
      "Epoch 1461/2000, Train Loss: 0.0676, Test Loss: 0.2760\n",
      "Epoch 1462/2000, Train Loss: 0.0680, Test Loss: 0.2768\n",
      "Epoch 1463/2000, Train Loss: 0.0676, Test Loss: 0.2762\n",
      "Epoch 1464/2000, Train Loss: 0.0677, Test Loss: 0.2795\n",
      "Epoch 1465/2000, Train Loss: 0.0676, Test Loss: 0.2747\n",
      "Epoch 1466/2000, Train Loss: 0.0681, Test Loss: 0.2788\n",
      "Epoch 1467/2000, Train Loss: 0.0677, Test Loss: 0.2849\n",
      "Epoch 1468/2000, Train Loss: 0.0673, Test Loss: 0.2776\n",
      "Epoch 1469/2000, Train Loss: 0.0677, Test Loss: 0.2821\n",
      "Epoch 1470/2000, Train Loss: 0.0678, Test Loss: 0.2767\n",
      "Epoch 1471/2000, Train Loss: 0.0677, Test Loss: 0.2818\n",
      "Epoch 1472/2000, Train Loss: 0.0676, Test Loss: 0.2745\n",
      "Epoch 1473/2000, Train Loss: 0.0678, Test Loss: 0.2747\n",
      "Epoch 1474/2000, Train Loss: 0.0678, Test Loss: 0.2824\n",
      "Epoch 1475/2000, Train Loss: 0.0679, Test Loss: 0.2757\n",
      "Epoch 1476/2000, Train Loss: 0.0677, Test Loss: 0.2781\n",
      "Epoch 1477/2000, Train Loss: 0.0673, Test Loss: 0.2782\n",
      "Epoch 1478/2000, Train Loss: 0.0678, Test Loss: 0.2791\n",
      "Epoch 1479/2000, Train Loss: 0.0677, Test Loss: 0.2770\n",
      "Epoch 1480/2000, Train Loss: 0.0674, Test Loss: 0.2761\n",
      "Epoch 1481/2000, Train Loss: 0.0671, Test Loss: 0.2794\n",
      "Epoch 1482/2000, Train Loss: 0.0675, Test Loss: 0.2797\n",
      "Epoch 1483/2000, Train Loss: 0.0677, Test Loss: 0.2814\n",
      "Epoch 1484/2000, Train Loss: 0.0671, Test Loss: 0.2797\n",
      "Epoch 1485/2000, Train Loss: 0.0679, Test Loss: 0.2753\n",
      "Epoch 1486/2000, Train Loss: 0.0673, Test Loss: 0.2757\n",
      "Epoch 1487/2000, Train Loss: 0.0676, Test Loss: 0.2768\n",
      "Epoch 1488/2000, Train Loss: 0.0678, Test Loss: 0.2755\n",
      "Epoch 1489/2000, Train Loss: 0.0678, Test Loss: 0.2777\n",
      "Epoch 1490/2000, Train Loss: 0.0672, Test Loss: 0.2753\n",
      "Epoch 1491/2000, Train Loss: 0.0671, Test Loss: 0.2847\n",
      "Epoch 1492/2000, Train Loss: 0.0675, Test Loss: 0.2851\n",
      "Epoch 1493/2000, Train Loss: 0.0671, Test Loss: 0.2816\n",
      "Epoch 1494/2000, Train Loss: 0.0673, Test Loss: 0.2875\n",
      "Epoch 1495/2000, Train Loss: 0.0678, Test Loss: 0.2788\n",
      "Epoch 1496/2000, Train Loss: 0.0672, Test Loss: 0.2768\n",
      "Epoch 1497/2000, Train Loss: 0.0671, Test Loss: 0.2800\n",
      "Epoch 1498/2000, Train Loss: 0.0672, Test Loss: 0.2780\n",
      "Epoch 1499/2000, Train Loss: 0.0671, Test Loss: 0.2759\n",
      "Epoch 1500/2000, Train Loss: 0.0672, Test Loss: 0.2765\n",
      "Epoch 1501/2000, Train Loss: 0.0674, Test Loss: 0.2805\n",
      "Epoch 1502/2000, Train Loss: 0.0676, Test Loss: 0.2775\n",
      "Epoch 1503/2000, Train Loss: 0.0670, Test Loss: 0.2767\n",
      "Epoch 1504/2000, Train Loss: 0.0671, Test Loss: 0.2816\n",
      "Epoch 1505/2000, Train Loss: 0.0673, Test Loss: 0.2778\n",
      "Epoch 1506/2000, Train Loss: 0.0672, Test Loss: 0.2766\n",
      "Epoch 1507/2000, Train Loss: 0.0670, Test Loss: 0.2774\n",
      "Epoch 1508/2000, Train Loss: 0.0671, Test Loss: 0.2797\n",
      "Epoch 1509/2000, Train Loss: 0.0676, Test Loss: 0.2776\n",
      "Epoch 1510/2000, Train Loss: 0.0676, Test Loss: 0.2769\n",
      "Epoch 1511/2000, Train Loss: 0.0671, Test Loss: 0.2840\n",
      "Epoch 1512/2000, Train Loss: 0.0672, Test Loss: 0.2761\n",
      "Epoch 1513/2000, Train Loss: 0.0670, Test Loss: 0.2824\n",
      "Epoch 1514/2000, Train Loss: 0.0668, Test Loss: 0.2785\n",
      "Epoch 1515/2000, Train Loss: 0.0671, Test Loss: 0.2753\n",
      "Epoch 1516/2000, Train Loss: 0.0673, Test Loss: 0.2788\n",
      "Epoch 1517/2000, Train Loss: 0.0674, Test Loss: 0.2792\n",
      "Epoch 1518/2000, Train Loss: 0.0669, Test Loss: 0.2778\n",
      "Epoch 1519/2000, Train Loss: 0.0671, Test Loss: 0.2798\n",
      "Epoch 1520/2000, Train Loss: 0.0669, Test Loss: 0.2788\n",
      "Epoch 1521/2000, Train Loss: 0.0673, Test Loss: 0.2766\n",
      "Epoch 1522/2000, Train Loss: 0.0669, Test Loss: 0.2838\n",
      "Epoch 1523/2000, Train Loss: 0.0668, Test Loss: 0.2825\n",
      "Epoch 1524/2000, Train Loss: 0.0667, Test Loss: 0.2779\n",
      "Epoch 1525/2000, Train Loss: 0.0668, Test Loss: 0.2845\n",
      "Epoch 1526/2000, Train Loss: 0.0670, Test Loss: 0.2844\n",
      "Epoch 1527/2000, Train Loss: 0.0670, Test Loss: 0.2775\n",
      "Epoch 1528/2000, Train Loss: 0.0667, Test Loss: 0.2804\n",
      "Epoch 1529/2000, Train Loss: 0.0672, Test Loss: 0.2768\n",
      "Epoch 1530/2000, Train Loss: 0.0668, Test Loss: 0.2833\n",
      "Epoch 1531/2000, Train Loss: 0.0671, Test Loss: 0.2786\n",
      "Epoch 1532/2000, Train Loss: 0.0670, Test Loss: 0.2768\n",
      "Epoch 1533/2000, Train Loss: 0.0669, Test Loss: 0.2832\n",
      "Epoch 1534/2000, Train Loss: 0.0669, Test Loss: 0.2794\n",
      "Epoch 1535/2000, Train Loss: 0.0668, Test Loss: 0.2843\n",
      "Epoch 1536/2000, Train Loss: 0.0665, Test Loss: 0.2802\n",
      "Epoch 1537/2000, Train Loss: 0.0669, Test Loss: 0.2783\n",
      "Epoch 1538/2000, Train Loss: 0.0667, Test Loss: 0.2790\n",
      "Epoch 1539/2000, Train Loss: 0.0668, Test Loss: 0.2828\n",
      "Epoch 1540/2000, Train Loss: 0.0668, Test Loss: 0.2817\n",
      "Epoch 1541/2000, Train Loss: 0.0669, Test Loss: 0.2775\n",
      "Epoch 1542/2000, Train Loss: 0.0666, Test Loss: 0.2812\n",
      "Epoch 1543/2000, Train Loss: 0.0668, Test Loss: 0.2803\n",
      "Epoch 1544/2000, Train Loss: 0.0665, Test Loss: 0.2790\n",
      "Epoch 1545/2000, Train Loss: 0.0669, Test Loss: 0.2811\n",
      "Epoch 1546/2000, Train Loss: 0.0668, Test Loss: 0.2901\n",
      "Epoch 1547/2000, Train Loss: 0.0667, Test Loss: 0.2791\n",
      "Epoch 1548/2000, Train Loss: 0.0669, Test Loss: 0.2910\n",
      "Epoch 1549/2000, Train Loss: 0.0668, Test Loss: 0.2906\n",
      "Epoch 1550/2000, Train Loss: 0.0666, Test Loss: 0.2797\n",
      "Epoch 1551/2000, Train Loss: 0.0670, Test Loss: 0.2782\n",
      "Epoch 1552/2000, Train Loss: 0.0665, Test Loss: 0.2794\n",
      "Epoch 1553/2000, Train Loss: 0.0671, Test Loss: 0.2788\n",
      "Epoch 1554/2000, Train Loss: 0.0664, Test Loss: 0.2795\n",
      "Epoch 1555/2000, Train Loss: 0.0664, Test Loss: 0.2830\n",
      "Epoch 1556/2000, Train Loss: 0.0666, Test Loss: 0.2801\n",
      "Epoch 1557/2000, Train Loss: 0.0668, Test Loss: 0.2783\n",
      "Epoch 1558/2000, Train Loss: 0.0666, Test Loss: 0.2807\n",
      "Epoch 1559/2000, Train Loss: 0.0669, Test Loss: 0.2821\n",
      "Epoch 1560/2000, Train Loss: 0.0670, Test Loss: 0.2907\n",
      "Epoch 1561/2000, Train Loss: 0.0667, Test Loss: 0.2864\n",
      "Epoch 1562/2000, Train Loss: 0.0662, Test Loss: 0.2956\n",
      "Epoch 1563/2000, Train Loss: 0.0666, Test Loss: 0.2834\n",
      "Epoch 1564/2000, Train Loss: 0.0667, Test Loss: 0.2820\n",
      "Epoch 1565/2000, Train Loss: 0.0663, Test Loss: 0.2831\n",
      "Epoch 1566/2000, Train Loss: 0.0667, Test Loss: 0.2804\n",
      "Epoch 1567/2000, Train Loss: 0.0664, Test Loss: 0.2837\n",
      "Epoch 1568/2000, Train Loss: 0.0666, Test Loss: 0.2785\n",
      "Epoch 1569/2000, Train Loss: 0.0663, Test Loss: 0.2811\n",
      "Epoch 1570/2000, Train Loss: 0.0659, Test Loss: 0.2817\n",
      "Epoch 1571/2000, Train Loss: 0.0662, Test Loss: 0.2842\n",
      "Epoch 1572/2000, Train Loss: 0.0659, Test Loss: 0.2893\n",
      "Epoch 1573/2000, Train Loss: 0.0663, Test Loss: 0.2785\n",
      "Epoch 1574/2000, Train Loss: 0.0658, Test Loss: 0.2795\n",
      "Epoch 1575/2000, Train Loss: 0.0666, Test Loss: 0.2814\n",
      "Epoch 1576/2000, Train Loss: 0.0665, Test Loss: 0.2793\n",
      "Epoch 1577/2000, Train Loss: 0.0665, Test Loss: 0.2809\n",
      "Epoch 1578/2000, Train Loss: 0.0665, Test Loss: 0.2923\n",
      "Epoch 1579/2000, Train Loss: 0.0667, Test Loss: 0.2816\n",
      "Epoch 1580/2000, Train Loss: 0.0664, Test Loss: 0.2795\n",
      "Epoch 1581/2000, Train Loss: 0.0661, Test Loss: 0.2819\n",
      "Epoch 1582/2000, Train Loss: 0.0663, Test Loss: 0.2802\n",
      "Epoch 1583/2000, Train Loss: 0.0662, Test Loss: 0.2825\n",
      "Epoch 1584/2000, Train Loss: 0.0662, Test Loss: 0.2830\n",
      "Epoch 1585/2000, Train Loss: 0.0661, Test Loss: 0.2813\n",
      "Epoch 1586/2000, Train Loss: 0.0662, Test Loss: 0.2801\n",
      "Epoch 1587/2000, Train Loss: 0.0662, Test Loss: 0.2879\n",
      "Epoch 1588/2000, Train Loss: 0.0658, Test Loss: 0.2814\n",
      "Epoch 1589/2000, Train Loss: 0.0659, Test Loss: 0.2819\n",
      "Epoch 1590/2000, Train Loss: 0.0659, Test Loss: 0.2783\n",
      "Epoch 1591/2000, Train Loss: 0.0660, Test Loss: 0.2836\n",
      "Epoch 1592/2000, Train Loss: 0.0661, Test Loss: 0.2820\n",
      "Epoch 1593/2000, Train Loss: 0.0661, Test Loss: 0.2828\n",
      "Epoch 1594/2000, Train Loss: 0.0663, Test Loss: 0.2822\n",
      "Epoch 1595/2000, Train Loss: 0.0662, Test Loss: 0.2809\n",
      "Epoch 1596/2000, Train Loss: 0.0658, Test Loss: 0.2838\n",
      "Epoch 1597/2000, Train Loss: 0.0660, Test Loss: 0.2854\n",
      "Epoch 1598/2000, Train Loss: 0.0662, Test Loss: 0.2798\n",
      "Epoch 1599/2000, Train Loss: 0.0658, Test Loss: 0.2836\n",
      "Epoch 1600/2000, Train Loss: 0.0665, Test Loss: 0.2821\n",
      "Epoch 1601/2000, Train Loss: 0.0659, Test Loss: 0.2832\n",
      "Epoch 1602/2000, Train Loss: 0.0663, Test Loss: 0.2806\n",
      "Epoch 1603/2000, Train Loss: 0.0659, Test Loss: 0.2897\n",
      "Epoch 1604/2000, Train Loss: 0.0660, Test Loss: 0.2856\n",
      "Epoch 1605/2000, Train Loss: 0.0660, Test Loss: 0.2836\n",
      "Epoch 1606/2000, Train Loss: 0.0665, Test Loss: 0.2856\n",
      "Epoch 1607/2000, Train Loss: 0.0662, Test Loss: 0.2828\n",
      "Epoch 1608/2000, Train Loss: 0.0660, Test Loss: 0.2804\n",
      "Epoch 1609/2000, Train Loss: 0.0659, Test Loss: 0.2844\n",
      "Epoch 1610/2000, Train Loss: 0.0658, Test Loss: 0.2888\n",
      "Epoch 1611/2000, Train Loss: 0.0665, Test Loss: 0.2892\n",
      "Epoch 1612/2000, Train Loss: 0.0665, Test Loss: 0.2794\n",
      "Epoch 1613/2000, Train Loss: 0.0660, Test Loss: 0.2954\n",
      "Epoch 1614/2000, Train Loss: 0.0663, Test Loss: 0.2923\n",
      "Epoch 1615/2000, Train Loss: 0.0663, Test Loss: 0.2815\n",
      "Epoch 1616/2000, Train Loss: 0.0658, Test Loss: 0.2823\n",
      "Epoch 1617/2000, Train Loss: 0.0655, Test Loss: 0.2815\n",
      "Epoch 1618/2000, Train Loss: 0.0659, Test Loss: 0.2820\n",
      "Epoch 1619/2000, Train Loss: 0.0662, Test Loss: 0.2869\n",
      "Epoch 1620/2000, Train Loss: 0.0655, Test Loss: 0.2879\n",
      "Epoch 1621/2000, Train Loss: 0.0657, Test Loss: 0.2824\n",
      "Epoch 1622/2000, Train Loss: 0.0661, Test Loss: 0.2896\n",
      "Epoch 1623/2000, Train Loss: 0.0661, Test Loss: 0.2867\n",
      "Epoch 1624/2000, Train Loss: 0.0658, Test Loss: 0.2816\n",
      "Epoch 1625/2000, Train Loss: 0.0662, Test Loss: 0.2835\n",
      "Epoch 1626/2000, Train Loss: 0.0658, Test Loss: 0.2947\n",
      "Epoch 1627/2000, Train Loss: 0.0657, Test Loss: 0.2900\n",
      "Epoch 1628/2000, Train Loss: 0.0655, Test Loss: 0.2930\n",
      "Epoch 1629/2000, Train Loss: 0.0660, Test Loss: 0.2831\n",
      "Epoch 1630/2000, Train Loss: 0.0655, Test Loss: 0.2863\n",
      "Epoch 1631/2000, Train Loss: 0.0663, Test Loss: 0.2849\n",
      "Epoch 1632/2000, Train Loss: 0.0656, Test Loss: 0.2858\n",
      "Epoch 1633/2000, Train Loss: 0.0656, Test Loss: 0.2834\n",
      "Epoch 1634/2000, Train Loss: 0.0656, Test Loss: 0.2936\n",
      "Epoch 1635/2000, Train Loss: 0.0658, Test Loss: 0.2837\n",
      "Epoch 1636/2000, Train Loss: 0.0654, Test Loss: 0.2832\n",
      "Epoch 1637/2000, Train Loss: 0.0660, Test Loss: 0.2833\n",
      "Epoch 1638/2000, Train Loss: 0.0656, Test Loss: 0.2835\n",
      "Epoch 1639/2000, Train Loss: 0.0657, Test Loss: 0.2851\n",
      "Epoch 1640/2000, Train Loss: 0.0654, Test Loss: 0.2843\n",
      "Epoch 1641/2000, Train Loss: 0.0656, Test Loss: 0.2877\n",
      "Epoch 1642/2000, Train Loss: 0.0656, Test Loss: 0.2889\n",
      "Epoch 1643/2000, Train Loss: 0.0656, Test Loss: 0.2835\n",
      "Epoch 1644/2000, Train Loss: 0.0655, Test Loss: 0.2830\n",
      "Epoch 1645/2000, Train Loss: 0.0655, Test Loss: 0.2848\n",
      "Epoch 1646/2000, Train Loss: 0.0655, Test Loss: 0.2849\n",
      "Epoch 1647/2000, Train Loss: 0.0656, Test Loss: 0.2903\n",
      "Epoch 1648/2000, Train Loss: 0.0656, Test Loss: 0.2896\n",
      "Epoch 1649/2000, Train Loss: 0.0656, Test Loss: 0.2837\n",
      "Epoch 1650/2000, Train Loss: 0.0655, Test Loss: 0.2841\n",
      "Epoch 1651/2000, Train Loss: 0.0654, Test Loss: 0.2832\n",
      "Epoch 1652/2000, Train Loss: 0.0655, Test Loss: 0.2833\n",
      "Epoch 1653/2000, Train Loss: 0.0652, Test Loss: 0.2874\n",
      "Epoch 1654/2000, Train Loss: 0.0655, Test Loss: 0.2822\n",
      "Epoch 1655/2000, Train Loss: 0.0653, Test Loss: 0.2832\n",
      "Epoch 1656/2000, Train Loss: 0.0656, Test Loss: 0.2837\n",
      "Epoch 1657/2000, Train Loss: 0.0654, Test Loss: 0.2893\n",
      "Epoch 1658/2000, Train Loss: 0.0656, Test Loss: 0.2856\n",
      "Epoch 1659/2000, Train Loss: 0.0652, Test Loss: 0.2842\n",
      "Epoch 1660/2000, Train Loss: 0.0655, Test Loss: 0.2832\n",
      "Epoch 1661/2000, Train Loss: 0.0656, Test Loss: 0.2828\n",
      "Epoch 1662/2000, Train Loss: 0.0655, Test Loss: 0.2887\n",
      "Epoch 1663/2000, Train Loss: 0.0655, Test Loss: 0.2845\n",
      "Epoch 1664/2000, Train Loss: 0.0653, Test Loss: 0.2844\n",
      "Epoch 1665/2000, Train Loss: 0.0656, Test Loss: 0.2872\n",
      "Epoch 1666/2000, Train Loss: 0.0657, Test Loss: 0.2838\n",
      "Epoch 1667/2000, Train Loss: 0.0656, Test Loss: 0.2870\n",
      "Epoch 1668/2000, Train Loss: 0.0656, Test Loss: 0.2875\n",
      "Epoch 1669/2000, Train Loss: 0.0654, Test Loss: 0.2835\n",
      "Epoch 1670/2000, Train Loss: 0.0657, Test Loss: 0.2841\n",
      "Epoch 1671/2000, Train Loss: 0.0654, Test Loss: 0.2845\n",
      "Epoch 1672/2000, Train Loss: 0.0652, Test Loss: 0.2893\n",
      "Epoch 1673/2000, Train Loss: 0.0655, Test Loss: 0.2826\n",
      "Epoch 1674/2000, Train Loss: 0.0655, Test Loss: 0.2851\n",
      "Epoch 1675/2000, Train Loss: 0.0651, Test Loss: 0.2910\n",
      "Epoch 1676/2000, Train Loss: 0.0649, Test Loss: 0.2838\n",
      "Epoch 1677/2000, Train Loss: 0.0650, Test Loss: 0.2862\n",
      "Epoch 1678/2000, Train Loss: 0.0649, Test Loss: 0.2850\n",
      "Epoch 1679/2000, Train Loss: 0.0653, Test Loss: 0.2908\n",
      "Epoch 1680/2000, Train Loss: 0.0654, Test Loss: 0.2875\n",
      "Epoch 1681/2000, Train Loss: 0.0653, Test Loss: 0.2934\n",
      "Epoch 1682/2000, Train Loss: 0.0658, Test Loss: 0.2833\n",
      "Epoch 1683/2000, Train Loss: 0.0649, Test Loss: 0.2909\n",
      "Epoch 1684/2000, Train Loss: 0.0652, Test Loss: 0.2880\n",
      "Epoch 1685/2000, Train Loss: 0.0648, Test Loss: 0.2877\n",
      "Epoch 1686/2000, Train Loss: 0.0651, Test Loss: 0.2846\n",
      "Epoch 1687/2000, Train Loss: 0.0650, Test Loss: 0.2871\n",
      "Epoch 1688/2000, Train Loss: 0.0652, Test Loss: 0.2865\n",
      "Epoch 1689/2000, Train Loss: 0.0648, Test Loss: 0.2871\n",
      "Epoch 1690/2000, Train Loss: 0.0653, Test Loss: 0.2858\n",
      "Epoch 1691/2000, Train Loss: 0.0654, Test Loss: 0.2918\n",
      "Epoch 1692/2000, Train Loss: 0.0655, Test Loss: 0.2869\n",
      "Epoch 1693/2000, Train Loss: 0.0653, Test Loss: 0.2879\n",
      "Epoch 1694/2000, Train Loss: 0.0650, Test Loss: 0.2874\n",
      "Epoch 1695/2000, Train Loss: 0.0651, Test Loss: 0.2849\n",
      "Epoch 1696/2000, Train Loss: 0.0648, Test Loss: 0.2951\n",
      "Epoch 1697/2000, Train Loss: 0.0652, Test Loss: 0.2859\n",
      "Epoch 1698/2000, Train Loss: 0.0652, Test Loss: 0.2887\n",
      "Epoch 1699/2000, Train Loss: 0.0652, Test Loss: 0.2892\n",
      "Epoch 1700/2000, Train Loss: 0.0654, Test Loss: 0.2856\n",
      "Epoch 1701/2000, Train Loss: 0.0652, Test Loss: 0.2895\n",
      "Epoch 1702/2000, Train Loss: 0.0651, Test Loss: 0.2882\n",
      "Epoch 1703/2000, Train Loss: 0.0648, Test Loss: 0.2872\n",
      "Epoch 1704/2000, Train Loss: 0.0647, Test Loss: 0.2899\n",
      "Epoch 1705/2000, Train Loss: 0.0651, Test Loss: 0.2983\n",
      "Epoch 1706/2000, Train Loss: 0.0646, Test Loss: 0.2938\n",
      "Epoch 1707/2000, Train Loss: 0.0648, Test Loss: 0.2870\n",
      "Epoch 1708/2000, Train Loss: 0.0649, Test Loss: 0.2842\n",
      "Epoch 1709/2000, Train Loss: 0.0647, Test Loss: 0.2850\n",
      "Epoch 1710/2000, Train Loss: 0.0645, Test Loss: 0.2847\n",
      "Epoch 1711/2000, Train Loss: 0.0649, Test Loss: 0.2854\n",
      "Epoch 1712/2000, Train Loss: 0.0646, Test Loss: 0.2900\n",
      "Epoch 1713/2000, Train Loss: 0.0648, Test Loss: 0.2871\n",
      "Epoch 1714/2000, Train Loss: 0.0651, Test Loss: 0.2848\n",
      "Epoch 1715/2000, Train Loss: 0.0648, Test Loss: 0.2848\n",
      "Epoch 1716/2000, Train Loss: 0.0646, Test Loss: 0.2887\n",
      "Epoch 1717/2000, Train Loss: 0.0649, Test Loss: 0.2855\n",
      "Epoch 1718/2000, Train Loss: 0.0653, Test Loss: 0.2864\n",
      "Epoch 1719/2000, Train Loss: 0.0651, Test Loss: 0.2918\n",
      "Epoch 1720/2000, Train Loss: 0.0648, Test Loss: 0.2894\n",
      "Epoch 1721/2000, Train Loss: 0.0648, Test Loss: 0.2876\n",
      "Epoch 1722/2000, Train Loss: 0.0648, Test Loss: 0.2861\n",
      "Epoch 1723/2000, Train Loss: 0.0647, Test Loss: 0.2997\n",
      "Epoch 1724/2000, Train Loss: 0.0649, Test Loss: 0.2843\n",
      "Epoch 1725/2000, Train Loss: 0.0652, Test Loss: 0.2955\n",
      "Epoch 1726/2000, Train Loss: 0.0644, Test Loss: 0.2871\n",
      "Epoch 1727/2000, Train Loss: 0.0646, Test Loss: 0.2852\n",
      "Epoch 1728/2000, Train Loss: 0.0648, Test Loss: 0.2872\n",
      "Epoch 1729/2000, Train Loss: 0.0644, Test Loss: 0.2858\n",
      "Epoch 1730/2000, Train Loss: 0.0646, Test Loss: 0.2872\n",
      "Epoch 1731/2000, Train Loss: 0.0648, Test Loss: 0.2918\n",
      "Epoch 1732/2000, Train Loss: 0.0643, Test Loss: 0.2908\n",
      "Epoch 1733/2000, Train Loss: 0.0645, Test Loss: 0.2862\n",
      "Epoch 1734/2000, Train Loss: 0.0646, Test Loss: 0.2853\n",
      "Epoch 1735/2000, Train Loss: 0.0647, Test Loss: 0.2847\n",
      "Epoch 1736/2000, Train Loss: 0.0646, Test Loss: 0.2876\n",
      "Epoch 1737/2000, Train Loss: 0.0645, Test Loss: 0.2904\n",
      "Epoch 1738/2000, Train Loss: 0.0644, Test Loss: 0.2850\n",
      "Epoch 1739/2000, Train Loss: 0.0646, Test Loss: 0.2855\n",
      "Epoch 1740/2000, Train Loss: 0.0645, Test Loss: 0.2907\n",
      "Epoch 1741/2000, Train Loss: 0.0646, Test Loss: 0.2937\n",
      "Epoch 1742/2000, Train Loss: 0.0646, Test Loss: 0.2912\n",
      "Epoch 1743/2000, Train Loss: 0.0648, Test Loss: 0.2892\n",
      "Epoch 1744/2000, Train Loss: 0.0645, Test Loss: 0.2949\n",
      "Epoch 1745/2000, Train Loss: 0.0646, Test Loss: 0.2925\n",
      "Epoch 1746/2000, Train Loss: 0.0648, Test Loss: 0.2873\n",
      "Epoch 1747/2000, Train Loss: 0.0647, Test Loss: 0.2887\n",
      "Epoch 1748/2000, Train Loss: 0.0644, Test Loss: 0.2893\n",
      "Epoch 1749/2000, Train Loss: 0.0642, Test Loss: 0.2961\n",
      "Epoch 1750/2000, Train Loss: 0.0645, Test Loss: 0.2873\n",
      "Epoch 1751/2000, Train Loss: 0.0646, Test Loss: 0.2869\n",
      "Epoch 1752/2000, Train Loss: 0.0645, Test Loss: 0.2890\n",
      "Epoch 1753/2000, Train Loss: 0.0645, Test Loss: 0.2942\n",
      "Epoch 1754/2000, Train Loss: 0.0642, Test Loss: 0.2984\n",
      "Epoch 1755/2000, Train Loss: 0.0645, Test Loss: 0.2865\n",
      "Epoch 1756/2000, Train Loss: 0.0645, Test Loss: 0.2872\n",
      "Epoch 1757/2000, Train Loss: 0.0645, Test Loss: 0.2931\n",
      "Epoch 1758/2000, Train Loss: 0.0645, Test Loss: 0.2869\n",
      "Epoch 1759/2000, Train Loss: 0.0641, Test Loss: 0.2870\n",
      "Epoch 1760/2000, Train Loss: 0.0641, Test Loss: 0.2863\n",
      "Epoch 1761/2000, Train Loss: 0.0643, Test Loss: 0.2927\n",
      "Epoch 1762/2000, Train Loss: 0.0644, Test Loss: 0.2878\n",
      "Epoch 1763/2000, Train Loss: 0.0646, Test Loss: 0.2869\n",
      "Epoch 1764/2000, Train Loss: 0.0647, Test Loss: 0.2994\n",
      "Epoch 1765/2000, Train Loss: 0.0644, Test Loss: 0.2923\n",
      "Epoch 1766/2000, Train Loss: 0.0647, Test Loss: 0.2870\n",
      "Epoch 1767/2000, Train Loss: 0.0645, Test Loss: 0.2951\n",
      "Epoch 1768/2000, Train Loss: 0.0643, Test Loss: 0.2869\n",
      "Epoch 1769/2000, Train Loss: 0.0646, Test Loss: 0.2876\n",
      "Epoch 1770/2000, Train Loss: 0.0643, Test Loss: 0.2855\n",
      "Epoch 1771/2000, Train Loss: 0.0641, Test Loss: 0.2877\n",
      "Epoch 1772/2000, Train Loss: 0.0641, Test Loss: 0.2873\n",
      "Epoch 1773/2000, Train Loss: 0.0646, Test Loss: 0.2888\n",
      "Epoch 1774/2000, Train Loss: 0.0648, Test Loss: 0.2997\n",
      "Epoch 1775/2000, Train Loss: 0.0644, Test Loss: 0.3091\n",
      "Epoch 1776/2000, Train Loss: 0.0644, Test Loss: 0.3028\n",
      "Epoch 1777/2000, Train Loss: 0.0642, Test Loss: 0.2947\n",
      "Epoch 1778/2000, Train Loss: 0.0642, Test Loss: 0.2877\n",
      "Epoch 1779/2000, Train Loss: 0.0642, Test Loss: 0.2891\n",
      "Epoch 1780/2000, Train Loss: 0.0641, Test Loss: 0.3023\n",
      "Epoch 1781/2000, Train Loss: 0.0642, Test Loss: 0.2902\n",
      "Epoch 1782/2000, Train Loss: 0.0641, Test Loss: 0.2880\n",
      "Epoch 1783/2000, Train Loss: 0.0637, Test Loss: 0.2878\n",
      "Epoch 1784/2000, Train Loss: 0.0641, Test Loss: 0.2893\n",
      "Epoch 1785/2000, Train Loss: 0.0639, Test Loss: 0.2884\n",
      "Epoch 1786/2000, Train Loss: 0.0637, Test Loss: 0.2887\n",
      "Epoch 1787/2000, Train Loss: 0.0640, Test Loss: 0.2903\n",
      "Epoch 1788/2000, Train Loss: 0.0640, Test Loss: 0.2886\n",
      "Epoch 1789/2000, Train Loss: 0.0642, Test Loss: 0.2913\n",
      "Epoch 1790/2000, Train Loss: 0.0647, Test Loss: 0.2898\n",
      "Epoch 1791/2000, Train Loss: 0.0640, Test Loss: 0.2901\n",
      "Epoch 1792/2000, Train Loss: 0.0645, Test Loss: 0.2867\n",
      "Epoch 1793/2000, Train Loss: 0.0638, Test Loss: 0.2929\n",
      "Epoch 1794/2000, Train Loss: 0.0643, Test Loss: 0.2881\n",
      "Epoch 1795/2000, Train Loss: 0.0645, Test Loss: 0.2930\n",
      "Epoch 1796/2000, Train Loss: 0.0638, Test Loss: 0.2886\n",
      "Epoch 1797/2000, Train Loss: 0.0642, Test Loss: 0.2884\n",
      "Epoch 1798/2000, Train Loss: 0.0640, Test Loss: 0.2896\n",
      "Epoch 1799/2000, Train Loss: 0.0643, Test Loss: 0.2924\n",
      "Epoch 1800/2000, Train Loss: 0.0638, Test Loss: 0.2901\n",
      "Epoch 1801/2000, Train Loss: 0.0641, Test Loss: 0.2933\n",
      "Epoch 1802/2000, Train Loss: 0.0635, Test Loss: 0.2930\n",
      "Epoch 1803/2000, Train Loss: 0.0641, Test Loss: 0.2934\n",
      "Epoch 1804/2000, Train Loss: 0.0641, Test Loss: 0.2904\n",
      "Epoch 1805/2000, Train Loss: 0.0640, Test Loss: 0.2896\n",
      "Epoch 1806/2000, Train Loss: 0.0640, Test Loss: 0.2938\n",
      "Epoch 1807/2000, Train Loss: 0.0644, Test Loss: 0.3057\n",
      "Epoch 1808/2000, Train Loss: 0.0639, Test Loss: 0.2899\n",
      "Epoch 1809/2000, Train Loss: 0.0638, Test Loss: 0.2903\n",
      "Epoch 1810/2000, Train Loss: 0.0638, Test Loss: 0.2911\n",
      "Epoch 1811/2000, Train Loss: 0.0641, Test Loss: 0.2880\n",
      "Epoch 1812/2000, Train Loss: 0.0639, Test Loss: 0.2894\n",
      "Epoch 1813/2000, Train Loss: 0.0638, Test Loss: 0.2881\n",
      "Epoch 1814/2000, Train Loss: 0.0641, Test Loss: 0.2928\n",
      "Epoch 1815/2000, Train Loss: 0.0636, Test Loss: 0.2935\n",
      "Epoch 1816/2000, Train Loss: 0.0639, Test Loss: 0.2884\n",
      "Epoch 1817/2000, Train Loss: 0.0638, Test Loss: 0.2905\n",
      "Epoch 1818/2000, Train Loss: 0.0637, Test Loss: 0.2920\n",
      "Epoch 1819/2000, Train Loss: 0.0638, Test Loss: 0.2898\n",
      "Epoch 1820/2000, Train Loss: 0.0638, Test Loss: 0.2886\n",
      "Epoch 1821/2000, Train Loss: 0.0638, Test Loss: 0.2927\n",
      "Epoch 1822/2000, Train Loss: 0.0638, Test Loss: 0.2928\n",
      "Epoch 1823/2000, Train Loss: 0.0646, Test Loss: 0.2898\n",
      "Epoch 1824/2000, Train Loss: 0.0637, Test Loss: 0.2931\n",
      "Epoch 1825/2000, Train Loss: 0.0637, Test Loss: 0.3002\n",
      "Epoch 1826/2000, Train Loss: 0.0636, Test Loss: 0.2964\n",
      "Epoch 1827/2000, Train Loss: 0.0640, Test Loss: 0.2897\n",
      "Epoch 1828/2000, Train Loss: 0.0642, Test Loss: 0.2903\n",
      "Epoch 1829/2000, Train Loss: 0.0633, Test Loss: 0.2949\n",
      "Epoch 1830/2000, Train Loss: 0.0636, Test Loss: 0.2970\n",
      "Epoch 1831/2000, Train Loss: 0.0639, Test Loss: 0.2913\n",
      "Epoch 1832/2000, Train Loss: 0.0636, Test Loss: 0.2920\n",
      "Epoch 1833/2000, Train Loss: 0.0635, Test Loss: 0.2955\n",
      "Epoch 1834/2000, Train Loss: 0.0637, Test Loss: 0.2977\n",
      "Epoch 1835/2000, Train Loss: 0.0634, Test Loss: 0.2977\n",
      "Epoch 1836/2000, Train Loss: 0.0633, Test Loss: 0.2923\n",
      "Epoch 1837/2000, Train Loss: 0.0636, Test Loss: 0.2923\n",
      "Epoch 1838/2000, Train Loss: 0.0636, Test Loss: 0.2906\n",
      "Epoch 1839/2000, Train Loss: 0.0639, Test Loss: 0.2979\n",
      "Epoch 1840/2000, Train Loss: 0.0635, Test Loss: 0.3005\n",
      "Epoch 1841/2000, Train Loss: 0.0635, Test Loss: 0.3237\n",
      "Epoch 1842/2000, Train Loss: 0.0637, Test Loss: 0.2962\n",
      "Epoch 1843/2000, Train Loss: 0.0636, Test Loss: 0.2916\n",
      "Epoch 1844/2000, Train Loss: 0.0633, Test Loss: 0.2914\n",
      "Epoch 1845/2000, Train Loss: 0.0638, Test Loss: 0.2941\n",
      "Epoch 1846/2000, Train Loss: 0.0642, Test Loss: 0.2953\n",
      "Epoch 1847/2000, Train Loss: 0.0641, Test Loss: 0.2900\n",
      "Epoch 1848/2000, Train Loss: 0.0639, Test Loss: 0.3004\n",
      "Epoch 1849/2000, Train Loss: 0.0637, Test Loss: 0.3018\n",
      "Epoch 1850/2000, Train Loss: 0.0638, Test Loss: 0.2918\n",
      "Epoch 1851/2000, Train Loss: 0.0635, Test Loss: 0.2909\n",
      "Epoch 1852/2000, Train Loss: 0.0634, Test Loss: 0.2926\n",
      "Epoch 1853/2000, Train Loss: 0.0635, Test Loss: 0.2954\n",
      "Epoch 1854/2000, Train Loss: 0.0636, Test Loss: 0.2894\n",
      "Epoch 1855/2000, Train Loss: 0.0638, Test Loss: 0.2907\n",
      "Epoch 1856/2000, Train Loss: 0.0631, Test Loss: 0.2975\n",
      "Epoch 1857/2000, Train Loss: 0.0638, Test Loss: 0.2949\n",
      "Epoch 1858/2000, Train Loss: 0.0640, Test Loss: 0.2951\n",
      "Epoch 1859/2000, Train Loss: 0.0631, Test Loss: 0.3022\n",
      "Epoch 1860/2000, Train Loss: 0.0635, Test Loss: 0.2917\n",
      "Epoch 1861/2000, Train Loss: 0.0634, Test Loss: 0.2899\n",
      "Epoch 1862/2000, Train Loss: 0.0633, Test Loss: 0.3008\n",
      "Epoch 1863/2000, Train Loss: 0.0633, Test Loss: 0.2927\n",
      "Epoch 1864/2000, Train Loss: 0.0630, Test Loss: 0.2963\n",
      "Epoch 1865/2000, Train Loss: 0.0635, Test Loss: 0.2931\n",
      "Epoch 1866/2000, Train Loss: 0.0635, Test Loss: 0.3003\n",
      "Epoch 1867/2000, Train Loss: 0.0632, Test Loss: 0.2942\n",
      "Epoch 1868/2000, Train Loss: 0.0635, Test Loss: 0.2944\n",
      "Epoch 1869/2000, Train Loss: 0.0639, Test Loss: 0.2906\n",
      "Epoch 1870/2000, Train Loss: 0.0631, Test Loss: 0.2911\n",
      "Epoch 1871/2000, Train Loss: 0.0633, Test Loss: 0.2933\n",
      "Epoch 1872/2000, Train Loss: 0.0632, Test Loss: 0.2909\n",
      "Epoch 1873/2000, Train Loss: 0.0631, Test Loss: 0.3163\n",
      "Epoch 1874/2000, Train Loss: 0.0640, Test Loss: 0.2923\n",
      "Epoch 1875/2000, Train Loss: 0.0631, Test Loss: 0.2923\n",
      "Epoch 1876/2000, Train Loss: 0.0633, Test Loss: 0.2903\n",
      "Epoch 1877/2000, Train Loss: 0.0632, Test Loss: 0.2935\n",
      "Epoch 1878/2000, Train Loss: 0.0632, Test Loss: 0.2919\n",
      "Epoch 1879/2000, Train Loss: 0.0635, Test Loss: 0.2911\n",
      "Epoch 1880/2000, Train Loss: 0.0635, Test Loss: 0.2930\n",
      "Epoch 1881/2000, Train Loss: 0.0632, Test Loss: 0.2946\n",
      "Epoch 1882/2000, Train Loss: 0.0630, Test Loss: 0.2916\n",
      "Epoch 1883/2000, Train Loss: 0.0630, Test Loss: 0.2926\n",
      "Epoch 1884/2000, Train Loss: 0.0630, Test Loss: 0.2958\n",
      "Epoch 1885/2000, Train Loss: 0.0628, Test Loss: 0.2919\n",
      "Epoch 1886/2000, Train Loss: 0.0634, Test Loss: 0.2966\n",
      "Epoch 1887/2000, Train Loss: 0.0633, Test Loss: 0.2923\n",
      "Epoch 1888/2000, Train Loss: 0.0634, Test Loss: 0.2963\n",
      "Epoch 1889/2000, Train Loss: 0.0631, Test Loss: 0.2932\n",
      "Epoch 1890/2000, Train Loss: 0.0638, Test Loss: 0.2942\n",
      "Epoch 1891/2000, Train Loss: 0.0631, Test Loss: 0.2932\n",
      "Epoch 1892/2000, Train Loss: 0.0630, Test Loss: 0.2942\n",
      "Epoch 1893/2000, Train Loss: 0.0635, Test Loss: 0.2917\n",
      "Epoch 1894/2000, Train Loss: 0.0631, Test Loss: 0.2928\n",
      "Epoch 1895/2000, Train Loss: 0.0631, Test Loss: 0.2927\n",
      "Epoch 1896/2000, Train Loss: 0.0631, Test Loss: 0.2949\n",
      "Epoch 1897/2000, Train Loss: 0.0635, Test Loss: 0.2948\n",
      "Epoch 1898/2000, Train Loss: 0.0634, Test Loss: 0.3059\n",
      "Epoch 1899/2000, Train Loss: 0.0629, Test Loss: 0.2958\n",
      "Epoch 1900/2000, Train Loss: 0.0628, Test Loss: 0.2966\n",
      "Epoch 1901/2000, Train Loss: 0.0630, Test Loss: 0.2961\n",
      "Epoch 1902/2000, Train Loss: 0.0634, Test Loss: 0.3016\n",
      "Epoch 1903/2000, Train Loss: 0.0630, Test Loss: 0.2946\n",
      "Epoch 1904/2000, Train Loss: 0.0629, Test Loss: 0.2969\n",
      "Epoch 1905/2000, Train Loss: 0.0630, Test Loss: 0.2926\n",
      "Epoch 1906/2000, Train Loss: 0.0630, Test Loss: 0.2931\n",
      "Epoch 1907/2000, Train Loss: 0.0631, Test Loss: 0.2945\n",
      "Epoch 1908/2000, Train Loss: 0.0634, Test Loss: 0.3072\n",
      "Epoch 1909/2000, Train Loss: 0.0630, Test Loss: 0.2949\n",
      "Epoch 1910/2000, Train Loss: 0.0631, Test Loss: 0.2941\n",
      "Epoch 1911/2000, Train Loss: 0.0630, Test Loss: 0.2937\n",
      "Epoch 1912/2000, Train Loss: 0.0630, Test Loss: 0.2929\n",
      "Epoch 1913/2000, Train Loss: 0.0624, Test Loss: 0.2930\n",
      "Epoch 1914/2000, Train Loss: 0.0626, Test Loss: 0.2982\n",
      "Epoch 1915/2000, Train Loss: 0.0626, Test Loss: 0.2938\n",
      "Epoch 1916/2000, Train Loss: 0.0629, Test Loss: 0.3033\n",
      "Epoch 1917/2000, Train Loss: 0.0630, Test Loss: 0.2960\n",
      "Epoch 1918/2000, Train Loss: 0.0631, Test Loss: 0.2926\n",
      "Epoch 1919/2000, Train Loss: 0.0630, Test Loss: 0.2985\n",
      "Epoch 1920/2000, Train Loss: 0.0628, Test Loss: 0.2928\n",
      "Epoch 1921/2000, Train Loss: 0.0628, Test Loss: 0.2937\n",
      "Epoch 1922/2000, Train Loss: 0.0629, Test Loss: 0.2932\n",
      "Epoch 1923/2000, Train Loss: 0.0629, Test Loss: 0.3002\n",
      "Epoch 1924/2000, Train Loss: 0.0628, Test Loss: 0.3006\n",
      "Epoch 1925/2000, Train Loss: 0.0632, Test Loss: 0.2937\n",
      "Epoch 1926/2000, Train Loss: 0.0627, Test Loss: 0.2993\n",
      "Epoch 1927/2000, Train Loss: 0.0630, Test Loss: 0.3054\n",
      "Epoch 1928/2000, Train Loss: 0.0629, Test Loss: 0.2948\n",
      "Epoch 1929/2000, Train Loss: 0.0626, Test Loss: 0.2972\n",
      "Epoch 1930/2000, Train Loss: 0.0626, Test Loss: 0.2997\n",
      "Epoch 1931/2000, Train Loss: 0.0628, Test Loss: 0.2991\n",
      "Epoch 1932/2000, Train Loss: 0.0626, Test Loss: 0.2960\n",
      "Epoch 1933/2000, Train Loss: 0.0630, Test Loss: 0.3069\n",
      "Epoch 1934/2000, Train Loss: 0.0628, Test Loss: 0.2945\n",
      "Epoch 1935/2000, Train Loss: 0.0628, Test Loss: 0.2967\n",
      "Epoch 1936/2000, Train Loss: 0.0624, Test Loss: 0.2925\n",
      "Epoch 1937/2000, Train Loss: 0.0627, Test Loss: 0.2941\n",
      "Epoch 1938/2000, Train Loss: 0.0626, Test Loss: 0.2938\n",
      "Epoch 1939/2000, Train Loss: 0.0629, Test Loss: 0.3074\n",
      "Epoch 1940/2000, Train Loss: 0.0628, Test Loss: 0.2972\n",
      "Epoch 1941/2000, Train Loss: 0.0627, Test Loss: 0.2953\n",
      "Epoch 1942/2000, Train Loss: 0.0628, Test Loss: 0.2934\n",
      "Epoch 1943/2000, Train Loss: 0.0630, Test Loss: 0.2930\n",
      "Epoch 1944/2000, Train Loss: 0.0628, Test Loss: 0.2947\n",
      "Epoch 1945/2000, Train Loss: 0.0627, Test Loss: 0.2937\n",
      "Epoch 1946/2000, Train Loss: 0.0628, Test Loss: 0.2949\n",
      "Epoch 1947/2000, Train Loss: 0.0623, Test Loss: 0.2959\n",
      "Epoch 1948/2000, Train Loss: 0.0625, Test Loss: 0.2964\n",
      "Epoch 1949/2000, Train Loss: 0.0627, Test Loss: 0.3046\n",
      "Epoch 1950/2000, Train Loss: 0.0626, Test Loss: 0.2936\n",
      "Epoch 1951/2000, Train Loss: 0.0621, Test Loss: 0.2952\n",
      "Epoch 1952/2000, Train Loss: 0.0624, Test Loss: 0.2964\n",
      "Epoch 1953/2000, Train Loss: 0.0624, Test Loss: 0.2984\n",
      "Epoch 1954/2000, Train Loss: 0.0623, Test Loss: 0.2993\n",
      "Epoch 1955/2000, Train Loss: 0.0623, Test Loss: 0.2997\n",
      "Epoch 1956/2000, Train Loss: 0.0626, Test Loss: 0.2977\n",
      "Epoch 1957/2000, Train Loss: 0.0627, Test Loss: 0.2945\n",
      "Epoch 1958/2000, Train Loss: 0.0625, Test Loss: 0.2942\n",
      "Epoch 1959/2000, Train Loss: 0.0625, Test Loss: 0.3047\n",
      "Epoch 1960/2000, Train Loss: 0.0627, Test Loss: 0.3121\n",
      "Epoch 1961/2000, Train Loss: 0.0624, Test Loss: 0.2938\n",
      "Epoch 1962/2000, Train Loss: 0.0624, Test Loss: 0.3028\n",
      "Epoch 1963/2000, Train Loss: 0.0626, Test Loss: 0.2954\n",
      "Epoch 1964/2000, Train Loss: 0.0626, Test Loss: 0.2974\n",
      "Epoch 1965/2000, Train Loss: 0.0625, Test Loss: 0.2976\n",
      "Epoch 1966/2000, Train Loss: 0.0626, Test Loss: 0.3000\n",
      "Epoch 1967/2000, Train Loss: 0.0626, Test Loss: 0.2940\n",
      "Epoch 1968/2000, Train Loss: 0.0625, Test Loss: 0.3015\n",
      "Epoch 1969/2000, Train Loss: 0.0620, Test Loss: 0.2979\n",
      "Epoch 1970/2000, Train Loss: 0.0623, Test Loss: 0.2956\n",
      "Epoch 1971/2000, Train Loss: 0.0624, Test Loss: 0.2938\n",
      "Epoch 1972/2000, Train Loss: 0.0623, Test Loss: 0.2950\n",
      "Epoch 1973/2000, Train Loss: 0.0625, Test Loss: 0.2990\n",
      "Epoch 1974/2000, Train Loss: 0.0627, Test Loss: 0.2954\n",
      "Epoch 1975/2000, Train Loss: 0.0622, Test Loss: 0.2958\n",
      "Epoch 1976/2000, Train Loss: 0.0621, Test Loss: 0.2989\n",
      "Epoch 1977/2000, Train Loss: 0.0620, Test Loss: 0.3027\n",
      "Epoch 1978/2000, Train Loss: 0.0624, Test Loss: 0.3024\n",
      "Epoch 1979/2000, Train Loss: 0.0624, Test Loss: 0.2988\n",
      "Epoch 1980/2000, Train Loss: 0.0622, Test Loss: 0.2952\n",
      "Epoch 1981/2000, Train Loss: 0.0621, Test Loss: 0.2977\n",
      "Epoch 1982/2000, Train Loss: 0.0627, Test Loss: 0.2992\n",
      "Epoch 1983/2000, Train Loss: 0.0627, Test Loss: 0.3020\n",
      "Epoch 1984/2000, Train Loss: 0.0626, Test Loss: 0.3033\n",
      "Epoch 1985/2000, Train Loss: 0.0623, Test Loss: 0.2962\n",
      "Epoch 1986/2000, Train Loss: 0.0622, Test Loss: 0.2985\n",
      "Epoch 1987/2000, Train Loss: 0.0623, Test Loss: 0.2973\n",
      "Epoch 1988/2000, Train Loss: 0.0623, Test Loss: 0.2990\n",
      "Epoch 1989/2000, Train Loss: 0.0623, Test Loss: 0.2958\n",
      "Epoch 1990/2000, Train Loss: 0.0626, Test Loss: 0.3032\n",
      "Epoch 1991/2000, Train Loss: 0.0624, Test Loss: 0.2972\n",
      "Epoch 1992/2000, Train Loss: 0.0623, Test Loss: 0.3163\n",
      "Epoch 1993/2000, Train Loss: 0.0623, Test Loss: 0.2983\n",
      "Epoch 1994/2000, Train Loss: 0.0622, Test Loss: 0.2978\n",
      "Epoch 1995/2000, Train Loss: 0.0623, Test Loss: 0.3022\n",
      "Epoch 1996/2000, Train Loss: 0.0621, Test Loss: 0.2956\n",
      "Epoch 1997/2000, Train Loss: 0.0620, Test Loss: 0.2978\n",
      "Epoch 1998/2000, Train Loss: 0.0623, Test Loss: 0.2982\n",
      "Epoch 1999/2000, Train Loss: 0.0623, Test Loss: 0.2962\n",
      "Epoch 2000/2000, Train Loss: 0.0621, Test Loss: 0.2964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.9366</td></tr><tr><td>accuracy/train</td><td>0.9833</td></tr><tr><td>batch_loss</td><td>0.02567</td></tr><tr><td>epoch</td><td>1999</td></tr><tr><td>loss/test</td><td>0.29642</td></tr><tr><td>loss/train</td><td>0.06207</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">serene-microwave-263</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/mw7z41vh' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/mw7z41vh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240313_102210-mw7z41vh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240313_121852-0p2h459d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/0p2h459d' target=\"_blank\">smart-bee-264</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/0p2h459d' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/0p2h459d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Train Loss: 0.5339, Test Loss: 0.3021\n",
      "Epoch 2/2000, Train Loss: 0.2637, Test Loss: 0.2412\n",
      "Epoch 3/2000, Train Loss: 0.2182, Test Loss: 0.2000\n",
      "Epoch 4/2000, Train Loss: 0.1904, Test Loss: 0.1906\n",
      "Epoch 5/2000, Train Loss: 0.1722, Test Loss: 0.1801\n",
      "Epoch 6/2000, Train Loss: 0.1583, Test Loss: 0.1633\n",
      "Epoch 7/2000, Train Loss: 0.1472, Test Loss: 0.1571\n",
      "Epoch 8/2000, Train Loss: 0.1372, Test Loss: 0.1493\n",
      "Epoch 9/2000, Train Loss: 0.1314, Test Loss: 0.1494\n",
      "Epoch 10/2000, Train Loss: 0.1247, Test Loss: 0.1471\n",
      "Epoch 11/2000, Train Loss: 0.1218, Test Loss: 0.1514\n",
      "Epoch 12/2000, Train Loss: 0.1170, Test Loss: 0.1383\n",
      "Epoch 13/2000, Train Loss: 0.1128, Test Loss: 0.1390\n",
      "Epoch 14/2000, Train Loss: 0.1101, Test Loss: 0.1373\n",
      "Epoch 15/2000, Train Loss: 0.1066, Test Loss: 0.1292\n",
      "Epoch 16/2000, Train Loss: 0.1052, Test Loss: 0.1359\n",
      "Epoch 17/2000, Train Loss: 0.1004, Test Loss: 0.1318\n",
      "Epoch 18/2000, Train Loss: 0.0973, Test Loss: 0.1261\n",
      "Epoch 19/2000, Train Loss: 0.0959, Test Loss: 0.1262\n",
      "Epoch 20/2000, Train Loss: 0.0937, Test Loss: 0.1332\n",
      "Epoch 21/2000, Train Loss: 0.0918, Test Loss: 0.1272\n",
      "Epoch 22/2000, Train Loss: 0.0898, Test Loss: 0.1269\n",
      "Epoch 23/2000, Train Loss: 0.0876, Test Loss: 0.1272\n",
      "Epoch 24/2000, Train Loss: 0.0853, Test Loss: 0.1246\n",
      "Epoch 25/2000, Train Loss: 0.0850, Test Loss: 0.1229\n",
      "Epoch 26/2000, Train Loss: 0.0825, Test Loss: 0.1282\n",
      "Epoch 27/2000, Train Loss: 0.0824, Test Loss: 0.1311\n",
      "Epoch 28/2000, Train Loss: 0.0818, Test Loss: 0.1239\n",
      "Epoch 29/2000, Train Loss: 0.0800, Test Loss: 0.1214\n",
      "Epoch 30/2000, Train Loss: 0.0782, Test Loss: 0.1209\n",
      "Epoch 31/2000, Train Loss: 0.0773, Test Loss: 0.1224\n",
      "Epoch 32/2000, Train Loss: 0.0754, Test Loss: 0.1230\n",
      "Epoch 33/2000, Train Loss: 0.0750, Test Loss: 0.1203\n",
      "Epoch 34/2000, Train Loss: 0.0733, Test Loss: 0.1218\n",
      "Epoch 35/2000, Train Loss: 0.0734, Test Loss: 0.1232\n",
      "Epoch 36/2000, Train Loss: 0.0718, Test Loss: 0.1183\n",
      "Epoch 37/2000, Train Loss: 0.0710, Test Loss: 0.1176\n",
      "Epoch 38/2000, Train Loss: 0.0702, Test Loss: 0.1187\n",
      "Epoch 39/2000, Train Loss: 0.0689, Test Loss: 0.1258\n",
      "Epoch 40/2000, Train Loss: 0.0686, Test Loss: 0.1250\n",
      "Epoch 41/2000, Train Loss: 0.0680, Test Loss: 0.1173\n",
      "Epoch 42/2000, Train Loss: 0.0670, Test Loss: 0.1315\n",
      "Epoch 43/2000, Train Loss: 0.0666, Test Loss: 0.1216\n",
      "Epoch 44/2000, Train Loss: 0.0653, Test Loss: 0.1211\n",
      "Epoch 45/2000, Train Loss: 0.0652, Test Loss: 0.1184\n",
      "Epoch 46/2000, Train Loss: 0.0647, Test Loss: 0.1193\n",
      "Epoch 47/2000, Train Loss: 0.0639, Test Loss: 0.1203\n",
      "Epoch 48/2000, Train Loss: 0.0624, Test Loss: 0.1174\n",
      "Epoch 49/2000, Train Loss: 0.0621, Test Loss: 0.1174\n",
      "Epoch 50/2000, Train Loss: 0.0617, Test Loss: 0.1183\n",
      "Epoch 51/2000, Train Loss: 0.0608, Test Loss: 0.1202\n",
      "Epoch 52/2000, Train Loss: 0.0602, Test Loss: 0.1244\n",
      "Epoch 53/2000, Train Loss: 0.0601, Test Loss: 0.1217\n",
      "Epoch 54/2000, Train Loss: 0.0598, Test Loss: 0.1244\n",
      "Epoch 55/2000, Train Loss: 0.0589, Test Loss: 0.1199\n",
      "Epoch 56/2000, Train Loss: 0.0580, Test Loss: 0.1180\n",
      "Epoch 57/2000, Train Loss: 0.0578, Test Loss: 0.1196\n",
      "Epoch 58/2000, Train Loss: 0.0570, Test Loss: 0.1205\n",
      "Epoch 59/2000, Train Loss: 0.0564, Test Loss: 0.1172\n",
      "Epoch 60/2000, Train Loss: 0.0566, Test Loss: 0.1207\n",
      "Epoch 61/2000, Train Loss: 0.0559, Test Loss: 0.1248\n",
      "Epoch 62/2000, Train Loss: 0.0558, Test Loss: 0.1212\n",
      "Epoch 63/2000, Train Loss: 0.0549, Test Loss: 0.1200\n",
      "Epoch 64/2000, Train Loss: 0.0539, Test Loss: 0.1287\n",
      "Epoch 65/2000, Train Loss: 0.0539, Test Loss: 0.1202\n",
      "Epoch 66/2000, Train Loss: 0.0533, Test Loss: 0.1184\n",
      "Epoch 67/2000, Train Loss: 0.0537, Test Loss: 0.1188\n",
      "Epoch 68/2000, Train Loss: 0.0525, Test Loss: 0.1214\n",
      "Epoch 69/2000, Train Loss: 0.0526, Test Loss: 0.1234\n",
      "Epoch 70/2000, Train Loss: 0.0512, Test Loss: 0.1286\n",
      "Epoch 71/2000, Train Loss: 0.0524, Test Loss: 0.1181\n",
      "Epoch 72/2000, Train Loss: 0.0510, Test Loss: 0.1187\n",
      "Epoch 73/2000, Train Loss: 0.0503, Test Loss: 0.1219\n",
      "Epoch 74/2000, Train Loss: 0.0504, Test Loss: 0.1187\n",
      "Epoch 75/2000, Train Loss: 0.0495, Test Loss: 0.1183\n",
      "Epoch 76/2000, Train Loss: 0.0491, Test Loss: 0.1197\n",
      "Epoch 77/2000, Train Loss: 0.0488, Test Loss: 0.1214\n",
      "Epoch 78/2000, Train Loss: 0.0489, Test Loss: 0.1184\n",
      "Epoch 79/2000, Train Loss: 0.0480, Test Loss: 0.1213\n",
      "Epoch 80/2000, Train Loss: 0.0477, Test Loss: 0.1190\n",
      "Epoch 81/2000, Train Loss: 0.0476, Test Loss: 0.1225\n",
      "Epoch 82/2000, Train Loss: 0.0479, Test Loss: 0.1269\n",
      "Epoch 83/2000, Train Loss: 0.0473, Test Loss: 0.1229\n",
      "Epoch 84/2000, Train Loss: 0.0468, Test Loss: 0.1233\n",
      "Epoch 85/2000, Train Loss: 0.0461, Test Loss: 0.1296\n",
      "Epoch 86/2000, Train Loss: 0.0459, Test Loss: 0.1232\n",
      "Epoch 87/2000, Train Loss: 0.0454, Test Loss: 0.1232\n",
      "Epoch 88/2000, Train Loss: 0.0455, Test Loss: 0.1256\n",
      "Epoch 89/2000, Train Loss: 0.0452, Test Loss: 0.1205\n",
      "Epoch 90/2000, Train Loss: 0.0451, Test Loss: 0.1227\n",
      "Epoch 91/2000, Train Loss: 0.0443, Test Loss: 0.1223\n",
      "Epoch 92/2000, Train Loss: 0.0441, Test Loss: 0.1211\n",
      "Epoch 93/2000, Train Loss: 0.0440, Test Loss: 0.1203\n",
      "Epoch 94/2000, Train Loss: 0.0438, Test Loss: 0.1238\n",
      "Epoch 95/2000, Train Loss: 0.0432, Test Loss: 0.1209\n",
      "Epoch 96/2000, Train Loss: 0.0434, Test Loss: 0.1217\n",
      "Epoch 97/2000, Train Loss: 0.0429, Test Loss: 0.1226\n",
      "Epoch 98/2000, Train Loss: 0.0426, Test Loss: 0.1234\n",
      "Epoch 99/2000, Train Loss: 0.0425, Test Loss: 0.1225\n",
      "Epoch 100/2000, Train Loss: 0.0420, Test Loss: 0.1249\n",
      "Epoch 101/2000, Train Loss: 0.0418, Test Loss: 0.1223\n",
      "Epoch 102/2000, Train Loss: 0.0414, Test Loss: 0.1282\n",
      "Epoch 103/2000, Train Loss: 0.0413, Test Loss: 0.1235\n",
      "Epoch 104/2000, Train Loss: 0.0411, Test Loss: 0.1239\n",
      "Epoch 105/2000, Train Loss: 0.0408, Test Loss: 0.1225\n",
      "Epoch 106/2000, Train Loss: 0.0404, Test Loss: 0.1257\n",
      "Epoch 107/2000, Train Loss: 0.0403, Test Loss: 0.1232\n",
      "Epoch 108/2000, Train Loss: 0.0403, Test Loss: 0.1240\n",
      "Epoch 109/2000, Train Loss: 0.0397, Test Loss: 0.1234\n",
      "Epoch 110/2000, Train Loss: 0.0392, Test Loss: 0.1256\n",
      "Epoch 111/2000, Train Loss: 0.0392, Test Loss: 0.1244\n",
      "Epoch 112/2000, Train Loss: 0.0392, Test Loss: 0.1239\n",
      "Epoch 113/2000, Train Loss: 0.0392, Test Loss: 0.1245\n",
      "Epoch 114/2000, Train Loss: 0.0383, Test Loss: 0.1243\n",
      "Epoch 115/2000, Train Loss: 0.0390, Test Loss: 0.1239\n",
      "Epoch 116/2000, Train Loss: 0.0381, Test Loss: 0.1251\n",
      "Epoch 117/2000, Train Loss: 0.0380, Test Loss: 0.1238\n",
      "Epoch 118/2000, Train Loss: 0.0381, Test Loss: 0.1311\n",
      "Epoch 119/2000, Train Loss: 0.0379, Test Loss: 0.1259\n",
      "Epoch 120/2000, Train Loss: 0.0372, Test Loss: 0.1299\n",
      "Epoch 121/2000, Train Loss: 0.0371, Test Loss: 0.1257\n",
      "Epoch 122/2000, Train Loss: 0.0373, Test Loss: 0.1297\n",
      "Epoch 123/2000, Train Loss: 0.0369, Test Loss: 0.1265\n",
      "Epoch 124/2000, Train Loss: 0.0367, Test Loss: 0.1248\n",
      "Epoch 125/2000, Train Loss: 0.0361, Test Loss: 0.1275\n",
      "Epoch 126/2000, Train Loss: 0.0362, Test Loss: 0.1276\n",
      "Epoch 127/2000, Train Loss: 0.0363, Test Loss: 0.1267\n",
      "Epoch 128/2000, Train Loss: 0.0360, Test Loss: 0.1292\n",
      "Epoch 129/2000, Train Loss: 0.0358, Test Loss: 0.1297\n",
      "Epoch 130/2000, Train Loss: 0.0356, Test Loss: 0.1261\n",
      "Epoch 131/2000, Train Loss: 0.0354, Test Loss: 0.1279\n",
      "Epoch 132/2000, Train Loss: 0.0347, Test Loss: 0.1290\n",
      "Epoch 133/2000, Train Loss: 0.0351, Test Loss: 0.1258\n",
      "Epoch 134/2000, Train Loss: 0.0347, Test Loss: 0.1272\n",
      "Epoch 135/2000, Train Loss: 0.0345, Test Loss: 0.1284\n",
      "Epoch 136/2000, Train Loss: 0.0346, Test Loss: 0.1272\n",
      "Epoch 137/2000, Train Loss: 0.0344, Test Loss: 0.1278\n",
      "Epoch 138/2000, Train Loss: 0.0341, Test Loss: 0.1281\n",
      "Epoch 139/2000, Train Loss: 0.0339, Test Loss: 0.1277\n",
      "Epoch 140/2000, Train Loss: 0.0336, Test Loss: 0.1296\n",
      "Epoch 141/2000, Train Loss: 0.0334, Test Loss: 0.1281\n",
      "Epoch 142/2000, Train Loss: 0.0332, Test Loss: 0.1285\n",
      "Epoch 143/2000, Train Loss: 0.0331, Test Loss: 0.1353\n",
      "Epoch 144/2000, Train Loss: 0.0330, Test Loss: 0.1355\n",
      "Epoch 145/2000, Train Loss: 0.0326, Test Loss: 0.1337\n",
      "Epoch 146/2000, Train Loss: 0.0327, Test Loss: 0.1337\n",
      "Epoch 147/2000, Train Loss: 0.0325, Test Loss: 0.1341\n",
      "Epoch 148/2000, Train Loss: 0.0327, Test Loss: 0.1306\n",
      "Epoch 149/2000, Train Loss: 0.0320, Test Loss: 0.1326\n",
      "Epoch 150/2000, Train Loss: 0.0320, Test Loss: 0.1301\n",
      "Epoch 151/2000, Train Loss: 0.0321, Test Loss: 0.1310\n",
      "Epoch 152/2000, Train Loss: 0.0318, Test Loss: 0.1298\n",
      "Epoch 153/2000, Train Loss: 0.0316, Test Loss: 0.1311\n",
      "Epoch 154/2000, Train Loss: 0.0317, Test Loss: 0.1309\n",
      "Epoch 155/2000, Train Loss: 0.0314, Test Loss: 0.1356\n",
      "Epoch 156/2000, Train Loss: 0.0314, Test Loss: 0.1313\n",
      "Epoch 157/2000, Train Loss: 0.0309, Test Loss: 0.1338\n",
      "Epoch 158/2000, Train Loss: 0.0308, Test Loss: 0.1329\n",
      "Epoch 159/2000, Train Loss: 0.0310, Test Loss: 0.1296\n",
      "Epoch 160/2000, Train Loss: 0.0304, Test Loss: 0.1317\n",
      "Epoch 161/2000, Train Loss: 0.0305, Test Loss: 0.1324\n",
      "Epoch 162/2000, Train Loss: 0.0302, Test Loss: 0.1328\n",
      "Epoch 163/2000, Train Loss: 0.0303, Test Loss: 0.1308\n",
      "Epoch 164/2000, Train Loss: 0.0301, Test Loss: 0.1319\n",
      "Epoch 165/2000, Train Loss: 0.0297, Test Loss: 0.1386\n",
      "Epoch 166/2000, Train Loss: 0.0298, Test Loss: 0.1328\n",
      "Epoch 167/2000, Train Loss: 0.0294, Test Loss: 0.1419\n",
      "Epoch 168/2000, Train Loss: 0.0295, Test Loss: 0.1330\n",
      "Epoch 169/2000, Train Loss: 0.0292, Test Loss: 0.1322\n",
      "Epoch 170/2000, Train Loss: 0.0295, Test Loss: 0.1329\n",
      "Epoch 171/2000, Train Loss: 0.0292, Test Loss: 0.1327\n",
      "Epoch 172/2000, Train Loss: 0.0290, Test Loss: 0.1332\n",
      "Epoch 173/2000, Train Loss: 0.0285, Test Loss: 0.1353\n",
      "Epoch 174/2000, Train Loss: 0.0288, Test Loss: 0.1349\n",
      "Epoch 175/2000, Train Loss: 0.0287, Test Loss: 0.1341\n",
      "Epoch 176/2000, Train Loss: 0.0285, Test Loss: 0.1347\n",
      "Epoch 177/2000, Train Loss: 0.0286, Test Loss: 0.1345\n",
      "Epoch 178/2000, Train Loss: 0.0281, Test Loss: 0.1363\n",
      "Epoch 179/2000, Train Loss: 0.0281, Test Loss: 0.1323\n",
      "Epoch 180/2000, Train Loss: 0.0279, Test Loss: 0.1419\n",
      "Epoch 181/2000, Train Loss: 0.0278, Test Loss: 0.1341\n",
      "Epoch 182/2000, Train Loss: 0.0277, Test Loss: 0.1351\n",
      "Epoch 183/2000, Train Loss: 0.0275, Test Loss: 0.1345\n",
      "Epoch 184/2000, Train Loss: 0.0276, Test Loss: 0.1333\n",
      "Epoch 185/2000, Train Loss: 0.0273, Test Loss: 0.1425\n",
      "Epoch 186/2000, Train Loss: 0.0277, Test Loss: 0.1336\n",
      "Epoch 187/2000, Train Loss: 0.0275, Test Loss: 0.1346\n",
      "Epoch 188/2000, Train Loss: 0.0270, Test Loss: 0.1345\n",
      "Epoch 189/2000, Train Loss: 0.0271, Test Loss: 0.1382\n",
      "Epoch 190/2000, Train Loss: 0.0267, Test Loss: 0.1362\n",
      "Epoch 191/2000, Train Loss: 0.0268, Test Loss: 0.1381\n",
      "Epoch 192/2000, Train Loss: 0.0264, Test Loss: 0.1412\n",
      "Epoch 193/2000, Train Loss: 0.0265, Test Loss: 0.1350\n",
      "Epoch 194/2000, Train Loss: 0.0267, Test Loss: 0.1392\n",
      "Epoch 195/2000, Train Loss: 0.0261, Test Loss: 0.1433\n",
      "Epoch 196/2000, Train Loss: 0.0263, Test Loss: 0.1390\n",
      "Epoch 197/2000, Train Loss: 0.0262, Test Loss: 0.1371\n",
      "Epoch 198/2000, Train Loss: 0.0261, Test Loss: 0.1400\n",
      "Epoch 199/2000, Train Loss: 0.0260, Test Loss: 0.1376\n",
      "Epoch 200/2000, Train Loss: 0.0257, Test Loss: 0.1378\n",
      "Epoch 201/2000, Train Loss: 0.0257, Test Loss: 0.1375\n",
      "Epoch 202/2000, Train Loss: 0.0256, Test Loss: 0.1410\n",
      "Epoch 203/2000, Train Loss: 0.0252, Test Loss: 0.1386\n",
      "Epoch 204/2000, Train Loss: 0.0254, Test Loss: 0.1399\n",
      "Epoch 205/2000, Train Loss: 0.0254, Test Loss: 0.1365\n",
      "Epoch 206/2000, Train Loss: 0.0253, Test Loss: 0.1360\n",
      "Epoch 207/2000, Train Loss: 0.0253, Test Loss: 0.1370\n",
      "Epoch 208/2000, Train Loss: 0.0248, Test Loss: 0.1378\n",
      "Epoch 209/2000, Train Loss: 0.0248, Test Loss: 0.1384\n",
      "Epoch 210/2000, Train Loss: 0.0249, Test Loss: 0.1450\n",
      "Epoch 211/2000, Train Loss: 0.0248, Test Loss: 0.1386\n",
      "Epoch 212/2000, Train Loss: 0.0246, Test Loss: 0.1374\n",
      "Epoch 213/2000, Train Loss: 0.0246, Test Loss: 0.1405\n",
      "Epoch 214/2000, Train Loss: 0.0245, Test Loss: 0.1522\n",
      "Epoch 215/2000, Train Loss: 0.0243, Test Loss: 0.1395\n",
      "Epoch 216/2000, Train Loss: 0.0242, Test Loss: 0.1379\n",
      "Epoch 217/2000, Train Loss: 0.0242, Test Loss: 0.1378\n",
      "Epoch 218/2000, Train Loss: 0.0240, Test Loss: 0.1399\n",
      "Epoch 219/2000, Train Loss: 0.0240, Test Loss: 0.1394\n",
      "Epoch 220/2000, Train Loss: 0.0239, Test Loss: 0.1400\n",
      "Epoch 221/2000, Train Loss: 0.0239, Test Loss: 0.1394\n",
      "Epoch 222/2000, Train Loss: 0.0240, Test Loss: 0.1390\n",
      "Epoch 223/2000, Train Loss: 0.0235, Test Loss: 0.1410\n",
      "Epoch 224/2000, Train Loss: 0.0236, Test Loss: 0.1419\n",
      "Epoch 225/2000, Train Loss: 0.0234, Test Loss: 0.1401\n",
      "Epoch 226/2000, Train Loss: 0.0234, Test Loss: 0.1411\n",
      "Epoch 227/2000, Train Loss: 0.0233, Test Loss: 0.1387\n",
      "Epoch 228/2000, Train Loss: 0.0234, Test Loss: 0.1434\n",
      "Epoch 229/2000, Train Loss: 0.0230, Test Loss: 0.1439\n",
      "Epoch 230/2000, Train Loss: 0.0230, Test Loss: 0.1438\n",
      "Epoch 231/2000, Train Loss: 0.0229, Test Loss: 0.1408\n",
      "Epoch 232/2000, Train Loss: 0.0229, Test Loss: 0.1422\n",
      "Epoch 233/2000, Train Loss: 0.0228, Test Loss: 0.1407\n",
      "Epoch 234/2000, Train Loss: 0.0226, Test Loss: 0.1428\n",
      "Epoch 235/2000, Train Loss: 0.0228, Test Loss: 0.1500\n",
      "Epoch 236/2000, Train Loss: 0.0225, Test Loss: 0.1415\n",
      "Epoch 237/2000, Train Loss: 0.0224, Test Loss: 0.1414\n",
      "Epoch 238/2000, Train Loss: 0.0223, Test Loss: 0.1414\n",
      "Epoch 239/2000, Train Loss: 0.0223, Test Loss: 0.1435\n",
      "Epoch 240/2000, Train Loss: 0.0223, Test Loss: 0.1417\n",
      "Epoch 241/2000, Train Loss: 0.0222, Test Loss: 0.1421\n",
      "Epoch 242/2000, Train Loss: 0.0219, Test Loss: 0.1452\n",
      "Epoch 243/2000, Train Loss: 0.0219, Test Loss: 0.1431\n",
      "Epoch 244/2000, Train Loss: 0.0219, Test Loss: 0.1426\n",
      "Epoch 245/2000, Train Loss: 0.0219, Test Loss: 0.1430\n",
      "Epoch 246/2000, Train Loss: 0.0218, Test Loss: 0.1462\n",
      "Epoch 247/2000, Train Loss: 0.0217, Test Loss: 0.1434\n",
      "Epoch 248/2000, Train Loss: 0.0217, Test Loss: 0.1422\n",
      "Epoch 249/2000, Train Loss: 0.0217, Test Loss: 0.1451\n",
      "Epoch 250/2000, Train Loss: 0.0213, Test Loss: 0.1447\n",
      "Epoch 251/2000, Train Loss: 0.0212, Test Loss: 0.1422\n",
      "Epoch 252/2000, Train Loss: 0.0212, Test Loss: 0.1492\n",
      "Epoch 253/2000, Train Loss: 0.0211, Test Loss: 0.1446\n",
      "Epoch 254/2000, Train Loss: 0.0212, Test Loss: 0.1425\n",
      "Epoch 255/2000, Train Loss: 0.0209, Test Loss: 0.1446\n",
      "Epoch 256/2000, Train Loss: 0.0214, Test Loss: 0.1440\n",
      "Epoch 257/2000, Train Loss: 0.0210, Test Loss: 0.1433\n",
      "Epoch 258/2000, Train Loss: 0.0209, Test Loss: 0.1435\n",
      "Epoch 259/2000, Train Loss: 0.0209, Test Loss: 0.1446\n",
      "Epoch 260/2000, Train Loss: 0.0207, Test Loss: 0.1451\n",
      "Epoch 261/2000, Train Loss: 0.0206, Test Loss: 0.1451\n",
      "Epoch 262/2000, Train Loss: 0.0207, Test Loss: 0.1445\n",
      "Epoch 263/2000, Train Loss: 0.0207, Test Loss: 0.1435\n",
      "Epoch 264/2000, Train Loss: 0.0205, Test Loss: 0.1438\n",
      "Epoch 265/2000, Train Loss: 0.0204, Test Loss: 0.1523\n",
      "Epoch 266/2000, Train Loss: 0.0203, Test Loss: 0.1459\n",
      "Epoch 267/2000, Train Loss: 0.0201, Test Loss: 0.1540\n",
      "Epoch 268/2000, Train Loss: 0.0202, Test Loss: 0.1483\n",
      "Epoch 269/2000, Train Loss: 0.0201, Test Loss: 0.1453\n",
      "Epoch 270/2000, Train Loss: 0.0201, Test Loss: 0.1447\n",
      "Epoch 271/2000, Train Loss: 0.0199, Test Loss: 0.1474\n",
      "Epoch 272/2000, Train Loss: 0.0200, Test Loss: 0.1477\n",
      "Epoch 273/2000, Train Loss: 0.0198, Test Loss: 0.1454\n",
      "Epoch 274/2000, Train Loss: 0.0199, Test Loss: 0.1470\n",
      "Epoch 275/2000, Train Loss: 0.0198, Test Loss: 0.1453\n",
      "Epoch 276/2000, Train Loss: 0.0197, Test Loss: 0.1488\n",
      "Epoch 277/2000, Train Loss: 0.0196, Test Loss: 0.1556\n",
      "Epoch 278/2000, Train Loss: 0.0195, Test Loss: 0.1494\n",
      "Epoch 279/2000, Train Loss: 0.0196, Test Loss: 0.1488\n",
      "Epoch 280/2000, Train Loss: 0.0194, Test Loss: 0.1453\n",
      "Epoch 281/2000, Train Loss: 0.0193, Test Loss: 0.1471\n",
      "Epoch 282/2000, Train Loss: 0.0193, Test Loss: 0.1553\n",
      "Epoch 283/2000, Train Loss: 0.0191, Test Loss: 0.1476\n",
      "Epoch 284/2000, Train Loss: 0.0191, Test Loss: 0.1487\n",
      "Epoch 285/2000, Train Loss: 0.0191, Test Loss: 0.1470\n",
      "Epoch 286/2000, Train Loss: 0.0190, Test Loss: 0.1503\n",
      "Epoch 287/2000, Train Loss: 0.0189, Test Loss: 0.1482\n",
      "Epoch 288/2000, Train Loss: 0.0190, Test Loss: 0.1477\n",
      "Epoch 289/2000, Train Loss: 0.0191, Test Loss: 0.1480\n",
      "Epoch 290/2000, Train Loss: 0.0188, Test Loss: 0.1478\n",
      "Epoch 291/2000, Train Loss: 0.0187, Test Loss: 0.1495\n",
      "Epoch 292/2000, Train Loss: 0.0186, Test Loss: 0.1521\n",
      "Epoch 293/2000, Train Loss: 0.0187, Test Loss: 0.1510\n",
      "Epoch 294/2000, Train Loss: 0.0185, Test Loss: 0.1539\n",
      "Epoch 295/2000, Train Loss: 0.0184, Test Loss: 0.1492\n",
      "Epoch 296/2000, Train Loss: 0.0185, Test Loss: 0.1491\n",
      "Epoch 297/2000, Train Loss: 0.0184, Test Loss: 0.1493\n",
      "Epoch 298/2000, Train Loss: 0.0183, Test Loss: 0.1490\n",
      "Epoch 299/2000, Train Loss: 0.0186, Test Loss: 0.1526\n",
      "Epoch 300/2000, Train Loss: 0.0182, Test Loss: 0.1487\n",
      "Epoch 301/2000, Train Loss: 0.0183, Test Loss: 0.1498\n",
      "Epoch 302/2000, Train Loss: 0.0181, Test Loss: 0.1501\n",
      "Epoch 303/2000, Train Loss: 0.0181, Test Loss: 0.1524\n",
      "Epoch 304/2000, Train Loss: 0.0179, Test Loss: 0.1512\n",
      "Epoch 305/2000, Train Loss: 0.0179, Test Loss: 0.1497\n",
      "Epoch 306/2000, Train Loss: 0.0179, Test Loss: 0.1561\n",
      "Epoch 307/2000, Train Loss: 0.0178, Test Loss: 0.1499\n",
      "Epoch 308/2000, Train Loss: 0.0178, Test Loss: 0.1502\n",
      "Epoch 309/2000, Train Loss: 0.0177, Test Loss: 0.1488\n",
      "Epoch 310/2000, Train Loss: 0.0178, Test Loss: 0.1502\n",
      "Epoch 311/2000, Train Loss: 0.0177, Test Loss: 0.1509\n",
      "Epoch 312/2000, Train Loss: 0.0176, Test Loss: 0.1522\n",
      "Epoch 313/2000, Train Loss: 0.0174, Test Loss: 0.1564\n",
      "Epoch 314/2000, Train Loss: 0.0174, Test Loss: 0.1561\n",
      "Epoch 315/2000, Train Loss: 0.0173, Test Loss: 0.1507\n",
      "Epoch 316/2000, Train Loss: 0.0173, Test Loss: 0.1550\n",
      "Epoch 317/2000, Train Loss: 0.0174, Test Loss: 0.1582\n",
      "Epoch 318/2000, Train Loss: 0.0172, Test Loss: 0.1504\n",
      "Epoch 319/2000, Train Loss: 0.0173, Test Loss: 0.1512\n",
      "Epoch 320/2000, Train Loss: 0.0172, Test Loss: 0.1573\n",
      "Epoch 321/2000, Train Loss: 0.0171, Test Loss: 0.1531\n",
      "Epoch 322/2000, Train Loss: 0.0171, Test Loss: 0.1531\n",
      "Epoch 323/2000, Train Loss: 0.0170, Test Loss: 0.1520\n",
      "Epoch 324/2000, Train Loss: 0.0170, Test Loss: 0.1577\n",
      "Epoch 325/2000, Train Loss: 0.0169, Test Loss: 0.1542\n",
      "Epoch 326/2000, Train Loss: 0.0167, Test Loss: 0.1536\n",
      "Epoch 327/2000, Train Loss: 0.0168, Test Loss: 0.1527\n",
      "Epoch 328/2000, Train Loss: 0.0168, Test Loss: 0.1518\n",
      "Epoch 329/2000, Train Loss: 0.0168, Test Loss: 0.1559\n",
      "Epoch 330/2000, Train Loss: 0.0167, Test Loss: 0.1559\n",
      "Epoch 331/2000, Train Loss: 0.0167, Test Loss: 0.1542\n",
      "Epoch 332/2000, Train Loss: 0.0166, Test Loss: 0.1538\n",
      "Epoch 333/2000, Train Loss: 0.0166, Test Loss: 0.1530\n",
      "Epoch 334/2000, Train Loss: 0.0165, Test Loss: 0.1567\n",
      "Epoch 335/2000, Train Loss: 0.0164, Test Loss: 0.1534\n",
      "Epoch 336/2000, Train Loss: 0.0166, Test Loss: 0.1533\n",
      "Epoch 337/2000, Train Loss: 0.0163, Test Loss: 0.1566\n",
      "Epoch 338/2000, Train Loss: 0.0164, Test Loss: 0.1552\n",
      "Epoch 339/2000, Train Loss: 0.0164, Test Loss: 0.1577\n",
      "Epoch 340/2000, Train Loss: 0.0161, Test Loss: 0.1541\n",
      "Epoch 341/2000, Train Loss: 0.0162, Test Loss: 0.1579\n",
      "Epoch 342/2000, Train Loss: 0.0162, Test Loss: 0.1541\n",
      "Epoch 343/2000, Train Loss: 0.0162, Test Loss: 0.1533\n",
      "Epoch 344/2000, Train Loss: 0.0161, Test Loss: 0.1568\n",
      "Epoch 345/2000, Train Loss: 0.0160, Test Loss: 0.1537\n",
      "Epoch 346/2000, Train Loss: 0.0159, Test Loss: 0.1555\n",
      "Epoch 347/2000, Train Loss: 0.0160, Test Loss: 0.1537\n",
      "Epoch 348/2000, Train Loss: 0.0160, Test Loss: 0.1563\n",
      "Epoch 349/2000, Train Loss: 0.0160, Test Loss: 0.1581\n",
      "Epoch 350/2000, Train Loss: 0.0157, Test Loss: 0.1548\n",
      "Epoch 351/2000, Train Loss: 0.0157, Test Loss: 0.1541\n",
      "Epoch 352/2000, Train Loss: 0.0157, Test Loss: 0.1547\n",
      "Epoch 353/2000, Train Loss: 0.0157, Test Loss: 0.1642\n",
      "Epoch 354/2000, Train Loss: 0.0156, Test Loss: 0.1545\n",
      "Epoch 355/2000, Train Loss: 0.0157, Test Loss: 0.1579\n",
      "Epoch 356/2000, Train Loss: 0.0157, Test Loss: 0.1579\n",
      "Epoch 357/2000, Train Loss: 0.0156, Test Loss: 0.1560\n",
      "Epoch 358/2000, Train Loss: 0.0155, Test Loss: 0.1607\n",
      "Epoch 359/2000, Train Loss: 0.0154, Test Loss: 0.1597\n",
      "Epoch 360/2000, Train Loss: 0.0153, Test Loss: 0.1567\n",
      "Epoch 361/2000, Train Loss: 0.0153, Test Loss: 0.1557\n",
      "Epoch 362/2000, Train Loss: 0.0153, Test Loss: 0.1562\n",
      "Epoch 363/2000, Train Loss: 0.0153, Test Loss: 0.1549\n",
      "Epoch 364/2000, Train Loss: 0.0152, Test Loss: 0.1562\n",
      "Epoch 365/2000, Train Loss: 0.0152, Test Loss: 0.1552\n",
      "Epoch 366/2000, Train Loss: 0.0151, Test Loss: 0.1565\n",
      "Epoch 367/2000, Train Loss: 0.0151, Test Loss: 0.1627\n",
      "Epoch 368/2000, Train Loss: 0.0150, Test Loss: 0.1571\n",
      "Epoch 369/2000, Train Loss: 0.0151, Test Loss: 0.1560\n",
      "Epoch 370/2000, Train Loss: 0.0149, Test Loss: 0.1555\n",
      "Epoch 371/2000, Train Loss: 0.0149, Test Loss: 0.1631\n",
      "Epoch 372/2000, Train Loss: 0.0149, Test Loss: 0.1563\n",
      "Epoch 373/2000, Train Loss: 0.0149, Test Loss: 0.1561\n",
      "Epoch 374/2000, Train Loss: 0.0148, Test Loss: 0.1579\n",
      "Epoch 375/2000, Train Loss: 0.0148, Test Loss: 0.1605\n",
      "Epoch 376/2000, Train Loss: 0.0146, Test Loss: 0.1568\n",
      "Epoch 377/2000, Train Loss: 0.0147, Test Loss: 0.1577\n",
      "Epoch 378/2000, Train Loss: 0.0147, Test Loss: 0.1566\n",
      "Epoch 379/2000, Train Loss: 0.0147, Test Loss: 0.1566\n",
      "Epoch 380/2000, Train Loss: 0.0146, Test Loss: 0.1668\n",
      "Epoch 381/2000, Train Loss: 0.0146, Test Loss: 0.1576\n",
      "Epoch 382/2000, Train Loss: 0.0145, Test Loss: 0.1587\n",
      "Epoch 383/2000, Train Loss: 0.0145, Test Loss: 0.1590\n",
      "Epoch 384/2000, Train Loss: 0.0144, Test Loss: 0.1612\n",
      "Epoch 385/2000, Train Loss: 0.0143, Test Loss: 0.1588\n",
      "Epoch 386/2000, Train Loss: 0.0143, Test Loss: 0.1581\n",
      "Epoch 387/2000, Train Loss: 0.0144, Test Loss: 0.1572\n",
      "Epoch 388/2000, Train Loss: 0.0143, Test Loss: 0.1606\n",
      "Epoch 389/2000, Train Loss: 0.0142, Test Loss: 0.1580\n",
      "Epoch 390/2000, Train Loss: 0.0142, Test Loss: 0.1585\n",
      "Epoch 391/2000, Train Loss: 0.0142, Test Loss: 0.1596\n",
      "Epoch 392/2000, Train Loss: 0.0145, Test Loss: 0.1602\n",
      "Epoch 393/2000, Train Loss: 0.0141, Test Loss: 0.1587\n",
      "Epoch 394/2000, Train Loss: 0.0141, Test Loss: 0.1578\n",
      "Epoch 395/2000, Train Loss: 0.0141, Test Loss: 0.1583\n",
      "Epoch 396/2000, Train Loss: 0.0139, Test Loss: 0.1615\n",
      "Epoch 397/2000, Train Loss: 0.0140, Test Loss: 0.1624\n",
      "Epoch 398/2000, Train Loss: 0.0140, Test Loss: 0.1585\n",
      "Epoch 399/2000, Train Loss: 0.0139, Test Loss: 0.1598\n",
      "Epoch 400/2000, Train Loss: 0.0139, Test Loss: 0.1618\n",
      "Epoch 401/2000, Train Loss: 0.0139, Test Loss: 0.1590\n",
      "Epoch 402/2000, Train Loss: 0.0138, Test Loss: 0.1601\n",
      "Epoch 403/2000, Train Loss: 0.0137, Test Loss: 0.1598\n",
      "Epoch 404/2000, Train Loss: 0.0137, Test Loss: 0.1596\n",
      "Epoch 405/2000, Train Loss: 0.0136, Test Loss: 0.1593\n",
      "Epoch 406/2000, Train Loss: 0.0136, Test Loss: 0.1584\n",
      "Epoch 407/2000, Train Loss: 0.0136, Test Loss: 0.1648\n",
      "Epoch 408/2000, Train Loss: 0.0135, Test Loss: 0.1606\n",
      "Epoch 409/2000, Train Loss: 0.0135, Test Loss: 0.1617\n",
      "Epoch 410/2000, Train Loss: 0.0136, Test Loss: 0.1588\n",
      "Epoch 411/2000, Train Loss: 0.0134, Test Loss: 0.1599\n",
      "Epoch 412/2000, Train Loss: 0.0135, Test Loss: 0.1609\n",
      "Epoch 413/2000, Train Loss: 0.0135, Test Loss: 0.1642\n",
      "Epoch 414/2000, Train Loss: 0.0134, Test Loss: 0.1610\n",
      "Epoch 415/2000, Train Loss: 0.0133, Test Loss: 0.1606\n",
      "Epoch 416/2000, Train Loss: 0.0133, Test Loss: 0.1650\n",
      "Epoch 417/2000, Train Loss: 0.0133, Test Loss: 0.1611\n",
      "Epoch 418/2000, Train Loss: 0.0132, Test Loss: 0.1603\n",
      "Epoch 419/2000, Train Loss: 0.0134, Test Loss: 0.1603\n",
      "Epoch 420/2000, Train Loss: 0.0132, Test Loss: 0.1610\n",
      "Epoch 421/2000, Train Loss: 0.0131, Test Loss: 0.1621\n",
      "Epoch 422/2000, Train Loss: 0.0132, Test Loss: 0.1609\n",
      "Epoch 423/2000, Train Loss: 0.0130, Test Loss: 0.1607\n",
      "Epoch 424/2000, Train Loss: 0.0130, Test Loss: 0.1656\n",
      "Epoch 425/2000, Train Loss: 0.0130, Test Loss: 0.1616\n",
      "Epoch 426/2000, Train Loss: 0.0130, Test Loss: 0.1619\n",
      "Epoch 427/2000, Train Loss: 0.0129, Test Loss: 0.1651\n",
      "Epoch 428/2000, Train Loss: 0.0129, Test Loss: 0.1626\n",
      "Epoch 429/2000, Train Loss: 0.0129, Test Loss: 0.1614\n",
      "Epoch 430/2000, Train Loss: 0.0128, Test Loss: 0.1613\n",
      "Epoch 431/2000, Train Loss: 0.0128, Test Loss: 0.1641\n",
      "Epoch 432/2000, Train Loss: 0.0127, Test Loss: 0.1621\n",
      "Epoch 433/2000, Train Loss: 0.0127, Test Loss: 0.1622\n",
      "Epoch 434/2000, Train Loss: 0.0128, Test Loss: 0.1631\n",
      "Epoch 435/2000, Train Loss: 0.0127, Test Loss: 0.1699\n",
      "Epoch 436/2000, Train Loss: 0.0127, Test Loss: 0.1641\n",
      "Epoch 437/2000, Train Loss: 0.0126, Test Loss: 0.1629\n",
      "Epoch 438/2000, Train Loss: 0.0127, Test Loss: 0.1622\n",
      "Epoch 439/2000, Train Loss: 0.0126, Test Loss: 0.1654\n",
      "Epoch 440/2000, Train Loss: 0.0126, Test Loss: 0.1634\n",
      "Epoch 441/2000, Train Loss: 0.0125, Test Loss: 0.1624\n",
      "Epoch 442/2000, Train Loss: 0.0126, Test Loss: 0.1638\n",
      "Epoch 443/2000, Train Loss: 0.0125, Test Loss: 0.1697\n",
      "Epoch 444/2000, Train Loss: 0.0125, Test Loss: 0.1648\n",
      "Epoch 445/2000, Train Loss: 0.0124, Test Loss: 0.1679\n",
      "Epoch 446/2000, Train Loss: 0.0124, Test Loss: 0.1631\n",
      "Epoch 447/2000, Train Loss: 0.0124, Test Loss: 0.1662\n",
      "Epoch 448/2000, Train Loss: 0.0123, Test Loss: 0.1662\n",
      "Epoch 449/2000, Train Loss: 0.0123, Test Loss: 0.1661\n",
      "Epoch 450/2000, Train Loss: 0.0122, Test Loss: 0.1643\n",
      "Epoch 451/2000, Train Loss: 0.0124, Test Loss: 0.1639\n",
      "Epoch 452/2000, Train Loss: 0.0122, Test Loss: 0.1686\n",
      "Epoch 453/2000, Train Loss: 0.0122, Test Loss: 0.1641\n",
      "Epoch 454/2000, Train Loss: 0.0121, Test Loss: 0.1644\n",
      "Epoch 455/2000, Train Loss: 0.0121, Test Loss: 0.1668\n",
      "Epoch 456/2000, Train Loss: 0.0122, Test Loss: 0.1637\n",
      "Epoch 457/2000, Train Loss: 0.0120, Test Loss: 0.1659\n",
      "Epoch 458/2000, Train Loss: 0.0121, Test Loss: 0.1648\n",
      "Epoch 459/2000, Train Loss: 0.0120, Test Loss: 0.1644\n",
      "Epoch 460/2000, Train Loss: 0.0120, Test Loss: 0.1652\n",
      "Epoch 461/2000, Train Loss: 0.0120, Test Loss: 0.1676\n",
      "Epoch 462/2000, Train Loss: 0.0119, Test Loss: 0.1651\n",
      "Epoch 463/2000, Train Loss: 0.0118, Test Loss: 0.1645\n",
      "Epoch 464/2000, Train Loss: 0.0119, Test Loss: 0.1646\n",
      "Epoch 465/2000, Train Loss: 0.0120, Test Loss: 0.1643\n",
      "Epoch 466/2000, Train Loss: 0.0118, Test Loss: 0.1663\n",
      "Epoch 467/2000, Train Loss: 0.0118, Test Loss: 0.1699\n",
      "Epoch 468/2000, Train Loss: 0.0118, Test Loss: 0.1714\n",
      "Epoch 469/2000, Train Loss: 0.0117, Test Loss: 0.1646\n",
      "Epoch 470/2000, Train Loss: 0.0118, Test Loss: 0.1655\n",
      "Epoch 471/2000, Train Loss: 0.0117, Test Loss: 0.1657\n",
      "Epoch 472/2000, Train Loss: 0.0117, Test Loss: 0.1700\n",
      "Epoch 473/2000, Train Loss: 0.0117, Test Loss: 0.1647\n",
      "Epoch 474/2000, Train Loss: 0.0116, Test Loss: 0.1656\n",
      "Epoch 475/2000, Train Loss: 0.0116, Test Loss: 0.1655\n",
      "Epoch 476/2000, Train Loss: 0.0116, Test Loss: 0.1658\n",
      "Epoch 477/2000, Train Loss: 0.0115, Test Loss: 0.1664\n",
      "Epoch 478/2000, Train Loss: 0.0115, Test Loss: 0.1655\n",
      "Epoch 479/2000, Train Loss: 0.0116, Test Loss: 0.1729\n",
      "Epoch 480/2000, Train Loss: 0.0115, Test Loss: 0.1765\n",
      "Epoch 481/2000, Train Loss: 0.0115, Test Loss: 0.1747\n",
      "Epoch 482/2000, Train Loss: 0.0114, Test Loss: 0.1652\n",
      "Epoch 483/2000, Train Loss: 0.0115, Test Loss: 0.1738\n",
      "Epoch 484/2000, Train Loss: 0.0115, Test Loss: 0.1716\n",
      "Epoch 485/2000, Train Loss: 0.0114, Test Loss: 0.1664\n",
      "Epoch 486/2000, Train Loss: 0.0114, Test Loss: 0.1684\n",
      "Epoch 487/2000, Train Loss: 0.0114, Test Loss: 0.1677\n",
      "Epoch 488/2000, Train Loss: 0.0113, Test Loss: 0.1717\n",
      "Epoch 489/2000, Train Loss: 0.0113, Test Loss: 0.1665\n",
      "Epoch 490/2000, Train Loss: 0.0113, Test Loss: 0.1661\n",
      "Epoch 491/2000, Train Loss: 0.0113, Test Loss: 0.1676\n",
      "Epoch 492/2000, Train Loss: 0.0113, Test Loss: 0.1667\n",
      "Epoch 493/2000, Train Loss: 0.0112, Test Loss: 0.1663\n",
      "Epoch 494/2000, Train Loss: 0.0112, Test Loss: 0.1669\n",
      "Epoch 495/2000, Train Loss: 0.0111, Test Loss: 0.1746\n",
      "Epoch 496/2000, Train Loss: 0.0111, Test Loss: 0.1681\n",
      "Epoch 497/2000, Train Loss: 0.0110, Test Loss: 0.1696\n",
      "Epoch 498/2000, Train Loss: 0.0111, Test Loss: 0.1677\n",
      "Epoch 499/2000, Train Loss: 0.0111, Test Loss: 0.1741\n",
      "Epoch 500/2000, Train Loss: 0.0110, Test Loss: 0.1675\n",
      "Epoch 501/2000, Train Loss: 0.0110, Test Loss: 0.1702\n",
      "Epoch 502/2000, Train Loss: 0.0111, Test Loss: 0.1759\n",
      "Epoch 503/2000, Train Loss: 0.0110, Test Loss: 0.1713\n",
      "Epoch 504/2000, Train Loss: 0.0109, Test Loss: 0.1684\n",
      "Epoch 505/2000, Train Loss: 0.0109, Test Loss: 0.1711\n",
      "Epoch 506/2000, Train Loss: 0.0108, Test Loss: 0.1687\n",
      "Epoch 507/2000, Train Loss: 0.0108, Test Loss: 0.1686\n",
      "Epoch 508/2000, Train Loss: 0.0109, Test Loss: 0.1682\n",
      "Epoch 509/2000, Train Loss: 0.0108, Test Loss: 0.1706\n",
      "Epoch 510/2000, Train Loss: 0.0108, Test Loss: 0.1680\n",
      "Epoch 511/2000, Train Loss: 0.0108, Test Loss: 0.1716\n",
      "Epoch 512/2000, Train Loss: 0.0108, Test Loss: 0.1707\n",
      "Epoch 513/2000, Train Loss: 0.0107, Test Loss: 0.1696\n",
      "Epoch 514/2000, Train Loss: 0.0107, Test Loss: 0.1692\n",
      "Epoch 515/2000, Train Loss: 0.0107, Test Loss: 0.1712\n",
      "Epoch 516/2000, Train Loss: 0.0106, Test Loss: 0.1719\n",
      "Epoch 517/2000, Train Loss: 0.0106, Test Loss: 0.1773\n",
      "Epoch 518/2000, Train Loss: 0.0107, Test Loss: 0.1690\n",
      "Epoch 519/2000, Train Loss: 0.0106, Test Loss: 0.1722\n",
      "Epoch 520/2000, Train Loss: 0.0106, Test Loss: 0.1705\n",
      "Epoch 521/2000, Train Loss: 0.0105, Test Loss: 0.1792\n",
      "Epoch 522/2000, Train Loss: 0.0106, Test Loss: 0.1690\n",
      "Epoch 523/2000, Train Loss: 0.0105, Test Loss: 0.1689\n",
      "Epoch 524/2000, Train Loss: 0.0105, Test Loss: 0.1744\n",
      "Epoch 525/2000, Train Loss: 0.0105, Test Loss: 0.1692\n",
      "Epoch 526/2000, Train Loss: 0.0105, Test Loss: 0.1714\n",
      "Epoch 527/2000, Train Loss: 0.0105, Test Loss: 0.1778\n",
      "Epoch 528/2000, Train Loss: 0.0105, Test Loss: 0.1691\n",
      "Epoch 529/2000, Train Loss: 0.0104, Test Loss: 0.1696\n",
      "Epoch 530/2000, Train Loss: 0.0104, Test Loss: 0.1697\n",
      "Epoch 531/2000, Train Loss: 0.0104, Test Loss: 0.1700\n",
      "Epoch 532/2000, Train Loss: 0.0103, Test Loss: 0.1700\n",
      "Epoch 533/2000, Train Loss: 0.0103, Test Loss: 0.1698\n",
      "Epoch 534/2000, Train Loss: 0.0103, Test Loss: 0.1709\n",
      "Epoch 535/2000, Train Loss: 0.0102, Test Loss: 0.1697\n",
      "Epoch 536/2000, Train Loss: 0.0102, Test Loss: 0.1698\n",
      "Epoch 537/2000, Train Loss: 0.0102, Test Loss: 0.1735\n",
      "Epoch 538/2000, Train Loss: 0.0103, Test Loss: 0.1707\n",
      "Epoch 539/2000, Train Loss: 0.0102, Test Loss: 0.1704\n",
      "Epoch 540/2000, Train Loss: 0.0102, Test Loss: 0.1705\n",
      "Epoch 541/2000, Train Loss: 0.0101, Test Loss: 0.1712\n",
      "Epoch 542/2000, Train Loss: 0.0101, Test Loss: 0.1802\n",
      "Epoch 543/2000, Train Loss: 0.0102, Test Loss: 0.1695\n",
      "Epoch 544/2000, Train Loss: 0.0101, Test Loss: 0.1705\n",
      "Epoch 545/2000, Train Loss: 0.0102, Test Loss: 0.1713\n",
      "Epoch 546/2000, Train Loss: 0.0100, Test Loss: 0.1723\n",
      "Epoch 547/2000, Train Loss: 0.0101, Test Loss: 0.1759\n",
      "Epoch 548/2000, Train Loss: 0.0100, Test Loss: 0.1712\n",
      "Epoch 549/2000, Train Loss: 0.0100, Test Loss: 0.1717\n",
      "Epoch 550/2000, Train Loss: 0.0099, Test Loss: 0.1790\n",
      "Epoch 551/2000, Train Loss: 0.0100, Test Loss: 0.1723\n",
      "Epoch 552/2000, Train Loss: 0.0100, Test Loss: 0.1815\n",
      "Epoch 553/2000, Train Loss: 0.0100, Test Loss: 0.1726\n",
      "Epoch 554/2000, Train Loss: 0.0100, Test Loss: 0.1708\n",
      "Epoch 555/2000, Train Loss: 0.0099, Test Loss: 0.1744\n",
      "Epoch 556/2000, Train Loss: 0.0099, Test Loss: 0.1715\n",
      "Epoch 557/2000, Train Loss: 0.0099, Test Loss: 0.1717\n",
      "Epoch 558/2000, Train Loss: 0.0098, Test Loss: 0.1756\n",
      "Epoch 559/2000, Train Loss: 0.0099, Test Loss: 0.1913\n",
      "Epoch 560/2000, Train Loss: 0.0099, Test Loss: 0.1719\n",
      "Epoch 561/2000, Train Loss: 0.0098, Test Loss: 0.1727\n",
      "Epoch 562/2000, Train Loss: 0.0097, Test Loss: 0.1721\n",
      "Epoch 563/2000, Train Loss: 0.0098, Test Loss: 0.1729\n",
      "Epoch 564/2000, Train Loss: 0.0097, Test Loss: 0.1709\n",
      "Epoch 565/2000, Train Loss: 0.0098, Test Loss: 0.1765\n",
      "Epoch 566/2000, Train Loss: 0.0097, Test Loss: 0.1718\n",
      "Epoch 567/2000, Train Loss: 0.0097, Test Loss: 0.1852\n",
      "Epoch 568/2000, Train Loss: 0.0096, Test Loss: 0.1750\n",
      "Epoch 569/2000, Train Loss: 0.0096, Test Loss: 0.1781\n",
      "Epoch 570/2000, Train Loss: 0.0097, Test Loss: 0.1726\n",
      "Epoch 571/2000, Train Loss: 0.0096, Test Loss: 0.1735\n",
      "Epoch 572/2000, Train Loss: 0.0096, Test Loss: 0.1815\n",
      "Epoch 573/2000, Train Loss: 0.0096, Test Loss: 0.1735\n",
      "Epoch 574/2000, Train Loss: 0.0096, Test Loss: 0.1782\n",
      "Epoch 575/2000, Train Loss: 0.0095, Test Loss: 0.1736\n",
      "Epoch 576/2000, Train Loss: 0.0095, Test Loss: 0.1722\n",
      "Epoch 577/2000, Train Loss: 0.0096, Test Loss: 0.1940\n",
      "Epoch 578/2000, Train Loss: 0.0095, Test Loss: 0.1741\n",
      "Epoch 579/2000, Train Loss: 0.0095, Test Loss: 0.1734\n",
      "Epoch 580/2000, Train Loss: 0.0095, Test Loss: 0.1794\n",
      "Epoch 581/2000, Train Loss: 0.0095, Test Loss: 0.1734\n",
      "Epoch 582/2000, Train Loss: 0.0095, Test Loss: 0.1746\n",
      "Epoch 583/2000, Train Loss: 0.0094, Test Loss: 0.1740\n",
      "Epoch 584/2000, Train Loss: 0.0094, Test Loss: 0.1732\n",
      "Epoch 585/2000, Train Loss: 0.0094, Test Loss: 0.1738\n",
      "Epoch 586/2000, Train Loss: 0.0094, Test Loss: 0.1736\n",
      "Epoch 587/2000, Train Loss: 0.0093, Test Loss: 0.1917\n",
      "Epoch 588/2000, Train Loss: 0.0093, Test Loss: 0.1755\n",
      "Epoch 589/2000, Train Loss: 0.0093, Test Loss: 0.1740\n",
      "Epoch 590/2000, Train Loss: 0.0093, Test Loss: 0.1793\n",
      "Epoch 591/2000, Train Loss: 0.0093, Test Loss: 0.1754\n",
      "Epoch 592/2000, Train Loss: 0.0092, Test Loss: 0.1762\n",
      "Epoch 593/2000, Train Loss: 0.0093, Test Loss: 0.1747\n",
      "Epoch 594/2000, Train Loss: 0.0092, Test Loss: 0.1880\n",
      "Epoch 595/2000, Train Loss: 0.0092, Test Loss: 0.1754\n",
      "Epoch 596/2000, Train Loss: 0.0092, Test Loss: 0.1837\n",
      "Epoch 597/2000, Train Loss: 0.0092, Test Loss: 0.1740\n",
      "Epoch 598/2000, Train Loss: 0.0092, Test Loss: 0.1761\n",
      "Epoch 599/2000, Train Loss: 0.0091, Test Loss: 0.1744\n",
      "Epoch 600/2000, Train Loss: 0.0092, Test Loss: 0.1743\n",
      "Epoch 601/2000, Train Loss: 0.0091, Test Loss: 0.1750\n",
      "Epoch 602/2000, Train Loss: 0.0091, Test Loss: 0.1771\n",
      "Epoch 603/2000, Train Loss: 0.0090, Test Loss: 0.1746\n",
      "Epoch 604/2000, Train Loss: 0.0091, Test Loss: 0.1783\n",
      "Epoch 605/2000, Train Loss: 0.0091, Test Loss: 0.1758\n",
      "Epoch 606/2000, Train Loss: 0.0090, Test Loss: 0.1820\n",
      "Epoch 607/2000, Train Loss: 0.0090, Test Loss: 0.1755\n",
      "Epoch 608/2000, Train Loss: 0.0091, Test Loss: 0.1805\n",
      "Epoch 609/2000, Train Loss: 0.0090, Test Loss: 0.1750\n",
      "Epoch 610/2000, Train Loss: 0.0090, Test Loss: 0.1787\n",
      "Epoch 611/2000, Train Loss: 0.0090, Test Loss: 0.1759\n",
      "Epoch 612/2000, Train Loss: 0.0090, Test Loss: 0.1798\n",
      "Epoch 613/2000, Train Loss: 0.0090, Test Loss: 0.1753\n",
      "Epoch 614/2000, Train Loss: 0.0090, Test Loss: 0.1756\n",
      "Epoch 615/2000, Train Loss: 0.0089, Test Loss: 0.1757\n",
      "Epoch 616/2000, Train Loss: 0.0089, Test Loss: 0.1760\n",
      "Epoch 617/2000, Train Loss: 0.0089, Test Loss: 0.1767\n",
      "Epoch 618/2000, Train Loss: 0.0089, Test Loss: 0.1837\n",
      "Epoch 619/2000, Train Loss: 0.0088, Test Loss: 0.1771\n",
      "Epoch 620/2000, Train Loss: 0.0088, Test Loss: 0.1872\n",
      "Epoch 621/2000, Train Loss: 0.0088, Test Loss: 0.1769\n",
      "Epoch 622/2000, Train Loss: 0.0088, Test Loss: 0.1883\n",
      "Epoch 623/2000, Train Loss: 0.0088, Test Loss: 0.1767\n",
      "Epoch 624/2000, Train Loss: 0.0088, Test Loss: 0.1789\n",
      "Epoch 625/2000, Train Loss: 0.0088, Test Loss: 0.1770\n",
      "Epoch 626/2000, Train Loss: 0.0088, Test Loss: 0.1826\n",
      "Epoch 627/2000, Train Loss: 0.0087, Test Loss: 0.1834\n",
      "Epoch 628/2000, Train Loss: 0.0087, Test Loss: 0.1762\n",
      "Epoch 629/2000, Train Loss: 0.0087, Test Loss: 0.1777\n",
      "Epoch 630/2000, Train Loss: 0.0087, Test Loss: 0.1847\n",
      "Epoch 631/2000, Train Loss: 0.0087, Test Loss: 0.1764\n",
      "Epoch 632/2000, Train Loss: 0.0087, Test Loss: 0.1781\n",
      "Epoch 633/2000, Train Loss: 0.0086, Test Loss: 0.1764\n",
      "Epoch 634/2000, Train Loss: 0.0086, Test Loss: 0.1765\n",
      "Epoch 635/2000, Train Loss: 0.0086, Test Loss: 0.1774\n",
      "Epoch 636/2000, Train Loss: 0.0086, Test Loss: 0.1789\n",
      "Epoch 637/2000, Train Loss: 0.0086, Test Loss: 0.1772\n",
      "Epoch 638/2000, Train Loss: 0.0085, Test Loss: 0.1771\n",
      "Epoch 639/2000, Train Loss: 0.0086, Test Loss: 0.1852\n",
      "Epoch 640/2000, Train Loss: 0.0086, Test Loss: 0.1887\n",
      "Epoch 641/2000, Train Loss: 0.0086, Test Loss: 0.1767\n",
      "Epoch 642/2000, Train Loss: 0.0085, Test Loss: 0.1806\n",
      "Epoch 643/2000, Train Loss: 0.0085, Test Loss: 0.1784\n",
      "Epoch 644/2000, Train Loss: 0.0085, Test Loss: 0.1820\n",
      "Epoch 645/2000, Train Loss: 0.0085, Test Loss: 0.1784\n",
      "Epoch 646/2000, Train Loss: 0.0085, Test Loss: 0.1767\n",
      "Epoch 647/2000, Train Loss: 0.0085, Test Loss: 0.1774\n",
      "Epoch 648/2000, Train Loss: 0.0085, Test Loss: 0.1780\n",
      "Epoch 649/2000, Train Loss: 0.0085, Test Loss: 0.1805\n",
      "Epoch 650/2000, Train Loss: 0.0085, Test Loss: 0.1778\n",
      "Epoch 651/2000, Train Loss: 0.0084, Test Loss: 0.1777\n",
      "Epoch 652/2000, Train Loss: 0.0084, Test Loss: 0.1837\n",
      "Epoch 653/2000, Train Loss: 0.0084, Test Loss: 0.1790\n",
      "Epoch 654/2000, Train Loss: 0.0084, Test Loss: 0.1793\n",
      "Epoch 655/2000, Train Loss: 0.0083, Test Loss: 0.1808\n",
      "Epoch 656/2000, Train Loss: 0.0083, Test Loss: 0.1827\n",
      "Epoch 657/2000, Train Loss: 0.0083, Test Loss: 0.1779\n",
      "Epoch 658/2000, Train Loss: 0.0084, Test Loss: 0.1781\n",
      "Epoch 659/2000, Train Loss: 0.0084, Test Loss: 0.1845\n",
      "Epoch 660/2000, Train Loss: 0.0083, Test Loss: 0.1806\n",
      "Epoch 661/2000, Train Loss: 0.0083, Test Loss: 0.1786\n",
      "Epoch 662/2000, Train Loss: 0.0083, Test Loss: 0.1787\n",
      "Epoch 663/2000, Train Loss: 0.0082, Test Loss: 0.1813\n",
      "Epoch 664/2000, Train Loss: 0.0083, Test Loss: 0.1784\n",
      "Epoch 665/2000, Train Loss: 0.0082, Test Loss: 0.1784\n",
      "Epoch 666/2000, Train Loss: 0.0082, Test Loss: 0.1788\n",
      "Epoch 667/2000, Train Loss: 0.0082, Test Loss: 0.1818\n",
      "Epoch 668/2000, Train Loss: 0.0082, Test Loss: 0.1789\n",
      "Epoch 669/2000, Train Loss: 0.0082, Test Loss: 0.1798\n",
      "Epoch 670/2000, Train Loss: 0.0081, Test Loss: 0.1789\n",
      "Epoch 671/2000, Train Loss: 0.0082, Test Loss: 0.1786\n",
      "Epoch 672/2000, Train Loss: 0.0081, Test Loss: 0.1786\n",
      "Epoch 673/2000, Train Loss: 0.0081, Test Loss: 0.1795\n",
      "Epoch 674/2000, Train Loss: 0.0081, Test Loss: 0.1802\n",
      "Epoch 675/2000, Train Loss: 0.0081, Test Loss: 0.1833\n",
      "Epoch 676/2000, Train Loss: 0.0081, Test Loss: 0.1808\n",
      "Epoch 677/2000, Train Loss: 0.0080, Test Loss: 0.1830\n",
      "Epoch 678/2000, Train Loss: 0.0080, Test Loss: 0.1791\n",
      "Epoch 679/2000, Train Loss: 0.0081, Test Loss: 0.1793\n",
      "Epoch 680/2000, Train Loss: 0.0080, Test Loss: 0.1809\n",
      "Epoch 681/2000, Train Loss: 0.0080, Test Loss: 0.1802\n",
      "Epoch 682/2000, Train Loss: 0.0080, Test Loss: 0.1804\n",
      "Epoch 683/2000, Train Loss: 0.0081, Test Loss: 0.1826\n",
      "Epoch 684/2000, Train Loss: 0.0080, Test Loss: 0.1812\n",
      "Epoch 685/2000, Train Loss: 0.0080, Test Loss: 0.1795\n",
      "Epoch 686/2000, Train Loss: 0.0080, Test Loss: 0.1797\n",
      "Epoch 687/2000, Train Loss: 0.0080, Test Loss: 0.1800\n",
      "Epoch 688/2000, Train Loss: 0.0079, Test Loss: 0.1806\n",
      "Epoch 689/2000, Train Loss: 0.0079, Test Loss: 0.1856\n",
      "Epoch 690/2000, Train Loss: 0.0079, Test Loss: 0.1849\n",
      "Epoch 691/2000, Train Loss: 0.0079, Test Loss: 0.1826\n",
      "Epoch 692/2000, Train Loss: 0.0079, Test Loss: 0.1802\n",
      "Epoch 693/2000, Train Loss: 0.0078, Test Loss: 0.1801\n",
      "Epoch 694/2000, Train Loss: 0.0079, Test Loss: 0.1804\n",
      "Epoch 695/2000, Train Loss: 0.0079, Test Loss: 0.1799\n",
      "Epoch 696/2000, Train Loss: 0.0079, Test Loss: 0.1797\n",
      "Epoch 697/2000, Train Loss: 0.0078, Test Loss: 0.1809\n",
      "Epoch 698/2000, Train Loss: 0.0078, Test Loss: 0.1805\n",
      "Epoch 699/2000, Train Loss: 0.0078, Test Loss: 0.1858\n",
      "Epoch 700/2000, Train Loss: 0.0078, Test Loss: 0.1805\n",
      "Epoch 701/2000, Train Loss: 0.0078, Test Loss: 0.1946\n",
      "Epoch 702/2000, Train Loss: 0.0078, Test Loss: 0.1808\n",
      "Epoch 703/2000, Train Loss: 0.0078, Test Loss: 0.1846\n",
      "Epoch 704/2000, Train Loss: 0.0078, Test Loss: 0.1882\n",
      "Epoch 705/2000, Train Loss: 0.0078, Test Loss: 0.1842\n",
      "Epoch 706/2000, Train Loss: 0.0077, Test Loss: 0.1816\n",
      "Epoch 707/2000, Train Loss: 0.0077, Test Loss: 0.1808\n",
      "Epoch 708/2000, Train Loss: 0.0077, Test Loss: 0.1817\n",
      "Epoch 709/2000, Train Loss: 0.0077, Test Loss: 0.1899\n",
      "Epoch 710/2000, Train Loss: 0.0076, Test Loss: 0.1847\n",
      "Epoch 711/2000, Train Loss: 0.0077, Test Loss: 0.1813\n",
      "Epoch 712/2000, Train Loss: 0.0077, Test Loss: 0.1819\n",
      "Epoch 713/2000, Train Loss: 0.0076, Test Loss: 0.1901\n",
      "Epoch 714/2000, Train Loss: 0.0076, Test Loss: 0.1831\n",
      "Epoch 715/2000, Train Loss: 0.0076, Test Loss: 0.1817\n",
      "Epoch 716/2000, Train Loss: 0.0076, Test Loss: 0.1843\n",
      "Epoch 717/2000, Train Loss: 0.0076, Test Loss: 0.1817\n",
      "Epoch 718/2000, Train Loss: 0.0077, Test Loss: 0.1815\n",
      "Epoch 719/2000, Train Loss: 0.0076, Test Loss: 0.1820\n",
      "Epoch 720/2000, Train Loss: 0.0076, Test Loss: 0.1826\n",
      "Epoch 721/2000, Train Loss: 0.0075, Test Loss: 0.1821\n",
      "Epoch 722/2000, Train Loss: 0.0076, Test Loss: 0.1849\n",
      "Epoch 723/2000, Train Loss: 0.0075, Test Loss: 0.1841\n",
      "Epoch 724/2000, Train Loss: 0.0075, Test Loss: 0.1837\n",
      "Epoch 725/2000, Train Loss: 0.0076, Test Loss: 0.1819\n",
      "Epoch 726/2000, Train Loss: 0.0075, Test Loss: 0.1860\n",
      "Epoch 727/2000, Train Loss: 0.0075, Test Loss: 0.1971\n",
      "Epoch 728/2000, Train Loss: 0.0075, Test Loss: 0.1829\n",
      "Epoch 729/2000, Train Loss: 0.0075, Test Loss: 0.1824\n",
      "Epoch 730/2000, Train Loss: 0.0075, Test Loss: 0.1825\n",
      "Epoch 731/2000, Train Loss: 0.0075, Test Loss: 0.1818\n",
      "Epoch 732/2000, Train Loss: 0.0075, Test Loss: 0.1838\n",
      "Epoch 733/2000, Train Loss: 0.0074, Test Loss: 0.1822\n",
      "Epoch 734/2000, Train Loss: 0.0074, Test Loss: 0.1837\n",
      "Epoch 735/2000, Train Loss: 0.0075, Test Loss: 0.1837\n",
      "Epoch 736/2000, Train Loss: 0.0075, Test Loss: 0.1832\n",
      "Epoch 737/2000, Train Loss: 0.0074, Test Loss: 0.1821\n",
      "Epoch 738/2000, Train Loss: 0.0073, Test Loss: 0.1825\n",
      "Epoch 739/2000, Train Loss: 0.0074, Test Loss: 0.1846\n",
      "Epoch 740/2000, Train Loss: 0.0074, Test Loss: 0.1911\n",
      "Epoch 741/2000, Train Loss: 0.0074, Test Loss: 0.1833\n",
      "Epoch 742/2000, Train Loss: 0.0073, Test Loss: 0.1831\n",
      "Epoch 743/2000, Train Loss: 0.0073, Test Loss: 0.1865\n",
      "Epoch 744/2000, Train Loss: 0.0073, Test Loss: 0.1822\n",
      "Epoch 745/2000, Train Loss: 0.0073, Test Loss: 0.1835\n",
      "Epoch 746/2000, Train Loss: 0.0073, Test Loss: 0.1843\n",
      "Epoch 747/2000, Train Loss: 0.0073, Test Loss: 0.1831\n",
      "Epoch 748/2000, Train Loss: 0.0073, Test Loss: 0.1829\n",
      "Epoch 749/2000, Train Loss: 0.0073, Test Loss: 0.1837\n",
      "Epoch 750/2000, Train Loss: 0.0073, Test Loss: 0.1848\n",
      "Epoch 751/2000, Train Loss: 0.0073, Test Loss: 0.1841\n",
      "Epoch 752/2000, Train Loss: 0.0072, Test Loss: 0.1835\n",
      "Epoch 753/2000, Train Loss: 0.0072, Test Loss: 0.1849\n",
      "Epoch 754/2000, Train Loss: 0.0073, Test Loss: 0.1922\n",
      "Epoch 755/2000, Train Loss: 0.0072, Test Loss: 0.1835\n",
      "Epoch 756/2000, Train Loss: 0.0072, Test Loss: 0.1847\n",
      "Epoch 757/2000, Train Loss: 0.0072, Test Loss: 0.1831\n",
      "Epoch 758/2000, Train Loss: 0.0072, Test Loss: 0.1852\n",
      "Epoch 759/2000, Train Loss: 0.0072, Test Loss: 0.1849\n",
      "Epoch 760/2000, Train Loss: 0.0072, Test Loss: 0.1837\n",
      "Epoch 761/2000, Train Loss: 0.0072, Test Loss: 0.1911\n",
      "Epoch 762/2000, Train Loss: 0.0072, Test Loss: 0.1848\n",
      "Epoch 763/2000, Train Loss: 0.0071, Test Loss: 0.1895\n",
      "Epoch 764/2000, Train Loss: 0.0071, Test Loss: 0.1848\n",
      "Epoch 765/2000, Train Loss: 0.0071, Test Loss: 0.1846\n",
      "Epoch 766/2000, Train Loss: 0.0071, Test Loss: 0.1925\n",
      "Epoch 767/2000, Train Loss: 0.0071, Test Loss: 0.1858\n",
      "Epoch 768/2000, Train Loss: 0.0071, Test Loss: 0.1845\n",
      "Epoch 769/2000, Train Loss: 0.0071, Test Loss: 0.1847\n",
      "Epoch 770/2000, Train Loss: 0.0071, Test Loss: 0.1877\n",
      "Epoch 771/2000, Train Loss: 0.0071, Test Loss: 0.1913\n",
      "Epoch 772/2000, Train Loss: 0.0070, Test Loss: 0.1863\n",
      "Epoch 773/2000, Train Loss: 0.0070, Test Loss: 0.1845\n",
      "Epoch 774/2000, Train Loss: 0.0070, Test Loss: 0.1869\n",
      "Epoch 775/2000, Train Loss: 0.0070, Test Loss: 0.1910\n",
      "Epoch 776/2000, Train Loss: 0.0070, Test Loss: 0.1870\n",
      "Epoch 777/2000, Train Loss: 0.0070, Test Loss: 0.1866\n",
      "Epoch 778/2000, Train Loss: 0.0070, Test Loss: 0.1857\n",
      "Epoch 779/2000, Train Loss: 0.0070, Test Loss: 0.1863\n",
      "Epoch 780/2000, Train Loss: 0.0070, Test Loss: 0.1851\n",
      "Epoch 781/2000, Train Loss: 0.0070, Test Loss: 0.1878\n",
      "Epoch 782/2000, Train Loss: 0.0070, Test Loss: 0.1877\n",
      "Epoch 783/2000, Train Loss: 0.0070, Test Loss: 0.1851\n",
      "Epoch 784/2000, Train Loss: 0.0069, Test Loss: 0.1852\n",
      "Epoch 785/2000, Train Loss: 0.0069, Test Loss: 0.1860\n",
      "Epoch 786/2000, Train Loss: 0.0069, Test Loss: 0.1848\n",
      "Epoch 787/2000, Train Loss: 0.0069, Test Loss: 0.1856\n",
      "Epoch 788/2000, Train Loss: 0.0069, Test Loss: 0.2005\n",
      "Epoch 789/2000, Train Loss: 0.0069, Test Loss: 0.1856\n",
      "Epoch 790/2000, Train Loss: 0.0069, Test Loss: 0.1866\n",
      "Epoch 791/2000, Train Loss: 0.0069, Test Loss: 0.1863\n",
      "Epoch 792/2000, Train Loss: 0.0069, Test Loss: 0.1855\n",
      "Epoch 793/2000, Train Loss: 0.0069, Test Loss: 0.1855\n",
      "Epoch 794/2000, Train Loss: 0.0069, Test Loss: 0.1859\n",
      "Epoch 795/2000, Train Loss: 0.0069, Test Loss: 0.1858\n",
      "Epoch 796/2000, Train Loss: 0.0069, Test Loss: 0.1856\n",
      "Epoch 797/2000, Train Loss: 0.0069, Test Loss: 0.1857\n",
      "Epoch 798/2000, Train Loss: 0.0068, Test Loss: 0.1886\n",
      "Epoch 799/2000, Train Loss: 0.0068, Test Loss: 0.1905\n",
      "Epoch 800/2000, Train Loss: 0.0068, Test Loss: 0.1875\n",
      "Epoch 801/2000, Train Loss: 0.0068, Test Loss: 0.1914\n",
      "Epoch 802/2000, Train Loss: 0.0068, Test Loss: 0.1861\n",
      "Epoch 803/2000, Train Loss: 0.0068, Test Loss: 0.1873\n",
      "Epoch 804/2000, Train Loss: 0.0068, Test Loss: 0.1866\n",
      "Epoch 805/2000, Train Loss: 0.0068, Test Loss: 0.1863\n",
      "Epoch 806/2000, Train Loss: 0.0068, Test Loss: 0.1859\n",
      "Epoch 807/2000, Train Loss: 0.0067, Test Loss: 0.1988\n",
      "Epoch 808/2000, Train Loss: 0.0067, Test Loss: 0.1915\n",
      "Epoch 809/2000, Train Loss: 0.0068, Test Loss: 0.1873\n",
      "Epoch 810/2000, Train Loss: 0.0067, Test Loss: 0.1891\n",
      "Epoch 811/2000, Train Loss: 0.0067, Test Loss: 0.1866\n",
      "Epoch 812/2000, Train Loss: 0.0067, Test Loss: 0.1878\n",
      "Epoch 813/2000, Train Loss: 0.0067, Test Loss: 0.1904\n",
      "Epoch 814/2000, Train Loss: 0.0067, Test Loss: 0.1871\n",
      "Epoch 815/2000, Train Loss: 0.0067, Test Loss: 0.1871\n",
      "Epoch 816/2000, Train Loss: 0.0067, Test Loss: 0.1867\n",
      "Epoch 817/2000, Train Loss: 0.0067, Test Loss: 0.1867\n",
      "Epoch 818/2000, Train Loss: 0.0067, Test Loss: 0.1878\n",
      "Epoch 819/2000, Train Loss: 0.0067, Test Loss: 0.2072\n",
      "Epoch 820/2000, Train Loss: 0.0067, Test Loss: 0.1874\n",
      "Epoch 821/2000, Train Loss: 0.0066, Test Loss: 0.1882\n",
      "Epoch 822/2000, Train Loss: 0.0066, Test Loss: 0.1930\n",
      "Epoch 823/2000, Train Loss: 0.0066, Test Loss: 0.1870\n",
      "Epoch 824/2000, Train Loss: 0.0066, Test Loss: 0.1874\n",
      "Epoch 825/2000, Train Loss: 0.0066, Test Loss: 0.1917\n",
      "Epoch 826/2000, Train Loss: 0.0066, Test Loss: 0.1896\n",
      "Epoch 827/2000, Train Loss: 0.0066, Test Loss: 0.1871\n",
      "Epoch 828/2000, Train Loss: 0.0066, Test Loss: 0.1907\n",
      "Epoch 829/2000, Train Loss: 0.0066, Test Loss: 0.1876\n",
      "Epoch 830/2000, Train Loss: 0.0066, Test Loss: 0.1878\n",
      "Epoch 831/2000, Train Loss: 0.0066, Test Loss: 0.1869\n",
      "Epoch 832/2000, Train Loss: 0.0065, Test Loss: 0.1873\n",
      "Epoch 833/2000, Train Loss: 0.0065, Test Loss: 0.1899\n",
      "Epoch 834/2000, Train Loss: 0.0065, Test Loss: 0.1886\n",
      "Epoch 835/2000, Train Loss: 0.0065, Test Loss: 0.1877\n",
      "Epoch 836/2000, Train Loss: 0.0065, Test Loss: 0.1873\n",
      "Epoch 837/2000, Train Loss: 0.0065, Test Loss: 0.1878\n",
      "Epoch 838/2000, Train Loss: 0.0065, Test Loss: 0.1878\n",
      "Epoch 839/2000, Train Loss: 0.0065, Test Loss: 0.1875\n",
      "Epoch 840/2000, Train Loss: 0.0065, Test Loss: 0.1914\n",
      "Epoch 841/2000, Train Loss: 0.0065, Test Loss: 0.1933\n",
      "Epoch 842/2000, Train Loss: 0.0065, Test Loss: 0.1977\n",
      "Epoch 843/2000, Train Loss: 0.0065, Test Loss: 0.1887\n",
      "Epoch 844/2000, Train Loss: 0.0064, Test Loss: 0.1884\n",
      "Epoch 845/2000, Train Loss: 0.0064, Test Loss: 0.1882\n",
      "Epoch 846/2000, Train Loss: 0.0064, Test Loss: 0.1879\n",
      "Epoch 847/2000, Train Loss: 0.0064, Test Loss: 0.1881\n",
      "Epoch 848/2000, Train Loss: 0.0064, Test Loss: 0.1980\n",
      "Epoch 849/2000, Train Loss: 0.0064, Test Loss: 0.1918\n",
      "Epoch 850/2000, Train Loss: 0.0064, Test Loss: 0.1951\n",
      "Epoch 851/2000, Train Loss: 0.0064, Test Loss: 0.1925\n",
      "Epoch 852/2000, Train Loss: 0.0064, Test Loss: 0.1884\n",
      "Epoch 853/2000, Train Loss: 0.0064, Test Loss: 0.1882\n",
      "Epoch 854/2000, Train Loss: 0.0064, Test Loss: 0.1883\n",
      "Epoch 855/2000, Train Loss: 0.0064, Test Loss: 0.1887\n",
      "Epoch 856/2000, Train Loss: 0.0064, Test Loss: 0.1884\n",
      "Epoch 857/2000, Train Loss: 0.0063, Test Loss: 0.1912\n",
      "Epoch 858/2000, Train Loss: 0.0063, Test Loss: 0.1892\n",
      "Epoch 859/2000, Train Loss: 0.0063, Test Loss: 0.1888\n",
      "Epoch 860/2000, Train Loss: 0.0063, Test Loss: 0.1888\n",
      "Epoch 861/2000, Train Loss: 0.0063, Test Loss: 0.1886\n",
      "Epoch 862/2000, Train Loss: 0.0063, Test Loss: 0.2013\n",
      "Epoch 863/2000, Train Loss: 0.0063, Test Loss: 0.1908\n",
      "Epoch 864/2000, Train Loss: 0.0063, Test Loss: 0.1947\n",
      "Epoch 865/2000, Train Loss: 0.0063, Test Loss: 0.1893\n",
      "Epoch 866/2000, Train Loss: 0.0063, Test Loss: 0.1896\n",
      "Epoch 867/2000, Train Loss: 0.0063, Test Loss: 0.1891\n",
      "Epoch 868/2000, Train Loss: 0.0063, Test Loss: 0.1912\n",
      "Epoch 869/2000, Train Loss: 0.0063, Test Loss: 0.1898\n",
      "Epoch 870/2000, Train Loss: 0.0063, Test Loss: 0.1904\n",
      "Epoch 871/2000, Train Loss: 0.0063, Test Loss: 0.1904\n",
      "Epoch 872/2000, Train Loss: 0.0062, Test Loss: 0.1927\n",
      "Epoch 873/2000, Train Loss: 0.0063, Test Loss: 0.1956\n",
      "Epoch 874/2000, Train Loss: 0.0062, Test Loss: 0.1950\n",
      "Epoch 875/2000, Train Loss: 0.0062, Test Loss: 0.1895\n",
      "Epoch 876/2000, Train Loss: 0.0062, Test Loss: 0.1891\n",
      "Epoch 877/2000, Train Loss: 0.0062, Test Loss: 0.1895\n",
      "Epoch 878/2000, Train Loss: 0.0062, Test Loss: 0.1898\n",
      "Epoch 879/2000, Train Loss: 0.0062, Test Loss: 0.1921\n",
      "Epoch 880/2000, Train Loss: 0.0062, Test Loss: 0.1898\n",
      "Epoch 881/2000, Train Loss: 0.0062, Test Loss: 0.1896\n",
      "Epoch 882/2000, Train Loss: 0.0062, Test Loss: 0.1895\n",
      "Epoch 883/2000, Train Loss: 0.0062, Test Loss: 0.1926\n",
      "Epoch 884/2000, Train Loss: 0.0061, Test Loss: 0.1898\n",
      "Epoch 885/2000, Train Loss: 0.0062, Test Loss: 0.1937\n",
      "Epoch 886/2000, Train Loss: 0.0061, Test Loss: 0.1900\n",
      "Epoch 887/2000, Train Loss: 0.0061, Test Loss: 0.1901\n",
      "Epoch 888/2000, Train Loss: 0.0061, Test Loss: 0.1898\n",
      "Epoch 889/2000, Train Loss: 0.0061, Test Loss: 0.1897\n",
      "Epoch 890/2000, Train Loss: 0.0061, Test Loss: 0.1900\n",
      "Epoch 891/2000, Train Loss: 0.0061, Test Loss: 0.1901\n",
      "Epoch 892/2000, Train Loss: 0.0061, Test Loss: 0.1904\n",
      "Epoch 893/2000, Train Loss: 0.0061, Test Loss: 0.1907\n",
      "Epoch 894/2000, Train Loss: 0.0060, Test Loss: 0.1898\n",
      "Epoch 895/2000, Train Loss: 0.0061, Test Loss: 0.1907\n",
      "Epoch 896/2000, Train Loss: 0.0061, Test Loss: 0.1912\n",
      "Epoch 897/2000, Train Loss: 0.0061, Test Loss: 0.1904\n",
      "Epoch 898/2000, Train Loss: 0.0061, Test Loss: 0.1926\n",
      "Epoch 899/2000, Train Loss: 0.0061, Test Loss: 0.1910\n",
      "Epoch 900/2000, Train Loss: 0.0060, Test Loss: 0.1906\n",
      "Epoch 901/2000, Train Loss: 0.0061, Test Loss: 0.1914\n",
      "Epoch 902/2000, Train Loss: 0.0060, Test Loss: 0.1909\n",
      "Epoch 903/2000, Train Loss: 0.0060, Test Loss: 0.1904\n",
      "Epoch 904/2000, Train Loss: 0.0060, Test Loss: 0.1912\n",
      "Epoch 905/2000, Train Loss: 0.0060, Test Loss: 0.1933\n",
      "Epoch 906/2000, Train Loss: 0.0060, Test Loss: 0.1995\n",
      "Epoch 907/2000, Train Loss: 0.0060, Test Loss: 0.1932\n",
      "Epoch 908/2000, Train Loss: 0.0060, Test Loss: 0.1905\n",
      "Epoch 909/2000, Train Loss: 0.0060, Test Loss: 0.1911\n",
      "Epoch 910/2000, Train Loss: 0.0060, Test Loss: 0.2008\n",
      "Epoch 911/2000, Train Loss: 0.0060, Test Loss: 0.1913\n",
      "Epoch 912/2000, Train Loss: 0.0060, Test Loss: 0.1915\n",
      "Epoch 913/2000, Train Loss: 0.0060, Test Loss: 0.1918\n",
      "Epoch 914/2000, Train Loss: 0.0059, Test Loss: 0.1910\n",
      "Epoch 915/2000, Train Loss: 0.0059, Test Loss: 0.1917\n",
      "Epoch 916/2000, Train Loss: 0.0059, Test Loss: 0.1914\n",
      "Epoch 917/2000, Train Loss: 0.0060, Test Loss: 0.1912\n",
      "Epoch 918/2000, Train Loss: 0.0059, Test Loss: 0.1966\n",
      "Epoch 919/2000, Train Loss: 0.0059, Test Loss: 0.2055\n",
      "Epoch 920/2000, Train Loss: 0.0059, Test Loss: 0.1953\n",
      "Epoch 921/2000, Train Loss: 0.0059, Test Loss: 0.1942\n",
      "Epoch 922/2000, Train Loss: 0.0059, Test Loss: 0.1913\n",
      "Epoch 923/2000, Train Loss: 0.0059, Test Loss: 0.1916\n",
      "Epoch 924/2000, Train Loss: 0.0059, Test Loss: 0.1917\n",
      "Epoch 925/2000, Train Loss: 0.0059, Test Loss: 0.1921\n",
      "Epoch 926/2000, Train Loss: 0.0059, Test Loss: 0.1915\n",
      "Epoch 927/2000, Train Loss: 0.0059, Test Loss: 0.2053\n",
      "Epoch 928/2000, Train Loss: 0.0059, Test Loss: 0.1919\n",
      "Epoch 929/2000, Train Loss: 0.0059, Test Loss: 0.1925\n",
      "Epoch 930/2000, Train Loss: 0.0058, Test Loss: 0.1969\n",
      "Epoch 931/2000, Train Loss: 0.0058, Test Loss: 0.1922\n",
      "Epoch 932/2000, Train Loss: 0.0058, Test Loss: 0.1932\n",
      "Epoch 933/2000, Train Loss: 0.0058, Test Loss: 0.1925\n",
      "Epoch 934/2000, Train Loss: 0.0058, Test Loss: 0.1920\n",
      "Epoch 935/2000, Train Loss: 0.0058, Test Loss: 0.1982\n",
      "Epoch 936/2000, Train Loss: 0.0058, Test Loss: 0.1920\n",
      "Epoch 937/2000, Train Loss: 0.0058, Test Loss: 0.1922\n",
      "Epoch 938/2000, Train Loss: 0.0058, Test Loss: 0.1982\n",
      "Epoch 939/2000, Train Loss: 0.0058, Test Loss: 0.1961\n",
      "Epoch 940/2000, Train Loss: 0.0058, Test Loss: 0.1922\n",
      "Epoch 941/2000, Train Loss: 0.0058, Test Loss: 0.2027\n",
      "Epoch 942/2000, Train Loss: 0.0058, Test Loss: 0.1924\n",
      "Epoch 943/2000, Train Loss: 0.0058, Test Loss: 0.1945\n",
      "Epoch 944/2000, Train Loss: 0.0058, Test Loss: 0.1920\n",
      "Epoch 945/2000, Train Loss: 0.0058, Test Loss: 0.1924\n",
      "Epoch 946/2000, Train Loss: 0.0057, Test Loss: 0.1933\n",
      "Epoch 947/2000, Train Loss: 0.0057, Test Loss: 0.1961\n",
      "Epoch 948/2000, Train Loss: 0.0057, Test Loss: 0.1930\n",
      "Epoch 949/2000, Train Loss: 0.0058, Test Loss: 0.1924\n",
      "Epoch 950/2000, Train Loss: 0.0057, Test Loss: 0.1927\n",
      "Epoch 951/2000, Train Loss: 0.0057, Test Loss: 0.1933\n",
      "Epoch 952/2000, Train Loss: 0.0057, Test Loss: 0.1931\n",
      "Epoch 953/2000, Train Loss: 0.0057, Test Loss: 0.1932\n",
      "Epoch 954/2000, Train Loss: 0.0057, Test Loss: 0.1933\n",
      "Epoch 955/2000, Train Loss: 0.0057, Test Loss: 0.1940\n",
      "Epoch 956/2000, Train Loss: 0.0057, Test Loss: 0.1932\n",
      "Epoch 957/2000, Train Loss: 0.0057, Test Loss: 0.1959\n",
      "Epoch 958/2000, Train Loss: 0.0057, Test Loss: 0.1988\n",
      "Epoch 959/2000, Train Loss: 0.0057, Test Loss: 0.1933\n",
      "Epoch 960/2000, Train Loss: 0.0057, Test Loss: 0.1978\n",
      "Epoch 961/2000, Train Loss: 0.0056, Test Loss: 0.1985\n",
      "Epoch 962/2000, Train Loss: 0.0056, Test Loss: 0.1943\n",
      "Epoch 963/2000, Train Loss: 0.0056, Test Loss: 0.1972\n",
      "Epoch 964/2000, Train Loss: 0.0056, Test Loss: 0.1975\n",
      "Epoch 965/2000, Train Loss: 0.0056, Test Loss: 0.1928\n",
      "Epoch 966/2000, Train Loss: 0.0056, Test Loss: 0.1946\n",
      "Epoch 967/2000, Train Loss: 0.0056, Test Loss: 0.1965\n",
      "Epoch 968/2000, Train Loss: 0.0056, Test Loss: 0.1934\n",
      "Epoch 969/2000, Train Loss: 0.0056, Test Loss: 0.1979\n",
      "Epoch 970/2000, Train Loss: 0.0056, Test Loss: 0.1934\n",
      "Epoch 971/2000, Train Loss: 0.0057, Test Loss: 0.1939\n",
      "Epoch 972/2000, Train Loss: 0.0056, Test Loss: 0.1938\n",
      "Epoch 973/2000, Train Loss: 0.0056, Test Loss: 0.1945\n",
      "Epoch 974/2000, Train Loss: 0.0056, Test Loss: 0.1939\n",
      "Epoch 975/2000, Train Loss: 0.0056, Test Loss: 0.1936\n",
      "Epoch 976/2000, Train Loss: 0.0056, Test Loss: 0.1937\n",
      "Epoch 977/2000, Train Loss: 0.0056, Test Loss: 0.1967\n",
      "Epoch 978/2000, Train Loss: 0.0056, Test Loss: 0.2048\n",
      "Epoch 979/2000, Train Loss: 0.0056, Test Loss: 0.1944\n",
      "Epoch 980/2000, Train Loss: 0.0056, Test Loss: 0.1961\n",
      "Epoch 981/2000, Train Loss: 0.0055, Test Loss: 0.1988\n",
      "Epoch 982/2000, Train Loss: 0.0056, Test Loss: 0.1944\n",
      "Epoch 983/2000, Train Loss: 0.0055, Test Loss: 0.2009\n",
      "Epoch 984/2000, Train Loss: 0.0055, Test Loss: 0.1949\n",
      "Epoch 985/2000, Train Loss: 0.0055, Test Loss: 0.1983\n",
      "Epoch 986/2000, Train Loss: 0.0055, Test Loss: 0.2119\n",
      "Epoch 987/2000, Train Loss: 0.0055, Test Loss: 0.1953\n",
      "Epoch 988/2000, Train Loss: 0.0055, Test Loss: 0.1942\n",
      "Epoch 989/2000, Train Loss: 0.0055, Test Loss: 0.1950\n",
      "Epoch 990/2000, Train Loss: 0.0055, Test Loss: 0.1940\n",
      "Epoch 991/2000, Train Loss: 0.0055, Test Loss: 0.1942\n",
      "Epoch 992/2000, Train Loss: 0.0055, Test Loss: 0.1943\n",
      "Epoch 993/2000, Train Loss: 0.0055, Test Loss: 0.1953\n",
      "Epoch 994/2000, Train Loss: 0.0055, Test Loss: 0.2134\n",
      "Epoch 995/2000, Train Loss: 0.0055, Test Loss: 0.1938\n",
      "Epoch 996/2000, Train Loss: 0.0055, Test Loss: 0.1984\n",
      "Epoch 997/2000, Train Loss: 0.0055, Test Loss: 0.1952\n",
      "Epoch 998/2000, Train Loss: 0.0054, Test Loss: 0.1964\n",
      "Epoch 999/2000, Train Loss: 0.0054, Test Loss: 0.1979\n",
      "Epoch 1000/2000, Train Loss: 0.0054, Test Loss: 0.1967\n",
      "Epoch 1001/2000, Train Loss: 0.0054, Test Loss: 0.1995\n",
      "Epoch 1002/2000, Train Loss: 0.0054, Test Loss: 0.2060\n",
      "Epoch 1003/2000, Train Loss: 0.0054, Test Loss: 0.1949\n",
      "Epoch 1004/2000, Train Loss: 0.0054, Test Loss: 0.1963\n",
      "Epoch 1005/2000, Train Loss: 0.0054, Test Loss: 0.1956\n",
      "Epoch 1006/2000, Train Loss: 0.0054, Test Loss: 0.1998\n",
      "Epoch 1007/2000, Train Loss: 0.0054, Test Loss: 0.2096\n",
      "Epoch 1008/2000, Train Loss: 0.0054, Test Loss: 0.1988\n",
      "Epoch 1009/2000, Train Loss: 0.0054, Test Loss: 0.1947\n",
      "Epoch 1010/2000, Train Loss: 0.0054, Test Loss: 0.1970\n",
      "Epoch 1011/2000, Train Loss: 0.0054, Test Loss: 0.2022\n",
      "Epoch 1012/2000, Train Loss: 0.0054, Test Loss: 0.1955\n",
      "Epoch 1013/2000, Train Loss: 0.0054, Test Loss: 0.1951\n",
      "Epoch 1014/2000, Train Loss: 0.0054, Test Loss: 0.1955\n",
      "Epoch 1015/2000, Train Loss: 0.0054, Test Loss: 0.1953\n",
      "Epoch 1016/2000, Train Loss: 0.0054, Test Loss: 0.1953\n",
      "Epoch 1017/2000, Train Loss: 0.0054, Test Loss: 0.1951\n",
      "Epoch 1018/2000, Train Loss: 0.0053, Test Loss: 0.1960\n",
      "Epoch 1019/2000, Train Loss: 0.0053, Test Loss: 0.2111\n",
      "Epoch 1020/2000, Train Loss: 0.0053, Test Loss: 0.2061\n",
      "Epoch 1021/2000, Train Loss: 0.0053, Test Loss: 0.1956\n",
      "Epoch 1022/2000, Train Loss: 0.0053, Test Loss: 0.2005\n",
      "Epoch 1023/2000, Train Loss: 0.0053, Test Loss: 0.1959\n",
      "Epoch 1024/2000, Train Loss: 0.0053, Test Loss: 0.1957\n",
      "Epoch 1025/2000, Train Loss: 0.0053, Test Loss: 0.1957\n",
      "Epoch 1026/2000, Train Loss: 0.0053, Test Loss: 0.1954\n",
      "Epoch 1027/2000, Train Loss: 0.0053, Test Loss: 0.1959\n",
      "Epoch 1028/2000, Train Loss: 0.0053, Test Loss: 0.1966\n",
      "Epoch 1029/2000, Train Loss: 0.0053, Test Loss: 0.1955\n",
      "Epoch 1030/2000, Train Loss: 0.0053, Test Loss: 0.1970\n",
      "Epoch 1031/2000, Train Loss: 0.0053, Test Loss: 0.1964\n",
      "Epoch 1032/2000, Train Loss: 0.0053, Test Loss: 0.1959\n",
      "Epoch 1033/2000, Train Loss: 0.0053, Test Loss: 0.1961\n",
      "Epoch 1034/2000, Train Loss: 0.0053, Test Loss: 0.1961\n",
      "Epoch 1035/2000, Train Loss: 0.0053, Test Loss: 0.2032\n",
      "Epoch 1036/2000, Train Loss: 0.0053, Test Loss: 0.1978\n",
      "Epoch 1037/2000, Train Loss: 0.0052, Test Loss: 0.2054\n",
      "Epoch 1038/2000, Train Loss: 0.0052, Test Loss: 0.1960\n",
      "Epoch 1039/2000, Train Loss: 0.0052, Test Loss: 0.1962\n",
      "Epoch 1040/2000, Train Loss: 0.0052, Test Loss: 0.1967\n",
      "Epoch 1041/2000, Train Loss: 0.0052, Test Loss: 0.2000\n",
      "Epoch 1042/2000, Train Loss: 0.0052, Test Loss: 0.2032\n",
      "Epoch 1043/2000, Train Loss: 0.0052, Test Loss: 0.1963\n",
      "Epoch 1044/2000, Train Loss: 0.0052, Test Loss: 0.2076\n",
      "Epoch 1045/2000, Train Loss: 0.0052, Test Loss: 0.2046\n",
      "Epoch 1046/2000, Train Loss: 0.0052, Test Loss: 0.1964\n",
      "Epoch 1047/2000, Train Loss: 0.0052, Test Loss: 0.1979\n",
      "Epoch 1048/2000, Train Loss: 0.0052, Test Loss: 0.2006\n",
      "Epoch 1049/2000, Train Loss: 0.0052, Test Loss: 0.1978\n",
      "Epoch 1050/2000, Train Loss: 0.0052, Test Loss: 0.1976\n",
      "Epoch 1051/2000, Train Loss: 0.0052, Test Loss: 0.2059\n",
      "Epoch 1052/2000, Train Loss: 0.0052, Test Loss: 0.2003\n",
      "Epoch 1053/2000, Train Loss: 0.0052, Test Loss: 0.1964\n",
      "Epoch 1054/2000, Train Loss: 0.0052, Test Loss: 0.1971\n",
      "Epoch 1055/2000, Train Loss: 0.0052, Test Loss: 0.1973\n",
      "Epoch 1056/2000, Train Loss: 0.0052, Test Loss: 0.1975\n",
      "Epoch 1057/2000, Train Loss: 0.0051, Test Loss: 0.1971\n",
      "Epoch 1058/2000, Train Loss: 0.0051, Test Loss: 0.2139\n",
      "Epoch 1059/2000, Train Loss: 0.0051, Test Loss: 0.2101\n",
      "Epoch 1060/2000, Train Loss: 0.0051, Test Loss: 0.1991\n",
      "Epoch 1061/2000, Train Loss: 0.0051, Test Loss: 0.1974\n",
      "Epoch 1062/2000, Train Loss: 0.0051, Test Loss: 0.1984\n",
      "Epoch 1063/2000, Train Loss: 0.0051, Test Loss: 0.1968\n",
      "Epoch 1064/2000, Train Loss: 0.0051, Test Loss: 0.2050\n",
      "Epoch 1065/2000, Train Loss: 0.0051, Test Loss: 0.1972\n",
      "Epoch 1066/2000, Train Loss: 0.0051, Test Loss: 0.1974\n",
      "Epoch 1067/2000, Train Loss: 0.0051, Test Loss: 0.1974\n",
      "Epoch 1068/2000, Train Loss: 0.0051, Test Loss: 0.1989\n",
      "Epoch 1069/2000, Train Loss: 0.0051, Test Loss: 0.2023\n",
      "Epoch 1070/2000, Train Loss: 0.0051, Test Loss: 0.2024\n",
      "Epoch 1071/2000, Train Loss: 0.0051, Test Loss: 0.1973\n",
      "Epoch 1072/2000, Train Loss: 0.0051, Test Loss: 0.1983\n",
      "Epoch 1073/2000, Train Loss: 0.0051, Test Loss: 0.1974\n",
      "Epoch 1074/2000, Train Loss: 0.0051, Test Loss: 0.2016\n",
      "Epoch 1075/2000, Train Loss: 0.0051, Test Loss: 0.2024\n",
      "Epoch 1076/2000, Train Loss: 0.0051, Test Loss: 0.1975\n",
      "Epoch 1077/2000, Train Loss: 0.0050, Test Loss: 0.2004\n",
      "Epoch 1078/2000, Train Loss: 0.0051, Test Loss: 0.1977\n",
      "Epoch 1079/2000, Train Loss: 0.0050, Test Loss: 0.1972\n",
      "Epoch 1080/2000, Train Loss: 0.0051, Test Loss: 0.1978\n",
      "Epoch 1081/2000, Train Loss: 0.0051, Test Loss: 0.1978\n",
      "Epoch 1082/2000, Train Loss: 0.0050, Test Loss: 0.1982\n",
      "Epoch 1083/2000, Train Loss: 0.0050, Test Loss: 0.2002\n",
      "Epoch 1084/2000, Train Loss: 0.0050, Test Loss: 0.2008\n",
      "Epoch 1085/2000, Train Loss: 0.0050, Test Loss: 0.1978\n",
      "Epoch 1086/2000, Train Loss: 0.0050, Test Loss: 0.2009\n",
      "Epoch 1087/2000, Train Loss: 0.0050, Test Loss: 0.1985\n",
      "Epoch 1088/2000, Train Loss: 0.0050, Test Loss: 0.1985\n",
      "Epoch 1089/2000, Train Loss: 0.0050, Test Loss: 0.1979\n",
      "Epoch 1090/2000, Train Loss: 0.0050, Test Loss: 0.1980\n",
      "Epoch 1091/2000, Train Loss: 0.0050, Test Loss: 0.1978\n",
      "Epoch 1092/2000, Train Loss: 0.0050, Test Loss: 0.2084\n",
      "Epoch 1093/2000, Train Loss: 0.0050, Test Loss: 0.1982\n",
      "Epoch 1094/2000, Train Loss: 0.0050, Test Loss: 0.1992\n",
      "Epoch 1095/2000, Train Loss: 0.0050, Test Loss: 0.1981\n",
      "Epoch 1096/2000, Train Loss: 0.0050, Test Loss: 0.1978\n",
      "Epoch 1097/2000, Train Loss: 0.0050, Test Loss: 0.1980\n",
      "Epoch 1098/2000, Train Loss: 0.0050, Test Loss: 0.1988\n",
      "Epoch 1099/2000, Train Loss: 0.0050, Test Loss: 0.2028\n",
      "Epoch 1100/2000, Train Loss: 0.0050, Test Loss: 0.1986\n",
      "Epoch 1101/2000, Train Loss: 0.0050, Test Loss: 0.1979\n",
      "Epoch 1102/2000, Train Loss: 0.0049, Test Loss: 0.1985\n",
      "Epoch 1103/2000, Train Loss: 0.0050, Test Loss: 0.2068\n",
      "Epoch 1104/2000, Train Loss: 0.0049, Test Loss: 0.1986\n",
      "Epoch 1105/2000, Train Loss: 0.0049, Test Loss: 0.2022\n",
      "Epoch 1106/2000, Train Loss: 0.0049, Test Loss: 0.1986\n",
      "Epoch 1107/2000, Train Loss: 0.0049, Test Loss: 0.1989\n",
      "Epoch 1108/2000, Train Loss: 0.0049, Test Loss: 0.2001\n",
      "Epoch 1109/2000, Train Loss: 0.0049, Test Loss: 0.1980\n",
      "Epoch 1110/2000, Train Loss: 0.0049, Test Loss: 0.1992\n",
      "Epoch 1111/2000, Train Loss: 0.0049, Test Loss: 0.1998\n",
      "Epoch 1112/2000, Train Loss: 0.0049, Test Loss: 0.1997\n",
      "Epoch 1113/2000, Train Loss: 0.0049, Test Loss: 0.2067\n",
      "Epoch 1114/2000, Train Loss: 0.0049, Test Loss: 0.1990\n",
      "Epoch 1115/2000, Train Loss: 0.0049, Test Loss: 0.1994\n",
      "Epoch 1116/2000, Train Loss: 0.0049, Test Loss: 0.1994\n",
      "Epoch 1117/2000, Train Loss: 0.0049, Test Loss: 0.1990\n",
      "Epoch 1118/2000, Train Loss: 0.0049, Test Loss: 0.1990\n",
      "Epoch 1119/2000, Train Loss: 0.0049, Test Loss: 0.1991\n",
      "Epoch 1120/2000, Train Loss: 0.0049, Test Loss: 0.1990\n",
      "Epoch 1121/2000, Train Loss: 0.0049, Test Loss: 0.2003\n",
      "Epoch 1122/2000, Train Loss: 0.0048, Test Loss: 0.2010\n",
      "Epoch 1123/2000, Train Loss: 0.0049, Test Loss: 0.2081\n",
      "Epoch 1124/2000, Train Loss: 0.0049, Test Loss: 0.1997\n",
      "Epoch 1125/2000, Train Loss: 0.0049, Test Loss: 0.2083\n",
      "Epoch 1126/2000, Train Loss: 0.0048, Test Loss: 0.2017\n",
      "Epoch 1127/2000, Train Loss: 0.0048, Test Loss: 0.2034\n",
      "Epoch 1128/2000, Train Loss: 0.0048, Test Loss: 0.2087\n",
      "Epoch 1129/2000, Train Loss: 0.0048, Test Loss: 0.2079\n",
      "Epoch 1130/2000, Train Loss: 0.0048, Test Loss: 0.1994\n",
      "Epoch 1131/2000, Train Loss: 0.0048, Test Loss: 0.2001\n",
      "Epoch 1132/2000, Train Loss: 0.0048, Test Loss: 0.2033\n",
      "Epoch 1133/2000, Train Loss: 0.0048, Test Loss: 0.2004\n",
      "Epoch 1134/2000, Train Loss: 0.0048, Test Loss: 0.2077\n",
      "Epoch 1135/2000, Train Loss: 0.0048, Test Loss: 0.2015\n",
      "Epoch 1136/2000, Train Loss: 0.0048, Test Loss: 0.1998\n",
      "Epoch 1137/2000, Train Loss: 0.0048, Test Loss: 0.1993\n",
      "Epoch 1138/2000, Train Loss: 0.0048, Test Loss: 0.2001\n",
      "Epoch 1139/2000, Train Loss: 0.0048, Test Loss: 0.2013\n",
      "Epoch 1140/2000, Train Loss: 0.0048, Test Loss: 0.2002\n",
      "Epoch 1141/2000, Train Loss: 0.0048, Test Loss: 0.2010\n",
      "Epoch 1142/2000, Train Loss: 0.0048, Test Loss: 0.2001\n",
      "Epoch 1143/2000, Train Loss: 0.0048, Test Loss: 0.2004\n",
      "Epoch 1144/2000, Train Loss: 0.0048, Test Loss: 0.2004\n",
      "Epoch 1145/2000, Train Loss: 0.0048, Test Loss: 0.1999\n",
      "Epoch 1146/2000, Train Loss: 0.0048, Test Loss: 0.2025\n",
      "Epoch 1147/2000, Train Loss: 0.0047, Test Loss: 0.1998\n",
      "Epoch 1148/2000, Train Loss: 0.0047, Test Loss: 0.1998\n",
      "Epoch 1149/2000, Train Loss: 0.0048, Test Loss: 0.1999\n",
      "Epoch 1150/2000, Train Loss: 0.0048, Test Loss: 0.2106\n",
      "Epoch 1151/2000, Train Loss: 0.0047, Test Loss: 0.2001\n",
      "Epoch 1152/2000, Train Loss: 0.0047, Test Loss: 0.2000\n",
      "Epoch 1153/2000, Train Loss: 0.0047, Test Loss: 0.2001\n",
      "Epoch 1154/2000, Train Loss: 0.0047, Test Loss: 0.2002\n",
      "Epoch 1155/2000, Train Loss: 0.0047, Test Loss: 0.2016\n",
      "Epoch 1156/2000, Train Loss: 0.0047, Test Loss: 0.2008\n",
      "Epoch 1157/2000, Train Loss: 0.0047, Test Loss: 0.2022\n",
      "Epoch 1158/2000, Train Loss: 0.0047, Test Loss: 0.2002\n",
      "Epoch 1159/2000, Train Loss: 0.0047, Test Loss: 0.2024\n",
      "Epoch 1160/2000, Train Loss: 0.0047, Test Loss: 0.2020\n",
      "Epoch 1161/2000, Train Loss: 0.0047, Test Loss: 0.2053\n",
      "Epoch 1162/2000, Train Loss: 0.0047, Test Loss: 0.2127\n",
      "Epoch 1163/2000, Train Loss: 0.0047, Test Loss: 0.2009\n",
      "Epoch 1164/2000, Train Loss: 0.0047, Test Loss: 0.2008\n",
      "Epoch 1165/2000, Train Loss: 0.0047, Test Loss: 0.2116\n",
      "Epoch 1166/2000, Train Loss: 0.0047, Test Loss: 0.2040\n",
      "Epoch 1167/2000, Train Loss: 0.0047, Test Loss: 0.2009\n",
      "Epoch 1168/2000, Train Loss: 0.0047, Test Loss: 0.2109\n",
      "Epoch 1169/2000, Train Loss: 0.0047, Test Loss: 0.2012\n",
      "Epoch 1170/2000, Train Loss: 0.0047, Test Loss: 0.2011\n",
      "Epoch 1171/2000, Train Loss: 0.0047, Test Loss: 0.2083\n",
      "Epoch 1172/2000, Train Loss: 0.0046, Test Loss: 0.2015\n",
      "Epoch 1173/2000, Train Loss: 0.0047, Test Loss: 0.2021\n",
      "Epoch 1174/2000, Train Loss: 0.0047, Test Loss: 0.2038\n",
      "Epoch 1175/2000, Train Loss: 0.0046, Test Loss: 0.2003\n",
      "Epoch 1176/2000, Train Loss: 0.0046, Test Loss: 0.2034\n",
      "Epoch 1177/2000, Train Loss: 0.0046, Test Loss: 0.2009\n",
      "Epoch 1178/2000, Train Loss: 0.0046, Test Loss: 0.2015\n",
      "Epoch 1179/2000, Train Loss: 0.0046, Test Loss: 0.2055\n",
      "Epoch 1180/2000, Train Loss: 0.0046, Test Loss: 0.2013\n",
      "Epoch 1181/2000, Train Loss: 0.0046, Test Loss: 0.2088\n",
      "Epoch 1182/2000, Train Loss: 0.0046, Test Loss: 0.2025\n",
      "Epoch 1183/2000, Train Loss: 0.0046, Test Loss: 0.2017\n",
      "Epoch 1184/2000, Train Loss: 0.0046, Test Loss: 0.2012\n",
      "Epoch 1185/2000, Train Loss: 0.0046, Test Loss: 0.2039\n",
      "Epoch 1186/2000, Train Loss: 0.0046, Test Loss: 0.2012\n",
      "Epoch 1187/2000, Train Loss: 0.0046, Test Loss: 0.2114\n",
      "Epoch 1188/2000, Train Loss: 0.0046, Test Loss: 0.2015\n",
      "Epoch 1189/2000, Train Loss: 0.0046, Test Loss: 0.2051\n",
      "Epoch 1190/2000, Train Loss: 0.0046, Test Loss: 0.2023\n",
      "Epoch 1191/2000, Train Loss: 0.0046, Test Loss: 0.2013\n",
      "Epoch 1192/2000, Train Loss: 0.0046, Test Loss: 0.2015\n",
      "Epoch 1193/2000, Train Loss: 0.0046, Test Loss: 0.2018\n",
      "Epoch 1194/2000, Train Loss: 0.0046, Test Loss: 0.2058\n",
      "Epoch 1195/2000, Train Loss: 0.0046, Test Loss: 0.2019\n",
      "Epoch 1196/2000, Train Loss: 0.0046, Test Loss: 0.2018\n",
      "Epoch 1197/2000, Train Loss: 0.0046, Test Loss: 0.2017\n",
      "Epoch 1198/2000, Train Loss: 0.0046, Test Loss: 0.2020\n",
      "Epoch 1199/2000, Train Loss: 0.0045, Test Loss: 0.2018\n",
      "Epoch 1200/2000, Train Loss: 0.0046, Test Loss: 0.2051\n",
      "Epoch 1201/2000, Train Loss: 0.0045, Test Loss: 0.2019\n",
      "Epoch 1202/2000, Train Loss: 0.0046, Test Loss: 0.2051\n",
      "Epoch 1203/2000, Train Loss: 0.0046, Test Loss: 0.2036\n",
      "Epoch 1204/2000, Train Loss: 0.0045, Test Loss: 0.2021\n",
      "Epoch 1205/2000, Train Loss: 0.0045, Test Loss: 0.2023\n",
      "Epoch 1206/2000, Train Loss: 0.0045, Test Loss: 0.2045\n",
      "Epoch 1207/2000, Train Loss: 0.0045, Test Loss: 0.2018\n",
      "Epoch 1208/2000, Train Loss: 0.0045, Test Loss: 0.2086\n",
      "Epoch 1209/2000, Train Loss: 0.0045, Test Loss: 0.2026\n",
      "Epoch 1210/2000, Train Loss: 0.0045, Test Loss: 0.2026\n",
      "Epoch 1211/2000, Train Loss: 0.0045, Test Loss: 0.2028\n",
      "Epoch 1212/2000, Train Loss: 0.0045, Test Loss: 0.2045\n",
      "Epoch 1213/2000, Train Loss: 0.0045, Test Loss: 0.2162\n",
      "Epoch 1214/2000, Train Loss: 0.0045, Test Loss: 0.2020\n",
      "Epoch 1215/2000, Train Loss: 0.0045, Test Loss: 0.2028\n",
      "Epoch 1216/2000, Train Loss: 0.0045, Test Loss: 0.2016\n",
      "Epoch 1217/2000, Train Loss: 0.0045, Test Loss: 0.2044\n",
      "Epoch 1218/2000, Train Loss: 0.0045, Test Loss: 0.2023\n",
      "Epoch 1219/2000, Train Loss: 0.0045, Test Loss: 0.2099\n",
      "Epoch 1220/2000, Train Loss: 0.0045, Test Loss: 0.2021\n",
      "Epoch 1221/2000, Train Loss: 0.0045, Test Loss: 0.2075\n",
      "Epoch 1222/2000, Train Loss: 0.0045, Test Loss: 0.2032\n",
      "Epoch 1223/2000, Train Loss: 0.0045, Test Loss: 0.2063\n",
      "Epoch 1224/2000, Train Loss: 0.0045, Test Loss: 0.2030\n",
      "Epoch 1225/2000, Train Loss: 0.0045, Test Loss: 0.2026\n",
      "Epoch 1226/2000, Train Loss: 0.0045, Test Loss: 0.2024\n",
      "Epoch 1227/2000, Train Loss: 0.0045, Test Loss: 0.2039\n",
      "Epoch 1228/2000, Train Loss: 0.0045, Test Loss: 0.2127\n",
      "Epoch 1229/2000, Train Loss: 0.0044, Test Loss: 0.2171\n",
      "Epoch 1230/2000, Train Loss: 0.0044, Test Loss: 0.2053\n",
      "Epoch 1231/2000, Train Loss: 0.0044, Test Loss: 0.2029\n",
      "Epoch 1232/2000, Train Loss: 0.0044, Test Loss: 0.2035\n",
      "Epoch 1233/2000, Train Loss: 0.0044, Test Loss: 0.2027\n",
      "Epoch 1234/2000, Train Loss: 0.0045, Test Loss: 0.2030\n",
      "Epoch 1235/2000, Train Loss: 0.0044, Test Loss: 0.2028\n",
      "Epoch 1236/2000, Train Loss: 0.0044, Test Loss: 0.2039\n",
      "Epoch 1237/2000, Train Loss: 0.0044, Test Loss: 0.2029\n",
      "Epoch 1238/2000, Train Loss: 0.0044, Test Loss: 0.2033\n",
      "Epoch 1239/2000, Train Loss: 0.0044, Test Loss: 0.2034\n",
      "Epoch 1240/2000, Train Loss: 0.0044, Test Loss: 0.2031\n",
      "Epoch 1241/2000, Train Loss: 0.0044, Test Loss: 0.2050\n",
      "Epoch 1242/2000, Train Loss: 0.0044, Test Loss: 0.2028\n",
      "Epoch 1243/2000, Train Loss: 0.0044, Test Loss: 0.2032\n",
      "Epoch 1244/2000, Train Loss: 0.0044, Test Loss: 0.2039\n",
      "Epoch 1245/2000, Train Loss: 0.0044, Test Loss: 0.2030\n",
      "Epoch 1246/2000, Train Loss: 0.0044, Test Loss: 0.2044\n",
      "Epoch 1247/2000, Train Loss: 0.0044, Test Loss: 0.2036\n",
      "Epoch 1248/2000, Train Loss: 0.0044, Test Loss: 0.2041\n",
      "Epoch 1249/2000, Train Loss: 0.0044, Test Loss: 0.2097\n",
      "Epoch 1250/2000, Train Loss: 0.0044, Test Loss: 0.2035\n",
      "Epoch 1251/2000, Train Loss: 0.0044, Test Loss: 0.2038\n",
      "Epoch 1252/2000, Train Loss: 0.0044, Test Loss: 0.2035\n",
      "Epoch 1253/2000, Train Loss: 0.0044, Test Loss: 0.2033\n",
      "Epoch 1254/2000, Train Loss: 0.0044, Test Loss: 0.2146\n",
      "Epoch 1255/2000, Train Loss: 0.0044, Test Loss: 0.2139\n",
      "Epoch 1256/2000, Train Loss: 0.0043, Test Loss: 0.2039\n",
      "Epoch 1257/2000, Train Loss: 0.0044, Test Loss: 0.2040\n",
      "Epoch 1258/2000, Train Loss: 0.0043, Test Loss: 0.2037\n",
      "Epoch 1259/2000, Train Loss: 0.0043, Test Loss: 0.2035\n",
      "Epoch 1260/2000, Train Loss: 0.0043, Test Loss: 0.2036\n",
      "Epoch 1261/2000, Train Loss: 0.0043, Test Loss: 0.2034\n",
      "Epoch 1262/2000, Train Loss: 0.0043, Test Loss: 0.2175\n",
      "Epoch 1263/2000, Train Loss: 0.0043, Test Loss: 0.2148\n",
      "Epoch 1264/2000, Train Loss: 0.0043, Test Loss: 0.2060\n",
      "Epoch 1265/2000, Train Loss: 0.0043, Test Loss: 0.2038\n",
      "Epoch 1266/2000, Train Loss: 0.0043, Test Loss: 0.2037\n",
      "Epoch 1267/2000, Train Loss: 0.0043, Test Loss: 0.2141\n",
      "Epoch 1268/2000, Train Loss: 0.0043, Test Loss: 0.2062\n",
      "Epoch 1269/2000, Train Loss: 0.0043, Test Loss: 0.2048\n",
      "Epoch 1270/2000, Train Loss: 0.0043, Test Loss: 0.2093\n",
      "Epoch 1271/2000, Train Loss: 0.0043, Test Loss: 0.2153\n",
      "Epoch 1272/2000, Train Loss: 0.0043, Test Loss: 0.2038\n",
      "Epoch 1273/2000, Train Loss: 0.0043, Test Loss: 0.2045\n",
      "Epoch 1274/2000, Train Loss: 0.0043, Test Loss: 0.2042\n",
      "Epoch 1275/2000, Train Loss: 0.0043, Test Loss: 0.2055\n",
      "Epoch 1276/2000, Train Loss: 0.0043, Test Loss: 0.2047\n",
      "Epoch 1277/2000, Train Loss: 0.0043, Test Loss: 0.2057\n",
      "Epoch 1278/2000, Train Loss: 0.0043, Test Loss: 0.2044\n",
      "Epoch 1279/2000, Train Loss: 0.0043, Test Loss: 0.2042\n",
      "Epoch 1280/2000, Train Loss: 0.0043, Test Loss: 0.2043\n",
      "Epoch 1281/2000, Train Loss: 0.0043, Test Loss: 0.2042\n",
      "Epoch 1282/2000, Train Loss: 0.0043, Test Loss: 0.2147\n",
      "Epoch 1283/2000, Train Loss: 0.0043, Test Loss: 0.2138\n",
      "Epoch 1284/2000, Train Loss: 0.0043, Test Loss: 0.2044\n",
      "Epoch 1285/2000, Train Loss: 0.0042, Test Loss: 0.2040\n",
      "Epoch 1286/2000, Train Loss: 0.0043, Test Loss: 0.2189\n",
      "Epoch 1287/2000, Train Loss: 0.0043, Test Loss: 0.2044\n",
      "Epoch 1288/2000, Train Loss: 0.0043, Test Loss: 0.2051\n",
      "Epoch 1289/2000, Train Loss: 0.0042, Test Loss: 0.2094\n",
      "Epoch 1290/2000, Train Loss: 0.0042, Test Loss: 0.2042\n",
      "Epoch 1291/2000, Train Loss: 0.0042, Test Loss: 0.2055\n",
      "Epoch 1292/2000, Train Loss: 0.0042, Test Loss: 0.2046\n",
      "Epoch 1293/2000, Train Loss: 0.0042, Test Loss: 0.2046\n",
      "Epoch 1294/2000, Train Loss: 0.0042, Test Loss: 0.2051\n",
      "Epoch 1295/2000, Train Loss: 0.0042, Test Loss: 0.2046\n",
      "Epoch 1296/2000, Train Loss: 0.0042, Test Loss: 0.2068\n",
      "Epoch 1297/2000, Train Loss: 0.0042, Test Loss: 0.2121\n",
      "Epoch 1298/2000, Train Loss: 0.0042, Test Loss: 0.2152\n",
      "Epoch 1299/2000, Train Loss: 0.0042, Test Loss: 0.2049\n",
      "Epoch 1300/2000, Train Loss: 0.0042, Test Loss: 0.2077\n",
      "Epoch 1301/2000, Train Loss: 0.0042, Test Loss: 0.2047\n",
      "Epoch 1302/2000, Train Loss: 0.0042, Test Loss: 0.2048\n",
      "Epoch 1303/2000, Train Loss: 0.0042, Test Loss: 0.2046\n",
      "Epoch 1304/2000, Train Loss: 0.0042, Test Loss: 0.2097\n",
      "Epoch 1305/2000, Train Loss: 0.0042, Test Loss: 0.2089\n",
      "Epoch 1306/2000, Train Loss: 0.0042, Test Loss: 0.2067\n",
      "Epoch 1307/2000, Train Loss: 0.0042, Test Loss: 0.2306\n",
      "Epoch 1308/2000, Train Loss: 0.0042, Test Loss: 0.2072\n",
      "Epoch 1309/2000, Train Loss: 0.0042, Test Loss: 0.2048\n",
      "Epoch 1310/2000, Train Loss: 0.0042, Test Loss: 0.2052\n",
      "Epoch 1311/2000, Train Loss: 0.0042, Test Loss: 0.2058\n",
      "Epoch 1312/2000, Train Loss: 0.0042, Test Loss: 0.2113\n",
      "Epoch 1313/2000, Train Loss: 0.0042, Test Loss: 0.2099\n",
      "Epoch 1314/2000, Train Loss: 0.0042, Test Loss: 0.2053\n",
      "Epoch 1315/2000, Train Loss: 0.0042, Test Loss: 0.2128\n",
      "Epoch 1316/2000, Train Loss: 0.0042, Test Loss: 0.2077\n",
      "Epoch 1317/2000, Train Loss: 0.0042, Test Loss: 0.2053\n",
      "Epoch 1318/2000, Train Loss: 0.0042, Test Loss: 0.2056\n",
      "Epoch 1319/2000, Train Loss: 0.0042, Test Loss: 0.2065\n",
      "Epoch 1320/2000, Train Loss: 0.0041, Test Loss: 0.2148\n",
      "Epoch 1321/2000, Train Loss: 0.0042, Test Loss: 0.2054\n",
      "Epoch 1322/2000, Train Loss: 0.0041, Test Loss: 0.2070\n",
      "Epoch 1323/2000, Train Loss: 0.0041, Test Loss: 0.2099\n",
      "Epoch 1324/2000, Train Loss: 0.0041, Test Loss: 0.2055\n",
      "Epoch 1325/2000, Train Loss: 0.0041, Test Loss: 0.2053\n",
      "Epoch 1326/2000, Train Loss: 0.0041, Test Loss: 0.2058\n",
      "Epoch 1327/2000, Train Loss: 0.0041, Test Loss: 0.2113\n",
      "Epoch 1328/2000, Train Loss: 0.0041, Test Loss: 0.2056\n",
      "Epoch 1329/2000, Train Loss: 0.0041, Test Loss: 0.2094\n",
      "Epoch 1330/2000, Train Loss: 0.0041, Test Loss: 0.2071\n",
      "Epoch 1331/2000, Train Loss: 0.0041, Test Loss: 0.2062\n",
      "Epoch 1332/2000, Train Loss: 0.0041, Test Loss: 0.2075\n",
      "Epoch 1333/2000, Train Loss: 0.0041, Test Loss: 0.2060\n",
      "Epoch 1334/2000, Train Loss: 0.0041, Test Loss: 0.2146\n",
      "Epoch 1335/2000, Train Loss: 0.0041, Test Loss: 0.2058\n",
      "Epoch 1336/2000, Train Loss: 0.0041, Test Loss: 0.2063\n",
      "Epoch 1337/2000, Train Loss: 0.0041, Test Loss: 0.2067\n",
      "Epoch 1338/2000, Train Loss: 0.0041, Test Loss: 0.2060\n",
      "Epoch 1339/2000, Train Loss: 0.0041, Test Loss: 0.2073\n",
      "Epoch 1340/2000, Train Loss: 0.0041, Test Loss: 0.2113\n",
      "Epoch 1341/2000, Train Loss: 0.0041, Test Loss: 0.2140\n",
      "Epoch 1342/2000, Train Loss: 0.0041, Test Loss: 0.2087\n",
      "Epoch 1343/2000, Train Loss: 0.0041, Test Loss: 0.2063\n",
      "Epoch 1344/2000, Train Loss: 0.0041, Test Loss: 0.2063\n",
      "Epoch 1345/2000, Train Loss: 0.0041, Test Loss: 0.2070\n",
      "Epoch 1346/2000, Train Loss: 0.0041, Test Loss: 0.2085\n",
      "Epoch 1347/2000, Train Loss: 0.0041, Test Loss: 0.2061\n",
      "Epoch 1348/2000, Train Loss: 0.0041, Test Loss: 0.2065\n",
      "Epoch 1349/2000, Train Loss: 0.0041, Test Loss: 0.2066\n",
      "Epoch 1350/2000, Train Loss: 0.0041, Test Loss: 0.2060\n",
      "Epoch 1351/2000, Train Loss: 0.0041, Test Loss: 0.2064\n",
      "Epoch 1352/2000, Train Loss: 0.0041, Test Loss: 0.2064\n",
      "Epoch 1353/2000, Train Loss: 0.0041, Test Loss: 0.2068\n",
      "Epoch 1354/2000, Train Loss: 0.0040, Test Loss: 0.2069\n",
      "Epoch 1355/2000, Train Loss: 0.0041, Test Loss: 0.2067\n",
      "Epoch 1356/2000, Train Loss: 0.0041, Test Loss: 0.2065\n",
      "Epoch 1357/2000, Train Loss: 0.0040, Test Loss: 0.2100\n",
      "Epoch 1358/2000, Train Loss: 0.0040, Test Loss: 0.2076\n",
      "Epoch 1359/2000, Train Loss: 0.0040, Test Loss: 0.2095\n",
      "Epoch 1360/2000, Train Loss: 0.0040, Test Loss: 0.2099\n",
      "Epoch 1361/2000, Train Loss: 0.0041, Test Loss: 0.2060\n",
      "Epoch 1362/2000, Train Loss: 0.0040, Test Loss: 0.2125\n",
      "Epoch 1363/2000, Train Loss: 0.0040, Test Loss: 0.2069\n",
      "Epoch 1364/2000, Train Loss: 0.0040, Test Loss: 0.2129\n",
      "Epoch 1365/2000, Train Loss: 0.0040, Test Loss: 0.2069\n",
      "Epoch 1366/2000, Train Loss: 0.0040, Test Loss: 0.2063\n",
      "Epoch 1367/2000, Train Loss: 0.0040, Test Loss: 0.2102\n",
      "Epoch 1368/2000, Train Loss: 0.0040, Test Loss: 0.2067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1369/2000, Train Loss: 0.0040, Test Loss: 0.2063\n",
      "Epoch 1370/2000, Train Loss: 0.0040, Test Loss: 0.2069\n",
      "Epoch 1371/2000, Train Loss: 0.0040, Test Loss: 0.2072\n",
      "Epoch 1372/2000, Train Loss: 0.0040, Test Loss: 0.2070\n",
      "Epoch 1373/2000, Train Loss: 0.0040, Test Loss: 0.2069\n",
      "Epoch 1374/2000, Train Loss: 0.0040, Test Loss: 0.2072\n",
      "Epoch 1375/2000, Train Loss: 0.0040, Test Loss: 0.2071\n",
      "Epoch 1376/2000, Train Loss: 0.0040, Test Loss: 0.2067\n",
      "Epoch 1377/2000, Train Loss: 0.0040, Test Loss: 0.2085\n",
      "Epoch 1378/2000, Train Loss: 0.0040, Test Loss: 0.2070\n",
      "Epoch 1379/2000, Train Loss: 0.0040, Test Loss: 0.2083\n",
      "Epoch 1380/2000, Train Loss: 0.0040, Test Loss: 0.2115\n",
      "Epoch 1381/2000, Train Loss: 0.0040, Test Loss: 0.2077\n",
      "Epoch 1382/2000, Train Loss: 0.0040, Test Loss: 0.2071\n",
      "Epoch 1383/2000, Train Loss: 0.0040, Test Loss: 0.2075\n",
      "Epoch 1384/2000, Train Loss: 0.0040, Test Loss: 0.2071\n",
      "Epoch 1385/2000, Train Loss: 0.0040, Test Loss: 0.2083\n",
      "Epoch 1386/2000, Train Loss: 0.0040, Test Loss: 0.2072\n",
      "Epoch 1387/2000, Train Loss: 0.0040, Test Loss: 0.2074\n",
      "Epoch 1388/2000, Train Loss: 0.0040, Test Loss: 0.2168\n",
      "Epoch 1389/2000, Train Loss: 0.0040, Test Loss: 0.2078\n",
      "Epoch 1390/2000, Train Loss: 0.0040, Test Loss: 0.2081\n",
      "Epoch 1391/2000, Train Loss: 0.0040, Test Loss: 0.2118\n",
      "Epoch 1392/2000, Train Loss: 0.0040, Test Loss: 0.2089\n",
      "Epoch 1393/2000, Train Loss: 0.0039, Test Loss: 0.2131\n",
      "Epoch 1394/2000, Train Loss: 0.0039, Test Loss: 0.2082\n",
      "Epoch 1395/2000, Train Loss: 0.0039, Test Loss: 0.2077\n",
      "Epoch 1396/2000, Train Loss: 0.0039, Test Loss: 0.2075\n",
      "Epoch 1397/2000, Train Loss: 0.0039, Test Loss: 0.2077\n",
      "Epoch 1398/2000, Train Loss: 0.0039, Test Loss: 0.2103\n",
      "Epoch 1399/2000, Train Loss: 0.0039, Test Loss: 0.2098\n",
      "Epoch 1400/2000, Train Loss: 0.0039, Test Loss: 0.2090\n",
      "Epoch 1401/2000, Train Loss: 0.0039, Test Loss: 0.2074\n",
      "Epoch 1402/2000, Train Loss: 0.0039, Test Loss: 0.2101\n",
      "Epoch 1403/2000, Train Loss: 0.0039, Test Loss: 0.2094\n",
      "Epoch 1404/2000, Train Loss: 0.0039, Test Loss: 0.2107\n",
      "Epoch 1405/2000, Train Loss: 0.0039, Test Loss: 0.2078\n",
      "Epoch 1406/2000, Train Loss: 0.0039, Test Loss: 0.2121\n",
      "Epoch 1407/2000, Train Loss: 0.0039, Test Loss: 0.2081\n",
      "Epoch 1408/2000, Train Loss: 0.0039, Test Loss: 0.2092\n",
      "Epoch 1409/2000, Train Loss: 0.0039, Test Loss: 0.2077\n",
      "Epoch 1410/2000, Train Loss: 0.0039, Test Loss: 0.2081\n",
      "Epoch 1411/2000, Train Loss: 0.0039, Test Loss: 0.2082\n",
      "Epoch 1412/2000, Train Loss: 0.0039, Test Loss: 0.2172\n",
      "Epoch 1413/2000, Train Loss: 0.0039, Test Loss: 0.2083\n",
      "Epoch 1414/2000, Train Loss: 0.0039, Test Loss: 0.2122\n",
      "Epoch 1415/2000, Train Loss: 0.0039, Test Loss: 0.2133\n",
      "Epoch 1416/2000, Train Loss: 0.0039, Test Loss: 0.2084\n",
      "Epoch 1417/2000, Train Loss: 0.0039, Test Loss: 0.2080\n",
      "Epoch 1418/2000, Train Loss: 0.0039, Test Loss: 0.2077\n",
      "Epoch 1419/2000, Train Loss: 0.0039, Test Loss: 0.2088\n",
      "Epoch 1420/2000, Train Loss: 0.0039, Test Loss: 0.2095\n",
      "Epoch 1421/2000, Train Loss: 0.0039, Test Loss: 0.2087\n",
      "Epoch 1422/2000, Train Loss: 0.0039, Test Loss: 0.2082\n",
      "Epoch 1423/2000, Train Loss: 0.0039, Test Loss: 0.2144\n",
      "Epoch 1424/2000, Train Loss: 0.0039, Test Loss: 0.2112\n",
      "Epoch 1425/2000, Train Loss: 0.0039, Test Loss: 0.2165\n",
      "Epoch 1426/2000, Train Loss: 0.0039, Test Loss: 0.2081\n",
      "Epoch 1427/2000, Train Loss: 0.0039, Test Loss: 0.2079\n",
      "Epoch 1428/2000, Train Loss: 0.0039, Test Loss: 0.2146\n",
      "Epoch 1429/2000, Train Loss: 0.0038, Test Loss: 0.2081\n",
      "Epoch 1430/2000, Train Loss: 0.0038, Test Loss: 0.2140\n",
      "Epoch 1431/2000, Train Loss: 0.0039, Test Loss: 0.2125\n",
      "Epoch 1432/2000, Train Loss: 0.0038, Test Loss: 0.2097\n",
      "Epoch 1433/2000, Train Loss: 0.0038, Test Loss: 0.2088\n",
      "Epoch 1434/2000, Train Loss: 0.0038, Test Loss: 0.2086\n",
      "Epoch 1435/2000, Train Loss: 0.0038, Test Loss: 0.2092\n",
      "Epoch 1436/2000, Train Loss: 0.0038, Test Loss: 0.2082\n",
      "Epoch 1437/2000, Train Loss: 0.0038, Test Loss: 0.2100\n",
      "Epoch 1438/2000, Train Loss: 0.0038, Test Loss: 0.2096\n",
      "Epoch 1439/2000, Train Loss: 0.0038, Test Loss: 0.2099\n",
      "Epoch 1440/2000, Train Loss: 0.0038, Test Loss: 0.2141\n",
      "Epoch 1441/2000, Train Loss: 0.0038, Test Loss: 0.2097\n",
      "Epoch 1442/2000, Train Loss: 0.0038, Test Loss: 0.2087\n",
      "Epoch 1443/2000, Train Loss: 0.0038, Test Loss: 0.2092\n",
      "Epoch 1444/2000, Train Loss: 0.0038, Test Loss: 0.2100\n",
      "Epoch 1445/2000, Train Loss: 0.0038, Test Loss: 0.2087\n",
      "Epoch 1446/2000, Train Loss: 0.0038, Test Loss: 0.2261\n",
      "Epoch 1447/2000, Train Loss: 0.0038, Test Loss: 0.2201\n",
      "Epoch 1448/2000, Train Loss: 0.0038, Test Loss: 0.2114\n",
      "Epoch 1449/2000, Train Loss: 0.0038, Test Loss: 0.2094\n",
      "Epoch 1450/2000, Train Loss: 0.0038, Test Loss: 0.2098\n",
      "Epoch 1451/2000, Train Loss: 0.0038, Test Loss: 0.2107\n",
      "Epoch 1452/2000, Train Loss: 0.0038, Test Loss: 0.2096\n",
      "Epoch 1453/2000, Train Loss: 0.0038, Test Loss: 0.2111\n",
      "Epoch 1454/2000, Train Loss: 0.0038, Test Loss: 0.2094\n",
      "Epoch 1455/2000, Train Loss: 0.0038, Test Loss: 0.2131\n",
      "Epoch 1456/2000, Train Loss: 0.0038, Test Loss: 0.2092\n",
      "Epoch 1457/2000, Train Loss: 0.0038, Test Loss: 0.2094\n",
      "Epoch 1458/2000, Train Loss: 0.0038, Test Loss: 0.2123\n",
      "Epoch 1459/2000, Train Loss: 0.0038, Test Loss: 0.2099\n",
      "Epoch 1460/2000, Train Loss: 0.0038, Test Loss: 0.2093\n",
      "Epoch 1461/2000, Train Loss: 0.0038, Test Loss: 0.2096\n",
      "Epoch 1462/2000, Train Loss: 0.0038, Test Loss: 0.2098\n",
      "Epoch 1463/2000, Train Loss: 0.0038, Test Loss: 0.2153\n",
      "Epoch 1464/2000, Train Loss: 0.0038, Test Loss: 0.2120\n",
      "Epoch 1465/2000, Train Loss: 0.0038, Test Loss: 0.2100\n",
      "Epoch 1466/2000, Train Loss: 0.0038, Test Loss: 0.2152\n",
      "Epoch 1467/2000, Train Loss: 0.0038, Test Loss: 0.2119\n",
      "Epoch 1468/2000, Train Loss: 0.0038, Test Loss: 0.2115\n",
      "Epoch 1469/2000, Train Loss: 0.0038, Test Loss: 0.2097\n",
      "Epoch 1470/2000, Train Loss: 0.0038, Test Loss: 0.2103\n",
      "Epoch 1471/2000, Train Loss: 0.0037, Test Loss: 0.2140\n",
      "Epoch 1472/2000, Train Loss: 0.0037, Test Loss: 0.2102\n",
      "Epoch 1473/2000, Train Loss: 0.0037, Test Loss: 0.2102\n",
      "Epoch 1474/2000, Train Loss: 0.0037, Test Loss: 0.2113\n",
      "Epoch 1475/2000, Train Loss: 0.0037, Test Loss: 0.2117\n",
      "Epoch 1476/2000, Train Loss: 0.0037, Test Loss: 0.2117\n",
      "Epoch 1477/2000, Train Loss: 0.0037, Test Loss: 0.2102\n",
      "Epoch 1478/2000, Train Loss: 0.0037, Test Loss: 0.2108\n",
      "Epoch 1479/2000, Train Loss: 0.0037, Test Loss: 0.2102\n",
      "Epoch 1480/2000, Train Loss: 0.0037, Test Loss: 0.2259\n",
      "Epoch 1481/2000, Train Loss: 0.0037, Test Loss: 0.2101\n",
      "Epoch 1482/2000, Train Loss: 0.0037, Test Loss: 0.2102\n",
      "Epoch 1483/2000, Train Loss: 0.0037, Test Loss: 0.2201\n",
      "Epoch 1484/2000, Train Loss: 0.0037, Test Loss: 0.2102\n",
      "Epoch 1485/2000, Train Loss: 0.0037, Test Loss: 0.2174\n",
      "Epoch 1486/2000, Train Loss: 0.0037, Test Loss: 0.2104\n",
      "Epoch 1487/2000, Train Loss: 0.0037, Test Loss: 0.2097\n",
      "Epoch 1488/2000, Train Loss: 0.0037, Test Loss: 0.2148\n",
      "Epoch 1489/2000, Train Loss: 0.0037, Test Loss: 0.2101\n",
      "Epoch 1490/2000, Train Loss: 0.0037, Test Loss: 0.2259\n",
      "Epoch 1491/2000, Train Loss: 0.0037, Test Loss: 0.2235\n",
      "Epoch 1492/2000, Train Loss: 0.0037, Test Loss: 0.2100\n",
      "Epoch 1493/2000, Train Loss: 0.0037, Test Loss: 0.2099\n",
      "Epoch 1494/2000, Train Loss: 0.0037, Test Loss: 0.2102\n",
      "Epoch 1495/2000, Train Loss: 0.0037, Test Loss: 0.2166\n",
      "Epoch 1496/2000, Train Loss: 0.0037, Test Loss: 0.2101\n",
      "Epoch 1497/2000, Train Loss: 0.0037, Test Loss: 0.2102\n",
      "Epoch 1498/2000, Train Loss: 0.0037, Test Loss: 0.2098\n",
      "Epoch 1499/2000, Train Loss: 0.0037, Test Loss: 0.2101\n",
      "Epoch 1500/2000, Train Loss: 0.0037, Test Loss: 0.2174\n",
      "Epoch 1501/2000, Train Loss: 0.0037, Test Loss: 0.2128\n",
      "Epoch 1502/2000, Train Loss: 0.0037, Test Loss: 0.2168\n",
      "Epoch 1503/2000, Train Loss: 0.0037, Test Loss: 0.2104\n",
      "Epoch 1504/2000, Train Loss: 0.0037, Test Loss: 0.2155\n",
      "Epoch 1505/2000, Train Loss: 0.0037, Test Loss: 0.2105\n",
      "Epoch 1506/2000, Train Loss: 0.0037, Test Loss: 0.2122\n",
      "Epoch 1507/2000, Train Loss: 0.0037, Test Loss: 0.2102\n",
      "Epoch 1508/2000, Train Loss: 0.0037, Test Loss: 0.2106\n",
      "Epoch 1509/2000, Train Loss: 0.0037, Test Loss: 0.2105\n",
      "Epoch 1510/2000, Train Loss: 0.0037, Test Loss: 0.2142\n",
      "Epoch 1511/2000, Train Loss: 0.0037, Test Loss: 0.2252\n",
      "Epoch 1512/2000, Train Loss: 0.0037, Test Loss: 0.2174\n",
      "Epoch 1513/2000, Train Loss: 0.0036, Test Loss: 0.2110\n",
      "Epoch 1514/2000, Train Loss: 0.0037, Test Loss: 0.2110\n",
      "Epoch 1515/2000, Train Loss: 0.0037, Test Loss: 0.2111\n",
      "Epoch 1516/2000, Train Loss: 0.0037, Test Loss: 0.2150\n",
      "Epoch 1517/2000, Train Loss: 0.0036, Test Loss: 0.2111\n",
      "Epoch 1518/2000, Train Loss: 0.0036, Test Loss: 0.2122\n",
      "Epoch 1519/2000, Train Loss: 0.0036, Test Loss: 0.2113\n",
      "Epoch 1520/2000, Train Loss: 0.0036, Test Loss: 0.2205\n",
      "Epoch 1521/2000, Train Loss: 0.0036, Test Loss: 0.2161\n",
      "Epoch 1522/2000, Train Loss: 0.0036, Test Loss: 0.2109\n",
      "Epoch 1523/2000, Train Loss: 0.0036, Test Loss: 0.2108\n",
      "Epoch 1524/2000, Train Loss: 0.0036, Test Loss: 0.2108\n",
      "Epoch 1525/2000, Train Loss: 0.0036, Test Loss: 0.2116\n",
      "Epoch 1526/2000, Train Loss: 0.0036, Test Loss: 0.2187\n",
      "Epoch 1527/2000, Train Loss: 0.0036, Test Loss: 0.2109\n",
      "Epoch 1528/2000, Train Loss: 0.0036, Test Loss: 0.2112\n",
      "Epoch 1529/2000, Train Loss: 0.0036, Test Loss: 0.2111\n",
      "Epoch 1530/2000, Train Loss: 0.0036, Test Loss: 0.2110\n",
      "Epoch 1531/2000, Train Loss: 0.0036, Test Loss: 0.2111\n",
      "Epoch 1532/2000, Train Loss: 0.0036, Test Loss: 0.2112\n",
      "Epoch 1533/2000, Train Loss: 0.0036, Test Loss: 0.2111\n",
      "Epoch 1534/2000, Train Loss: 0.0036, Test Loss: 0.2113\n",
      "Epoch 1535/2000, Train Loss: 0.0036, Test Loss: 0.2111\n",
      "Epoch 1536/2000, Train Loss: 0.0036, Test Loss: 0.2115\n",
      "Epoch 1537/2000, Train Loss: 0.0036, Test Loss: 0.2129\n",
      "Epoch 1538/2000, Train Loss: 0.0036, Test Loss: 0.2141\n",
      "Epoch 1539/2000, Train Loss: 0.0036, Test Loss: 0.2117\n",
      "Epoch 1540/2000, Train Loss: 0.0036, Test Loss: 0.2125\n",
      "Epoch 1541/2000, Train Loss: 0.0036, Test Loss: 0.2227\n",
      "Epoch 1542/2000, Train Loss: 0.0036, Test Loss: 0.2125\n",
      "Epoch 1543/2000, Train Loss: 0.0036, Test Loss: 0.2156\n",
      "Epoch 1544/2000, Train Loss: 0.0036, Test Loss: 0.2114\n",
      "Epoch 1545/2000, Train Loss: 0.0036, Test Loss: 0.2112\n",
      "Epoch 1546/2000, Train Loss: 0.0036, Test Loss: 0.2142\n",
      "Epoch 1547/2000, Train Loss: 0.0036, Test Loss: 0.2124\n",
      "Epoch 1548/2000, Train Loss: 0.0036, Test Loss: 0.2118\n",
      "Epoch 1549/2000, Train Loss: 0.0036, Test Loss: 0.2134\n",
      "Epoch 1550/2000, Train Loss: 0.0036, Test Loss: 0.2227\n",
      "Epoch 1551/2000, Train Loss: 0.0036, Test Loss: 0.2166\n",
      "Epoch 1552/2000, Train Loss: 0.0036, Test Loss: 0.2125\n",
      "Epoch 1553/2000, Train Loss: 0.0036, Test Loss: 0.2119\n",
      "Epoch 1554/2000, Train Loss: 0.0036, Test Loss: 0.2118\n",
      "Epoch 1555/2000, Train Loss: 0.0036, Test Loss: 0.2117\n",
      "Epoch 1556/2000, Train Loss: 0.0036, Test Loss: 0.2127\n",
      "Epoch 1557/2000, Train Loss: 0.0036, Test Loss: 0.2178\n",
      "Epoch 1558/2000, Train Loss: 0.0036, Test Loss: 0.2146\n",
      "Epoch 1559/2000, Train Loss: 0.0036, Test Loss: 0.2123\n",
      "Epoch 1560/2000, Train Loss: 0.0035, Test Loss: 0.2172\n",
      "Epoch 1561/2000, Train Loss: 0.0036, Test Loss: 0.2120\n",
      "Epoch 1562/2000, Train Loss: 0.0035, Test Loss: 0.2133\n",
      "Epoch 1563/2000, Train Loss: 0.0035, Test Loss: 0.2120\n",
      "Epoch 1564/2000, Train Loss: 0.0035, Test Loss: 0.2124\n",
      "Epoch 1565/2000, Train Loss: 0.0035, Test Loss: 0.2138\n",
      "Epoch 1566/2000, Train Loss: 0.0035, Test Loss: 0.2121\n",
      "Epoch 1567/2000, Train Loss: 0.0035, Test Loss: 0.2124\n",
      "Epoch 1568/2000, Train Loss: 0.0035, Test Loss: 0.2121\n",
      "Epoch 1569/2000, Train Loss: 0.0035, Test Loss: 0.2139\n",
      "Epoch 1570/2000, Train Loss: 0.0035, Test Loss: 0.2122\n",
      "Epoch 1571/2000, Train Loss: 0.0035, Test Loss: 0.2125\n",
      "Epoch 1572/2000, Train Loss: 0.0035, Test Loss: 0.2152\n",
      "Epoch 1573/2000, Train Loss: 0.0035, Test Loss: 0.2127\n",
      "Epoch 1574/2000, Train Loss: 0.0035, Test Loss: 0.2163\n",
      "Epoch 1575/2000, Train Loss: 0.0035, Test Loss: 0.2159\n",
      "Epoch 1576/2000, Train Loss: 0.0035, Test Loss: 0.2137\n",
      "Epoch 1577/2000, Train Loss: 0.0035, Test Loss: 0.2122\n",
      "Epoch 1578/2000, Train Loss: 0.0035, Test Loss: 0.2120\n",
      "Epoch 1579/2000, Train Loss: 0.0035, Test Loss: 0.2134\n",
      "Epoch 1580/2000, Train Loss: 0.0035, Test Loss: 0.2161\n",
      "Epoch 1581/2000, Train Loss: 0.0035, Test Loss: 0.2126\n",
      "Epoch 1582/2000, Train Loss: 0.0035, Test Loss: 0.2131\n",
      "Epoch 1583/2000, Train Loss: 0.0035, Test Loss: 0.2125\n",
      "Epoch 1584/2000, Train Loss: 0.0035, Test Loss: 0.2177\n",
      "Epoch 1585/2000, Train Loss: 0.0035, Test Loss: 0.2126\n",
      "Epoch 1586/2000, Train Loss: 0.0035, Test Loss: 0.2126\n",
      "Epoch 1587/2000, Train Loss: 0.0035, Test Loss: 0.2123\n",
      "Epoch 1588/2000, Train Loss: 0.0035, Test Loss: 0.2159\n",
      "Epoch 1589/2000, Train Loss: 0.0035, Test Loss: 0.2126\n",
      "Epoch 1590/2000, Train Loss: 0.0035, Test Loss: 0.2175\n",
      "Epoch 1591/2000, Train Loss: 0.0035, Test Loss: 0.2236\n",
      "Epoch 1592/2000, Train Loss: 0.0035, Test Loss: 0.2127\n",
      "Epoch 1593/2000, Train Loss: 0.0035, Test Loss: 0.2173\n",
      "Epoch 1594/2000, Train Loss: 0.0035, Test Loss: 0.2128\n",
      "Epoch 1595/2000, Train Loss: 0.0035, Test Loss: 0.2135\n",
      "Epoch 1596/2000, Train Loss: 0.0035, Test Loss: 0.2127\n",
      "Epoch 1597/2000, Train Loss: 0.0035, Test Loss: 0.2129\n",
      "Epoch 1598/2000, Train Loss: 0.0035, Test Loss: 0.2188\n",
      "Epoch 1599/2000, Train Loss: 0.0035, Test Loss: 0.2251\n",
      "Epoch 1600/2000, Train Loss: 0.0035, Test Loss: 0.2128\n",
      "Epoch 1601/2000, Train Loss: 0.0035, Test Loss: 0.2126\n",
      "Epoch 1602/2000, Train Loss: 0.0035, Test Loss: 0.2172\n",
      "Epoch 1603/2000, Train Loss: 0.0035, Test Loss: 0.2131\n",
      "Epoch 1604/2000, Train Loss: 0.0035, Test Loss: 0.2155\n",
      "Epoch 1605/2000, Train Loss: 0.0035, Test Loss: 0.2131\n",
      "Epoch 1606/2000, Train Loss: 0.0035, Test Loss: 0.2125\n",
      "Epoch 1607/2000, Train Loss: 0.0035, Test Loss: 0.2180\n",
      "Epoch 1608/2000, Train Loss: 0.0034, Test Loss: 0.2132\n",
      "Epoch 1609/2000, Train Loss: 0.0035, Test Loss: 0.2134\n",
      "Epoch 1610/2000, Train Loss: 0.0034, Test Loss: 0.2133\n",
      "Epoch 1611/2000, Train Loss: 0.0034, Test Loss: 0.2131\n",
      "Epoch 1612/2000, Train Loss: 0.0034, Test Loss: 0.2257\n",
      "Epoch 1613/2000, Train Loss: 0.0035, Test Loss: 0.2139\n",
      "Epoch 1614/2000, Train Loss: 0.0034, Test Loss: 0.2168\n",
      "Epoch 1615/2000, Train Loss: 0.0034, Test Loss: 0.2134\n",
      "Epoch 1616/2000, Train Loss: 0.0034, Test Loss: 0.2130\n",
      "Epoch 1617/2000, Train Loss: 0.0034, Test Loss: 0.2134\n",
      "Epoch 1618/2000, Train Loss: 0.0034, Test Loss: 0.2143\n",
      "Epoch 1619/2000, Train Loss: 0.0034, Test Loss: 0.2151\n",
      "Epoch 1620/2000, Train Loss: 0.0034, Test Loss: 0.2140\n",
      "Epoch 1621/2000, Train Loss: 0.0034, Test Loss: 0.2139\n",
      "Epoch 1622/2000, Train Loss: 0.0034, Test Loss: 0.2132\n",
      "Epoch 1623/2000, Train Loss: 0.0034, Test Loss: 0.2174\n",
      "Epoch 1624/2000, Train Loss: 0.0034, Test Loss: 0.2145\n",
      "Epoch 1625/2000, Train Loss: 0.0034, Test Loss: 0.2152\n",
      "Epoch 1626/2000, Train Loss: 0.0034, Test Loss: 0.2219\n",
      "Epoch 1627/2000, Train Loss: 0.0034, Test Loss: 0.2144\n",
      "Epoch 1628/2000, Train Loss: 0.0034, Test Loss: 0.2135\n",
      "Epoch 1629/2000, Train Loss: 0.0034, Test Loss: 0.2135\n",
      "Epoch 1630/2000, Train Loss: 0.0034, Test Loss: 0.2139\n",
      "Epoch 1631/2000, Train Loss: 0.0034, Test Loss: 0.2163\n",
      "Epoch 1632/2000, Train Loss: 0.0034, Test Loss: 0.2136\n",
      "Epoch 1633/2000, Train Loss: 0.0034, Test Loss: 0.2190\n",
      "Epoch 1634/2000, Train Loss: 0.0034, Test Loss: 0.2209\n",
      "Epoch 1635/2000, Train Loss: 0.0034, Test Loss: 0.2199\n",
      "Epoch 1636/2000, Train Loss: 0.0034, Test Loss: 0.2138\n",
      "Epoch 1637/2000, Train Loss: 0.0034, Test Loss: 0.2141\n",
      "Epoch 1638/2000, Train Loss: 0.0034, Test Loss: 0.2136\n",
      "Epoch 1639/2000, Train Loss: 0.0034, Test Loss: 0.2259\n",
      "Epoch 1640/2000, Train Loss: 0.0034, Test Loss: 0.2188\n",
      "Epoch 1641/2000, Train Loss: 0.0034, Test Loss: 0.2143\n",
      "Epoch 1642/2000, Train Loss: 0.0034, Test Loss: 0.2137\n",
      "Epoch 1643/2000, Train Loss: 0.0034, Test Loss: 0.2146\n",
      "Epoch 1644/2000, Train Loss: 0.0034, Test Loss: 0.2205\n",
      "Epoch 1645/2000, Train Loss: 0.0034, Test Loss: 0.2143\n",
      "Epoch 1646/2000, Train Loss: 0.0034, Test Loss: 0.2137\n",
      "Epoch 1647/2000, Train Loss: 0.0034, Test Loss: 0.2187\n",
      "Epoch 1648/2000, Train Loss: 0.0034, Test Loss: 0.2139\n",
      "Epoch 1649/2000, Train Loss: 0.0034, Test Loss: 0.2138\n",
      "Epoch 1650/2000, Train Loss: 0.0034, Test Loss: 0.2181\n",
      "Epoch 1651/2000, Train Loss: 0.0034, Test Loss: 0.2139\n",
      "Epoch 1652/2000, Train Loss: 0.0034, Test Loss: 0.2145\n",
      "Epoch 1653/2000, Train Loss: 0.0034, Test Loss: 0.2142\n",
      "Epoch 1654/2000, Train Loss: 0.0034, Test Loss: 0.2143\n",
      "Epoch 1655/2000, Train Loss: 0.0034, Test Loss: 0.2144\n",
      "Epoch 1656/2000, Train Loss: 0.0034, Test Loss: 0.2174\n",
      "Epoch 1657/2000, Train Loss: 0.0034, Test Loss: 0.2139\n",
      "Epoch 1658/2000, Train Loss: 0.0034, Test Loss: 0.2138\n",
      "Epoch 1659/2000, Train Loss: 0.0034, Test Loss: 0.2182\n",
      "Epoch 1660/2000, Train Loss: 0.0033, Test Loss: 0.2146\n",
      "Epoch 1661/2000, Train Loss: 0.0034, Test Loss: 0.2175\n",
      "Epoch 1662/2000, Train Loss: 0.0034, Test Loss: 0.2141\n",
      "Epoch 1663/2000, Train Loss: 0.0033, Test Loss: 0.2142\n",
      "Epoch 1664/2000, Train Loss: 0.0034, Test Loss: 0.2142\n",
      "Epoch 1665/2000, Train Loss: 0.0033, Test Loss: 0.2152\n",
      "Epoch 1666/2000, Train Loss: 0.0033, Test Loss: 0.2146\n",
      "Epoch 1667/2000, Train Loss: 0.0034, Test Loss: 0.2165\n",
      "Epoch 1668/2000, Train Loss: 0.0033, Test Loss: 0.2141\n",
      "Epoch 1669/2000, Train Loss: 0.0033, Test Loss: 0.2159\n",
      "Epoch 1670/2000, Train Loss: 0.0033, Test Loss: 0.2142\n",
      "Epoch 1671/2000, Train Loss: 0.0033, Test Loss: 0.2144\n",
      "Epoch 1672/2000, Train Loss: 0.0033, Test Loss: 0.2245\n",
      "Epoch 1673/2000, Train Loss: 0.0033, Test Loss: 0.2143\n",
      "Epoch 1674/2000, Train Loss: 0.0033, Test Loss: 0.2145\n",
      "Epoch 1675/2000, Train Loss: 0.0033, Test Loss: 0.2205\n",
      "Epoch 1676/2000, Train Loss: 0.0033, Test Loss: 0.2156\n",
      "Epoch 1677/2000, Train Loss: 0.0033, Test Loss: 0.2189\n",
      "Epoch 1678/2000, Train Loss: 0.0033, Test Loss: 0.2145\n",
      "Epoch 1679/2000, Train Loss: 0.0033, Test Loss: 0.2315\n",
      "Epoch 1680/2000, Train Loss: 0.0033, Test Loss: 0.2143\n",
      "Epoch 1681/2000, Train Loss: 0.0033, Test Loss: 0.2152\n",
      "Epoch 1682/2000, Train Loss: 0.0033, Test Loss: 0.2146\n",
      "Epoch 1683/2000, Train Loss: 0.0033, Test Loss: 0.2144\n",
      "Epoch 1684/2000, Train Loss: 0.0033, Test Loss: 0.2147\n",
      "Epoch 1685/2000, Train Loss: 0.0033, Test Loss: 0.2151\n",
      "Epoch 1686/2000, Train Loss: 0.0033, Test Loss: 0.2268\n",
      "Epoch 1687/2000, Train Loss: 0.0033, Test Loss: 0.2146\n",
      "Epoch 1688/2000, Train Loss: 0.0033, Test Loss: 0.2151\n",
      "Epoch 1689/2000, Train Loss: 0.0033, Test Loss: 0.2148\n",
      "Epoch 1690/2000, Train Loss: 0.0033, Test Loss: 0.2150\n",
      "Epoch 1691/2000, Train Loss: 0.0033, Test Loss: 0.2196\n",
      "Epoch 1692/2000, Train Loss: 0.0033, Test Loss: 0.2219\n",
      "Epoch 1693/2000, Train Loss: 0.0033, Test Loss: 0.2147\n",
      "Epoch 1694/2000, Train Loss: 0.0033, Test Loss: 0.2149\n",
      "Epoch 1695/2000, Train Loss: 0.0033, Test Loss: 0.2148\n",
      "Epoch 1696/2000, Train Loss: 0.0033, Test Loss: 0.2265\n",
      "Epoch 1697/2000, Train Loss: 0.0033, Test Loss: 0.2174\n",
      "Epoch 1698/2000, Train Loss: 0.0033, Test Loss: 0.2154\n",
      "Epoch 1699/2000, Train Loss: 0.0033, Test Loss: 0.2160\n",
      "Epoch 1700/2000, Train Loss: 0.0033, Test Loss: 0.2204\n",
      "Epoch 1701/2000, Train Loss: 0.0033, Test Loss: 0.2176\n",
      "Epoch 1702/2000, Train Loss: 0.0033, Test Loss: 0.2210\n",
      "Epoch 1703/2000, Train Loss: 0.0033, Test Loss: 0.2179\n",
      "Epoch 1704/2000, Train Loss: 0.0033, Test Loss: 0.2159\n",
      "Epoch 1705/2000, Train Loss: 0.0033, Test Loss: 0.2175\n",
      "Epoch 1706/2000, Train Loss: 0.0033, Test Loss: 0.2193\n",
      "Epoch 1707/2000, Train Loss: 0.0033, Test Loss: 0.2157\n",
      "Epoch 1708/2000, Train Loss: 0.0033, Test Loss: 0.2175\n",
      "Epoch 1709/2000, Train Loss: 0.0033, Test Loss: 0.2155\n",
      "Epoch 1710/2000, Train Loss: 0.0033, Test Loss: 0.2150\n",
      "Epoch 1711/2000, Train Loss: 0.0033, Test Loss: 0.2169\n",
      "Epoch 1712/2000, Train Loss: 0.0033, Test Loss: 0.2155\n",
      "Epoch 1713/2000, Train Loss: 0.0033, Test Loss: 0.2153\n",
      "Epoch 1714/2000, Train Loss: 0.0033, Test Loss: 0.2153\n",
      "Epoch 1715/2000, Train Loss: 0.0033, Test Loss: 0.2157\n",
      "Epoch 1716/2000, Train Loss: 0.0033, Test Loss: 0.2188\n",
      "Epoch 1717/2000, Train Loss: 0.0033, Test Loss: 0.2156\n",
      "Epoch 1718/2000, Train Loss: 0.0033, Test Loss: 0.2159\n",
      "Epoch 1719/2000, Train Loss: 0.0032, Test Loss: 0.2156\n",
      "Epoch 1720/2000, Train Loss: 0.0032, Test Loss: 0.2157\n",
      "Epoch 1721/2000, Train Loss: 0.0032, Test Loss: 0.2177\n",
      "Epoch 1722/2000, Train Loss: 0.0032, Test Loss: 0.2239\n",
      "Epoch 1723/2000, Train Loss: 0.0032, Test Loss: 0.2231\n",
      "Epoch 1724/2000, Train Loss: 0.0032, Test Loss: 0.2201\n",
      "Epoch 1725/2000, Train Loss: 0.0032, Test Loss: 0.2156\n",
      "Epoch 1726/2000, Train Loss: 0.0032, Test Loss: 0.2162\n",
      "Epoch 1727/2000, Train Loss: 0.0032, Test Loss: 0.2160\n",
      "Epoch 1728/2000, Train Loss: 0.0032, Test Loss: 0.2194\n",
      "Epoch 1729/2000, Train Loss: 0.0032, Test Loss: 0.2156\n",
      "Epoch 1730/2000, Train Loss: 0.0032, Test Loss: 0.2184\n",
      "Epoch 1731/2000, Train Loss: 0.0032, Test Loss: 0.2158\n",
      "Epoch 1732/2000, Train Loss: 0.0032, Test Loss: 0.2197\n",
      "Epoch 1733/2000, Train Loss: 0.0032, Test Loss: 0.2159\n",
      "Epoch 1734/2000, Train Loss: 0.0032, Test Loss: 0.2164\n",
      "Epoch 1735/2000, Train Loss: 0.0032, Test Loss: 0.2159\n",
      "Epoch 1736/2000, Train Loss: 0.0032, Test Loss: 0.2218\n",
      "Epoch 1737/2000, Train Loss: 0.0032, Test Loss: 0.2205\n",
      "Epoch 1738/2000, Train Loss: 0.0032, Test Loss: 0.2174\n",
      "Epoch 1739/2000, Train Loss: 0.0032, Test Loss: 0.2160\n",
      "Epoch 1740/2000, Train Loss: 0.0032, Test Loss: 0.2186\n",
      "Epoch 1741/2000, Train Loss: 0.0032, Test Loss: 0.2202\n",
      "Epoch 1742/2000, Train Loss: 0.0032, Test Loss: 0.2190\n",
      "Epoch 1743/2000, Train Loss: 0.0032, Test Loss: 0.2199\n",
      "Epoch 1744/2000, Train Loss: 0.0032, Test Loss: 0.2162\n",
      "Epoch 1745/2000, Train Loss: 0.0032, Test Loss: 0.2159\n",
      "Epoch 1746/2000, Train Loss: 0.0032, Test Loss: 0.2159\n",
      "Epoch 1747/2000, Train Loss: 0.0032, Test Loss: 0.2240\n",
      "Epoch 1748/2000, Train Loss: 0.0032, Test Loss: 0.2169\n",
      "Epoch 1749/2000, Train Loss: 0.0032, Test Loss: 0.2217\n",
      "Epoch 1750/2000, Train Loss: 0.0032, Test Loss: 0.2159\n",
      "Epoch 1751/2000, Train Loss: 0.0032, Test Loss: 0.2164\n",
      "Epoch 1752/2000, Train Loss: 0.0032, Test Loss: 0.2161\n",
      "Epoch 1753/2000, Train Loss: 0.0032, Test Loss: 0.2182\n",
      "Epoch 1754/2000, Train Loss: 0.0032, Test Loss: 0.2212\n",
      "Epoch 1755/2000, Train Loss: 0.0032, Test Loss: 0.2368\n",
      "Epoch 1756/2000, Train Loss: 0.0032, Test Loss: 0.2269\n",
      "Epoch 1757/2000, Train Loss: 0.0032, Test Loss: 0.2169\n",
      "Epoch 1758/2000, Train Loss: 0.0032, Test Loss: 0.2168\n",
      "Epoch 1759/2000, Train Loss: 0.0032, Test Loss: 0.2166\n",
      "Epoch 1760/2000, Train Loss: 0.0032, Test Loss: 0.2163\n",
      "Epoch 1761/2000, Train Loss: 0.0032, Test Loss: 0.2223\n",
      "Epoch 1762/2000, Train Loss: 0.0032, Test Loss: 0.2192\n",
      "Epoch 1763/2000, Train Loss: 0.0032, Test Loss: 0.2167\n",
      "Epoch 1764/2000, Train Loss: 0.0032, Test Loss: 0.2166\n",
      "Epoch 1765/2000, Train Loss: 0.0032, Test Loss: 0.2211\n",
      "Epoch 1766/2000, Train Loss: 0.0032, Test Loss: 0.2329\n",
      "Epoch 1767/2000, Train Loss: 0.0032, Test Loss: 0.2166\n",
      "Epoch 1768/2000, Train Loss: 0.0032, Test Loss: 0.2167\n",
      "Epoch 1769/2000, Train Loss: 0.0032, Test Loss: 0.2265\n",
      "Epoch 1770/2000, Train Loss: 0.0032, Test Loss: 0.2167\n",
      "Epoch 1771/2000, Train Loss: 0.0032, Test Loss: 0.2249\n",
      "Epoch 1772/2000, Train Loss: 0.0032, Test Loss: 0.2160\n",
      "Epoch 1773/2000, Train Loss: 0.0032, Test Loss: 0.2169\n",
      "Epoch 1774/2000, Train Loss: 0.0032, Test Loss: 0.2165\n",
      "Epoch 1775/2000, Train Loss: 0.0032, Test Loss: 0.2299\n",
      "Epoch 1776/2000, Train Loss: 0.0032, Test Loss: 0.2214\n",
      "Epoch 1777/2000, Train Loss: 0.0031, Test Loss: 0.2167\n",
      "Epoch 1778/2000, Train Loss: 0.0031, Test Loss: 0.2228\n",
      "Epoch 1779/2000, Train Loss: 0.0031, Test Loss: 0.2170\n",
      "Epoch 1780/2000, Train Loss: 0.0031, Test Loss: 0.2169\n",
      "Epoch 1781/2000, Train Loss: 0.0031, Test Loss: 0.2172\n",
      "Epoch 1782/2000, Train Loss: 0.0031, Test Loss: 0.2168\n",
      "Epoch 1783/2000, Train Loss: 0.0031, Test Loss: 0.2206\n",
      "Epoch 1784/2000, Train Loss: 0.0031, Test Loss: 0.2186\n",
      "Epoch 1785/2000, Train Loss: 0.0031, Test Loss: 0.2168\n",
      "Epoch 1786/2000, Train Loss: 0.0031, Test Loss: 0.2204\n",
      "Epoch 1787/2000, Train Loss: 0.0031, Test Loss: 0.2174\n",
      "Epoch 1788/2000, Train Loss: 0.0031, Test Loss: 0.2223\n",
      "Epoch 1789/2000, Train Loss: 0.0031, Test Loss: 0.2171\n",
      "Epoch 1790/2000, Train Loss: 0.0031, Test Loss: 0.2166\n",
      "Epoch 1791/2000, Train Loss: 0.0031, Test Loss: 0.2175\n",
      "Epoch 1792/2000, Train Loss: 0.0031, Test Loss: 0.2174\n",
      "Epoch 1793/2000, Train Loss: 0.0031, Test Loss: 0.2174\n",
      "Epoch 1794/2000, Train Loss: 0.0031, Test Loss: 0.2219\n",
      "Epoch 1795/2000, Train Loss: 0.0031, Test Loss: 0.2190\n",
      "Epoch 1796/2000, Train Loss: 0.0031, Test Loss: 0.2173\n",
      "Epoch 1797/2000, Train Loss: 0.0031, Test Loss: 0.2238\n",
      "Epoch 1798/2000, Train Loss: 0.0031, Test Loss: 0.2175\n",
      "Epoch 1799/2000, Train Loss: 0.0031, Test Loss: 0.2215\n",
      "Epoch 1800/2000, Train Loss: 0.0031, Test Loss: 0.2195\n",
      "Epoch 1801/2000, Train Loss: 0.0031, Test Loss: 0.2235\n",
      "Epoch 1802/2000, Train Loss: 0.0031, Test Loss: 0.2208\n",
      "Epoch 1803/2000, Train Loss: 0.0031, Test Loss: 0.2170\n",
      "Epoch 1804/2000, Train Loss: 0.0031, Test Loss: 0.2209\n",
      "Epoch 1805/2000, Train Loss: 0.0031, Test Loss: 0.2176\n",
      "Epoch 1806/2000, Train Loss: 0.0031, Test Loss: 0.2172\n",
      "Epoch 1807/2000, Train Loss: 0.0031, Test Loss: 0.2186\n",
      "Epoch 1808/2000, Train Loss: 0.0031, Test Loss: 0.2175\n",
      "Epoch 1809/2000, Train Loss: 0.0031, Test Loss: 0.2178\n",
      "Epoch 1810/2000, Train Loss: 0.0031, Test Loss: 0.2173\n",
      "Epoch 1811/2000, Train Loss: 0.0031, Test Loss: 0.2173\n",
      "Epoch 1812/2000, Train Loss: 0.0031, Test Loss: 0.2170\n",
      "Epoch 1813/2000, Train Loss: 0.0031, Test Loss: 0.2175\n",
      "Epoch 1814/2000, Train Loss: 0.0031, Test Loss: 0.2237\n",
      "Epoch 1815/2000, Train Loss: 0.0031, Test Loss: 0.2268\n",
      "Epoch 1816/2000, Train Loss: 0.0031, Test Loss: 0.2242\n",
      "Epoch 1817/2000, Train Loss: 0.0031, Test Loss: 0.2176\n",
      "Epoch 1818/2000, Train Loss: 0.0031, Test Loss: 0.2182\n",
      "Epoch 1819/2000, Train Loss: 0.0031, Test Loss: 0.2180\n",
      "Epoch 1820/2000, Train Loss: 0.0031, Test Loss: 0.2175\n",
      "Epoch 1821/2000, Train Loss: 0.0031, Test Loss: 0.2215\n",
      "Epoch 1822/2000, Train Loss: 0.0031, Test Loss: 0.2175\n",
      "Epoch 1823/2000, Train Loss: 0.0031, Test Loss: 0.2328\n",
      "Epoch 1824/2000, Train Loss: 0.0031, Test Loss: 0.2192\n",
      "Epoch 1825/2000, Train Loss: 0.0031, Test Loss: 0.2265\n",
      "Epoch 1826/2000, Train Loss: 0.0031, Test Loss: 0.2180\n",
      "Epoch 1827/2000, Train Loss: 0.0031, Test Loss: 0.2313\n",
      "Epoch 1828/2000, Train Loss: 0.0031, Test Loss: 0.2181\n",
      "Epoch 1829/2000, Train Loss: 0.0031, Test Loss: 0.2210\n",
      "Epoch 1830/2000, Train Loss: 0.0031, Test Loss: 0.2183\n",
      "Epoch 1831/2000, Train Loss: 0.0031, Test Loss: 0.2178\n",
      "Epoch 1832/2000, Train Loss: 0.0031, Test Loss: 0.2185\n",
      "Epoch 1833/2000, Train Loss: 0.0031, Test Loss: 0.2198\n",
      "Epoch 1834/2000, Train Loss: 0.0031, Test Loss: 0.2188\n",
      "Epoch 1835/2000, Train Loss: 0.0031, Test Loss: 0.2232\n",
      "Epoch 1836/2000, Train Loss: 0.0031, Test Loss: 0.2275\n",
      "Epoch 1837/2000, Train Loss: 0.0031, Test Loss: 0.2223\n",
      "Epoch 1838/2000, Train Loss: 0.0030, Test Loss: 0.2210\n",
      "Epoch 1839/2000, Train Loss: 0.0031, Test Loss: 0.2226\n",
      "Epoch 1840/2000, Train Loss: 0.0030, Test Loss: 0.2225\n",
      "Epoch 1841/2000, Train Loss: 0.0031, Test Loss: 0.2211\n",
      "Epoch 1842/2000, Train Loss: 0.0030, Test Loss: 0.2181\n",
      "Epoch 1843/2000, Train Loss: 0.0030, Test Loss: 0.2179\n",
      "Epoch 1844/2000, Train Loss: 0.0031, Test Loss: 0.2193\n",
      "Epoch 1845/2000, Train Loss: 0.0030, Test Loss: 0.2217\n",
      "Epoch 1846/2000, Train Loss: 0.0030, Test Loss: 0.2201\n",
      "Epoch 1847/2000, Train Loss: 0.0030, Test Loss: 0.2190\n",
      "Epoch 1848/2000, Train Loss: 0.0030, Test Loss: 0.2184\n",
      "Epoch 1849/2000, Train Loss: 0.0030, Test Loss: 0.2211\n",
      "Epoch 1850/2000, Train Loss: 0.0030, Test Loss: 0.2290\n",
      "Epoch 1851/2000, Train Loss: 0.0030, Test Loss: 0.2183\n",
      "Epoch 1852/2000, Train Loss: 0.0030, Test Loss: 0.2182\n",
      "Epoch 1853/2000, Train Loss: 0.0030, Test Loss: 0.2183\n",
      "Epoch 1854/2000, Train Loss: 0.0030, Test Loss: 0.2183\n",
      "Epoch 1855/2000, Train Loss: 0.0030, Test Loss: 0.2201\n",
      "Epoch 1856/2000, Train Loss: 0.0030, Test Loss: 0.2187\n",
      "Epoch 1857/2000, Train Loss: 0.0030, Test Loss: 0.2182\n",
      "Epoch 1858/2000, Train Loss: 0.0030, Test Loss: 0.2272\n",
      "Epoch 1859/2000, Train Loss: 0.0030, Test Loss: 0.2236\n",
      "Epoch 1860/2000, Train Loss: 0.0030, Test Loss: 0.2251\n",
      "Epoch 1861/2000, Train Loss: 0.0030, Test Loss: 0.2181\n",
      "Epoch 1862/2000, Train Loss: 0.0030, Test Loss: 0.2188\n",
      "Epoch 1863/2000, Train Loss: 0.0030, Test Loss: 0.2246\n",
      "Epoch 1864/2000, Train Loss: 0.0030, Test Loss: 0.2296\n",
      "Epoch 1865/2000, Train Loss: 0.0030, Test Loss: 0.2203\n",
      "Epoch 1866/2000, Train Loss: 0.0030, Test Loss: 0.2192\n",
      "Epoch 1867/2000, Train Loss: 0.0030, Test Loss: 0.2185\n",
      "Epoch 1868/2000, Train Loss: 0.0030, Test Loss: 0.2204\n",
      "Epoch 1869/2000, Train Loss: 0.0030, Test Loss: 0.2186\n",
      "Epoch 1870/2000, Train Loss: 0.0030, Test Loss: 0.2258\n",
      "Epoch 1871/2000, Train Loss: 0.0030, Test Loss: 0.2186\n",
      "Epoch 1872/2000, Train Loss: 0.0030, Test Loss: 0.2207\n",
      "Epoch 1873/2000, Train Loss: 0.0030, Test Loss: 0.2234\n",
      "Epoch 1874/2000, Train Loss: 0.0030, Test Loss: 0.2187\n",
      "Epoch 1875/2000, Train Loss: 0.0030, Test Loss: 0.2188\n",
      "Epoch 1876/2000, Train Loss: 0.0030, Test Loss: 0.2190\n",
      "Epoch 1877/2000, Train Loss: 0.0030, Test Loss: 0.2225\n",
      "Epoch 1878/2000, Train Loss: 0.0030, Test Loss: 0.2244\n",
      "Epoch 1879/2000, Train Loss: 0.0030, Test Loss: 0.2265\n",
      "Epoch 1880/2000, Train Loss: 0.0030, Test Loss: 0.2223\n",
      "Epoch 1881/2000, Train Loss: 0.0030, Test Loss: 0.2220\n",
      "Epoch 1882/2000, Train Loss: 0.0030, Test Loss: 0.2205\n",
      "Epoch 1883/2000, Train Loss: 0.0030, Test Loss: 0.2194\n",
      "Epoch 1884/2000, Train Loss: 0.0030, Test Loss: 0.2189\n",
      "Epoch 1885/2000, Train Loss: 0.0030, Test Loss: 0.2232\n",
      "Epoch 1886/2000, Train Loss: 0.0030, Test Loss: 0.2245\n",
      "Epoch 1887/2000, Train Loss: 0.0030, Test Loss: 0.2195\n",
      "Epoch 1888/2000, Train Loss: 0.0030, Test Loss: 0.2215\n",
      "Epoch 1889/2000, Train Loss: 0.0030, Test Loss: 0.2196\n",
      "Epoch 1890/2000, Train Loss: 0.0030, Test Loss: 0.2214\n",
      "Epoch 1891/2000, Train Loss: 0.0030, Test Loss: 0.2190\n",
      "Epoch 1892/2000, Train Loss: 0.0030, Test Loss: 0.2189\n",
      "Epoch 1893/2000, Train Loss: 0.0030, Test Loss: 0.2220\n",
      "Epoch 1894/2000, Train Loss: 0.0030, Test Loss: 0.2201\n",
      "Epoch 1895/2000, Train Loss: 0.0030, Test Loss: 0.2193\n",
      "Epoch 1896/2000, Train Loss: 0.0030, Test Loss: 0.2215\n",
      "Epoch 1897/2000, Train Loss: 0.0030, Test Loss: 0.2190\n",
      "Epoch 1898/2000, Train Loss: 0.0030, Test Loss: 0.2206\n",
      "Epoch 1899/2000, Train Loss: 0.0030, Test Loss: 0.2192\n",
      "Epoch 1900/2000, Train Loss: 0.0030, Test Loss: 0.2255\n",
      "Epoch 1901/2000, Train Loss: 0.0030, Test Loss: 0.2221\n",
      "Epoch 1902/2000, Train Loss: 0.0030, Test Loss: 0.2196\n",
      "Epoch 1903/2000, Train Loss: 0.0030, Test Loss: 0.2254\n",
      "Epoch 1904/2000, Train Loss: 0.0030, Test Loss: 0.2210\n",
      "Epoch 1905/2000, Train Loss: 0.0030, Test Loss: 0.2193\n",
      "Epoch 1906/2000, Train Loss: 0.0030, Test Loss: 0.2241\n",
      "Epoch 1907/2000, Train Loss: 0.0030, Test Loss: 0.2194\n",
      "Epoch 1908/2000, Train Loss: 0.0029, Test Loss: 0.2257\n",
      "Epoch 1909/2000, Train Loss: 0.0030, Test Loss: 0.2308\n",
      "Epoch 1910/2000, Train Loss: 0.0030, Test Loss: 0.2237\n",
      "Epoch 1911/2000, Train Loss: 0.0030, Test Loss: 0.2192\n",
      "Epoch 1912/2000, Train Loss: 0.0030, Test Loss: 0.2229\n",
      "Epoch 1913/2000, Train Loss: 0.0030, Test Loss: 0.2198\n",
      "Epoch 1914/2000, Train Loss: 0.0030, Test Loss: 0.2194\n",
      "Epoch 1915/2000, Train Loss: 0.0029, Test Loss: 0.2194\n",
      "Epoch 1916/2000, Train Loss: 0.0029, Test Loss: 0.2195\n",
      "Epoch 1917/2000, Train Loss: 0.0029, Test Loss: 0.2250\n",
      "Epoch 1918/2000, Train Loss: 0.0029, Test Loss: 0.2194\n",
      "Epoch 1919/2000, Train Loss: 0.0029, Test Loss: 0.2283\n",
      "Epoch 1920/2000, Train Loss: 0.0029, Test Loss: 0.2198\n",
      "Epoch 1921/2000, Train Loss: 0.0029, Test Loss: 0.2197\n",
      "Epoch 1922/2000, Train Loss: 0.0029, Test Loss: 0.2221\n",
      "Epoch 1923/2000, Train Loss: 0.0029, Test Loss: 0.2197\n",
      "Epoch 1924/2000, Train Loss: 0.0029, Test Loss: 0.2204\n",
      "Epoch 1925/2000, Train Loss: 0.0029, Test Loss: 0.2242\n",
      "Epoch 1926/2000, Train Loss: 0.0029, Test Loss: 0.2208\n",
      "Epoch 1927/2000, Train Loss: 0.0029, Test Loss: 0.2201\n",
      "Epoch 1928/2000, Train Loss: 0.0029, Test Loss: 0.2201\n",
      "Epoch 1929/2000, Train Loss: 0.0029, Test Loss: 0.2197\n",
      "Epoch 1930/2000, Train Loss: 0.0029, Test Loss: 0.2198\n",
      "Epoch 1931/2000, Train Loss: 0.0029, Test Loss: 0.2201\n",
      "Epoch 1932/2000, Train Loss: 0.0029, Test Loss: 0.2201\n",
      "Epoch 1933/2000, Train Loss: 0.0029, Test Loss: 0.2265\n",
      "Epoch 1934/2000, Train Loss: 0.0029, Test Loss: 0.2221\n",
      "Epoch 1935/2000, Train Loss: 0.0029, Test Loss: 0.2200\n",
      "Epoch 1936/2000, Train Loss: 0.0029, Test Loss: 0.2197\n",
      "Epoch 1937/2000, Train Loss: 0.0029, Test Loss: 0.2205\n",
      "Epoch 1938/2000, Train Loss: 0.0029, Test Loss: 0.2224\n",
      "Epoch 1939/2000, Train Loss: 0.0029, Test Loss: 0.2201\n",
      "Epoch 1940/2000, Train Loss: 0.0029, Test Loss: 0.2199\n",
      "Epoch 1941/2000, Train Loss: 0.0029, Test Loss: 0.2245\n",
      "Epoch 1942/2000, Train Loss: 0.0029, Test Loss: 0.2209\n",
      "Epoch 1943/2000, Train Loss: 0.0029, Test Loss: 0.2444\n",
      "Epoch 1944/2000, Train Loss: 0.0029, Test Loss: 0.2204\n",
      "Epoch 1945/2000, Train Loss: 0.0029, Test Loss: 0.2202\n",
      "Epoch 1946/2000, Train Loss: 0.0029, Test Loss: 0.2202\n",
      "Epoch 1947/2000, Train Loss: 0.0029, Test Loss: 0.2209\n",
      "Epoch 1948/2000, Train Loss: 0.0029, Test Loss: 0.2203\n",
      "Epoch 1949/2000, Train Loss: 0.0029, Test Loss: 0.2241\n",
      "Epoch 1950/2000, Train Loss: 0.0029, Test Loss: 0.2275\n",
      "Epoch 1951/2000, Train Loss: 0.0029, Test Loss: 0.2227\n",
      "Epoch 1952/2000, Train Loss: 0.0029, Test Loss: 0.2268\n",
      "Epoch 1953/2000, Train Loss: 0.0029, Test Loss: 0.2206\n",
      "Epoch 1954/2000, Train Loss: 0.0029, Test Loss: 0.2214\n",
      "Epoch 1955/2000, Train Loss: 0.0029, Test Loss: 0.2217\n",
      "Epoch 1956/2000, Train Loss: 0.0029, Test Loss: 0.2201\n",
      "Epoch 1957/2000, Train Loss: 0.0029, Test Loss: 0.2272\n",
      "Epoch 1958/2000, Train Loss: 0.0029, Test Loss: 0.2281\n",
      "Epoch 1959/2000, Train Loss: 0.0029, Test Loss: 0.2204\n",
      "Epoch 1960/2000, Train Loss: 0.0029, Test Loss: 0.2204\n",
      "Epoch 1961/2000, Train Loss: 0.0029, Test Loss: 0.2233\n",
      "Epoch 1962/2000, Train Loss: 0.0029, Test Loss: 0.2206\n",
      "Epoch 1963/2000, Train Loss: 0.0029, Test Loss: 0.2245\n",
      "Epoch 1964/2000, Train Loss: 0.0029, Test Loss: 0.2351\n",
      "Epoch 1965/2000, Train Loss: 0.0029, Test Loss: 0.2208\n",
      "Epoch 1966/2000, Train Loss: 0.0029, Test Loss: 0.2243\n",
      "Epoch 1967/2000, Train Loss: 0.0029, Test Loss: 0.2222\n",
      "Epoch 1968/2000, Train Loss: 0.0029, Test Loss: 0.2241\n",
      "Epoch 1969/2000, Train Loss: 0.0029, Test Loss: 0.2206\n",
      "Epoch 1970/2000, Train Loss: 0.0029, Test Loss: 0.2207\n",
      "Epoch 1971/2000, Train Loss: 0.0029, Test Loss: 0.2204\n",
      "Epoch 1972/2000, Train Loss: 0.0029, Test Loss: 0.2205\n",
      "Epoch 1973/2000, Train Loss: 0.0029, Test Loss: 0.2210\n",
      "Epoch 1974/2000, Train Loss: 0.0029, Test Loss: 0.2208\n",
      "Epoch 1975/2000, Train Loss: 0.0029, Test Loss: 0.2208\n",
      "Epoch 1976/2000, Train Loss: 0.0029, Test Loss: 0.2205\n",
      "Epoch 1977/2000, Train Loss: 0.0029, Test Loss: 0.2215\n",
      "Epoch 1978/2000, Train Loss: 0.0029, Test Loss: 0.2213\n",
      "Epoch 1979/2000, Train Loss: 0.0029, Test Loss: 0.2207\n",
      "Epoch 1980/2000, Train Loss: 0.0029, Test Loss: 0.2211\n",
      "Epoch 1981/2000, Train Loss: 0.0029, Test Loss: 0.2255\n",
      "Epoch 1982/2000, Train Loss: 0.0029, Test Loss: 0.2266\n",
      "Epoch 1983/2000, Train Loss: 0.0029, Test Loss: 0.2329\n",
      "Epoch 1984/2000, Train Loss: 0.0029, Test Loss: 0.2234\n",
      "Epoch 1985/2000, Train Loss: 0.0029, Test Loss: 0.2225\n",
      "Epoch 1986/2000, Train Loss: 0.0029, Test Loss: 0.2208\n",
      "Epoch 1987/2000, Train Loss: 0.0028, Test Loss: 0.2210\n",
      "Epoch 1988/2000, Train Loss: 0.0029, Test Loss: 0.2210\n",
      "Epoch 1989/2000, Train Loss: 0.0028, Test Loss: 0.2216\n",
      "Epoch 1990/2000, Train Loss: 0.0028, Test Loss: 0.2212\n",
      "Epoch 1991/2000, Train Loss: 0.0028, Test Loss: 0.2211\n",
      "Epoch 1992/2000, Train Loss: 0.0028, Test Loss: 0.2245\n",
      "Epoch 1993/2000, Train Loss: 0.0029, Test Loss: 0.2230\n",
      "Epoch 1994/2000, Train Loss: 0.0028, Test Loss: 0.2255\n",
      "Epoch 1995/2000, Train Loss: 0.0028, Test Loss: 0.2210\n",
      "Epoch 1996/2000, Train Loss: 0.0028, Test Loss: 0.2215\n",
      "Epoch 1997/2000, Train Loss: 0.0028, Test Loss: 0.2279\n",
      "Epoch 1998/2000, Train Loss: 0.0028, Test Loss: 0.2278\n",
      "Epoch 1999/2000, Train Loss: 0.0028, Test Loss: 0.2242\n",
      "Epoch 2000/2000, Train Loss: 0.0028, Test Loss: 0.2216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.9591</td></tr><tr><td>accuracy/train</td><td>1.0</td></tr><tr><td>batch_loss</td><td>0.00069</td></tr><tr><td>epoch</td><td>1999</td></tr><tr><td>loss/test</td><td>0.22159</td></tr><tr><td>loss/train</td><td>0.00283</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smart-bee-264</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/0p2h459d' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/0p2h459d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240313_121852-0p2h459d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240313_142136-hw0cpod1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/hw0cpod1' target=\"_blank\">proud-glitter-265</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/hw0cpod1' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/hw0cpod1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Train Loss: 0.5367, Test Loss: 0.2860\n",
      "Epoch 2/2000, Train Loss: 0.2505, Test Loss: 0.2249\n",
      "Epoch 3/2000, Train Loss: 0.2023, Test Loss: 0.1863\n",
      "Epoch 4/2000, Train Loss: 0.1711, Test Loss: 0.1666\n",
      "Epoch 5/2000, Train Loss: 0.1511, Test Loss: 0.1543\n",
      "Epoch 6/2000, Train Loss: 0.1368, Test Loss: 0.1396\n",
      "Epoch 7/2000, Train Loss: 0.1267, Test Loss: 0.1339\n",
      "Epoch 8/2000, Train Loss: 0.1176, Test Loss: 0.1376\n",
      "Epoch 9/2000, Train Loss: 0.1118, Test Loss: 0.1294\n",
      "Epoch 10/2000, Train Loss: 0.1049, Test Loss: 0.1194\n",
      "Epoch 11/2000, Train Loss: 0.0989, Test Loss: 0.1186\n",
      "Epoch 12/2000, Train Loss: 0.0954, Test Loss: 0.1199\n",
      "Epoch 13/2000, Train Loss: 0.0902, Test Loss: 0.1184\n",
      "Epoch 14/2000, Train Loss: 0.0864, Test Loss: 0.1108\n",
      "Epoch 15/2000, Train Loss: 0.0837, Test Loss: 0.1153\n",
      "Epoch 16/2000, Train Loss: 0.0803, Test Loss: 0.1062\n",
      "Epoch 17/2000, Train Loss: 0.0772, Test Loss: 0.1122\n",
      "Epoch 18/2000, Train Loss: 0.0751, Test Loss: 0.1068\n",
      "Epoch 19/2000, Train Loss: 0.0729, Test Loss: 0.1082\n",
      "Epoch 20/2000, Train Loss: 0.0697, Test Loss: 0.1054\n",
      "Epoch 21/2000, Train Loss: 0.0678, Test Loss: 0.1068\n",
      "Epoch 22/2000, Train Loss: 0.0654, Test Loss: 0.1032\n",
      "Epoch 23/2000, Train Loss: 0.0638, Test Loss: 0.1047\n",
      "Epoch 24/2000, Train Loss: 0.0630, Test Loss: 0.1025\n",
      "Epoch 25/2000, Train Loss: 0.0608, Test Loss: 0.1046\n",
      "Epoch 26/2000, Train Loss: 0.0594, Test Loss: 0.1042\n",
      "Epoch 27/2000, Train Loss: 0.0582, Test Loss: 0.1002\n",
      "Epoch 28/2000, Train Loss: 0.0565, Test Loss: 0.1004\n",
      "Epoch 29/2000, Train Loss: 0.0556, Test Loss: 0.1011\n",
      "Epoch 30/2000, Train Loss: 0.0538, Test Loss: 0.1013\n",
      "Epoch 31/2000, Train Loss: 0.0522, Test Loss: 0.1007\n",
      "Epoch 32/2000, Train Loss: 0.0515, Test Loss: 0.0984\n",
      "Epoch 33/2000, Train Loss: 0.0502, Test Loss: 0.0969\n",
      "Epoch 34/2000, Train Loss: 0.0495, Test Loss: 0.1018\n",
      "Epoch 35/2000, Train Loss: 0.0489, Test Loss: 0.1002\n",
      "Epoch 36/2000, Train Loss: 0.0471, Test Loss: 0.0994\n",
      "Epoch 37/2000, Train Loss: 0.0468, Test Loss: 0.0989\n",
      "Epoch 38/2000, Train Loss: 0.0455, Test Loss: 0.0973\n",
      "Epoch 39/2000, Train Loss: 0.0448, Test Loss: 0.1014\n",
      "Epoch 40/2000, Train Loss: 0.0439, Test Loss: 0.0993\n",
      "Epoch 41/2000, Train Loss: 0.0431, Test Loss: 0.0995\n",
      "Epoch 42/2000, Train Loss: 0.0423, Test Loss: 0.0980\n",
      "Epoch 43/2000, Train Loss: 0.0418, Test Loss: 0.1062\n",
      "Epoch 44/2000, Train Loss: 0.0413, Test Loss: 0.0964\n",
      "Epoch 45/2000, Train Loss: 0.0400, Test Loss: 0.1004\n",
      "Epoch 46/2000, Train Loss: 0.0397, Test Loss: 0.0989\n",
      "Epoch 47/2000, Train Loss: 0.0387, Test Loss: 0.0985\n",
      "Epoch 48/2000, Train Loss: 0.0380, Test Loss: 0.0976\n",
      "Epoch 49/2000, Train Loss: 0.0374, Test Loss: 0.0974\n",
      "Epoch 50/2000, Train Loss: 0.0367, Test Loss: 0.1008\n",
      "Epoch 51/2000, Train Loss: 0.0368, Test Loss: 0.0967\n",
      "Epoch 52/2000, Train Loss: 0.0355, Test Loss: 0.1016\n",
      "Epoch 53/2000, Train Loss: 0.0353, Test Loss: 0.0975\n",
      "Epoch 54/2000, Train Loss: 0.0350, Test Loss: 0.0989\n",
      "Epoch 55/2000, Train Loss: 0.0342, Test Loss: 0.0978\n",
      "Epoch 56/2000, Train Loss: 0.0336, Test Loss: 0.0989\n",
      "Epoch 57/2000, Train Loss: 0.0326, Test Loss: 0.0976\n",
      "Epoch 58/2000, Train Loss: 0.0324, Test Loss: 0.0990\n",
      "Epoch 59/2000, Train Loss: 0.0322, Test Loss: 0.0979\n",
      "Epoch 60/2000, Train Loss: 0.0317, Test Loss: 0.0982\n",
      "Epoch 61/2000, Train Loss: 0.0313, Test Loss: 0.0990\n",
      "Epoch 62/2000, Train Loss: 0.0308, Test Loss: 0.1007\n",
      "Epoch 63/2000, Train Loss: 0.0304, Test Loss: 0.1018\n",
      "Epoch 64/2000, Train Loss: 0.0298, Test Loss: 0.1022\n",
      "Epoch 65/2000, Train Loss: 0.0295, Test Loss: 0.0966\n",
      "Epoch 66/2000, Train Loss: 0.0292, Test Loss: 0.0966\n",
      "Epoch 67/2000, Train Loss: 0.0289, Test Loss: 0.0989\n",
      "Epoch 68/2000, Train Loss: 0.0286, Test Loss: 0.0976\n",
      "Epoch 69/2000, Train Loss: 0.0277, Test Loss: 0.0975\n",
      "Epoch 70/2000, Train Loss: 0.0275, Test Loss: 0.0994\n",
      "Epoch 71/2000, Train Loss: 0.0274, Test Loss: 0.0995\n",
      "Epoch 72/2000, Train Loss: 0.0270, Test Loss: 0.0970\n",
      "Epoch 73/2000, Train Loss: 0.0266, Test Loss: 0.1000\n",
      "Epoch 74/2000, Train Loss: 0.0263, Test Loss: 0.1037\n",
      "Epoch 75/2000, Train Loss: 0.0262, Test Loss: 0.0973\n",
      "Epoch 76/2000, Train Loss: 0.0255, Test Loss: 0.0978\n",
      "Epoch 77/2000, Train Loss: 0.0253, Test Loss: 0.0985\n",
      "Epoch 78/2000, Train Loss: 0.0250, Test Loss: 0.0988\n",
      "Epoch 79/2000, Train Loss: 0.0249, Test Loss: 0.0988\n",
      "Epoch 80/2000, Train Loss: 0.0244, Test Loss: 0.0987\n",
      "Epoch 81/2000, Train Loss: 0.0242, Test Loss: 0.0986\n",
      "Epoch 82/2000, Train Loss: 0.0239, Test Loss: 0.1018\n",
      "Epoch 83/2000, Train Loss: 0.0237, Test Loss: 0.1009\n",
      "Epoch 84/2000, Train Loss: 0.0233, Test Loss: 0.0984\n",
      "Epoch 85/2000, Train Loss: 0.0230, Test Loss: 0.0992\n",
      "Epoch 86/2000, Train Loss: 0.0231, Test Loss: 0.1023\n",
      "Epoch 87/2000, Train Loss: 0.0225, Test Loss: 0.0993\n",
      "Epoch 88/2000, Train Loss: 0.0225, Test Loss: 0.1026\n",
      "Epoch 89/2000, Train Loss: 0.0219, Test Loss: 0.1010\n",
      "Epoch 90/2000, Train Loss: 0.0218, Test Loss: 0.1014\n",
      "Epoch 91/2000, Train Loss: 0.0217, Test Loss: 0.0993\n",
      "Epoch 92/2000, Train Loss: 0.0213, Test Loss: 0.1000\n",
      "Epoch 93/2000, Train Loss: 0.0211, Test Loss: 0.1004\n",
      "Epoch 94/2000, Train Loss: 0.0209, Test Loss: 0.0995\n",
      "Epoch 95/2000, Train Loss: 0.0208, Test Loss: 0.0997\n",
      "Epoch 96/2000, Train Loss: 0.0207, Test Loss: 0.1000\n",
      "Epoch 97/2000, Train Loss: 0.0205, Test Loss: 0.1033\n",
      "Epoch 98/2000, Train Loss: 0.0200, Test Loss: 0.0997\n",
      "Epoch 99/2000, Train Loss: 0.0201, Test Loss: 0.0993\n",
      "Epoch 100/2000, Train Loss: 0.0198, Test Loss: 0.1010\n",
      "Epoch 101/2000, Train Loss: 0.0195, Test Loss: 0.1015\n",
      "Epoch 102/2000, Train Loss: 0.0195, Test Loss: 0.1006\n",
      "Epoch 103/2000, Train Loss: 0.0192, Test Loss: 0.1005\n",
      "Epoch 104/2000, Train Loss: 0.0190, Test Loss: 0.1007\n",
      "Epoch 105/2000, Train Loss: 0.0188, Test Loss: 0.1002\n",
      "Epoch 106/2000, Train Loss: 0.0187, Test Loss: 0.1005\n",
      "Epoch 107/2000, Train Loss: 0.0184, Test Loss: 0.1001\n",
      "Epoch 108/2000, Train Loss: 0.0183, Test Loss: 0.1002\n",
      "Epoch 109/2000, Train Loss: 0.0181, Test Loss: 0.1025\n",
      "Epoch 110/2000, Train Loss: 0.0181, Test Loss: 0.1011\n",
      "Epoch 111/2000, Train Loss: 0.0177, Test Loss: 0.1024\n",
      "Epoch 112/2000, Train Loss: 0.0176, Test Loss: 0.1013\n",
      "Epoch 113/2000, Train Loss: 0.0174, Test Loss: 0.1001\n",
      "Epoch 114/2000, Train Loss: 0.0173, Test Loss: 0.1014\n",
      "Epoch 115/2000, Train Loss: 0.0171, Test Loss: 0.1024\n",
      "Epoch 116/2000, Train Loss: 0.0171, Test Loss: 0.1021\n",
      "Epoch 117/2000, Train Loss: 0.0169, Test Loss: 0.1040\n",
      "Epoch 118/2000, Train Loss: 0.0169, Test Loss: 0.1022\n",
      "Epoch 119/2000, Train Loss: 0.0166, Test Loss: 0.1039\n",
      "Epoch 120/2000, Train Loss: 0.0165, Test Loss: 0.1050\n",
      "Epoch 121/2000, Train Loss: 0.0165, Test Loss: 0.1029\n",
      "Epoch 122/2000, Train Loss: 0.0162, Test Loss: 0.1020\n",
      "Epoch 123/2000, Train Loss: 0.0161, Test Loss: 0.1018\n",
      "Epoch 124/2000, Train Loss: 0.0161, Test Loss: 0.1044\n",
      "Epoch 125/2000, Train Loss: 0.0159, Test Loss: 0.1063\n",
      "Epoch 126/2000, Train Loss: 0.0157, Test Loss: 0.1031\n",
      "Epoch 127/2000, Train Loss: 0.0156, Test Loss: 0.1031\n",
      "Epoch 128/2000, Train Loss: 0.0154, Test Loss: 0.1026\n",
      "Epoch 129/2000, Train Loss: 0.0151, Test Loss: 0.1038\n",
      "Epoch 130/2000, Train Loss: 0.0152, Test Loss: 0.1065\n",
      "Epoch 131/2000, Train Loss: 0.0151, Test Loss: 0.1039\n",
      "Epoch 132/2000, Train Loss: 0.0148, Test Loss: 0.1031\n",
      "Epoch 133/2000, Train Loss: 0.0148, Test Loss: 0.1030\n",
      "Epoch 134/2000, Train Loss: 0.0147, Test Loss: 0.1035\n",
      "Epoch 135/2000, Train Loss: 0.0146, Test Loss: 0.1043\n",
      "Epoch 136/2000, Train Loss: 0.0146, Test Loss: 0.1022\n",
      "Epoch 137/2000, Train Loss: 0.0143, Test Loss: 0.1062\n",
      "Epoch 138/2000, Train Loss: 0.0142, Test Loss: 0.1027\n",
      "Epoch 139/2000, Train Loss: 0.0141, Test Loss: 0.1067\n",
      "Epoch 140/2000, Train Loss: 0.0141, Test Loss: 0.1047\n",
      "Epoch 141/2000, Train Loss: 0.0141, Test Loss: 0.1034\n",
      "Epoch 142/2000, Train Loss: 0.0138, Test Loss: 0.1061\n",
      "Epoch 143/2000, Train Loss: 0.0138, Test Loss: 0.1044\n",
      "Epoch 144/2000, Train Loss: 0.0138, Test Loss: 0.1045\n",
      "Epoch 145/2000, Train Loss: 0.0136, Test Loss: 0.1055\n",
      "Epoch 146/2000, Train Loss: 0.0136, Test Loss: 0.1044\n",
      "Epoch 147/2000, Train Loss: 0.0133, Test Loss: 0.1076\n",
      "Epoch 148/2000, Train Loss: 0.0133, Test Loss: 0.1046\n",
      "Epoch 149/2000, Train Loss: 0.0133, Test Loss: 0.1047\n",
      "Epoch 150/2000, Train Loss: 0.0131, Test Loss: 0.1044\n",
      "Epoch 151/2000, Train Loss: 0.0130, Test Loss: 0.1043\n",
      "Epoch 152/2000, Train Loss: 0.0129, Test Loss: 0.1052\n",
      "Epoch 153/2000, Train Loss: 0.0128, Test Loss: 0.1044\n",
      "Epoch 154/2000, Train Loss: 0.0127, Test Loss: 0.1074\n",
      "Epoch 155/2000, Train Loss: 0.0126, Test Loss: 0.1041\n",
      "Epoch 156/2000, Train Loss: 0.0126, Test Loss: 0.1050\n",
      "Epoch 157/2000, Train Loss: 0.0125, Test Loss: 0.1049\n",
      "Epoch 158/2000, Train Loss: 0.0124, Test Loss: 0.1045\n",
      "Epoch 159/2000, Train Loss: 0.0123, Test Loss: 0.1056\n",
      "Epoch 160/2000, Train Loss: 0.0122, Test Loss: 0.1043\n",
      "Epoch 161/2000, Train Loss: 0.0121, Test Loss: 0.1085\n",
      "Epoch 162/2000, Train Loss: 0.0121, Test Loss: 0.1063\n",
      "Epoch 163/2000, Train Loss: 0.0120, Test Loss: 0.1056\n",
      "Epoch 164/2000, Train Loss: 0.0119, Test Loss: 0.1047\n",
      "Epoch 165/2000, Train Loss: 0.0118, Test Loss: 0.1079\n",
      "Epoch 166/2000, Train Loss: 0.0118, Test Loss: 0.1067\n",
      "Epoch 167/2000, Train Loss: 0.0118, Test Loss: 0.1054\n",
      "Epoch 168/2000, Train Loss: 0.0117, Test Loss: 0.1062\n",
      "Epoch 169/2000, Train Loss: 0.0116, Test Loss: 0.1087\n",
      "Epoch 170/2000, Train Loss: 0.0114, Test Loss: 0.1062\n",
      "Epoch 171/2000, Train Loss: 0.0114, Test Loss: 0.1056\n",
      "Epoch 172/2000, Train Loss: 0.0115, Test Loss: 0.1057\n",
      "Epoch 173/2000, Train Loss: 0.0113, Test Loss: 0.1076\n",
      "Epoch 174/2000, Train Loss: 0.0112, Test Loss: 0.1065\n",
      "Epoch 175/2000, Train Loss: 0.0112, Test Loss: 0.1068\n",
      "Epoch 176/2000, Train Loss: 0.0110, Test Loss: 0.1060\n",
      "Epoch 177/2000, Train Loss: 0.0110, Test Loss: 0.1064\n",
      "Epoch 178/2000, Train Loss: 0.0109, Test Loss: 0.1060\n",
      "Epoch 179/2000, Train Loss: 0.0109, Test Loss: 0.1071\n",
      "Epoch 180/2000, Train Loss: 0.0108, Test Loss: 0.1096\n",
      "Epoch 181/2000, Train Loss: 0.0108, Test Loss: 0.1066\n",
      "Epoch 182/2000, Train Loss: 0.0106, Test Loss: 0.1092\n",
      "Epoch 183/2000, Train Loss: 0.0105, Test Loss: 0.1069\n",
      "Epoch 184/2000, Train Loss: 0.0105, Test Loss: 0.1065\n",
      "Epoch 185/2000, Train Loss: 0.0106, Test Loss: 0.1090\n",
      "Epoch 186/2000, Train Loss: 0.0106, Test Loss: 0.1074\n",
      "Epoch 187/2000, Train Loss: 0.0104, Test Loss: 0.1071\n",
      "Epoch 188/2000, Train Loss: 0.0103, Test Loss: 0.1079\n",
      "Epoch 189/2000, Train Loss: 0.0102, Test Loss: 0.1081\n",
      "Epoch 190/2000, Train Loss: 0.0101, Test Loss: 0.1076\n",
      "Epoch 191/2000, Train Loss: 0.0101, Test Loss: 0.1082\n",
      "Epoch 192/2000, Train Loss: 0.0101, Test Loss: 0.1083\n",
      "Epoch 193/2000, Train Loss: 0.0101, Test Loss: 0.1076\n",
      "Epoch 194/2000, Train Loss: 0.0100, Test Loss: 0.1073\n",
      "Epoch 195/2000, Train Loss: 0.0099, Test Loss: 0.1076\n",
      "Epoch 196/2000, Train Loss: 0.0099, Test Loss: 0.1080\n",
      "Epoch 197/2000, Train Loss: 0.0098, Test Loss: 0.1071\n",
      "Epoch 198/2000, Train Loss: 0.0097, Test Loss: 0.1127\n",
      "Epoch 199/2000, Train Loss: 0.0096, Test Loss: 0.1095\n",
      "Epoch 200/2000, Train Loss: 0.0097, Test Loss: 0.1086\n",
      "Epoch 201/2000, Train Loss: 0.0096, Test Loss: 0.1089\n",
      "Epoch 202/2000, Train Loss: 0.0095, Test Loss: 0.1084\n",
      "Epoch 203/2000, Train Loss: 0.0095, Test Loss: 0.1080\n",
      "Epoch 204/2000, Train Loss: 0.0094, Test Loss: 0.1082\n",
      "Epoch 205/2000, Train Loss: 0.0094, Test Loss: 0.1090\n",
      "Epoch 206/2000, Train Loss: 0.0094, Test Loss: 0.1088\n",
      "Epoch 207/2000, Train Loss: 0.0093, Test Loss: 0.1089\n",
      "Epoch 208/2000, Train Loss: 0.0093, Test Loss: 0.1087\n",
      "Epoch 209/2000, Train Loss: 0.0093, Test Loss: 0.1080\n",
      "Epoch 210/2000, Train Loss: 0.0091, Test Loss: 0.1100\n",
      "Epoch 211/2000, Train Loss: 0.0091, Test Loss: 0.1109\n",
      "Epoch 212/2000, Train Loss: 0.0091, Test Loss: 0.1088\n",
      "Epoch 213/2000, Train Loss: 0.0091, Test Loss: 0.1085\n",
      "Epoch 214/2000, Train Loss: 0.0090, Test Loss: 0.1087\n",
      "Epoch 215/2000, Train Loss: 0.0089, Test Loss: 0.1114\n",
      "Epoch 216/2000, Train Loss: 0.0089, Test Loss: 0.1125\n",
      "Epoch 217/2000, Train Loss: 0.0089, Test Loss: 0.1106\n",
      "Epoch 218/2000, Train Loss: 0.0088, Test Loss: 0.1123\n",
      "Epoch 219/2000, Train Loss: 0.0087, Test Loss: 0.1108\n",
      "Epoch 220/2000, Train Loss: 0.0087, Test Loss: 0.1087\n",
      "Epoch 221/2000, Train Loss: 0.0087, Test Loss: 0.1095\n",
      "Epoch 222/2000, Train Loss: 0.0086, Test Loss: 0.1094\n",
      "Epoch 223/2000, Train Loss: 0.0086, Test Loss: 0.1121\n",
      "Epoch 224/2000, Train Loss: 0.0085, Test Loss: 0.1097\n",
      "Epoch 225/2000, Train Loss: 0.0086, Test Loss: 0.1090\n",
      "Epoch 226/2000, Train Loss: 0.0084, Test Loss: 0.1101\n",
      "Epoch 227/2000, Train Loss: 0.0084, Test Loss: 0.1098\n",
      "Epoch 228/2000, Train Loss: 0.0084, Test Loss: 0.1113\n",
      "Epoch 229/2000, Train Loss: 0.0085, Test Loss: 0.1094\n",
      "Epoch 230/2000, Train Loss: 0.0084, Test Loss: 0.1097\n",
      "Epoch 231/2000, Train Loss: 0.0083, Test Loss: 0.1130\n",
      "Epoch 232/2000, Train Loss: 0.0083, Test Loss: 0.1097\n",
      "Epoch 233/2000, Train Loss: 0.0082, Test Loss: 0.1148\n",
      "Epoch 234/2000, Train Loss: 0.0082, Test Loss: 0.1125\n",
      "Epoch 235/2000, Train Loss: 0.0082, Test Loss: 0.1108\n",
      "Epoch 236/2000, Train Loss: 0.0081, Test Loss: 0.1108\n",
      "Epoch 237/2000, Train Loss: 0.0080, Test Loss: 0.1105\n",
      "Epoch 238/2000, Train Loss: 0.0080, Test Loss: 0.1111\n",
      "Epoch 239/2000, Train Loss: 0.0080, Test Loss: 0.1097\n",
      "Epoch 240/2000, Train Loss: 0.0080, Test Loss: 0.1172\n",
      "Epoch 241/2000, Train Loss: 0.0079, Test Loss: 0.1105\n",
      "Epoch 242/2000, Train Loss: 0.0079, Test Loss: 0.1104\n",
      "Epoch 243/2000, Train Loss: 0.0078, Test Loss: 0.1110\n",
      "Epoch 244/2000, Train Loss: 0.0079, Test Loss: 0.1112\n",
      "Epoch 245/2000, Train Loss: 0.0078, Test Loss: 0.1133\n",
      "Epoch 246/2000, Train Loss: 0.0078, Test Loss: 0.1102\n",
      "Epoch 247/2000, Train Loss: 0.0077, Test Loss: 0.1107\n",
      "Epoch 248/2000, Train Loss: 0.0077, Test Loss: 0.1143\n",
      "Epoch 249/2000, Train Loss: 0.0076, Test Loss: 0.1145\n",
      "Epoch 250/2000, Train Loss: 0.0077, Test Loss: 0.1112\n",
      "Epoch 251/2000, Train Loss: 0.0076, Test Loss: 0.1114\n",
      "Epoch 252/2000, Train Loss: 0.0076, Test Loss: 0.1115\n",
      "Epoch 253/2000, Train Loss: 0.0075, Test Loss: 0.1111\n",
      "Epoch 254/2000, Train Loss: 0.0075, Test Loss: 0.1137\n",
      "Epoch 255/2000, Train Loss: 0.0075, Test Loss: 0.1118\n",
      "Epoch 256/2000, Train Loss: 0.0074, Test Loss: 0.1143\n",
      "Epoch 257/2000, Train Loss: 0.0074, Test Loss: 0.1128\n",
      "Epoch 258/2000, Train Loss: 0.0074, Test Loss: 0.1127\n",
      "Epoch 259/2000, Train Loss: 0.0073, Test Loss: 0.1112\n",
      "Epoch 260/2000, Train Loss: 0.0073, Test Loss: 0.1120\n",
      "Epoch 261/2000, Train Loss: 0.0072, Test Loss: 0.1116\n",
      "Epoch 262/2000, Train Loss: 0.0073, Test Loss: 0.1115\n",
      "Epoch 263/2000, Train Loss: 0.0072, Test Loss: 0.1131\n",
      "Epoch 264/2000, Train Loss: 0.0073, Test Loss: 0.1145\n",
      "Epoch 265/2000, Train Loss: 0.0072, Test Loss: 0.1148\n",
      "Epoch 266/2000, Train Loss: 0.0071, Test Loss: 0.1137\n",
      "Epoch 267/2000, Train Loss: 0.0071, Test Loss: 0.1112\n",
      "Epoch 268/2000, Train Loss: 0.0071, Test Loss: 0.1114\n",
      "Epoch 269/2000, Train Loss: 0.0071, Test Loss: 0.1142\n",
      "Epoch 270/2000, Train Loss: 0.0070, Test Loss: 0.1133\n",
      "Epoch 271/2000, Train Loss: 0.0070, Test Loss: 0.1119\n",
      "Epoch 272/2000, Train Loss: 0.0070, Test Loss: 0.1121\n",
      "Epoch 273/2000, Train Loss: 0.0069, Test Loss: 0.1130\n",
      "Epoch 274/2000, Train Loss: 0.0069, Test Loss: 0.1124\n",
      "Epoch 275/2000, Train Loss: 0.0069, Test Loss: 0.1122\n",
      "Epoch 276/2000, Train Loss: 0.0069, Test Loss: 0.1126\n",
      "Epoch 277/2000, Train Loss: 0.0069, Test Loss: 0.1122\n",
      "Epoch 278/2000, Train Loss: 0.0068, Test Loss: 0.1120\n",
      "Epoch 279/2000, Train Loss: 0.0068, Test Loss: 0.1137\n",
      "Epoch 280/2000, Train Loss: 0.0068, Test Loss: 0.1120\n",
      "Epoch 281/2000, Train Loss: 0.0067, Test Loss: 0.1123\n",
      "Epoch 282/2000, Train Loss: 0.0067, Test Loss: 0.1141\n",
      "Epoch 283/2000, Train Loss: 0.0067, Test Loss: 0.1137\n",
      "Epoch 284/2000, Train Loss: 0.0067, Test Loss: 0.1136\n",
      "Epoch 285/2000, Train Loss: 0.0067, Test Loss: 0.1129\n",
      "Epoch 286/2000, Train Loss: 0.0066, Test Loss: 0.1132\n",
      "Epoch 287/2000, Train Loss: 0.0066, Test Loss: 0.1128\n",
      "Epoch 288/2000, Train Loss: 0.0066, Test Loss: 0.1128\n",
      "Epoch 289/2000, Train Loss: 0.0065, Test Loss: 0.1132\n",
      "Epoch 290/2000, Train Loss: 0.0065, Test Loss: 0.1139\n",
      "Epoch 291/2000, Train Loss: 0.0065, Test Loss: 0.1136\n",
      "Epoch 292/2000, Train Loss: 0.0065, Test Loss: 0.1130\n",
      "Epoch 293/2000, Train Loss: 0.0065, Test Loss: 0.1139\n",
      "Epoch 294/2000, Train Loss: 0.0065, Test Loss: 0.1160\n",
      "Epoch 295/2000, Train Loss: 0.0064, Test Loss: 0.1141\n",
      "Epoch 296/2000, Train Loss: 0.0064, Test Loss: 0.1156\n",
      "Epoch 297/2000, Train Loss: 0.0064, Test Loss: 0.1129\n",
      "Epoch 298/2000, Train Loss: 0.0063, Test Loss: 0.1127\n",
      "Epoch 299/2000, Train Loss: 0.0063, Test Loss: 0.1138\n",
      "Epoch 300/2000, Train Loss: 0.0063, Test Loss: 0.1157\n",
      "Epoch 301/2000, Train Loss: 0.0063, Test Loss: 0.1138\n",
      "Epoch 302/2000, Train Loss: 0.0063, Test Loss: 0.1152\n",
      "Epoch 303/2000, Train Loss: 0.0062, Test Loss: 0.1134\n",
      "Epoch 304/2000, Train Loss: 0.0062, Test Loss: 0.1180\n",
      "Epoch 305/2000, Train Loss: 0.0062, Test Loss: 0.1153\n",
      "Epoch 306/2000, Train Loss: 0.0062, Test Loss: 0.1175\n",
      "Epoch 307/2000, Train Loss: 0.0062, Test Loss: 0.1182\n",
      "Epoch 308/2000, Train Loss: 0.0061, Test Loss: 0.1140\n",
      "Epoch 309/2000, Train Loss: 0.0061, Test Loss: 0.1148\n",
      "Epoch 310/2000, Train Loss: 0.0061, Test Loss: 0.1147\n",
      "Epoch 311/2000, Train Loss: 0.0061, Test Loss: 0.1141\n",
      "Epoch 312/2000, Train Loss: 0.0061, Test Loss: 0.1140\n",
      "Epoch 313/2000, Train Loss: 0.0060, Test Loss: 0.1154\n",
      "Epoch 314/2000, Train Loss: 0.0060, Test Loss: 0.1143\n",
      "Epoch 315/2000, Train Loss: 0.0060, Test Loss: 0.1137\n",
      "Epoch 316/2000, Train Loss: 0.0060, Test Loss: 0.1150\n",
      "Epoch 317/2000, Train Loss: 0.0060, Test Loss: 0.1138\n",
      "Epoch 318/2000, Train Loss: 0.0059, Test Loss: 0.1143\n",
      "Epoch 319/2000, Train Loss: 0.0059, Test Loss: 0.1173\n",
      "Epoch 320/2000, Train Loss: 0.0059, Test Loss: 0.1170\n",
      "Epoch 321/2000, Train Loss: 0.0058, Test Loss: 0.1144\n",
      "Epoch 322/2000, Train Loss: 0.0059, Test Loss: 0.1146\n",
      "Epoch 323/2000, Train Loss: 0.0058, Test Loss: 0.1154\n",
      "Epoch 324/2000, Train Loss: 0.0058, Test Loss: 0.1153\n",
      "Epoch 325/2000, Train Loss: 0.0058, Test Loss: 0.1143\n",
      "Epoch 326/2000, Train Loss: 0.0058, Test Loss: 0.1159\n",
      "Epoch 327/2000, Train Loss: 0.0058, Test Loss: 0.1188\n",
      "Epoch 328/2000, Train Loss: 0.0057, Test Loss: 0.1173\n",
      "Epoch 329/2000, Train Loss: 0.0057, Test Loss: 0.1165\n",
      "Epoch 330/2000, Train Loss: 0.0057, Test Loss: 0.1148\n",
      "Epoch 331/2000, Train Loss: 0.0057, Test Loss: 0.1151\n",
      "Epoch 332/2000, Train Loss: 0.0057, Test Loss: 0.1157\n",
      "Epoch 333/2000, Train Loss: 0.0057, Test Loss: 0.1150\n",
      "Epoch 334/2000, Train Loss: 0.0057, Test Loss: 0.1152\n",
      "Epoch 335/2000, Train Loss: 0.0056, Test Loss: 0.1152\n",
      "Epoch 336/2000, Train Loss: 0.0056, Test Loss: 0.1150\n",
      "Epoch 337/2000, Train Loss: 0.0056, Test Loss: 0.1148\n",
      "Epoch 338/2000, Train Loss: 0.0056, Test Loss: 0.1154\n",
      "Epoch 339/2000, Train Loss: 0.0056, Test Loss: 0.1225\n",
      "Epoch 340/2000, Train Loss: 0.0056, Test Loss: 0.1155\n",
      "Epoch 341/2000, Train Loss: 0.0055, Test Loss: 0.1148\n",
      "Epoch 342/2000, Train Loss: 0.0055, Test Loss: 0.1165\n",
      "Epoch 343/2000, Train Loss: 0.0055, Test Loss: 0.1209\n",
      "Epoch 344/2000, Train Loss: 0.0055, Test Loss: 0.1158\n",
      "Epoch 345/2000, Train Loss: 0.0055, Test Loss: 0.1155\n",
      "Epoch 346/2000, Train Loss: 0.0054, Test Loss: 0.1215\n",
      "Epoch 347/2000, Train Loss: 0.0054, Test Loss: 0.1178\n",
      "Epoch 348/2000, Train Loss: 0.0054, Test Loss: 0.1171\n",
      "Epoch 349/2000, Train Loss: 0.0054, Test Loss: 0.1154\n",
      "Epoch 350/2000, Train Loss: 0.0054, Test Loss: 0.1166\n",
      "Epoch 351/2000, Train Loss: 0.0054, Test Loss: 0.1155\n",
      "Epoch 352/2000, Train Loss: 0.0054, Test Loss: 0.1161\n",
      "Epoch 353/2000, Train Loss: 0.0053, Test Loss: 0.1158\n",
      "Epoch 354/2000, Train Loss: 0.0053, Test Loss: 0.1159\n",
      "Epoch 355/2000, Train Loss: 0.0053, Test Loss: 0.1157\n",
      "Epoch 356/2000, Train Loss: 0.0053, Test Loss: 0.1162\n",
      "Epoch 357/2000, Train Loss: 0.0053, Test Loss: 0.1160\n",
      "Epoch 358/2000, Train Loss: 0.0053, Test Loss: 0.1175\n",
      "Epoch 359/2000, Train Loss: 0.0052, Test Loss: 0.1158\n",
      "Epoch 360/2000, Train Loss: 0.0053, Test Loss: 0.1159\n",
      "Epoch 361/2000, Train Loss: 0.0052, Test Loss: 0.1158\n",
      "Epoch 362/2000, Train Loss: 0.0052, Test Loss: 0.1158\n",
      "Epoch 363/2000, Train Loss: 0.0052, Test Loss: 0.1163\n",
      "Epoch 364/2000, Train Loss: 0.0052, Test Loss: 0.1157\n",
      "Epoch 365/2000, Train Loss: 0.0052, Test Loss: 0.1169\n",
      "Epoch 366/2000, Train Loss: 0.0052, Test Loss: 0.1198\n",
      "Epoch 367/2000, Train Loss: 0.0052, Test Loss: 0.1162\n",
      "Epoch 368/2000, Train Loss: 0.0051, Test Loss: 0.1166\n",
      "Epoch 369/2000, Train Loss: 0.0051, Test Loss: 0.1240\n",
      "Epoch 370/2000, Train Loss: 0.0051, Test Loss: 0.1223\n",
      "Epoch 371/2000, Train Loss: 0.0051, Test Loss: 0.1170\n",
      "Epoch 372/2000, Train Loss: 0.0051, Test Loss: 0.1167\n",
      "Epoch 373/2000, Train Loss: 0.0051, Test Loss: 0.1183\n",
      "Epoch 374/2000, Train Loss: 0.0051, Test Loss: 0.1181\n",
      "Epoch 375/2000, Train Loss: 0.0051, Test Loss: 0.1165\n",
      "Epoch 376/2000, Train Loss: 0.0050, Test Loss: 0.1185\n",
      "Epoch 377/2000, Train Loss: 0.0050, Test Loss: 0.1167\n",
      "Epoch 378/2000, Train Loss: 0.0050, Test Loss: 0.1180\n",
      "Epoch 379/2000, Train Loss: 0.0050, Test Loss: 0.1163\n",
      "Epoch 380/2000, Train Loss: 0.0049, Test Loss: 0.1167\n",
      "Epoch 381/2000, Train Loss: 0.0050, Test Loss: 0.1165\n",
      "Epoch 382/2000, Train Loss: 0.0049, Test Loss: 0.1213\n",
      "Epoch 383/2000, Train Loss: 0.0049, Test Loss: 0.1193\n",
      "Epoch 384/2000, Train Loss: 0.0049, Test Loss: 0.1167\n",
      "Epoch 385/2000, Train Loss: 0.0049, Test Loss: 0.1169\n",
      "Epoch 386/2000, Train Loss: 0.0049, Test Loss: 0.1170\n",
      "Epoch 387/2000, Train Loss: 0.0049, Test Loss: 0.1226\n",
      "Epoch 388/2000, Train Loss: 0.0049, Test Loss: 0.1170\n",
      "Epoch 389/2000, Train Loss: 0.0048, Test Loss: 0.1175\n",
      "Epoch 390/2000, Train Loss: 0.0048, Test Loss: 0.1204\n",
      "Epoch 391/2000, Train Loss: 0.0048, Test Loss: 0.1214\n",
      "Epoch 392/2000, Train Loss: 0.0048, Test Loss: 0.1176\n",
      "Epoch 393/2000, Train Loss: 0.0048, Test Loss: 0.1228\n",
      "Epoch 394/2000, Train Loss: 0.0048, Test Loss: 0.1185\n",
      "Epoch 395/2000, Train Loss: 0.0048, Test Loss: 0.1206\n",
      "Epoch 396/2000, Train Loss: 0.0048, Test Loss: 0.1171\n",
      "Epoch 397/2000, Train Loss: 0.0048, Test Loss: 0.1172\n",
      "Epoch 398/2000, Train Loss: 0.0048, Test Loss: 0.1205\n",
      "Epoch 399/2000, Train Loss: 0.0047, Test Loss: 0.1176\n",
      "Epoch 400/2000, Train Loss: 0.0047, Test Loss: 0.1184\n",
      "Epoch 401/2000, Train Loss: 0.0047, Test Loss: 0.1178\n",
      "Epoch 402/2000, Train Loss: 0.0047, Test Loss: 0.1175\n",
      "Epoch 403/2000, Train Loss: 0.0047, Test Loss: 0.1174\n",
      "Epoch 404/2000, Train Loss: 0.0047, Test Loss: 0.1173\n",
      "Epoch 405/2000, Train Loss: 0.0047, Test Loss: 0.1184\n",
      "Epoch 406/2000, Train Loss: 0.0046, Test Loss: 0.1183\n",
      "Epoch 407/2000, Train Loss: 0.0046, Test Loss: 0.1187\n",
      "Epoch 408/2000, Train Loss: 0.0046, Test Loss: 0.1176\n",
      "Epoch 409/2000, Train Loss: 0.0046, Test Loss: 0.1178\n",
      "Epoch 410/2000, Train Loss: 0.0046, Test Loss: 0.1180\n",
      "Epoch 411/2000, Train Loss: 0.0046, Test Loss: 0.1182\n",
      "Epoch 412/2000, Train Loss: 0.0046, Test Loss: 0.1278\n",
      "Epoch 413/2000, Train Loss: 0.0046, Test Loss: 0.1256\n",
      "Epoch 414/2000, Train Loss: 0.0046, Test Loss: 0.1182\n",
      "Epoch 415/2000, Train Loss: 0.0045, Test Loss: 0.1179\n",
      "Epoch 416/2000, Train Loss: 0.0046, Test Loss: 0.1211\n",
      "Epoch 417/2000, Train Loss: 0.0045, Test Loss: 0.1179\n",
      "Epoch 418/2000, Train Loss: 0.0045, Test Loss: 0.1196\n",
      "Epoch 419/2000, Train Loss: 0.0045, Test Loss: 0.1183\n",
      "Epoch 420/2000, Train Loss: 0.0045, Test Loss: 0.1180\n",
      "Epoch 421/2000, Train Loss: 0.0045, Test Loss: 0.1179\n",
      "Epoch 422/2000, Train Loss: 0.0045, Test Loss: 0.1182\n",
      "Epoch 423/2000, Train Loss: 0.0045, Test Loss: 0.1185\n",
      "Epoch 424/2000, Train Loss: 0.0045, Test Loss: 0.1180\n",
      "Epoch 425/2000, Train Loss: 0.0045, Test Loss: 0.1182\n",
      "Epoch 426/2000, Train Loss: 0.0044, Test Loss: 0.1182\n",
      "Epoch 427/2000, Train Loss: 0.0044, Test Loss: 0.1206\n",
      "Epoch 428/2000, Train Loss: 0.0044, Test Loss: 0.1190\n",
      "Epoch 429/2000, Train Loss: 0.0044, Test Loss: 0.1195\n",
      "Epoch 430/2000, Train Loss: 0.0044, Test Loss: 0.1181\n",
      "Epoch 431/2000, Train Loss: 0.0044, Test Loss: 0.1237\n",
      "Epoch 432/2000, Train Loss: 0.0044, Test Loss: 0.1185\n",
      "Epoch 433/2000, Train Loss: 0.0044, Test Loss: 0.1187\n",
      "Epoch 434/2000, Train Loss: 0.0044, Test Loss: 0.1225\n",
      "Epoch 435/2000, Train Loss: 0.0044, Test Loss: 0.1187\n",
      "Epoch 436/2000, Train Loss: 0.0044, Test Loss: 0.1195\n",
      "Epoch 437/2000, Train Loss: 0.0043, Test Loss: 0.1190\n",
      "Epoch 438/2000, Train Loss: 0.0043, Test Loss: 0.1199\n",
      "Epoch 439/2000, Train Loss: 0.0043, Test Loss: 0.1189\n",
      "Epoch 440/2000, Train Loss: 0.0043, Test Loss: 0.1215\n",
      "Epoch 441/2000, Train Loss: 0.0043, Test Loss: 0.1189\n",
      "Epoch 442/2000, Train Loss: 0.0043, Test Loss: 0.1186\n",
      "Epoch 443/2000, Train Loss: 0.0043, Test Loss: 0.1238\n",
      "Epoch 444/2000, Train Loss: 0.0043, Test Loss: 0.1239\n",
      "Epoch 445/2000, Train Loss: 0.0043, Test Loss: 0.1189\n",
      "Epoch 446/2000, Train Loss: 0.0043, Test Loss: 0.1195\n",
      "Epoch 447/2000, Train Loss: 0.0042, Test Loss: 0.1190\n",
      "Epoch 448/2000, Train Loss: 0.0042, Test Loss: 0.1218\n",
      "Epoch 449/2000, Train Loss: 0.0042, Test Loss: 0.1208\n",
      "Epoch 450/2000, Train Loss: 0.0042, Test Loss: 0.1217\n",
      "Epoch 451/2000, Train Loss: 0.0042, Test Loss: 0.1194\n",
      "Epoch 452/2000, Train Loss: 0.0042, Test Loss: 0.1199\n",
      "Epoch 453/2000, Train Loss: 0.0042, Test Loss: 0.1191\n",
      "Epoch 454/2000, Train Loss: 0.0042, Test Loss: 0.1190\n",
      "Epoch 455/2000, Train Loss: 0.0042, Test Loss: 0.1196\n",
      "Epoch 456/2000, Train Loss: 0.0042, Test Loss: 0.1194\n",
      "Epoch 457/2000, Train Loss: 0.0041, Test Loss: 0.1194\n",
      "Epoch 458/2000, Train Loss: 0.0041, Test Loss: 0.1193\n",
      "Epoch 459/2000, Train Loss: 0.0041, Test Loss: 0.1232\n",
      "Epoch 460/2000, Train Loss: 0.0041, Test Loss: 0.1194\n",
      "Epoch 461/2000, Train Loss: 0.0041, Test Loss: 0.1197\n",
      "Epoch 462/2000, Train Loss: 0.0041, Test Loss: 0.1197\n",
      "Epoch 463/2000, Train Loss: 0.0041, Test Loss: 0.1196\n",
      "Epoch 464/2000, Train Loss: 0.0041, Test Loss: 0.1250\n",
      "Epoch 465/2000, Train Loss: 0.0041, Test Loss: 0.1196\n",
      "Epoch 466/2000, Train Loss: 0.0041, Test Loss: 0.1204\n",
      "Epoch 467/2000, Train Loss: 0.0041, Test Loss: 0.1234\n",
      "Epoch 468/2000, Train Loss: 0.0041, Test Loss: 0.1233\n",
      "Epoch 469/2000, Train Loss: 0.0041, Test Loss: 0.1196\n",
      "Epoch 470/2000, Train Loss: 0.0040, Test Loss: 0.1213\n",
      "Epoch 471/2000, Train Loss: 0.0040, Test Loss: 0.1225\n",
      "Epoch 472/2000, Train Loss: 0.0040, Test Loss: 0.1196\n",
      "Epoch 473/2000, Train Loss: 0.0040, Test Loss: 0.1199\n",
      "Epoch 474/2000, Train Loss: 0.0040, Test Loss: 0.1201\n",
      "Epoch 475/2000, Train Loss: 0.0040, Test Loss: 0.1221\n",
      "Epoch 476/2000, Train Loss: 0.0040, Test Loss: 0.1197\n",
      "Epoch 477/2000, Train Loss: 0.0040, Test Loss: 0.1198\n",
      "Epoch 478/2000, Train Loss: 0.0040, Test Loss: 0.1251\n",
      "Epoch 479/2000, Train Loss: 0.0040, Test Loss: 0.1202\n",
      "Epoch 480/2000, Train Loss: 0.0040, Test Loss: 0.1199\n",
      "Epoch 481/2000, Train Loss: 0.0040, Test Loss: 0.1201\n",
      "Epoch 482/2000, Train Loss: 0.0040, Test Loss: 0.1201\n",
      "Epoch 483/2000, Train Loss: 0.0039, Test Loss: 0.1201\n",
      "Epoch 484/2000, Train Loss: 0.0039, Test Loss: 0.1218\n",
      "Epoch 485/2000, Train Loss: 0.0039, Test Loss: 0.1211\n",
      "Epoch 486/2000, Train Loss: 0.0039, Test Loss: 0.1210\n",
      "Epoch 487/2000, Train Loss: 0.0039, Test Loss: 0.1213\n",
      "Epoch 488/2000, Train Loss: 0.0039, Test Loss: 0.1198\n",
      "Epoch 489/2000, Train Loss: 0.0039, Test Loss: 0.1243\n",
      "Epoch 490/2000, Train Loss: 0.0039, Test Loss: 0.1248\n",
      "Epoch 491/2000, Train Loss: 0.0039, Test Loss: 0.1218\n",
      "Epoch 492/2000, Train Loss: 0.0039, Test Loss: 0.1202\n",
      "Epoch 493/2000, Train Loss: 0.0039, Test Loss: 0.1213\n",
      "Epoch 494/2000, Train Loss: 0.0039, Test Loss: 0.1203\n",
      "Epoch 495/2000, Train Loss: 0.0039, Test Loss: 0.1216\n",
      "Epoch 496/2000, Train Loss: 0.0038, Test Loss: 0.1213\n",
      "Epoch 497/2000, Train Loss: 0.0038, Test Loss: 0.1219\n",
      "Epoch 498/2000, Train Loss: 0.0038, Test Loss: 0.1212\n",
      "Epoch 499/2000, Train Loss: 0.0038, Test Loss: 0.1209\n",
      "Epoch 500/2000, Train Loss: 0.0038, Test Loss: 0.1217\n",
      "Epoch 501/2000, Train Loss: 0.0038, Test Loss: 0.1207\n",
      "Epoch 502/2000, Train Loss: 0.0038, Test Loss: 0.1210\n",
      "Epoch 503/2000, Train Loss: 0.0038, Test Loss: 0.1205\n",
      "Epoch 504/2000, Train Loss: 0.0038, Test Loss: 0.1224\n",
      "Epoch 505/2000, Train Loss: 0.0038, Test Loss: 0.1258\n",
      "Epoch 506/2000, Train Loss: 0.0038, Test Loss: 0.1222\n",
      "Epoch 507/2000, Train Loss: 0.0038, Test Loss: 0.1218\n",
      "Epoch 508/2000, Train Loss: 0.0038, Test Loss: 0.1210\n",
      "Epoch 509/2000, Train Loss: 0.0038, Test Loss: 0.1242\n",
      "Epoch 510/2000, Train Loss: 0.0037, Test Loss: 0.1255\n",
      "Epoch 511/2000, Train Loss: 0.0037, Test Loss: 0.1211\n",
      "Epoch 512/2000, Train Loss: 0.0037, Test Loss: 0.1209\n",
      "Epoch 513/2000, Train Loss: 0.0037, Test Loss: 0.1208\n",
      "Epoch 514/2000, Train Loss: 0.0037, Test Loss: 0.1211\n",
      "Epoch 515/2000, Train Loss: 0.0037, Test Loss: 0.1226\n",
      "Epoch 516/2000, Train Loss: 0.0037, Test Loss: 0.1254\n",
      "Epoch 517/2000, Train Loss: 0.0037, Test Loss: 0.1212\n",
      "Epoch 518/2000, Train Loss: 0.0037, Test Loss: 0.1214\n",
      "Epoch 519/2000, Train Loss: 0.0037, Test Loss: 0.1212\n",
      "Epoch 520/2000, Train Loss: 0.0037, Test Loss: 0.1209\n",
      "Epoch 521/2000, Train Loss: 0.0037, Test Loss: 0.1213\n",
      "Epoch 522/2000, Train Loss: 0.0037, Test Loss: 0.1244\n",
      "Epoch 523/2000, Train Loss: 0.0037, Test Loss: 0.1241\n",
      "Epoch 524/2000, Train Loss: 0.0037, Test Loss: 0.1215\n",
      "Epoch 525/2000, Train Loss: 0.0036, Test Loss: 0.1212\n",
      "Epoch 526/2000, Train Loss: 0.0036, Test Loss: 0.1213\n",
      "Epoch 527/2000, Train Loss: 0.0036, Test Loss: 0.1212\n",
      "Epoch 528/2000, Train Loss: 0.0036, Test Loss: 0.1223\n",
      "Epoch 529/2000, Train Loss: 0.0036, Test Loss: 0.1273\n",
      "Epoch 530/2000, Train Loss: 0.0036, Test Loss: 0.1213\n",
      "Epoch 531/2000, Train Loss: 0.0036, Test Loss: 0.1250\n",
      "Epoch 532/2000, Train Loss: 0.0036, Test Loss: 0.1213\n",
      "Epoch 533/2000, Train Loss: 0.0036, Test Loss: 0.1213\n",
      "Epoch 534/2000, Train Loss: 0.0036, Test Loss: 0.1244\n",
      "Epoch 535/2000, Train Loss: 0.0036, Test Loss: 0.1213\n",
      "Epoch 536/2000, Train Loss: 0.0036, Test Loss: 0.1236\n",
      "Epoch 537/2000, Train Loss: 0.0036, Test Loss: 0.1226\n",
      "Epoch 538/2000, Train Loss: 0.0036, Test Loss: 0.1215\n",
      "Epoch 539/2000, Train Loss: 0.0036, Test Loss: 0.1214\n",
      "Epoch 540/2000, Train Loss: 0.0036, Test Loss: 0.1218\n",
      "Epoch 541/2000, Train Loss: 0.0036, Test Loss: 0.1218\n",
      "Epoch 542/2000, Train Loss: 0.0035, Test Loss: 0.1217\n",
      "Epoch 543/2000, Train Loss: 0.0035, Test Loss: 0.1217\n",
      "Epoch 544/2000, Train Loss: 0.0035, Test Loss: 0.1218\n",
      "Epoch 545/2000, Train Loss: 0.0035, Test Loss: 0.1218\n",
      "Epoch 546/2000, Train Loss: 0.0035, Test Loss: 0.1246\n",
      "Epoch 547/2000, Train Loss: 0.0035, Test Loss: 0.1263\n",
      "Epoch 548/2000, Train Loss: 0.0035, Test Loss: 0.1262\n",
      "Epoch 549/2000, Train Loss: 0.0035, Test Loss: 0.1240\n",
      "Epoch 550/2000, Train Loss: 0.0035, Test Loss: 0.1216\n",
      "Epoch 551/2000, Train Loss: 0.0035, Test Loss: 0.1221\n",
      "Epoch 552/2000, Train Loss: 0.0035, Test Loss: 0.1219\n",
      "Epoch 553/2000, Train Loss: 0.0035, Test Loss: 0.1249\n",
      "Epoch 554/2000, Train Loss: 0.0035, Test Loss: 0.1221\n",
      "Epoch 555/2000, Train Loss: 0.0035, Test Loss: 0.1220\n",
      "Epoch 556/2000, Train Loss: 0.0035, Test Loss: 0.1222\n",
      "Epoch 557/2000, Train Loss: 0.0035, Test Loss: 0.1232\n",
      "Epoch 558/2000, Train Loss: 0.0035, Test Loss: 0.1221\n",
      "Epoch 559/2000, Train Loss: 0.0034, Test Loss: 0.1225\n",
      "Epoch 560/2000, Train Loss: 0.0034, Test Loss: 0.1220\n",
      "Epoch 561/2000, Train Loss: 0.0034, Test Loss: 0.1232\n",
      "Epoch 562/2000, Train Loss: 0.0034, Test Loss: 0.1223\n",
      "Epoch 563/2000, Train Loss: 0.0034, Test Loss: 0.1223\n",
      "Epoch 564/2000, Train Loss: 0.0034, Test Loss: 0.1283\n",
      "Epoch 565/2000, Train Loss: 0.0034, Test Loss: 0.1224\n",
      "Epoch 566/2000, Train Loss: 0.0034, Test Loss: 0.1220\n",
      "Epoch 567/2000, Train Loss: 0.0034, Test Loss: 0.1222\n",
      "Epoch 568/2000, Train Loss: 0.0034, Test Loss: 0.1248\n",
      "Epoch 569/2000, Train Loss: 0.0034, Test Loss: 0.1318\n",
      "Epoch 570/2000, Train Loss: 0.0034, Test Loss: 0.1266\n",
      "Epoch 571/2000, Train Loss: 0.0034, Test Loss: 0.1226\n",
      "Epoch 572/2000, Train Loss: 0.0034, Test Loss: 0.1224\n",
      "Epoch 573/2000, Train Loss: 0.0034, Test Loss: 0.1226\n",
      "Epoch 574/2000, Train Loss: 0.0034, Test Loss: 0.1225\n",
      "Epoch 575/2000, Train Loss: 0.0034, Test Loss: 0.1222\n",
      "Epoch 576/2000, Train Loss: 0.0034, Test Loss: 0.1313\n",
      "Epoch 577/2000, Train Loss: 0.0033, Test Loss: 0.1228\n",
      "Epoch 578/2000, Train Loss: 0.0033, Test Loss: 0.1252\n",
      "Epoch 579/2000, Train Loss: 0.0033, Test Loss: 0.1226\n",
      "Epoch 580/2000, Train Loss: 0.0033, Test Loss: 0.1226\n",
      "Epoch 581/2000, Train Loss: 0.0033, Test Loss: 0.1260\n",
      "Epoch 582/2000, Train Loss: 0.0033, Test Loss: 0.1228\n",
      "Epoch 583/2000, Train Loss: 0.0033, Test Loss: 0.1229\n",
      "Epoch 584/2000, Train Loss: 0.0033, Test Loss: 0.1225\n",
      "Epoch 585/2000, Train Loss: 0.0033, Test Loss: 0.1239\n",
      "Epoch 586/2000, Train Loss: 0.0033, Test Loss: 0.1231\n",
      "Epoch 587/2000, Train Loss: 0.0033, Test Loss: 0.1229\n",
      "Epoch 588/2000, Train Loss: 0.0033, Test Loss: 0.1226\n",
      "Epoch 589/2000, Train Loss: 0.0033, Test Loss: 0.1238\n",
      "Epoch 590/2000, Train Loss: 0.0033, Test Loss: 0.1251\n",
      "Epoch 591/2000, Train Loss: 0.0033, Test Loss: 0.1229\n",
      "Epoch 592/2000, Train Loss: 0.0033, Test Loss: 0.1229\n",
      "Epoch 593/2000, Train Loss: 0.0033, Test Loss: 0.1257\n",
      "Epoch 594/2000, Train Loss: 0.0033, Test Loss: 0.1229\n",
      "Epoch 595/2000, Train Loss: 0.0033, Test Loss: 0.1231\n",
      "Epoch 596/2000, Train Loss: 0.0032, Test Loss: 0.1231\n",
      "Epoch 597/2000, Train Loss: 0.0032, Test Loss: 0.1239\n",
      "Epoch 598/2000, Train Loss: 0.0032, Test Loss: 0.1253\n",
      "Epoch 599/2000, Train Loss: 0.0032, Test Loss: 0.1247\n",
      "Epoch 600/2000, Train Loss: 0.0032, Test Loss: 0.1231\n",
      "Epoch 601/2000, Train Loss: 0.0032, Test Loss: 0.1251\n",
      "Epoch 602/2000, Train Loss: 0.0032, Test Loss: 0.1233\n",
      "Epoch 603/2000, Train Loss: 0.0032, Test Loss: 0.1234\n",
      "Epoch 604/2000, Train Loss: 0.0032, Test Loss: 0.1264\n",
      "Epoch 605/2000, Train Loss: 0.0032, Test Loss: 0.1232\n",
      "Epoch 606/2000, Train Loss: 0.0032, Test Loss: 0.1233\n",
      "Epoch 607/2000, Train Loss: 0.0032, Test Loss: 0.1233\n",
      "Epoch 608/2000, Train Loss: 0.0032, Test Loss: 0.1232\n",
      "Epoch 609/2000, Train Loss: 0.0032, Test Loss: 0.1234\n",
      "Epoch 610/2000, Train Loss: 0.0032, Test Loss: 0.1234\n",
      "Epoch 611/2000, Train Loss: 0.0032, Test Loss: 0.1234\n",
      "Epoch 612/2000, Train Loss: 0.0032, Test Loss: 0.1263\n",
      "Epoch 613/2000, Train Loss: 0.0032, Test Loss: 0.1235\n",
      "Epoch 614/2000, Train Loss: 0.0032, Test Loss: 0.1234\n",
      "Epoch 615/2000, Train Loss: 0.0032, Test Loss: 0.1251\n",
      "Epoch 616/2000, Train Loss: 0.0031, Test Loss: 0.1248\n",
      "Epoch 617/2000, Train Loss: 0.0032, Test Loss: 0.1307\n",
      "Epoch 618/2000, Train Loss: 0.0032, Test Loss: 0.1254\n",
      "Epoch 619/2000, Train Loss: 0.0031, Test Loss: 0.1241\n",
      "Epoch 620/2000, Train Loss: 0.0031, Test Loss: 0.1238\n",
      "Epoch 621/2000, Train Loss: 0.0031, Test Loss: 0.1235\n",
      "Epoch 622/2000, Train Loss: 0.0031, Test Loss: 0.1237\n",
      "Epoch 623/2000, Train Loss: 0.0031, Test Loss: 0.1234\n",
      "Epoch 624/2000, Train Loss: 0.0031, Test Loss: 0.1237\n",
      "Epoch 625/2000, Train Loss: 0.0031, Test Loss: 0.1345\n",
      "Epoch 626/2000, Train Loss: 0.0031, Test Loss: 0.1241\n",
      "Epoch 627/2000, Train Loss: 0.0031, Test Loss: 0.1237\n",
      "Epoch 628/2000, Train Loss: 0.0031, Test Loss: 0.1289\n",
      "Epoch 629/2000, Train Loss: 0.0031, Test Loss: 0.1237\n",
      "Epoch 630/2000, Train Loss: 0.0031, Test Loss: 0.1238\n",
      "Epoch 631/2000, Train Loss: 0.0031, Test Loss: 0.1252\n",
      "Epoch 632/2000, Train Loss: 0.0031, Test Loss: 0.1237\n",
      "Epoch 633/2000, Train Loss: 0.0031, Test Loss: 0.1250\n",
      "Epoch 634/2000, Train Loss: 0.0031, Test Loss: 0.1259\n",
      "Epoch 635/2000, Train Loss: 0.0031, Test Loss: 0.1239\n",
      "Epoch 636/2000, Train Loss: 0.0031, Test Loss: 0.1237\n",
      "Epoch 637/2000, Train Loss: 0.0031, Test Loss: 0.1239\n",
      "Epoch 638/2000, Train Loss: 0.0031, Test Loss: 0.1244\n",
      "Epoch 639/2000, Train Loss: 0.0031, Test Loss: 0.1240\n",
      "Epoch 640/2000, Train Loss: 0.0030, Test Loss: 0.1238\n",
      "Epoch 641/2000, Train Loss: 0.0031, Test Loss: 0.1240\n",
      "Epoch 642/2000, Train Loss: 0.0030, Test Loss: 0.1280\n",
      "Epoch 643/2000, Train Loss: 0.0030, Test Loss: 0.1251\n",
      "Epoch 644/2000, Train Loss: 0.0030, Test Loss: 0.1302\n",
      "Epoch 645/2000, Train Loss: 0.0030, Test Loss: 0.1263\n",
      "Epoch 646/2000, Train Loss: 0.0030, Test Loss: 0.1256\n",
      "Epoch 647/2000, Train Loss: 0.0030, Test Loss: 0.1241\n",
      "Epoch 648/2000, Train Loss: 0.0030, Test Loss: 0.1266\n",
      "Epoch 649/2000, Train Loss: 0.0030, Test Loss: 0.1242\n",
      "Epoch 650/2000, Train Loss: 0.0030, Test Loss: 0.1239\n",
      "Epoch 651/2000, Train Loss: 0.0030, Test Loss: 0.1240\n",
      "Epoch 652/2000, Train Loss: 0.0030, Test Loss: 0.1244\n",
      "Epoch 653/2000, Train Loss: 0.0030, Test Loss: 0.1242\n",
      "Epoch 654/2000, Train Loss: 0.0030, Test Loss: 0.1243\n",
      "Epoch 655/2000, Train Loss: 0.0030, Test Loss: 0.1263\n",
      "Epoch 656/2000, Train Loss: 0.0030, Test Loss: 0.1256\n",
      "Epoch 657/2000, Train Loss: 0.0030, Test Loss: 0.1243\n",
      "Epoch 658/2000, Train Loss: 0.0030, Test Loss: 0.1243\n",
      "Epoch 659/2000, Train Loss: 0.0030, Test Loss: 0.1284\n",
      "Epoch 660/2000, Train Loss: 0.0030, Test Loss: 0.1274\n",
      "Epoch 661/2000, Train Loss: 0.0030, Test Loss: 0.1281\n",
      "Epoch 662/2000, Train Loss: 0.0030, Test Loss: 0.1245\n",
      "Epoch 663/2000, Train Loss: 0.0030, Test Loss: 0.1324\n",
      "Epoch 664/2000, Train Loss: 0.0029, Test Loss: 0.1244\n",
      "Epoch 665/2000, Train Loss: 0.0029, Test Loss: 0.1244\n",
      "Epoch 666/2000, Train Loss: 0.0029, Test Loss: 0.1313\n",
      "Epoch 667/2000, Train Loss: 0.0029, Test Loss: 0.1248\n",
      "Epoch 668/2000, Train Loss: 0.0029, Test Loss: 0.1247\n",
      "Epoch 669/2000, Train Loss: 0.0029, Test Loss: 0.1247\n",
      "Epoch 670/2000, Train Loss: 0.0029, Test Loss: 0.1304\n",
      "Epoch 671/2000, Train Loss: 0.0029, Test Loss: 0.1247\n",
      "Epoch 672/2000, Train Loss: 0.0029, Test Loss: 0.1249\n",
      "Epoch 673/2000, Train Loss: 0.0029, Test Loss: 0.1250\n",
      "Epoch 674/2000, Train Loss: 0.0029, Test Loss: 0.1247\n",
      "Epoch 675/2000, Train Loss: 0.0029, Test Loss: 0.1247\n",
      "Epoch 676/2000, Train Loss: 0.0029, Test Loss: 0.1292\n",
      "Epoch 677/2000, Train Loss: 0.0029, Test Loss: 0.1262\n",
      "Epoch 678/2000, Train Loss: 0.0029, Test Loss: 0.1247\n",
      "Epoch 679/2000, Train Loss: 0.0029, Test Loss: 0.1249\n",
      "Epoch 680/2000, Train Loss: 0.0029, Test Loss: 0.1298\n",
      "Epoch 681/2000, Train Loss: 0.0029, Test Loss: 0.1261\n",
      "Epoch 682/2000, Train Loss: 0.0029, Test Loss: 0.1250\n",
      "Epoch 683/2000, Train Loss: 0.0029, Test Loss: 0.1266\n",
      "Epoch 684/2000, Train Loss: 0.0029, Test Loss: 0.1250\n",
      "Epoch 685/2000, Train Loss: 0.0029, Test Loss: 0.1249\n",
      "Epoch 686/2000, Train Loss: 0.0029, Test Loss: 0.1250\n",
      "Epoch 687/2000, Train Loss: 0.0029, Test Loss: 0.1300\n",
      "Epoch 688/2000, Train Loss: 0.0029, Test Loss: 0.1257\n",
      "Epoch 689/2000, Train Loss: 0.0029, Test Loss: 0.1251\n",
      "Epoch 690/2000, Train Loss: 0.0029, Test Loss: 0.1251\n",
      "Epoch 691/2000, Train Loss: 0.0028, Test Loss: 0.1250\n",
      "Epoch 692/2000, Train Loss: 0.0028, Test Loss: 0.1250\n",
      "Epoch 693/2000, Train Loss: 0.0028, Test Loss: 0.1257\n",
      "Epoch 694/2000, Train Loss: 0.0028, Test Loss: 0.1252\n",
      "Epoch 695/2000, Train Loss: 0.0028, Test Loss: 0.1318\n",
      "Epoch 696/2000, Train Loss: 0.0028, Test Loss: 0.1251\n",
      "Epoch 697/2000, Train Loss: 0.0028, Test Loss: 0.1280\n",
      "Epoch 698/2000, Train Loss: 0.0028, Test Loss: 0.1296\n",
      "Epoch 699/2000, Train Loss: 0.0028, Test Loss: 0.1269\n",
      "Epoch 700/2000, Train Loss: 0.0028, Test Loss: 0.1254\n",
      "Epoch 701/2000, Train Loss: 0.0028, Test Loss: 0.1283\n",
      "Epoch 702/2000, Train Loss: 0.0028, Test Loss: 0.1253\n",
      "Epoch 703/2000, Train Loss: 0.0028, Test Loss: 0.1319\n",
      "Epoch 704/2000, Train Loss: 0.0028, Test Loss: 0.1253\n",
      "Epoch 705/2000, Train Loss: 0.0028, Test Loss: 0.1265\n",
      "Epoch 706/2000, Train Loss: 0.0028, Test Loss: 0.1255\n",
      "Epoch 707/2000, Train Loss: 0.0028, Test Loss: 0.1283\n",
      "Epoch 708/2000, Train Loss: 0.0028, Test Loss: 0.1253\n",
      "Epoch 709/2000, Train Loss: 0.0028, Test Loss: 0.1345\n",
      "Epoch 710/2000, Train Loss: 0.0028, Test Loss: 0.1257\n",
      "Epoch 711/2000, Train Loss: 0.0028, Test Loss: 0.1272\n",
      "Epoch 712/2000, Train Loss: 0.0028, Test Loss: 0.1256\n",
      "Epoch 713/2000, Train Loss: 0.0028, Test Loss: 0.1301\n",
      "Epoch 714/2000, Train Loss: 0.0028, Test Loss: 0.1262\n",
      "Epoch 715/2000, Train Loss: 0.0028, Test Loss: 0.1308\n",
      "Epoch 716/2000, Train Loss: 0.0028, Test Loss: 0.1318\n",
      "Epoch 717/2000, Train Loss: 0.0028, Test Loss: 0.1259\n",
      "Epoch 718/2000, Train Loss: 0.0028, Test Loss: 0.1257\n",
      "Epoch 719/2000, Train Loss: 0.0027, Test Loss: 0.1254\n",
      "Epoch 720/2000, Train Loss: 0.0027, Test Loss: 0.1335\n",
      "Epoch 721/2000, Train Loss: 0.0027, Test Loss: 0.1284\n",
      "Epoch 722/2000, Train Loss: 0.0027, Test Loss: 0.1311\n",
      "Epoch 723/2000, Train Loss: 0.0027, Test Loss: 0.1292\n",
      "Epoch 724/2000, Train Loss: 0.0027, Test Loss: 0.1258\n",
      "Epoch 725/2000, Train Loss: 0.0027, Test Loss: 0.1259\n",
      "Epoch 726/2000, Train Loss: 0.0027, Test Loss: 0.1258\n",
      "Epoch 727/2000, Train Loss: 0.0027, Test Loss: 0.1257\n",
      "Epoch 728/2000, Train Loss: 0.0027, Test Loss: 0.1255\n",
      "Epoch 729/2000, Train Loss: 0.0027, Test Loss: 0.1296\n",
      "Epoch 730/2000, Train Loss: 0.0027, Test Loss: 0.1257\n",
      "Epoch 731/2000, Train Loss: 0.0027, Test Loss: 0.1267\n",
      "Epoch 732/2000, Train Loss: 0.0027, Test Loss: 0.1260\n",
      "Epoch 733/2000, Train Loss: 0.0027, Test Loss: 0.1257\n",
      "Epoch 734/2000, Train Loss: 0.0027, Test Loss: 0.1261\n",
      "Epoch 735/2000, Train Loss: 0.0027, Test Loss: 0.1270\n",
      "Epoch 736/2000, Train Loss: 0.0027, Test Loss: 0.1260\n",
      "Epoch 737/2000, Train Loss: 0.0027, Test Loss: 0.1259\n",
      "Epoch 738/2000, Train Loss: 0.0027, Test Loss: 0.1261\n",
      "Epoch 739/2000, Train Loss: 0.0027, Test Loss: 0.1275\n",
      "Epoch 740/2000, Train Loss: 0.0027, Test Loss: 0.1260\n",
      "Epoch 741/2000, Train Loss: 0.0027, Test Loss: 0.1260\n",
      "Epoch 742/2000, Train Loss: 0.0027, Test Loss: 0.1264\n",
      "Epoch 743/2000, Train Loss: 0.0027, Test Loss: 0.1260\n",
      "Epoch 744/2000, Train Loss: 0.0027, Test Loss: 0.1261\n",
      "Epoch 745/2000, Train Loss: 0.0027, Test Loss: 0.1267\n",
      "Epoch 746/2000, Train Loss: 0.0027, Test Loss: 0.1260\n",
      "Epoch 747/2000, Train Loss: 0.0027, Test Loss: 0.1259\n",
      "Epoch 748/2000, Train Loss: 0.0027, Test Loss: 0.1260\n",
      "Epoch 749/2000, Train Loss: 0.0027, Test Loss: 0.1267\n",
      "Epoch 750/2000, Train Loss: 0.0026, Test Loss: 0.1262\n",
      "Epoch 751/2000, Train Loss: 0.0026, Test Loss: 0.1280\n",
      "Epoch 752/2000, Train Loss: 0.0027, Test Loss: 0.1263\n",
      "Epoch 753/2000, Train Loss: 0.0026, Test Loss: 0.1264\n",
      "Epoch 754/2000, Train Loss: 0.0026, Test Loss: 0.1310\n",
      "Epoch 755/2000, Train Loss: 0.0026, Test Loss: 0.1262\n",
      "Epoch 756/2000, Train Loss: 0.0026, Test Loss: 0.1262\n",
      "Epoch 757/2000, Train Loss: 0.0026, Test Loss: 0.1329\n",
      "Epoch 758/2000, Train Loss: 0.0026, Test Loss: 0.1262\n",
      "Epoch 759/2000, Train Loss: 0.0026, Test Loss: 0.1262\n",
      "Epoch 760/2000, Train Loss: 0.0026, Test Loss: 0.1262\n",
      "Epoch 761/2000, Train Loss: 0.0026, Test Loss: 0.1332\n",
      "Epoch 762/2000, Train Loss: 0.0026, Test Loss: 0.1263\n",
      "Epoch 763/2000, Train Loss: 0.0026, Test Loss: 0.1263\n",
      "Epoch 764/2000, Train Loss: 0.0026, Test Loss: 0.1278\n",
      "Epoch 765/2000, Train Loss: 0.0026, Test Loss: 0.1264\n",
      "Epoch 766/2000, Train Loss: 0.0026, Test Loss: 0.1270\n",
      "Epoch 767/2000, Train Loss: 0.0026, Test Loss: 0.1279\n",
      "Epoch 768/2000, Train Loss: 0.0026, Test Loss: 0.1273\n",
      "Epoch 769/2000, Train Loss: 0.0026, Test Loss: 0.1271\n",
      "Epoch 770/2000, Train Loss: 0.0026, Test Loss: 0.1266\n",
      "Epoch 771/2000, Train Loss: 0.0026, Test Loss: 0.1270\n",
      "Epoch 772/2000, Train Loss: 0.0026, Test Loss: 0.1266\n",
      "Epoch 773/2000, Train Loss: 0.0026, Test Loss: 0.1267\n",
      "Epoch 774/2000, Train Loss: 0.0026, Test Loss: 0.1267\n",
      "Epoch 775/2000, Train Loss: 0.0026, Test Loss: 0.1273\n",
      "Epoch 776/2000, Train Loss: 0.0026, Test Loss: 0.1265\n",
      "Epoch 777/2000, Train Loss: 0.0026, Test Loss: 0.1267\n",
      "Epoch 778/2000, Train Loss: 0.0026, Test Loss: 0.1268\n",
      "Epoch 779/2000, Train Loss: 0.0026, Test Loss: 0.1268\n",
      "Epoch 780/2000, Train Loss: 0.0026, Test Loss: 0.1274\n",
      "Epoch 781/2000, Train Loss: 0.0026, Test Loss: 0.1267\n",
      "Epoch 782/2000, Train Loss: 0.0026, Test Loss: 0.1267\n",
      "Epoch 783/2000, Train Loss: 0.0026, Test Loss: 0.1267\n",
      "Epoch 784/2000, Train Loss: 0.0026, Test Loss: 0.1268\n",
      "Epoch 785/2000, Train Loss: 0.0026, Test Loss: 0.1279\n",
      "Epoch 786/2000, Train Loss: 0.0025, Test Loss: 0.1265\n",
      "Epoch 787/2000, Train Loss: 0.0025, Test Loss: 0.1270\n",
      "Epoch 788/2000, Train Loss: 0.0025, Test Loss: 0.1269\n",
      "Epoch 789/2000, Train Loss: 0.0025, Test Loss: 0.1269\n",
      "Epoch 790/2000, Train Loss: 0.0025, Test Loss: 0.1276\n",
      "Epoch 791/2000, Train Loss: 0.0025, Test Loss: 0.1286\n",
      "Epoch 792/2000, Train Loss: 0.0025, Test Loss: 0.1270\n",
      "Epoch 793/2000, Train Loss: 0.0025, Test Loss: 0.1269\n",
      "Epoch 794/2000, Train Loss: 0.0025, Test Loss: 0.1272\n",
      "Epoch 795/2000, Train Loss: 0.0025, Test Loss: 0.1269\n",
      "Epoch 796/2000, Train Loss: 0.0025, Test Loss: 0.1269\n",
      "Epoch 797/2000, Train Loss: 0.0025, Test Loss: 0.1270\n",
      "Epoch 798/2000, Train Loss: 0.0025, Test Loss: 0.1376\n",
      "Epoch 799/2000, Train Loss: 0.0025, Test Loss: 0.1272\n",
      "Epoch 800/2000, Train Loss: 0.0025, Test Loss: 0.1272\n",
      "Epoch 801/2000, Train Loss: 0.0025, Test Loss: 0.1273\n",
      "Epoch 802/2000, Train Loss: 0.0025, Test Loss: 0.1302\n",
      "Epoch 803/2000, Train Loss: 0.0025, Test Loss: 0.1347\n",
      "Epoch 804/2000, Train Loss: 0.0025, Test Loss: 0.1272\n",
      "Epoch 805/2000, Train Loss: 0.0025, Test Loss: 0.1283\n",
      "Epoch 806/2000, Train Loss: 0.0025, Test Loss: 0.1272\n",
      "Epoch 807/2000, Train Loss: 0.0025, Test Loss: 0.1272\n",
      "Epoch 808/2000, Train Loss: 0.0025, Test Loss: 0.1274\n",
      "Epoch 809/2000, Train Loss: 0.0025, Test Loss: 0.1298\n",
      "Epoch 810/2000, Train Loss: 0.0025, Test Loss: 0.1276\n",
      "Epoch 811/2000, Train Loss: 0.0025, Test Loss: 0.1273\n",
      "Epoch 812/2000, Train Loss: 0.0025, Test Loss: 0.1283\n",
      "Epoch 813/2000, Train Loss: 0.0025, Test Loss: 0.1294\n",
      "Epoch 814/2000, Train Loss: 0.0025, Test Loss: 0.1274\n",
      "Epoch 815/2000, Train Loss: 0.0025, Test Loss: 0.1273\n",
      "Epoch 816/2000, Train Loss: 0.0025, Test Loss: 0.1275\n",
      "Epoch 817/2000, Train Loss: 0.0025, Test Loss: 0.1286\n",
      "Epoch 818/2000, Train Loss: 0.0025, Test Loss: 0.1353\n",
      "Epoch 819/2000, Train Loss: 0.0025, Test Loss: 0.1273\n",
      "Epoch 820/2000, Train Loss: 0.0025, Test Loss: 0.1327\n",
      "Epoch 821/2000, Train Loss: 0.0025, Test Loss: 0.1317\n",
      "Epoch 822/2000, Train Loss: 0.0025, Test Loss: 0.1276\n",
      "Epoch 823/2000, Train Loss: 0.0025, Test Loss: 0.1274\n",
      "Epoch 824/2000, Train Loss: 0.0024, Test Loss: 0.1298\n",
      "Epoch 825/2000, Train Loss: 0.0024, Test Loss: 0.1277\n",
      "Epoch 826/2000, Train Loss: 0.0024, Test Loss: 0.1293\n",
      "Epoch 827/2000, Train Loss: 0.0024, Test Loss: 0.1277\n",
      "Epoch 828/2000, Train Loss: 0.0024, Test Loss: 0.1281\n",
      "Epoch 829/2000, Train Loss: 0.0024, Test Loss: 0.1288\n",
      "Epoch 830/2000, Train Loss: 0.0024, Test Loss: 0.1282\n",
      "Epoch 831/2000, Train Loss: 0.0024, Test Loss: 0.1291\n",
      "Epoch 832/2000, Train Loss: 0.0024, Test Loss: 0.1275\n",
      "Epoch 833/2000, Train Loss: 0.0024, Test Loss: 0.1274\n",
      "Epoch 834/2000, Train Loss: 0.0024, Test Loss: 0.1280\n",
      "Epoch 835/2000, Train Loss: 0.0024, Test Loss: 0.1358\n",
      "Epoch 836/2000, Train Loss: 0.0024, Test Loss: 0.1277\n",
      "Epoch 837/2000, Train Loss: 0.0024, Test Loss: 0.1284\n",
      "Epoch 838/2000, Train Loss: 0.0024, Test Loss: 0.1352\n",
      "Epoch 839/2000, Train Loss: 0.0024, Test Loss: 0.1279\n",
      "Epoch 840/2000, Train Loss: 0.0024, Test Loss: 0.1276\n",
      "Epoch 841/2000, Train Loss: 0.0024, Test Loss: 0.1276\n",
      "Epoch 842/2000, Train Loss: 0.0024, Test Loss: 0.1345\n",
      "Epoch 843/2000, Train Loss: 0.0024, Test Loss: 0.1276\n",
      "Epoch 844/2000, Train Loss: 0.0024, Test Loss: 0.1278\n",
      "Epoch 845/2000, Train Loss: 0.0024, Test Loss: 0.1277\n",
      "Epoch 846/2000, Train Loss: 0.0024, Test Loss: 0.1278\n",
      "Epoch 847/2000, Train Loss: 0.0024, Test Loss: 0.1278\n",
      "Epoch 848/2000, Train Loss: 0.0024, Test Loss: 0.1280\n",
      "Epoch 849/2000, Train Loss: 0.0024, Test Loss: 0.1318\n",
      "Epoch 850/2000, Train Loss: 0.0024, Test Loss: 0.1364\n",
      "Epoch 851/2000, Train Loss: 0.0024, Test Loss: 0.1288\n",
      "Epoch 852/2000, Train Loss: 0.0024, Test Loss: 0.1299\n",
      "Epoch 853/2000, Train Loss: 0.0024, Test Loss: 0.1298\n",
      "Epoch 854/2000, Train Loss: 0.0024, Test Loss: 0.1281\n",
      "Epoch 855/2000, Train Loss: 0.0024, Test Loss: 0.1335\n",
      "Epoch 856/2000, Train Loss: 0.0024, Test Loss: 0.1281\n",
      "Epoch 857/2000, Train Loss: 0.0024, Test Loss: 0.1282\n",
      "Epoch 858/2000, Train Loss: 0.0024, Test Loss: 0.1279\n",
      "Epoch 859/2000, Train Loss: 0.0024, Test Loss: 0.1279\n",
      "Epoch 860/2000, Train Loss: 0.0024, Test Loss: 0.1281\n",
      "Epoch 861/2000, Train Loss: 0.0023, Test Loss: 0.1282\n",
      "Epoch 862/2000, Train Loss: 0.0023, Test Loss: 0.1317\n",
      "Epoch 863/2000, Train Loss: 0.0024, Test Loss: 0.1291\n",
      "Epoch 864/2000, Train Loss: 0.0023, Test Loss: 0.1342\n",
      "Epoch 865/2000, Train Loss: 0.0023, Test Loss: 0.1281\n",
      "Epoch 866/2000, Train Loss: 0.0023, Test Loss: 0.1282\n",
      "Epoch 867/2000, Train Loss: 0.0023, Test Loss: 0.1281\n",
      "Epoch 868/2000, Train Loss: 0.0023, Test Loss: 0.1285\n",
      "Epoch 869/2000, Train Loss: 0.0023, Test Loss: 0.1303\n",
      "Epoch 870/2000, Train Loss: 0.0023, Test Loss: 0.1281\n",
      "Epoch 871/2000, Train Loss: 0.0023, Test Loss: 0.1282\n",
      "Epoch 872/2000, Train Loss: 0.0023, Test Loss: 0.1282\n",
      "Epoch 873/2000, Train Loss: 0.0023, Test Loss: 0.1325\n",
      "Epoch 874/2000, Train Loss: 0.0023, Test Loss: 0.1293\n",
      "Epoch 875/2000, Train Loss: 0.0023, Test Loss: 0.1283\n",
      "Epoch 876/2000, Train Loss: 0.0023, Test Loss: 0.1283\n",
      "Epoch 877/2000, Train Loss: 0.0023, Test Loss: 0.1286\n",
      "Epoch 878/2000, Train Loss: 0.0023, Test Loss: 0.1305\n",
      "Epoch 879/2000, Train Loss: 0.0023, Test Loss: 0.1283\n",
      "Epoch 880/2000, Train Loss: 0.0023, Test Loss: 0.1283\n",
      "Epoch 881/2000, Train Loss: 0.0023, Test Loss: 0.1283\n",
      "Epoch 882/2000, Train Loss: 0.0023, Test Loss: 0.1283\n",
      "Epoch 883/2000, Train Loss: 0.0023, Test Loss: 0.1327\n",
      "Epoch 884/2000, Train Loss: 0.0023, Test Loss: 0.1286\n",
      "Epoch 885/2000, Train Loss: 0.0023, Test Loss: 0.1284\n",
      "Epoch 886/2000, Train Loss: 0.0023, Test Loss: 0.1284\n",
      "Epoch 887/2000, Train Loss: 0.0023, Test Loss: 0.1287\n",
      "Epoch 888/2000, Train Loss: 0.0023, Test Loss: 0.1290\n",
      "Epoch 889/2000, Train Loss: 0.0023, Test Loss: 0.1284\n",
      "Epoch 890/2000, Train Loss: 0.0023, Test Loss: 0.1285\n",
      "Epoch 891/2000, Train Loss: 0.0023, Test Loss: 0.1286\n",
      "Epoch 892/2000, Train Loss: 0.0023, Test Loss: 0.1286\n",
      "Epoch 893/2000, Train Loss: 0.0023, Test Loss: 0.1308\n",
      "Epoch 894/2000, Train Loss: 0.0023, Test Loss: 0.1286\n",
      "Epoch 895/2000, Train Loss: 0.0023, Test Loss: 0.1287\n",
      "Epoch 896/2000, Train Loss: 0.0023, Test Loss: 0.1292\n",
      "Epoch 897/2000, Train Loss: 0.0023, Test Loss: 0.1286\n",
      "Epoch 898/2000, Train Loss: 0.0023, Test Loss: 0.1312\n",
      "Epoch 899/2000, Train Loss: 0.0023, Test Loss: 0.1307\n",
      "Epoch 900/2000, Train Loss: 0.0023, Test Loss: 0.1366\n",
      "Epoch 901/2000, Train Loss: 0.0023, Test Loss: 0.1343\n",
      "Epoch 902/2000, Train Loss: 0.0023, Test Loss: 0.1287\n",
      "Epoch 903/2000, Train Loss: 0.0023, Test Loss: 0.1392\n",
      "Epoch 904/2000, Train Loss: 0.0023, Test Loss: 0.1287\n",
      "Epoch 905/2000, Train Loss: 0.0023, Test Loss: 0.1287\n",
      "Epoch 906/2000, Train Loss: 0.0023, Test Loss: 0.1326\n",
      "Epoch 907/2000, Train Loss: 0.0023, Test Loss: 0.1296\n",
      "Epoch 908/2000, Train Loss: 0.0023, Test Loss: 0.1288\n",
      "Epoch 909/2000, Train Loss: 0.0022, Test Loss: 0.1287\n",
      "Epoch 910/2000, Train Loss: 0.0022, Test Loss: 0.1360\n",
      "Epoch 911/2000, Train Loss: 0.0023, Test Loss: 0.1289\n",
      "Epoch 912/2000, Train Loss: 0.0022, Test Loss: 0.1312\n",
      "Epoch 913/2000, Train Loss: 0.0022, Test Loss: 0.1292\n",
      "Epoch 914/2000, Train Loss: 0.0022, Test Loss: 0.1361\n",
      "Epoch 915/2000, Train Loss: 0.0022, Test Loss: 0.1286\n",
      "Epoch 916/2000, Train Loss: 0.0022, Test Loss: 0.1290\n",
      "Epoch 917/2000, Train Loss: 0.0022, Test Loss: 0.1309\n",
      "Epoch 918/2000, Train Loss: 0.0022, Test Loss: 0.1305\n",
      "Epoch 919/2000, Train Loss: 0.0022, Test Loss: 0.1293\n",
      "Epoch 920/2000, Train Loss: 0.0022, Test Loss: 0.1287\n",
      "Epoch 921/2000, Train Loss: 0.0022, Test Loss: 0.1302\n",
      "Epoch 922/2000, Train Loss: 0.0022, Test Loss: 0.1329\n",
      "Epoch 923/2000, Train Loss: 0.0022, Test Loss: 0.1288\n",
      "Epoch 924/2000, Train Loss: 0.0022, Test Loss: 0.1339\n",
      "Epoch 925/2000, Train Loss: 0.0022, Test Loss: 0.1376\n",
      "Epoch 926/2000, Train Loss: 0.0022, Test Loss: 0.1289\n",
      "Epoch 927/2000, Train Loss: 0.0022, Test Loss: 0.1294\n",
      "Epoch 928/2000, Train Loss: 0.0022, Test Loss: 0.1292\n",
      "Epoch 929/2000, Train Loss: 0.0022, Test Loss: 0.1292\n",
      "Epoch 930/2000, Train Loss: 0.0022, Test Loss: 0.1309\n",
      "Epoch 931/2000, Train Loss: 0.0022, Test Loss: 0.1291\n",
      "Epoch 932/2000, Train Loss: 0.0022, Test Loss: 0.1292\n",
      "Epoch 933/2000, Train Loss: 0.0022, Test Loss: 0.1298\n",
      "Epoch 934/2000, Train Loss: 0.0022, Test Loss: 0.1292\n",
      "Epoch 935/2000, Train Loss: 0.0022, Test Loss: 0.1290\n",
      "Epoch 936/2000, Train Loss: 0.0022, Test Loss: 0.1290\n",
      "Epoch 937/2000, Train Loss: 0.0022, Test Loss: 0.1292\n",
      "Epoch 938/2000, Train Loss: 0.0022, Test Loss: 0.1292\n",
      "Epoch 939/2000, Train Loss: 0.0022, Test Loss: 0.1326\n",
      "Epoch 940/2000, Train Loss: 0.0022, Test Loss: 0.1321\n",
      "Epoch 941/2000, Train Loss: 0.0022, Test Loss: 0.1293\n",
      "Epoch 942/2000, Train Loss: 0.0022, Test Loss: 0.1383\n",
      "Epoch 943/2000, Train Loss: 0.0022, Test Loss: 0.1294\n",
      "Epoch 944/2000, Train Loss: 0.0022, Test Loss: 0.1295\n",
      "Epoch 945/2000, Train Loss: 0.0022, Test Loss: 0.1327\n",
      "Epoch 946/2000, Train Loss: 0.0022, Test Loss: 0.1389\n",
      "Epoch 947/2000, Train Loss: 0.0022, Test Loss: 0.1349\n",
      "Epoch 948/2000, Train Loss: 0.0022, Test Loss: 0.1303\n",
      "Epoch 949/2000, Train Loss: 0.0022, Test Loss: 0.1294\n",
      "Epoch 950/2000, Train Loss: 0.0022, Test Loss: 0.1296\n",
      "Epoch 951/2000, Train Loss: 0.0022, Test Loss: 0.1295\n",
      "Epoch 952/2000, Train Loss: 0.0022, Test Loss: 0.1350\n",
      "Epoch 953/2000, Train Loss: 0.0022, Test Loss: 0.1293\n",
      "Epoch 954/2000, Train Loss: 0.0022, Test Loss: 0.1294\n",
      "Epoch 955/2000, Train Loss: 0.0022, Test Loss: 0.1293\n",
      "Epoch 956/2000, Train Loss: 0.0022, Test Loss: 0.1344\n",
      "Epoch 957/2000, Train Loss: 0.0022, Test Loss: 0.1331\n",
      "Epoch 958/2000, Train Loss: 0.0022, Test Loss: 0.1299\n",
      "Epoch 959/2000, Train Loss: 0.0021, Test Loss: 0.1295\n",
      "Epoch 960/2000, Train Loss: 0.0021, Test Loss: 0.1295\n",
      "Epoch 961/2000, Train Loss: 0.0021, Test Loss: 0.1298\n",
      "Epoch 962/2000, Train Loss: 0.0021, Test Loss: 0.1323\n",
      "Epoch 963/2000, Train Loss: 0.0021, Test Loss: 0.1296\n",
      "Epoch 964/2000, Train Loss: 0.0021, Test Loss: 0.1306\n",
      "Epoch 965/2000, Train Loss: 0.0021, Test Loss: 0.1298\n",
      "Epoch 966/2000, Train Loss: 0.0021, Test Loss: 0.1374\n",
      "Epoch 967/2000, Train Loss: 0.0021, Test Loss: 0.1320\n",
      "Epoch 968/2000, Train Loss: 0.0021, Test Loss: 0.1299\n",
      "Epoch 969/2000, Train Loss: 0.0021, Test Loss: 0.1321\n",
      "Epoch 970/2000, Train Loss: 0.0021, Test Loss: 0.1295\n",
      "Epoch 971/2000, Train Loss: 0.0021, Test Loss: 0.1297\n",
      "Epoch 972/2000, Train Loss: 0.0021, Test Loss: 0.1296\n",
      "Epoch 973/2000, Train Loss: 0.0021, Test Loss: 0.1298\n",
      "Epoch 974/2000, Train Loss: 0.0021, Test Loss: 0.1361\n",
      "Epoch 975/2000, Train Loss: 0.0021, Test Loss: 0.1340\n",
      "Epoch 976/2000, Train Loss: 0.0021, Test Loss: 0.1309\n",
      "Epoch 977/2000, Train Loss: 0.0021, Test Loss: 0.1296\n",
      "Epoch 978/2000, Train Loss: 0.0021, Test Loss: 0.1298\n",
      "Epoch 979/2000, Train Loss: 0.0021, Test Loss: 0.1355\n",
      "Epoch 980/2000, Train Loss: 0.0021, Test Loss: 0.1297\n",
      "Epoch 981/2000, Train Loss: 0.0021, Test Loss: 0.1298\n",
      "Epoch 982/2000, Train Loss: 0.0021, Test Loss: 0.1312\n",
      "Epoch 983/2000, Train Loss: 0.0021, Test Loss: 0.1314\n",
      "Epoch 984/2000, Train Loss: 0.0021, Test Loss: 0.1320\n",
      "Epoch 985/2000, Train Loss: 0.0021, Test Loss: 0.1298\n",
      "Epoch 986/2000, Train Loss: 0.0021, Test Loss: 0.1303\n",
      "Epoch 987/2000, Train Loss: 0.0021, Test Loss: 0.1299\n",
      "Epoch 988/2000, Train Loss: 0.0021, Test Loss: 0.1333\n",
      "Epoch 989/2000, Train Loss: 0.0021, Test Loss: 0.1297\n",
      "Epoch 990/2000, Train Loss: 0.0021, Test Loss: 0.1299\n",
      "Epoch 991/2000, Train Loss: 0.0021, Test Loss: 0.1352\n",
      "Epoch 992/2000, Train Loss: 0.0021, Test Loss: 0.1305\n",
      "Epoch 993/2000, Train Loss: 0.0021, Test Loss: 0.1300\n",
      "Epoch 994/2000, Train Loss: 0.0021, Test Loss: 0.1302\n",
      "Epoch 995/2000, Train Loss: 0.0021, Test Loss: 0.1341\n",
      "Epoch 996/2000, Train Loss: 0.0021, Test Loss: 0.1300\n",
      "Epoch 997/2000, Train Loss: 0.0021, Test Loss: 0.1300\n",
      "Epoch 998/2000, Train Loss: 0.0021, Test Loss: 0.1301\n",
      "Epoch 999/2000, Train Loss: 0.0021, Test Loss: 0.1331\n",
      "Epoch 1000/2000, Train Loss: 0.0021, Test Loss: 0.1329\n",
      "Epoch 1001/2000, Train Loss: 0.0021, Test Loss: 0.1336\n",
      "Epoch 1002/2000, Train Loss: 0.0021, Test Loss: 0.1325\n",
      "Epoch 1003/2000, Train Loss: 0.0021, Test Loss: 0.1300\n",
      "Epoch 1004/2000, Train Loss: 0.0021, Test Loss: 0.1303\n",
      "Epoch 1005/2000, Train Loss: 0.0021, Test Loss: 0.1302\n",
      "Epoch 1006/2000, Train Loss: 0.0021, Test Loss: 0.1309\n",
      "Epoch 1007/2000, Train Loss: 0.0021, Test Loss: 0.1301\n",
      "Epoch 1008/2000, Train Loss: 0.0021, Test Loss: 0.1356\n",
      "Epoch 1009/2000, Train Loss: 0.0021, Test Loss: 0.1302\n",
      "Epoch 1010/2000, Train Loss: 0.0021, Test Loss: 0.1327\n",
      "Epoch 1011/2000, Train Loss: 0.0021, Test Loss: 0.1301\n",
      "Epoch 1012/2000, Train Loss: 0.0021, Test Loss: 0.1333\n",
      "Epoch 1013/2000, Train Loss: 0.0021, Test Loss: 0.1301\n",
      "Epoch 1014/2000, Train Loss: 0.0020, Test Loss: 0.1323\n",
      "Epoch 1015/2000, Train Loss: 0.0021, Test Loss: 0.1305\n",
      "Epoch 1016/2000, Train Loss: 0.0020, Test Loss: 0.1352\n",
      "Epoch 1017/2000, Train Loss: 0.0020, Test Loss: 0.1303\n",
      "Epoch 1018/2000, Train Loss: 0.0020, Test Loss: 0.1392\n",
      "Epoch 1019/2000, Train Loss: 0.0020, Test Loss: 0.1304\n",
      "Epoch 1020/2000, Train Loss: 0.0020, Test Loss: 0.1305\n",
      "Epoch 1021/2000, Train Loss: 0.0020, Test Loss: 0.1303\n",
      "Epoch 1022/2000, Train Loss: 0.0020, Test Loss: 0.1335\n",
      "Epoch 1023/2000, Train Loss: 0.0020, Test Loss: 0.1306\n",
      "Epoch 1024/2000, Train Loss: 0.0020, Test Loss: 0.1305\n",
      "Epoch 1025/2000, Train Loss: 0.0020, Test Loss: 0.1307\n",
      "Epoch 1026/2000, Train Loss: 0.0020, Test Loss: 0.1305\n",
      "Epoch 1027/2000, Train Loss: 0.0020, Test Loss: 0.1304\n",
      "Epoch 1028/2000, Train Loss: 0.0020, Test Loss: 0.1306\n",
      "Epoch 1029/2000, Train Loss: 0.0020, Test Loss: 0.1336\n",
      "Epoch 1030/2000, Train Loss: 0.0020, Test Loss: 0.1344\n",
      "Epoch 1031/2000, Train Loss: 0.0020, Test Loss: 0.1313\n",
      "Epoch 1032/2000, Train Loss: 0.0020, Test Loss: 0.1362\n",
      "Epoch 1033/2000, Train Loss: 0.0020, Test Loss: 0.1304\n",
      "Epoch 1034/2000, Train Loss: 0.0020, Test Loss: 0.1317\n",
      "Epoch 1035/2000, Train Loss: 0.0020, Test Loss: 0.1306\n",
      "Epoch 1036/2000, Train Loss: 0.0020, Test Loss: 0.1376\n",
      "Epoch 1037/2000, Train Loss: 0.0020, Test Loss: 0.1309\n",
      "Epoch 1038/2000, Train Loss: 0.0020, Test Loss: 0.1321\n",
      "Epoch 1039/2000, Train Loss: 0.0020, Test Loss: 0.1444\n",
      "Epoch 1040/2000, Train Loss: 0.0020, Test Loss: 0.1305\n",
      "Epoch 1041/2000, Train Loss: 0.0020, Test Loss: 0.1307\n",
      "Epoch 1042/2000, Train Loss: 0.0020, Test Loss: 0.1308\n",
      "Epoch 1043/2000, Train Loss: 0.0020, Test Loss: 0.1309\n",
      "Epoch 1044/2000, Train Loss: 0.0020, Test Loss: 0.1309\n",
      "Epoch 1045/2000, Train Loss: 0.0020, Test Loss: 0.1307\n",
      "Epoch 1046/2000, Train Loss: 0.0020, Test Loss: 0.1306\n",
      "Epoch 1047/2000, Train Loss: 0.0020, Test Loss: 0.1308\n",
      "Epoch 1048/2000, Train Loss: 0.0020, Test Loss: 0.1358\n",
      "Epoch 1049/2000, Train Loss: 0.0020, Test Loss: 0.1349\n",
      "Epoch 1050/2000, Train Loss: 0.0020, Test Loss: 0.1305\n",
      "Epoch 1051/2000, Train Loss: 0.0020, Test Loss: 0.1307\n",
      "Epoch 1052/2000, Train Loss: 0.0020, Test Loss: 0.1307\n",
      "Epoch 1053/2000, Train Loss: 0.0020, Test Loss: 0.1308\n",
      "Epoch 1054/2000, Train Loss: 0.0020, Test Loss: 0.1307\n",
      "Epoch 1055/2000, Train Loss: 0.0020, Test Loss: 0.1310\n",
      "Epoch 1056/2000, Train Loss: 0.0020, Test Loss: 0.1310\n",
      "Epoch 1057/2000, Train Loss: 0.0020, Test Loss: 0.1309\n",
      "Epoch 1058/2000, Train Loss: 0.0020, Test Loss: 0.1307\n",
      "Epoch 1059/2000, Train Loss: 0.0020, Test Loss: 0.1343\n",
      "Epoch 1060/2000, Train Loss: 0.0020, Test Loss: 0.1346\n",
      "Epoch 1061/2000, Train Loss: 0.0020, Test Loss: 0.1308\n",
      "Epoch 1062/2000, Train Loss: 0.0020, Test Loss: 0.1309\n",
      "Epoch 1063/2000, Train Loss: 0.0020, Test Loss: 0.1372\n",
      "Epoch 1064/2000, Train Loss: 0.0020, Test Loss: 0.1326\n",
      "Epoch 1065/2000, Train Loss: 0.0020, Test Loss: 0.1310\n",
      "Epoch 1066/2000, Train Loss: 0.0020, Test Loss: 0.1309\n",
      "Epoch 1067/2000, Train Loss: 0.0020, Test Loss: 0.1309\n",
      "Epoch 1068/2000, Train Loss: 0.0020, Test Loss: 0.1310\n",
      "Epoch 1069/2000, Train Loss: 0.0020, Test Loss: 0.1310\n",
      "Epoch 1070/2000, Train Loss: 0.0020, Test Loss: 0.1310\n",
      "Epoch 1071/2000, Train Loss: 0.0020, Test Loss: 0.1309\n",
      "Epoch 1072/2000, Train Loss: 0.0020, Test Loss: 0.1319\n",
      "Epoch 1073/2000, Train Loss: 0.0020, Test Loss: 0.1325\n",
      "Epoch 1074/2000, Train Loss: 0.0020, Test Loss: 0.1309\n",
      "Epoch 1075/2000, Train Loss: 0.0020, Test Loss: 0.1314\n",
      "Epoch 1076/2000, Train Loss: 0.0020, Test Loss: 0.1311\n",
      "Epoch 1077/2000, Train Loss: 0.0019, Test Loss: 0.1355\n",
      "Epoch 1078/2000, Train Loss: 0.0019, Test Loss: 0.1389\n",
      "Epoch 1079/2000, Train Loss: 0.0020, Test Loss: 0.1315\n",
      "Epoch 1080/2000, Train Loss: 0.0019, Test Loss: 0.1312\n",
      "Epoch 1081/2000, Train Loss: 0.0019, Test Loss: 0.1314\n",
      "Epoch 1082/2000, Train Loss: 0.0019, Test Loss: 0.1312\n",
      "Epoch 1083/2000, Train Loss: 0.0019, Test Loss: 0.1313\n",
      "Epoch 1084/2000, Train Loss: 0.0019, Test Loss: 0.1312\n",
      "Epoch 1085/2000, Train Loss: 0.0019, Test Loss: 0.1366\n",
      "Epoch 1086/2000, Train Loss: 0.0019, Test Loss: 0.1311\n",
      "Epoch 1087/2000, Train Loss: 0.0019, Test Loss: 0.1340\n",
      "Epoch 1088/2000, Train Loss: 0.0019, Test Loss: 0.1321\n",
      "Epoch 1089/2000, Train Loss: 0.0019, Test Loss: 0.1311\n",
      "Epoch 1090/2000, Train Loss: 0.0019, Test Loss: 0.1328\n",
      "Epoch 1091/2000, Train Loss: 0.0019, Test Loss: 0.1313\n",
      "Epoch 1092/2000, Train Loss: 0.0019, Test Loss: 0.1318\n",
      "Epoch 1093/2000, Train Loss: 0.0019, Test Loss: 0.1331\n",
      "Epoch 1094/2000, Train Loss: 0.0019, Test Loss: 0.1312\n",
      "Epoch 1095/2000, Train Loss: 0.0019, Test Loss: 0.1342\n",
      "Epoch 1096/2000, Train Loss: 0.0019, Test Loss: 0.1343\n",
      "Epoch 1097/2000, Train Loss: 0.0019, Test Loss: 0.1315\n",
      "Epoch 1098/2000, Train Loss: 0.0019, Test Loss: 0.1312\n",
      "Epoch 1099/2000, Train Loss: 0.0019, Test Loss: 0.1315\n",
      "Epoch 1100/2000, Train Loss: 0.0019, Test Loss: 0.1313\n",
      "Epoch 1101/2000, Train Loss: 0.0019, Test Loss: 0.1315\n",
      "Epoch 1102/2000, Train Loss: 0.0019, Test Loss: 0.1333\n",
      "Epoch 1103/2000, Train Loss: 0.0019, Test Loss: 0.1313\n",
      "Epoch 1104/2000, Train Loss: 0.0019, Test Loss: 0.1342\n",
      "Epoch 1105/2000, Train Loss: 0.0019, Test Loss: 0.1341\n",
      "Epoch 1106/2000, Train Loss: 0.0019, Test Loss: 0.1315\n",
      "Epoch 1107/2000, Train Loss: 0.0019, Test Loss: 0.1340\n",
      "Epoch 1108/2000, Train Loss: 0.0019, Test Loss: 0.1314\n",
      "Epoch 1109/2000, Train Loss: 0.0019, Test Loss: 0.1315\n",
      "Epoch 1110/2000, Train Loss: 0.0019, Test Loss: 0.1334\n",
      "Epoch 1111/2000, Train Loss: 0.0019, Test Loss: 0.1315\n",
      "Epoch 1112/2000, Train Loss: 0.0019, Test Loss: 0.1314\n",
      "Epoch 1113/2000, Train Loss: 0.0019, Test Loss: 0.1360\n",
      "Epoch 1114/2000, Train Loss: 0.0019, Test Loss: 0.1316\n",
      "Epoch 1115/2000, Train Loss: 0.0019, Test Loss: 0.1315\n",
      "Epoch 1116/2000, Train Loss: 0.0019, Test Loss: 0.1315\n",
      "Epoch 1117/2000, Train Loss: 0.0019, Test Loss: 0.1315\n",
      "Epoch 1118/2000, Train Loss: 0.0019, Test Loss: 0.1315\n",
      "Epoch 1119/2000, Train Loss: 0.0019, Test Loss: 0.1315\n",
      "Epoch 1120/2000, Train Loss: 0.0019, Test Loss: 0.1316\n",
      "Epoch 1121/2000, Train Loss: 0.0019, Test Loss: 0.1346\n",
      "Epoch 1122/2000, Train Loss: 0.0019, Test Loss: 0.1315\n",
      "Epoch 1123/2000, Train Loss: 0.0019, Test Loss: 0.1366\n",
      "Epoch 1124/2000, Train Loss: 0.0019, Test Loss: 0.1316\n",
      "Epoch 1125/2000, Train Loss: 0.0019, Test Loss: 0.1318\n",
      "Epoch 1126/2000, Train Loss: 0.0019, Test Loss: 0.1389\n",
      "Epoch 1127/2000, Train Loss: 0.0019, Test Loss: 0.1317\n",
      "Epoch 1128/2000, Train Loss: 0.0019, Test Loss: 0.1330\n",
      "Epoch 1129/2000, Train Loss: 0.0019, Test Loss: 0.1317\n",
      "Epoch 1130/2000, Train Loss: 0.0019, Test Loss: 0.1317\n",
      "Epoch 1131/2000, Train Loss: 0.0019, Test Loss: 0.1319\n",
      "Epoch 1132/2000, Train Loss: 0.0019, Test Loss: 0.1334\n",
      "Epoch 1133/2000, Train Loss: 0.0019, Test Loss: 0.1339\n",
      "Epoch 1134/2000, Train Loss: 0.0019, Test Loss: 0.1334\n",
      "Epoch 1135/2000, Train Loss: 0.0019, Test Loss: 0.1336\n",
      "Epoch 1136/2000, Train Loss: 0.0019, Test Loss: 0.1318\n",
      "Epoch 1137/2000, Train Loss: 0.0019, Test Loss: 0.1403\n",
      "Epoch 1138/2000, Train Loss: 0.0019, Test Loss: 0.1330\n",
      "Epoch 1139/2000, Train Loss: 0.0019, Test Loss: 0.1318\n",
      "Epoch 1140/2000, Train Loss: 0.0019, Test Loss: 0.1319\n",
      "Epoch 1141/2000, Train Loss: 0.0019, Test Loss: 0.1321\n",
      "Epoch 1142/2000, Train Loss: 0.0019, Test Loss: 0.1319\n",
      "Epoch 1143/2000, Train Loss: 0.0019, Test Loss: 0.1321\n",
      "Epoch 1144/2000, Train Loss: 0.0019, Test Loss: 0.1344\n",
      "Epoch 1145/2000, Train Loss: 0.0019, Test Loss: 0.1319\n",
      "Epoch 1146/2000, Train Loss: 0.0019, Test Loss: 0.1319\n",
      "Epoch 1147/2000, Train Loss: 0.0019, Test Loss: 0.1337\n",
      "Epoch 1148/2000, Train Loss: 0.0019, Test Loss: 0.1319\n",
      "Epoch 1149/2000, Train Loss: 0.0019, Test Loss: 0.1321\n",
      "Epoch 1150/2000, Train Loss: 0.0019, Test Loss: 0.1319\n",
      "Epoch 1151/2000, Train Loss: 0.0018, Test Loss: 0.1318\n",
      "Epoch 1152/2000, Train Loss: 0.0018, Test Loss: 0.1320\n",
      "Epoch 1153/2000, Train Loss: 0.0018, Test Loss: 0.1324\n",
      "Epoch 1154/2000, Train Loss: 0.0018, Test Loss: 0.1319\n",
      "Epoch 1155/2000, Train Loss: 0.0018, Test Loss: 0.1321\n",
      "Epoch 1156/2000, Train Loss: 0.0018, Test Loss: 0.1320\n",
      "Epoch 1157/2000, Train Loss: 0.0018, Test Loss: 0.1321\n",
      "Epoch 1158/2000, Train Loss: 0.0018, Test Loss: 0.1320\n",
      "Epoch 1159/2000, Train Loss: 0.0018, Test Loss: 0.1321\n",
      "Epoch 1160/2000, Train Loss: 0.0018, Test Loss: 0.1330\n",
      "Epoch 1161/2000, Train Loss: 0.0018, Test Loss: 0.1321\n",
      "Epoch 1162/2000, Train Loss: 0.0018, Test Loss: 0.1332\n",
      "Epoch 1163/2000, Train Loss: 0.0018, Test Loss: 0.1337\n",
      "Epoch 1164/2000, Train Loss: 0.0018, Test Loss: 0.1409\n",
      "Epoch 1165/2000, Train Loss: 0.0018, Test Loss: 0.1321\n",
      "Epoch 1166/2000, Train Loss: 0.0018, Test Loss: 0.1334\n",
      "Epoch 1167/2000, Train Loss: 0.0018, Test Loss: 0.1480\n",
      "Epoch 1168/2000, Train Loss: 0.0018, Test Loss: 0.1321\n",
      "Epoch 1169/2000, Train Loss: 0.0018, Test Loss: 0.1321\n",
      "Epoch 1170/2000, Train Loss: 0.0018, Test Loss: 0.1322\n",
      "Epoch 1171/2000, Train Loss: 0.0018, Test Loss: 0.1360\n",
      "Epoch 1172/2000, Train Loss: 0.0018, Test Loss: 0.1333\n",
      "Epoch 1173/2000, Train Loss: 0.0018, Test Loss: 0.1322\n",
      "Epoch 1174/2000, Train Loss: 0.0018, Test Loss: 0.1322\n",
      "Epoch 1175/2000, Train Loss: 0.0018, Test Loss: 0.1322\n",
      "Epoch 1176/2000, Train Loss: 0.0018, Test Loss: 0.1323\n",
      "Epoch 1177/2000, Train Loss: 0.0018, Test Loss: 0.1369\n",
      "Epoch 1178/2000, Train Loss: 0.0018, Test Loss: 0.1323\n",
      "Epoch 1179/2000, Train Loss: 0.0018, Test Loss: 0.1324\n",
      "Epoch 1180/2000, Train Loss: 0.0018, Test Loss: 0.1332\n",
      "Epoch 1181/2000, Train Loss: 0.0018, Test Loss: 0.1323\n",
      "Epoch 1182/2000, Train Loss: 0.0018, Test Loss: 0.1324\n",
      "Epoch 1183/2000, Train Loss: 0.0018, Test Loss: 0.1374\n",
      "Epoch 1184/2000, Train Loss: 0.0018, Test Loss: 0.1387\n",
      "Epoch 1185/2000, Train Loss: 0.0018, Test Loss: 0.1459\n",
      "Epoch 1186/2000, Train Loss: 0.0018, Test Loss: 0.1426\n",
      "Epoch 1187/2000, Train Loss: 0.0018, Test Loss: 0.1323\n",
      "Epoch 1188/2000, Train Loss: 0.0018, Test Loss: 0.1348\n",
      "Epoch 1189/2000, Train Loss: 0.0018, Test Loss: 0.1326\n",
      "Epoch 1190/2000, Train Loss: 0.0018, Test Loss: 0.1385\n",
      "Epoch 1191/2000, Train Loss: 0.0018, Test Loss: 0.1367\n",
      "Epoch 1192/2000, Train Loss: 0.0018, Test Loss: 0.1325\n",
      "Epoch 1193/2000, Train Loss: 0.0018, Test Loss: 0.1411\n",
      "Epoch 1194/2000, Train Loss: 0.0018, Test Loss: 0.1339\n",
      "Epoch 1195/2000, Train Loss: 0.0018, Test Loss: 0.1324\n",
      "Epoch 1196/2000, Train Loss: 0.0018, Test Loss: 0.1333\n",
      "Epoch 1197/2000, Train Loss: 0.0018, Test Loss: 0.1400\n",
      "Epoch 1198/2000, Train Loss: 0.0018, Test Loss: 0.1329\n",
      "Epoch 1199/2000, Train Loss: 0.0018, Test Loss: 0.1325\n",
      "Epoch 1200/2000, Train Loss: 0.0018, Test Loss: 0.1348\n",
      "Epoch 1201/2000, Train Loss: 0.0018, Test Loss: 0.1332\n",
      "Epoch 1202/2000, Train Loss: 0.0018, Test Loss: 0.1325\n",
      "Epoch 1203/2000, Train Loss: 0.0018, Test Loss: 0.1325\n",
      "Epoch 1204/2000, Train Loss: 0.0018, Test Loss: 0.1340\n",
      "Epoch 1205/2000, Train Loss: 0.0018, Test Loss: 0.1325\n",
      "Epoch 1206/2000, Train Loss: 0.0018, Test Loss: 0.1324\n",
      "Epoch 1207/2000, Train Loss: 0.0018, Test Loss: 0.1329\n",
      "Epoch 1208/2000, Train Loss: 0.0018, Test Loss: 0.1335\n",
      "Epoch 1209/2000, Train Loss: 0.0018, Test Loss: 0.1368\n",
      "Epoch 1210/2000, Train Loss: 0.0018, Test Loss: 0.1334\n",
      "Epoch 1211/2000, Train Loss: 0.0018, Test Loss: 0.1328\n",
      "Epoch 1212/2000, Train Loss: 0.0018, Test Loss: 0.1329\n",
      "Epoch 1213/2000, Train Loss: 0.0018, Test Loss: 0.1327\n",
      "Epoch 1214/2000, Train Loss: 0.0018, Test Loss: 0.1340\n",
      "Epoch 1215/2000, Train Loss: 0.0018, Test Loss: 0.1407\n",
      "Epoch 1216/2000, Train Loss: 0.0018, Test Loss: 0.1332\n",
      "Epoch 1217/2000, Train Loss: 0.0018, Test Loss: 0.1327\n",
      "Epoch 1218/2000, Train Loss: 0.0018, Test Loss: 0.1366\n",
      "Epoch 1219/2000, Train Loss: 0.0018, Test Loss: 0.1327\n",
      "Epoch 1220/2000, Train Loss: 0.0018, Test Loss: 0.1352\n",
      "Epoch 1221/2000, Train Loss: 0.0018, Test Loss: 0.1453\n",
      "Epoch 1222/2000, Train Loss: 0.0018, Test Loss: 0.1371\n",
      "Epoch 1223/2000, Train Loss: 0.0018, Test Loss: 0.1385\n",
      "Epoch 1224/2000, Train Loss: 0.0018, Test Loss: 0.1373\n",
      "Epoch 1225/2000, Train Loss: 0.0018, Test Loss: 0.1388\n",
      "Epoch 1226/2000, Train Loss: 0.0018, Test Loss: 0.1365\n",
      "Epoch 1227/2000, Train Loss: 0.0018, Test Loss: 0.1339\n",
      "Epoch 1228/2000, Train Loss: 0.0018, Test Loss: 0.1333\n",
      "Epoch 1229/2000, Train Loss: 0.0018, Test Loss: 0.1340\n",
      "Epoch 1230/2000, Train Loss: 0.0018, Test Loss: 0.1331\n",
      "Epoch 1231/2000, Train Loss: 0.0018, Test Loss: 0.1333\n",
      "Epoch 1232/2000, Train Loss: 0.0018, Test Loss: 0.1385\n",
      "Epoch 1233/2000, Train Loss: 0.0018, Test Loss: 0.1379\n",
      "Epoch 1234/2000, Train Loss: 0.0017, Test Loss: 0.1329\n",
      "Epoch 1235/2000, Train Loss: 0.0017, Test Loss: 0.1331\n",
      "Epoch 1236/2000, Train Loss: 0.0017, Test Loss: 0.1332\n",
      "Epoch 1237/2000, Train Loss: 0.0017, Test Loss: 0.1329\n",
      "Epoch 1238/2000, Train Loss: 0.0017, Test Loss: 0.1358\n",
      "Epoch 1239/2000, Train Loss: 0.0017, Test Loss: 0.1357\n",
      "Epoch 1240/2000, Train Loss: 0.0017, Test Loss: 0.1334\n",
      "Epoch 1241/2000, Train Loss: 0.0017, Test Loss: 0.1329\n",
      "Epoch 1242/2000, Train Loss: 0.0017, Test Loss: 0.1331\n",
      "Epoch 1243/2000, Train Loss: 0.0017, Test Loss: 0.1375\n",
      "Epoch 1244/2000, Train Loss: 0.0017, Test Loss: 0.1330\n",
      "Epoch 1245/2000, Train Loss: 0.0017, Test Loss: 0.1331\n",
      "Epoch 1246/2000, Train Loss: 0.0017, Test Loss: 0.1401\n",
      "Epoch 1247/2000, Train Loss: 0.0017, Test Loss: 0.1360\n",
      "Epoch 1248/2000, Train Loss: 0.0017, Test Loss: 0.1340\n",
      "Epoch 1249/2000, Train Loss: 0.0017, Test Loss: 0.1336\n",
      "Epoch 1250/2000, Train Loss: 0.0017, Test Loss: 0.1335\n",
      "Epoch 1251/2000, Train Loss: 0.0017, Test Loss: 0.1331\n",
      "Epoch 1252/2000, Train Loss: 0.0017, Test Loss: 0.1330\n",
      "Epoch 1253/2000, Train Loss: 0.0017, Test Loss: 0.1330\n",
      "Epoch 1254/2000, Train Loss: 0.0017, Test Loss: 0.1331\n",
      "Epoch 1255/2000, Train Loss: 0.0017, Test Loss: 0.1332\n",
      "Epoch 1256/2000, Train Loss: 0.0017, Test Loss: 0.1378\n",
      "Epoch 1257/2000, Train Loss: 0.0017, Test Loss: 0.1332\n",
      "Epoch 1258/2000, Train Loss: 0.0017, Test Loss: 0.1357\n",
      "Epoch 1259/2000, Train Loss: 0.0017, Test Loss: 0.1367\n",
      "Epoch 1260/2000, Train Loss: 0.0017, Test Loss: 0.1330\n",
      "Epoch 1261/2000, Train Loss: 0.0017, Test Loss: 0.1364\n",
      "Epoch 1262/2000, Train Loss: 0.0017, Test Loss: 0.1332\n",
      "Epoch 1263/2000, Train Loss: 0.0017, Test Loss: 0.1332\n",
      "Epoch 1264/2000, Train Loss: 0.0017, Test Loss: 0.1366\n",
      "Epoch 1265/2000, Train Loss: 0.0017, Test Loss: 0.1332\n",
      "Epoch 1266/2000, Train Loss: 0.0017, Test Loss: 0.1332\n",
      "Epoch 1267/2000, Train Loss: 0.0017, Test Loss: 0.1356\n",
      "Epoch 1268/2000, Train Loss: 0.0017, Test Loss: 0.1332\n",
      "Epoch 1269/2000, Train Loss: 0.0017, Test Loss: 0.1333\n",
      "Epoch 1270/2000, Train Loss: 0.0017, Test Loss: 0.1349\n",
      "Epoch 1271/2000, Train Loss: 0.0017, Test Loss: 0.1333\n",
      "Epoch 1272/2000, Train Loss: 0.0017, Test Loss: 0.1333\n",
      "Epoch 1273/2000, Train Loss: 0.0017, Test Loss: 0.1333\n",
      "Epoch 1274/2000, Train Loss: 0.0017, Test Loss: 0.1333\n",
      "Epoch 1275/2000, Train Loss: 0.0017, Test Loss: 0.1335\n",
      "Epoch 1276/2000, Train Loss: 0.0017, Test Loss: 0.1334\n",
      "Epoch 1277/2000, Train Loss: 0.0017, Test Loss: 0.1483\n",
      "Epoch 1278/2000, Train Loss: 0.0017, Test Loss: 0.1364\n",
      "Epoch 1279/2000, Train Loss: 0.0017, Test Loss: 0.1333\n",
      "Epoch 1280/2000, Train Loss: 0.0017, Test Loss: 0.1347\n",
      "Epoch 1281/2000, Train Loss: 0.0017, Test Loss: 0.1341\n",
      "Epoch 1282/2000, Train Loss: 0.0017, Test Loss: 0.1336\n",
      "Epoch 1283/2000, Train Loss: 0.0017, Test Loss: 0.1441\n",
      "Epoch 1284/2000, Train Loss: 0.0017, Test Loss: 0.1333\n",
      "Epoch 1285/2000, Train Loss: 0.0017, Test Loss: 0.1346\n",
      "Epoch 1286/2000, Train Loss: 0.0017, Test Loss: 0.1334\n",
      "Epoch 1287/2000, Train Loss: 0.0017, Test Loss: 0.1336\n",
      "Epoch 1288/2000, Train Loss: 0.0017, Test Loss: 0.1335\n",
      "Epoch 1289/2000, Train Loss: 0.0017, Test Loss: 0.1335\n",
      "Epoch 1290/2000, Train Loss: 0.0017, Test Loss: 0.1335\n",
      "Epoch 1291/2000, Train Loss: 0.0017, Test Loss: 0.1335\n",
      "Epoch 1292/2000, Train Loss: 0.0017, Test Loss: 0.1340\n",
      "Epoch 1293/2000, Train Loss: 0.0017, Test Loss: 0.1337\n",
      "Epoch 1294/2000, Train Loss: 0.0017, Test Loss: 0.1370\n",
      "Epoch 1295/2000, Train Loss: 0.0017, Test Loss: 0.1335\n",
      "Epoch 1296/2000, Train Loss: 0.0017, Test Loss: 0.1334\n",
      "Epoch 1297/2000, Train Loss: 0.0017, Test Loss: 0.1350\n",
      "Epoch 1298/2000, Train Loss: 0.0017, Test Loss: 0.1379\n",
      "Epoch 1299/2000, Train Loss: 0.0017, Test Loss: 0.1337\n",
      "Epoch 1300/2000, Train Loss: 0.0017, Test Loss: 0.1336\n",
      "Epoch 1301/2000, Train Loss: 0.0017, Test Loss: 0.1342\n",
      "Epoch 1302/2000, Train Loss: 0.0017, Test Loss: 0.1337\n",
      "Epoch 1303/2000, Train Loss: 0.0017, Test Loss: 0.1348\n",
      "Epoch 1304/2000, Train Loss: 0.0017, Test Loss: 0.1338\n",
      "Epoch 1305/2000, Train Loss: 0.0017, Test Loss: 0.1339\n",
      "Epoch 1306/2000, Train Loss: 0.0017, Test Loss: 0.1366\n",
      "Epoch 1307/2000, Train Loss: 0.0017, Test Loss: 0.1336\n",
      "Epoch 1308/2000, Train Loss: 0.0017, Test Loss: 0.1372\n",
      "Epoch 1309/2000, Train Loss: 0.0017, Test Loss: 0.1367\n",
      "Epoch 1310/2000, Train Loss: 0.0017, Test Loss: 0.1337\n",
      "Epoch 1311/2000, Train Loss: 0.0017, Test Loss: 0.1342\n",
      "Epoch 1312/2000, Train Loss: 0.0017, Test Loss: 0.1337\n",
      "Epoch 1313/2000, Train Loss: 0.0017, Test Loss: 0.1338\n",
      "Epoch 1314/2000, Train Loss: 0.0017, Test Loss: 0.1348\n",
      "Epoch 1315/2000, Train Loss: 0.0017, Test Loss: 0.1380\n",
      "Epoch 1316/2000, Train Loss: 0.0017, Test Loss: 0.1381\n",
      "Epoch 1317/2000, Train Loss: 0.0017, Test Loss: 0.1337\n",
      "Epoch 1318/2000, Train Loss: 0.0017, Test Loss: 0.1350\n",
      "Epoch 1319/2000, Train Loss: 0.0017, Test Loss: 0.1431\n",
      "Epoch 1320/2000, Train Loss: 0.0017, Test Loss: 0.1390\n",
      "Epoch 1321/2000, Train Loss: 0.0017, Test Loss: 0.1350\n",
      "Epoch 1322/2000, Train Loss: 0.0017, Test Loss: 0.1371\n",
      "Epoch 1323/2000, Train Loss: 0.0017, Test Loss: 0.1359\n",
      "Epoch 1324/2000, Train Loss: 0.0017, Test Loss: 0.1337\n",
      "Epoch 1325/2000, Train Loss: 0.0016, Test Loss: 0.1339\n",
      "Epoch 1326/2000, Train Loss: 0.0017, Test Loss: 0.1415\n",
      "Epoch 1327/2000, Train Loss: 0.0017, Test Loss: 0.1338\n",
      "Epoch 1328/2000, Train Loss: 0.0016, Test Loss: 0.1341\n",
      "Epoch 1329/2000, Train Loss: 0.0016, Test Loss: 0.1339\n",
      "Epoch 1330/2000, Train Loss: 0.0016, Test Loss: 0.1400\n",
      "Epoch 1331/2000, Train Loss: 0.0016, Test Loss: 0.1347\n",
      "Epoch 1332/2000, Train Loss: 0.0016, Test Loss: 0.1338\n",
      "Epoch 1333/2000, Train Loss: 0.0016, Test Loss: 0.1412\n",
      "Epoch 1334/2000, Train Loss: 0.0016, Test Loss: 0.1339\n",
      "Epoch 1335/2000, Train Loss: 0.0016, Test Loss: 0.1343\n",
      "Epoch 1336/2000, Train Loss: 0.0016, Test Loss: 0.1354\n",
      "Epoch 1337/2000, Train Loss: 0.0016, Test Loss: 0.1340\n",
      "Epoch 1338/2000, Train Loss: 0.0016, Test Loss: 0.1370\n",
      "Epoch 1339/2000, Train Loss: 0.0016, Test Loss: 0.1451\n",
      "Epoch 1340/2000, Train Loss: 0.0016, Test Loss: 0.1340\n",
      "Epoch 1341/2000, Train Loss: 0.0016, Test Loss: 0.1377\n",
      "Epoch 1342/2000, Train Loss: 0.0016, Test Loss: 0.1340\n",
      "Epoch 1343/2000, Train Loss: 0.0016, Test Loss: 0.1452\n",
      "Epoch 1344/2000, Train Loss: 0.0016, Test Loss: 0.1341\n",
      "Epoch 1345/2000, Train Loss: 0.0016, Test Loss: 0.1351\n",
      "Epoch 1346/2000, Train Loss: 0.0016, Test Loss: 0.1354\n",
      "Epoch 1347/2000, Train Loss: 0.0016, Test Loss: 0.1351\n",
      "Epoch 1348/2000, Train Loss: 0.0016, Test Loss: 0.1371\n",
      "Epoch 1349/2000, Train Loss: 0.0016, Test Loss: 0.1429\n",
      "Epoch 1350/2000, Train Loss: 0.0016, Test Loss: 0.1376\n",
      "Epoch 1351/2000, Train Loss: 0.0016, Test Loss: 0.1366\n",
      "Epoch 1352/2000, Train Loss: 0.0016, Test Loss: 0.1342\n",
      "Epoch 1353/2000, Train Loss: 0.0016, Test Loss: 0.1341\n",
      "Epoch 1354/2000, Train Loss: 0.0016, Test Loss: 0.1341\n",
      "Epoch 1355/2000, Train Loss: 0.0016, Test Loss: 0.1342\n",
      "Epoch 1356/2000, Train Loss: 0.0016, Test Loss: 0.1342\n",
      "Epoch 1357/2000, Train Loss: 0.0016, Test Loss: 0.1343\n",
      "Epoch 1358/2000, Train Loss: 0.0016, Test Loss: 0.1344\n",
      "Epoch 1359/2000, Train Loss: 0.0016, Test Loss: 0.1342\n",
      "Epoch 1360/2000, Train Loss: 0.0016, Test Loss: 0.1343\n",
      "Epoch 1361/2000, Train Loss: 0.0016, Test Loss: 0.1354\n",
      "Epoch 1362/2000, Train Loss: 0.0016, Test Loss: 0.1359\n",
      "Epoch 1363/2000, Train Loss: 0.0016, Test Loss: 0.1342\n",
      "Epoch 1364/2000, Train Loss: 0.0016, Test Loss: 0.1342\n",
      "Epoch 1365/2000, Train Loss: 0.0016, Test Loss: 0.1343\n",
      "Epoch 1366/2000, Train Loss: 0.0016, Test Loss: 0.1351\n",
      "Epoch 1367/2000, Train Loss: 0.0016, Test Loss: 0.1351\n",
      "Epoch 1368/2000, Train Loss: 0.0016, Test Loss: 0.1374\n",
      "Epoch 1369/2000, Train Loss: 0.0016, Test Loss: 0.1344\n",
      "Epoch 1370/2000, Train Loss: 0.0016, Test Loss: 0.1343\n",
      "Epoch 1371/2000, Train Loss: 0.0016, Test Loss: 0.1342\n",
      "Epoch 1372/2000, Train Loss: 0.0016, Test Loss: 0.1343\n",
      "Epoch 1373/2000, Train Loss: 0.0016, Test Loss: 0.1342\n",
      "Epoch 1374/2000, Train Loss: 0.0016, Test Loss: 0.1351\n",
      "Epoch 1375/2000, Train Loss: 0.0016, Test Loss: 0.1343\n",
      "Epoch 1376/2000, Train Loss: 0.0016, Test Loss: 0.1356\n",
      "Epoch 1377/2000, Train Loss: 0.0016, Test Loss: 0.1366\n",
      "Epoch 1378/2000, Train Loss: 0.0016, Test Loss: 0.1345\n",
      "Epoch 1379/2000, Train Loss: 0.0016, Test Loss: 0.1394\n",
      "Epoch 1380/2000, Train Loss: 0.0016, Test Loss: 0.1344\n",
      "Epoch 1381/2000, Train Loss: 0.0016, Test Loss: 0.1352\n",
      "Epoch 1382/2000, Train Loss: 0.0016, Test Loss: 0.1347\n",
      "Epoch 1383/2000, Train Loss: 0.0016, Test Loss: 0.1343\n",
      "Epoch 1384/2000, Train Loss: 0.0016, Test Loss: 0.1402\n",
      "Epoch 1385/2000, Train Loss: 0.0016, Test Loss: 0.1345\n",
      "Epoch 1386/2000, Train Loss: 0.0016, Test Loss: 0.1344\n",
      "Epoch 1387/2000, Train Loss: 0.0016, Test Loss: 0.1345\n",
      "Epoch 1388/2000, Train Loss: 0.0016, Test Loss: 0.1378\n",
      "Epoch 1389/2000, Train Loss: 0.0016, Test Loss: 0.1475\n",
      "Epoch 1390/2000, Train Loss: 0.0016, Test Loss: 0.1344\n",
      "Epoch 1391/2000, Train Loss: 0.0016, Test Loss: 0.1345\n",
      "Epoch 1392/2000, Train Loss: 0.0016, Test Loss: 0.1365\n",
      "Epoch 1393/2000, Train Loss: 0.0016, Test Loss: 0.1345\n",
      "Epoch 1394/2000, Train Loss: 0.0016, Test Loss: 0.1362\n",
      "Epoch 1395/2000, Train Loss: 0.0016, Test Loss: 0.1343\n",
      "Epoch 1396/2000, Train Loss: 0.0016, Test Loss: 0.1368\n",
      "Epoch 1397/2000, Train Loss: 0.0016, Test Loss: 0.1345\n",
      "Epoch 1398/2000, Train Loss: 0.0016, Test Loss: 0.1346\n",
      "Epoch 1399/2000, Train Loss: 0.0016, Test Loss: 0.1389\n",
      "Epoch 1400/2000, Train Loss: 0.0016, Test Loss: 0.1348\n",
      "Epoch 1401/2000, Train Loss: 0.0016, Test Loss: 0.1346\n",
      "Epoch 1402/2000, Train Loss: 0.0016, Test Loss: 0.1346\n",
      "Epoch 1403/2000, Train Loss: 0.0016, Test Loss: 0.1346\n",
      "Epoch 1404/2000, Train Loss: 0.0016, Test Loss: 0.1348\n",
      "Epoch 1405/2000, Train Loss: 0.0016, Test Loss: 0.1348\n",
      "Epoch 1406/2000, Train Loss: 0.0016, Test Loss: 0.1346\n",
      "Epoch 1407/2000, Train Loss: 0.0016, Test Loss: 0.1346\n",
      "Epoch 1408/2000, Train Loss: 0.0016, Test Loss: 0.1346\n",
      "Epoch 1409/2000, Train Loss: 0.0016, Test Loss: 0.1351\n",
      "Epoch 1410/2000, Train Loss: 0.0016, Test Loss: 0.1347\n",
      "Epoch 1411/2000, Train Loss: 0.0016, Test Loss: 0.1351\n",
      "Epoch 1412/2000, Train Loss: 0.0016, Test Loss: 0.1358\n",
      "Epoch 1413/2000, Train Loss: 0.0016, Test Loss: 0.1349\n",
      "Epoch 1414/2000, Train Loss: 0.0016, Test Loss: 0.1347\n",
      "Epoch 1415/2000, Train Loss: 0.0016, Test Loss: 0.1360\n",
      "Epoch 1416/2000, Train Loss: 0.0016, Test Loss: 0.1365\n",
      "Epoch 1417/2000, Train Loss: 0.0016, Test Loss: 0.1347\n",
      "Epoch 1418/2000, Train Loss: 0.0016, Test Loss: 0.1490\n",
      "Epoch 1419/2000, Train Loss: 0.0016, Test Loss: 0.1360\n",
      "Epoch 1420/2000, Train Loss: 0.0016, Test Loss: 0.1353\n",
      "Epoch 1421/2000, Train Loss: 0.0016, Test Loss: 0.1348\n",
      "Epoch 1422/2000, Train Loss: 0.0016, Test Loss: 0.1359\n",
      "Epoch 1423/2000, Train Loss: 0.0016, Test Loss: 0.1367\n",
      "Epoch 1424/2000, Train Loss: 0.0016, Test Loss: 0.1356\n",
      "Epoch 1425/2000, Train Loss: 0.0016, Test Loss: 0.1348\n",
      "Epoch 1426/2000, Train Loss: 0.0016, Test Loss: 0.1352\n",
      "Epoch 1427/2000, Train Loss: 0.0016, Test Loss: 0.1348\n",
      "Epoch 1428/2000, Train Loss: 0.0016, Test Loss: 0.1370\n",
      "Epoch 1429/2000, Train Loss: 0.0016, Test Loss: 0.1366\n",
      "Epoch 1430/2000, Train Loss: 0.0016, Test Loss: 0.1409\n",
      "Epoch 1431/2000, Train Loss: 0.0016, Test Loss: 0.1352\n",
      "Epoch 1432/2000, Train Loss: 0.0016, Test Loss: 0.1363\n",
      "Epoch 1433/2000, Train Loss: 0.0016, Test Loss: 0.1370\n",
      "Epoch 1434/2000, Train Loss: 0.0015, Test Loss: 0.1348\n",
      "Epoch 1435/2000, Train Loss: 0.0015, Test Loss: 0.1349\n",
      "Epoch 1436/2000, Train Loss: 0.0015, Test Loss: 0.1439\n",
      "Epoch 1437/2000, Train Loss: 0.0015, Test Loss: 0.1357\n",
      "Epoch 1438/2000, Train Loss: 0.0015, Test Loss: 0.1349\n",
      "Epoch 1439/2000, Train Loss: 0.0015, Test Loss: 0.1373\n",
      "Epoch 1440/2000, Train Loss: 0.0015, Test Loss: 0.1468\n",
      "Epoch 1441/2000, Train Loss: 0.0015, Test Loss: 0.1462\n",
      "Epoch 1442/2000, Train Loss: 0.0015, Test Loss: 0.1415\n",
      "Epoch 1443/2000, Train Loss: 0.0015, Test Loss: 0.1351\n",
      "Epoch 1444/2000, Train Loss: 0.0015, Test Loss: 0.1349\n",
      "Epoch 1445/2000, Train Loss: 0.0015, Test Loss: 0.1349\n",
      "Epoch 1446/2000, Train Loss: 0.0015, Test Loss: 0.1350\n",
      "Epoch 1447/2000, Train Loss: 0.0015, Test Loss: 0.1350\n",
      "Epoch 1448/2000, Train Loss: 0.0015, Test Loss: 0.1351\n",
      "Epoch 1449/2000, Train Loss: 0.0015, Test Loss: 0.1436\n",
      "Epoch 1450/2000, Train Loss: 0.0015, Test Loss: 0.1365\n",
      "Epoch 1451/2000, Train Loss: 0.0015, Test Loss: 0.1357\n",
      "Epoch 1452/2000, Train Loss: 0.0015, Test Loss: 0.1350\n",
      "Epoch 1453/2000, Train Loss: 0.0015, Test Loss: 0.1361\n",
      "Epoch 1454/2000, Train Loss: 0.0015, Test Loss: 0.1350\n",
      "Epoch 1455/2000, Train Loss: 0.0015, Test Loss: 0.1352\n",
      "Epoch 1456/2000, Train Loss: 0.0015, Test Loss: 0.1350\n",
      "Epoch 1457/2000, Train Loss: 0.0015, Test Loss: 0.1354\n",
      "Epoch 1458/2000, Train Loss: 0.0015, Test Loss: 0.1352\n",
      "Epoch 1459/2000, Train Loss: 0.0015, Test Loss: 0.1351\n",
      "Epoch 1460/2000, Train Loss: 0.0015, Test Loss: 0.1350\n",
      "Epoch 1461/2000, Train Loss: 0.0015, Test Loss: 0.1412\n",
      "Epoch 1462/2000, Train Loss: 0.0015, Test Loss: 0.1351\n",
      "Epoch 1463/2000, Train Loss: 0.0015, Test Loss: 0.1352\n",
      "Epoch 1464/2000, Train Loss: 0.0015, Test Loss: 0.1386\n",
      "Epoch 1465/2000, Train Loss: 0.0015, Test Loss: 0.1364\n",
      "Epoch 1466/2000, Train Loss: 0.0015, Test Loss: 0.1352\n",
      "Epoch 1467/2000, Train Loss: 0.0015, Test Loss: 0.1352\n",
      "Epoch 1468/2000, Train Loss: 0.0015, Test Loss: 0.1351\n",
      "Epoch 1469/2000, Train Loss: 0.0015, Test Loss: 0.1380\n",
      "Epoch 1470/2000, Train Loss: 0.0015, Test Loss: 0.1351\n",
      "Epoch 1471/2000, Train Loss: 0.0015, Test Loss: 0.1351\n",
      "Epoch 1472/2000, Train Loss: 0.0015, Test Loss: 0.1352\n",
      "Epoch 1473/2000, Train Loss: 0.0015, Test Loss: 0.1353\n",
      "Epoch 1474/2000, Train Loss: 0.0015, Test Loss: 0.1415\n",
      "Epoch 1475/2000, Train Loss: 0.0015, Test Loss: 0.1458\n",
      "Epoch 1476/2000, Train Loss: 0.0015, Test Loss: 0.1366\n",
      "Epoch 1477/2000, Train Loss: 0.0015, Test Loss: 0.1376\n",
      "Epoch 1478/2000, Train Loss: 0.0015, Test Loss: 0.1439\n",
      "Epoch 1479/2000, Train Loss: 0.0015, Test Loss: 0.1354\n",
      "Epoch 1480/2000, Train Loss: 0.0015, Test Loss: 0.1437\n",
      "Epoch 1481/2000, Train Loss: 0.0015, Test Loss: 0.1374\n",
      "Epoch 1482/2000, Train Loss: 0.0015, Test Loss: 0.1354\n",
      "Epoch 1483/2000, Train Loss: 0.0015, Test Loss: 0.1353\n",
      "Epoch 1484/2000, Train Loss: 0.0015, Test Loss: 0.1353\n",
      "Epoch 1485/2000, Train Loss: 0.0015, Test Loss: 0.1354\n",
      "Epoch 1486/2000, Train Loss: 0.0015, Test Loss: 0.1354\n",
      "Epoch 1487/2000, Train Loss: 0.0015, Test Loss: 0.1380\n",
      "Epoch 1488/2000, Train Loss: 0.0015, Test Loss: 0.1355\n",
      "Epoch 1489/2000, Train Loss: 0.0015, Test Loss: 0.1376\n",
      "Epoch 1490/2000, Train Loss: 0.0015, Test Loss: 0.1369\n",
      "Epoch 1491/2000, Train Loss: 0.0015, Test Loss: 0.1414\n",
      "Epoch 1492/2000, Train Loss: 0.0015, Test Loss: 0.1387\n",
      "Epoch 1493/2000, Train Loss: 0.0015, Test Loss: 0.1355\n",
      "Epoch 1494/2000, Train Loss: 0.0015, Test Loss: 0.1355\n",
      "Epoch 1495/2000, Train Loss: 0.0015, Test Loss: 0.1375\n",
      "Epoch 1496/2000, Train Loss: 0.0015, Test Loss: 0.1355\n",
      "Epoch 1497/2000, Train Loss: 0.0015, Test Loss: 0.1355\n",
      "Epoch 1498/2000, Train Loss: 0.0015, Test Loss: 0.1400\n",
      "Epoch 1499/2000, Train Loss: 0.0015, Test Loss: 0.1415\n",
      "Epoch 1500/2000, Train Loss: 0.0015, Test Loss: 0.1355\n",
      "Epoch 1501/2000, Train Loss: 0.0015, Test Loss: 0.1363\n",
      "Epoch 1502/2000, Train Loss: 0.0015, Test Loss: 0.1424\n",
      "Epoch 1503/2000, Train Loss: 0.0015, Test Loss: 0.1377\n",
      "Epoch 1504/2000, Train Loss: 0.0015, Test Loss: 0.1362\n",
      "Epoch 1505/2000, Train Loss: 0.0015, Test Loss: 0.1355\n",
      "Epoch 1506/2000, Train Loss: 0.0015, Test Loss: 0.1356\n",
      "Epoch 1507/2000, Train Loss: 0.0015, Test Loss: 0.1356\n",
      "Epoch 1508/2000, Train Loss: 0.0015, Test Loss: 0.1369\n",
      "Epoch 1509/2000, Train Loss: 0.0015, Test Loss: 0.1357\n",
      "Epoch 1510/2000, Train Loss: 0.0015, Test Loss: 0.1355\n",
      "Epoch 1511/2000, Train Loss: 0.0015, Test Loss: 0.1356\n",
      "Epoch 1512/2000, Train Loss: 0.0015, Test Loss: 0.1365\n",
      "Epoch 1513/2000, Train Loss: 0.0015, Test Loss: 0.1394\n",
      "Epoch 1514/2000, Train Loss: 0.0015, Test Loss: 0.1356\n",
      "Epoch 1515/2000, Train Loss: 0.0015, Test Loss: 0.1356\n",
      "Epoch 1516/2000, Train Loss: 0.0015, Test Loss: 0.1386\n",
      "Epoch 1517/2000, Train Loss: 0.0015, Test Loss: 0.1361\n",
      "Epoch 1518/2000, Train Loss: 0.0015, Test Loss: 0.1370\n",
      "Epoch 1519/2000, Train Loss: 0.0015, Test Loss: 0.1371\n",
      "Epoch 1520/2000, Train Loss: 0.0015, Test Loss: 0.1406\n",
      "Epoch 1521/2000, Train Loss: 0.0015, Test Loss: 0.1358\n",
      "Epoch 1522/2000, Train Loss: 0.0015, Test Loss: 0.1380\n",
      "Epoch 1523/2000, Train Loss: 0.0015, Test Loss: 0.1358\n",
      "Epoch 1524/2000, Train Loss: 0.0015, Test Loss: 0.1357\n",
      "Epoch 1525/2000, Train Loss: 0.0015, Test Loss: 0.1382\n",
      "Epoch 1526/2000, Train Loss: 0.0015, Test Loss: 0.1364\n",
      "Epoch 1527/2000, Train Loss: 0.0015, Test Loss: 0.1403\n",
      "Epoch 1528/2000, Train Loss: 0.0015, Test Loss: 0.1358\n",
      "Epoch 1529/2000, Train Loss: 0.0015, Test Loss: 0.1392\n",
      "Epoch 1530/2000, Train Loss: 0.0015, Test Loss: 0.1367\n",
      "Epoch 1531/2000, Train Loss: 0.0015, Test Loss: 0.1371\n",
      "Epoch 1532/2000, Train Loss: 0.0015, Test Loss: 0.1361\n",
      "Epoch 1533/2000, Train Loss: 0.0015, Test Loss: 0.1378\n",
      "Epoch 1534/2000, Train Loss: 0.0015, Test Loss: 0.1360\n",
      "Epoch 1535/2000, Train Loss: 0.0015, Test Loss: 0.1363\n",
      "Epoch 1536/2000, Train Loss: 0.0015, Test Loss: 0.1403\n",
      "Epoch 1537/2000, Train Loss: 0.0015, Test Loss: 0.1358\n",
      "Epoch 1538/2000, Train Loss: 0.0015, Test Loss: 0.1358\n",
      "Epoch 1539/2000, Train Loss: 0.0015, Test Loss: 0.1358\n",
      "Epoch 1540/2000, Train Loss: 0.0015, Test Loss: 0.1426\n",
      "Epoch 1541/2000, Train Loss: 0.0015, Test Loss: 0.1359\n",
      "Epoch 1542/2000, Train Loss: 0.0015, Test Loss: 0.1360\n",
      "Epoch 1543/2000, Train Loss: 0.0015, Test Loss: 0.1395\n",
      "Epoch 1544/2000, Train Loss: 0.0015, Test Loss: 0.1381\n",
      "Epoch 1545/2000, Train Loss: 0.0015, Test Loss: 0.1390\n",
      "Epoch 1546/2000, Train Loss: 0.0015, Test Loss: 0.1400\n",
      "Epoch 1547/2000, Train Loss: 0.0015, Test Loss: 0.1471\n",
      "Epoch 1548/2000, Train Loss: 0.0015, Test Loss: 0.1382\n",
      "Epoch 1549/2000, Train Loss: 0.0015, Test Loss: 0.1360\n",
      "Epoch 1550/2000, Train Loss: 0.0015, Test Loss: 0.1415\n",
      "Epoch 1551/2000, Train Loss: 0.0015, Test Loss: 0.1365\n",
      "Epoch 1552/2000, Train Loss: 0.0015, Test Loss: 0.1360\n",
      "Epoch 1553/2000, Train Loss: 0.0015, Test Loss: 0.1362\n",
      "Epoch 1554/2000, Train Loss: 0.0015, Test Loss: 0.1360\n",
      "Epoch 1555/2000, Train Loss: 0.0015, Test Loss: 0.1396\n",
      "Epoch 1556/2000, Train Loss: 0.0015, Test Loss: 0.1421\n",
      "Epoch 1557/2000, Train Loss: 0.0015, Test Loss: 0.1360\n",
      "Epoch 1558/2000, Train Loss: 0.0015, Test Loss: 0.1359\n",
      "Epoch 1559/2000, Train Loss: 0.0015, Test Loss: 0.1421\n",
      "Epoch 1560/2000, Train Loss: 0.0015, Test Loss: 0.1362\n",
      "Epoch 1561/2000, Train Loss: 0.0015, Test Loss: 0.1393\n",
      "Epoch 1562/2000, Train Loss: 0.0015, Test Loss: 0.1366\n",
      "Epoch 1563/2000, Train Loss: 0.0014, Test Loss: 0.1369\n",
      "Epoch 1564/2000, Train Loss: 0.0015, Test Loss: 0.1363\n",
      "Epoch 1565/2000, Train Loss: 0.0014, Test Loss: 0.1361\n",
      "Epoch 1566/2000, Train Loss: 0.0014, Test Loss: 0.1361\n",
      "Epoch 1567/2000, Train Loss: 0.0014, Test Loss: 0.1360\n",
      "Epoch 1568/2000, Train Loss: 0.0014, Test Loss: 0.1361\n",
      "Epoch 1569/2000, Train Loss: 0.0014, Test Loss: 0.1367\n",
      "Epoch 1570/2000, Train Loss: 0.0014, Test Loss: 0.1361\n",
      "Epoch 1571/2000, Train Loss: 0.0014, Test Loss: 0.1361\n",
      "Epoch 1572/2000, Train Loss: 0.0014, Test Loss: 0.1361\n",
      "Epoch 1573/2000, Train Loss: 0.0014, Test Loss: 0.1386\n",
      "Epoch 1574/2000, Train Loss: 0.0014, Test Loss: 0.1361\n",
      "Epoch 1575/2000, Train Loss: 0.0014, Test Loss: 0.1361\n",
      "Epoch 1576/2000, Train Loss: 0.0014, Test Loss: 0.1476\n",
      "Epoch 1577/2000, Train Loss: 0.0014, Test Loss: 0.1361\n",
      "Epoch 1578/2000, Train Loss: 0.0014, Test Loss: 0.1362\n",
      "Epoch 1579/2000, Train Loss: 0.0014, Test Loss: 0.1405\n",
      "Epoch 1580/2000, Train Loss: 0.0014, Test Loss: 0.1362\n",
      "Epoch 1581/2000, Train Loss: 0.0014, Test Loss: 0.1362\n",
      "Epoch 1582/2000, Train Loss: 0.0014, Test Loss: 0.1364\n",
      "Epoch 1583/2000, Train Loss: 0.0014, Test Loss: 0.1373\n",
      "Epoch 1584/2000, Train Loss: 0.0014, Test Loss: 0.1361\n",
      "Epoch 1585/2000, Train Loss: 0.0014, Test Loss: 0.1363\n",
      "Epoch 1586/2000, Train Loss: 0.0014, Test Loss: 0.1362\n",
      "Epoch 1587/2000, Train Loss: 0.0014, Test Loss: 0.1362\n",
      "Epoch 1588/2000, Train Loss: 0.0014, Test Loss: 0.1362\n",
      "Epoch 1589/2000, Train Loss: 0.0014, Test Loss: 0.1363\n",
      "Epoch 1590/2000, Train Loss: 0.0014, Test Loss: 0.1381\n",
      "Epoch 1591/2000, Train Loss: 0.0014, Test Loss: 0.1363\n",
      "Epoch 1592/2000, Train Loss: 0.0014, Test Loss: 0.1531\n",
      "Epoch 1593/2000, Train Loss: 0.0014, Test Loss: 0.1406\n",
      "Epoch 1594/2000, Train Loss: 0.0014, Test Loss: 0.1365\n",
      "Epoch 1595/2000, Train Loss: 0.0014, Test Loss: 0.1362\n",
      "Epoch 1596/2000, Train Loss: 0.0014, Test Loss: 0.1362\n",
      "Epoch 1597/2000, Train Loss: 0.0014, Test Loss: 0.1370\n",
      "Epoch 1598/2000, Train Loss: 0.0014, Test Loss: 0.1398\n",
      "Epoch 1599/2000, Train Loss: 0.0014, Test Loss: 0.1364\n",
      "Epoch 1600/2000, Train Loss: 0.0014, Test Loss: 0.1364\n",
      "Epoch 1601/2000, Train Loss: 0.0014, Test Loss: 0.1363\n",
      "Epoch 1602/2000, Train Loss: 0.0014, Test Loss: 0.1363\n",
      "Epoch 1603/2000, Train Loss: 0.0014, Test Loss: 0.1363\n",
      "Epoch 1604/2000, Train Loss: 0.0014, Test Loss: 0.1379\n",
      "Epoch 1605/2000, Train Loss: 0.0014, Test Loss: 0.1384\n",
      "Epoch 1606/2000, Train Loss: 0.0014, Test Loss: 0.1366\n",
      "Epoch 1607/2000, Train Loss: 0.0014, Test Loss: 0.1369\n",
      "Epoch 1608/2000, Train Loss: 0.0014, Test Loss: 0.1365\n",
      "Epoch 1609/2000, Train Loss: 0.0014, Test Loss: 0.1365\n",
      "Epoch 1610/2000, Train Loss: 0.0014, Test Loss: 0.1364\n",
      "Epoch 1611/2000, Train Loss: 0.0014, Test Loss: 0.1364\n",
      "Epoch 1612/2000, Train Loss: 0.0014, Test Loss: 0.1376\n",
      "Epoch 1613/2000, Train Loss: 0.0014, Test Loss: 0.1411\n",
      "Epoch 1614/2000, Train Loss: 0.0014, Test Loss: 0.1391\n",
      "Epoch 1615/2000, Train Loss: 0.0014, Test Loss: 0.1364\n",
      "Epoch 1616/2000, Train Loss: 0.0014, Test Loss: 0.1385\n",
      "Epoch 1617/2000, Train Loss: 0.0014, Test Loss: 0.1365\n",
      "Epoch 1618/2000, Train Loss: 0.0014, Test Loss: 0.1372\n",
      "Epoch 1619/2000, Train Loss: 0.0014, Test Loss: 0.1385\n",
      "Epoch 1620/2000, Train Loss: 0.0014, Test Loss: 0.1363\n",
      "Epoch 1621/2000, Train Loss: 0.0014, Test Loss: 0.1381\n",
      "Epoch 1622/2000, Train Loss: 0.0014, Test Loss: 0.1404\n",
      "Epoch 1623/2000, Train Loss: 0.0014, Test Loss: 0.1365\n",
      "Epoch 1624/2000, Train Loss: 0.0014, Test Loss: 0.1373\n",
      "Epoch 1625/2000, Train Loss: 0.0014, Test Loss: 0.1366\n",
      "Epoch 1626/2000, Train Loss: 0.0014, Test Loss: 0.1391\n",
      "Epoch 1627/2000, Train Loss: 0.0014, Test Loss: 0.1369\n",
      "Epoch 1628/2000, Train Loss: 0.0014, Test Loss: 0.1382\n",
      "Epoch 1629/2000, Train Loss: 0.0014, Test Loss: 0.1412\n",
      "Epoch 1630/2000, Train Loss: 0.0014, Test Loss: 0.1366\n",
      "Epoch 1631/2000, Train Loss: 0.0014, Test Loss: 0.1367\n",
      "Epoch 1632/2000, Train Loss: 0.0014, Test Loss: 0.1365\n",
      "Epoch 1633/2000, Train Loss: 0.0014, Test Loss: 0.1370\n",
      "Epoch 1634/2000, Train Loss: 0.0014, Test Loss: 0.1366\n",
      "Epoch 1635/2000, Train Loss: 0.0014, Test Loss: 0.1367\n",
      "Epoch 1636/2000, Train Loss: 0.0014, Test Loss: 0.1440\n",
      "Epoch 1637/2000, Train Loss: 0.0014, Test Loss: 0.1366\n",
      "Epoch 1638/2000, Train Loss: 0.0014, Test Loss: 0.1366\n",
      "Epoch 1639/2000, Train Loss: 0.0014, Test Loss: 0.1389\n",
      "Epoch 1640/2000, Train Loss: 0.0014, Test Loss: 0.1475\n",
      "Epoch 1641/2000, Train Loss: 0.0014, Test Loss: 0.1368\n",
      "Epoch 1642/2000, Train Loss: 0.0014, Test Loss: 0.1366\n",
      "Epoch 1643/2000, Train Loss: 0.0014, Test Loss: 0.1369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1644/2000, Train Loss: 0.0014, Test Loss: 0.1367\n",
      "Epoch 1645/2000, Train Loss: 0.0014, Test Loss: 0.1367\n",
      "Epoch 1646/2000, Train Loss: 0.0014, Test Loss: 0.1367\n",
      "Epoch 1647/2000, Train Loss: 0.0014, Test Loss: 0.1374\n",
      "Epoch 1648/2000, Train Loss: 0.0014, Test Loss: 0.1368\n",
      "Epoch 1649/2000, Train Loss: 0.0014, Test Loss: 0.1370\n",
      "Epoch 1650/2000, Train Loss: 0.0014, Test Loss: 0.1475\n",
      "Epoch 1651/2000, Train Loss: 0.0014, Test Loss: 0.1368\n",
      "Epoch 1652/2000, Train Loss: 0.0014, Test Loss: 0.1378\n",
      "Epoch 1653/2000, Train Loss: 0.0014, Test Loss: 0.1378\n",
      "Epoch 1654/2000, Train Loss: 0.0014, Test Loss: 0.1429\n",
      "Epoch 1655/2000, Train Loss: 0.0014, Test Loss: 0.1368\n",
      "Epoch 1656/2000, Train Loss: 0.0014, Test Loss: 0.1368\n",
      "Epoch 1657/2000, Train Loss: 0.0014, Test Loss: 0.1378\n",
      "Epoch 1658/2000, Train Loss: 0.0014, Test Loss: 0.1373\n",
      "Epoch 1659/2000, Train Loss: 0.0014, Test Loss: 0.1369\n",
      "Epoch 1660/2000, Train Loss: 0.0014, Test Loss: 0.1368\n",
      "Epoch 1661/2000, Train Loss: 0.0014, Test Loss: 0.1368\n",
      "Epoch 1662/2000, Train Loss: 0.0014, Test Loss: 0.1367\n",
      "Epoch 1663/2000, Train Loss: 0.0014, Test Loss: 0.1391\n",
      "Epoch 1664/2000, Train Loss: 0.0014, Test Loss: 0.1377\n",
      "Epoch 1665/2000, Train Loss: 0.0014, Test Loss: 0.1370\n",
      "Epoch 1666/2000, Train Loss: 0.0014, Test Loss: 0.1369\n",
      "Epoch 1667/2000, Train Loss: 0.0014, Test Loss: 0.1383\n",
      "Epoch 1668/2000, Train Loss: 0.0014, Test Loss: 0.1380\n",
      "Epoch 1669/2000, Train Loss: 0.0014, Test Loss: 0.1374\n",
      "Epoch 1670/2000, Train Loss: 0.0014, Test Loss: 0.1370\n",
      "Epoch 1671/2000, Train Loss: 0.0014, Test Loss: 0.1372\n",
      "Epoch 1672/2000, Train Loss: 0.0014, Test Loss: 0.1368\n",
      "Epoch 1673/2000, Train Loss: 0.0014, Test Loss: 0.1369\n",
      "Epoch 1674/2000, Train Loss: 0.0014, Test Loss: 0.1369\n",
      "Epoch 1675/2000, Train Loss: 0.0014, Test Loss: 0.1419\n",
      "Epoch 1676/2000, Train Loss: 0.0014, Test Loss: 0.1369\n",
      "Epoch 1677/2000, Train Loss: 0.0014, Test Loss: 0.1379\n",
      "Epoch 1678/2000, Train Loss: 0.0014, Test Loss: 0.1422\n",
      "Epoch 1679/2000, Train Loss: 0.0014, Test Loss: 0.1374\n",
      "Epoch 1680/2000, Train Loss: 0.0014, Test Loss: 0.1369\n",
      "Epoch 1681/2000, Train Loss: 0.0014, Test Loss: 0.1433\n",
      "Epoch 1682/2000, Train Loss: 0.0014, Test Loss: 0.1384\n",
      "Epoch 1683/2000, Train Loss: 0.0014, Test Loss: 0.1385\n",
      "Epoch 1684/2000, Train Loss: 0.0014, Test Loss: 0.1370\n",
      "Epoch 1685/2000, Train Loss: 0.0014, Test Loss: 0.1370\n",
      "Epoch 1686/2000, Train Loss: 0.0014, Test Loss: 0.1430\n",
      "Epoch 1687/2000, Train Loss: 0.0014, Test Loss: 0.1383\n",
      "Epoch 1688/2000, Train Loss: 0.0014, Test Loss: 0.1375\n",
      "Epoch 1689/2000, Train Loss: 0.0014, Test Loss: 0.1371\n",
      "Epoch 1690/2000, Train Loss: 0.0014, Test Loss: 0.1415\n",
      "Epoch 1691/2000, Train Loss: 0.0014, Test Loss: 0.1371\n",
      "Epoch 1692/2000, Train Loss: 0.0014, Test Loss: 0.1371\n",
      "Epoch 1693/2000, Train Loss: 0.0014, Test Loss: 0.1371\n",
      "Epoch 1694/2000, Train Loss: 0.0014, Test Loss: 0.1459\n",
      "Epoch 1695/2000, Train Loss: 0.0014, Test Loss: 0.1371\n",
      "Epoch 1696/2000, Train Loss: 0.0014, Test Loss: 0.1373\n",
      "Epoch 1697/2000, Train Loss: 0.0014, Test Loss: 0.1371\n",
      "Epoch 1698/2000, Train Loss: 0.0014, Test Loss: 0.1372\n",
      "Epoch 1699/2000, Train Loss: 0.0014, Test Loss: 0.1372\n",
      "Epoch 1700/2000, Train Loss: 0.0014, Test Loss: 0.1371\n",
      "Epoch 1701/2000, Train Loss: 0.0014, Test Loss: 0.1373\n",
      "Epoch 1702/2000, Train Loss: 0.0014, Test Loss: 0.1380\n",
      "Epoch 1703/2000, Train Loss: 0.0014, Test Loss: 0.1393\n",
      "Epoch 1704/2000, Train Loss: 0.0014, Test Loss: 0.1380\n",
      "Epoch 1705/2000, Train Loss: 0.0014, Test Loss: 0.1371\n",
      "Epoch 1706/2000, Train Loss: 0.0014, Test Loss: 0.1372\n",
      "Epoch 1707/2000, Train Loss: 0.0014, Test Loss: 0.1427\n",
      "Epoch 1708/2000, Train Loss: 0.0014, Test Loss: 0.1450\n",
      "Epoch 1709/2000, Train Loss: 0.0014, Test Loss: 0.1374\n",
      "Epoch 1710/2000, Train Loss: 0.0014, Test Loss: 0.1398\n",
      "Epoch 1711/2000, Train Loss: 0.0014, Test Loss: 0.1372\n",
      "Epoch 1712/2000, Train Loss: 0.0014, Test Loss: 0.1372\n",
      "Epoch 1713/2000, Train Loss: 0.0013, Test Loss: 0.1397\n",
      "Epoch 1714/2000, Train Loss: 0.0013, Test Loss: 0.1372\n",
      "Epoch 1715/2000, Train Loss: 0.0013, Test Loss: 0.1373\n",
      "Epoch 1716/2000, Train Loss: 0.0013, Test Loss: 0.1374\n",
      "Epoch 1717/2000, Train Loss: 0.0013, Test Loss: 0.1373\n",
      "Epoch 1718/2000, Train Loss: 0.0013, Test Loss: 0.1517\n",
      "Epoch 1719/2000, Train Loss: 0.0013, Test Loss: 0.1373\n",
      "Epoch 1720/2000, Train Loss: 0.0013, Test Loss: 0.1384\n",
      "Epoch 1721/2000, Train Loss: 0.0013, Test Loss: 0.1532\n",
      "Epoch 1722/2000, Train Loss: 0.0013, Test Loss: 0.1404\n",
      "Epoch 1723/2000, Train Loss: 0.0013, Test Loss: 0.1378\n",
      "Epoch 1724/2000, Train Loss: 0.0013, Test Loss: 0.1391\n",
      "Epoch 1725/2000, Train Loss: 0.0013, Test Loss: 0.1374\n",
      "Epoch 1726/2000, Train Loss: 0.0013, Test Loss: 0.1374\n",
      "Epoch 1727/2000, Train Loss: 0.0013, Test Loss: 0.1376\n",
      "Epoch 1728/2000, Train Loss: 0.0013, Test Loss: 0.1374\n",
      "Epoch 1729/2000, Train Loss: 0.0013, Test Loss: 0.1373\n",
      "Epoch 1730/2000, Train Loss: 0.0013, Test Loss: 0.1392\n",
      "Epoch 1731/2000, Train Loss: 0.0013, Test Loss: 0.1374\n",
      "Epoch 1732/2000, Train Loss: 0.0013, Test Loss: 0.1375\n",
      "Epoch 1733/2000, Train Loss: 0.0013, Test Loss: 0.1374\n",
      "Epoch 1734/2000, Train Loss: 0.0013, Test Loss: 0.1374\n",
      "Epoch 1735/2000, Train Loss: 0.0013, Test Loss: 0.1375\n",
      "Epoch 1736/2000, Train Loss: 0.0013, Test Loss: 0.1408\n",
      "Epoch 1737/2000, Train Loss: 0.0013, Test Loss: 0.1376\n",
      "Epoch 1738/2000, Train Loss: 0.0013, Test Loss: 0.1401\n",
      "Epoch 1739/2000, Train Loss: 0.0013, Test Loss: 0.1443\n",
      "Epoch 1740/2000, Train Loss: 0.0013, Test Loss: 0.1434\n",
      "Epoch 1741/2000, Train Loss: 0.0013, Test Loss: 0.1440\n",
      "Epoch 1742/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1743/2000, Train Loss: 0.0013, Test Loss: 0.1404\n",
      "Epoch 1744/2000, Train Loss: 0.0013, Test Loss: 0.1414\n",
      "Epoch 1745/2000, Train Loss: 0.0013, Test Loss: 0.1404\n",
      "Epoch 1746/2000, Train Loss: 0.0013, Test Loss: 0.1375\n",
      "Epoch 1747/2000, Train Loss: 0.0013, Test Loss: 0.1375\n",
      "Epoch 1748/2000, Train Loss: 0.0013, Test Loss: 0.1376\n",
      "Epoch 1749/2000, Train Loss: 0.0013, Test Loss: 0.1375\n",
      "Epoch 1750/2000, Train Loss: 0.0013, Test Loss: 0.1375\n",
      "Epoch 1751/2000, Train Loss: 0.0013, Test Loss: 0.1376\n",
      "Epoch 1752/2000, Train Loss: 0.0013, Test Loss: 0.1444\n",
      "Epoch 1753/2000, Train Loss: 0.0013, Test Loss: 0.1375\n",
      "Epoch 1754/2000, Train Loss: 0.0013, Test Loss: 0.1388\n",
      "Epoch 1755/2000, Train Loss: 0.0013, Test Loss: 0.1418\n",
      "Epoch 1756/2000, Train Loss: 0.0013, Test Loss: 0.1454\n",
      "Epoch 1757/2000, Train Loss: 0.0013, Test Loss: 0.1376\n",
      "Epoch 1758/2000, Train Loss: 0.0013, Test Loss: 0.1375\n",
      "Epoch 1759/2000, Train Loss: 0.0013, Test Loss: 0.1424\n",
      "Epoch 1760/2000, Train Loss: 0.0013, Test Loss: 0.1402\n",
      "Epoch 1761/2000, Train Loss: 0.0013, Test Loss: 0.1375\n",
      "Epoch 1762/2000, Train Loss: 0.0013, Test Loss: 0.1379\n",
      "Epoch 1763/2000, Train Loss: 0.0013, Test Loss: 0.1376\n",
      "Epoch 1764/2000, Train Loss: 0.0013, Test Loss: 0.1376\n",
      "Epoch 1765/2000, Train Loss: 0.0013, Test Loss: 0.1436\n",
      "Epoch 1766/2000, Train Loss: 0.0013, Test Loss: 0.1377\n",
      "Epoch 1767/2000, Train Loss: 0.0013, Test Loss: 0.1469\n",
      "Epoch 1768/2000, Train Loss: 0.0013, Test Loss: 0.1377\n",
      "Epoch 1769/2000, Train Loss: 0.0013, Test Loss: 0.1402\n",
      "Epoch 1770/2000, Train Loss: 0.0013, Test Loss: 0.1465\n",
      "Epoch 1771/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1772/2000, Train Loss: 0.0013, Test Loss: 0.1378\n",
      "Epoch 1773/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1774/2000, Train Loss: 0.0013, Test Loss: 0.1426\n",
      "Epoch 1775/2000, Train Loss: 0.0013, Test Loss: 0.1378\n",
      "Epoch 1776/2000, Train Loss: 0.0013, Test Loss: 0.1400\n",
      "Epoch 1777/2000, Train Loss: 0.0013, Test Loss: 0.1451\n",
      "Epoch 1778/2000, Train Loss: 0.0013, Test Loss: 0.1386\n",
      "Epoch 1779/2000, Train Loss: 0.0013, Test Loss: 0.1419\n",
      "Epoch 1780/2000, Train Loss: 0.0013, Test Loss: 0.1414\n",
      "Epoch 1781/2000, Train Loss: 0.0013, Test Loss: 0.1378\n",
      "Epoch 1782/2000, Train Loss: 0.0013, Test Loss: 0.1378\n",
      "Epoch 1783/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1784/2000, Train Loss: 0.0013, Test Loss: 0.1384\n",
      "Epoch 1785/2000, Train Loss: 0.0013, Test Loss: 0.1427\n",
      "Epoch 1786/2000, Train Loss: 0.0013, Test Loss: 0.1399\n",
      "Epoch 1787/2000, Train Loss: 0.0013, Test Loss: 0.1451\n",
      "Epoch 1788/2000, Train Loss: 0.0013, Test Loss: 0.1379\n",
      "Epoch 1789/2000, Train Loss: 0.0013, Test Loss: 0.1406\n",
      "Epoch 1790/2000, Train Loss: 0.0013, Test Loss: 0.1442\n",
      "Epoch 1791/2000, Train Loss: 0.0013, Test Loss: 0.1390\n",
      "Epoch 1792/2000, Train Loss: 0.0013, Test Loss: 0.1401\n",
      "Epoch 1793/2000, Train Loss: 0.0013, Test Loss: 0.1380\n",
      "Epoch 1794/2000, Train Loss: 0.0013, Test Loss: 0.1379\n",
      "Epoch 1795/2000, Train Loss: 0.0013, Test Loss: 0.1379\n",
      "Epoch 1796/2000, Train Loss: 0.0013, Test Loss: 0.1379\n",
      "Epoch 1797/2000, Train Loss: 0.0013, Test Loss: 0.1380\n",
      "Epoch 1798/2000, Train Loss: 0.0013, Test Loss: 0.1380\n",
      "Epoch 1799/2000, Train Loss: 0.0013, Test Loss: 0.1379\n",
      "Epoch 1800/2000, Train Loss: 0.0013, Test Loss: 0.1380\n",
      "Epoch 1801/2000, Train Loss: 0.0013, Test Loss: 0.1388\n",
      "Epoch 1802/2000, Train Loss: 0.0013, Test Loss: 0.1383\n",
      "Epoch 1803/2000, Train Loss: 0.0013, Test Loss: 0.1379\n",
      "Epoch 1804/2000, Train Loss: 0.0013, Test Loss: 0.1400\n",
      "Epoch 1805/2000, Train Loss: 0.0013, Test Loss: 0.1383\n",
      "Epoch 1806/2000, Train Loss: 0.0013, Test Loss: 0.1389\n",
      "Epoch 1807/2000, Train Loss: 0.0013, Test Loss: 0.1405\n",
      "Epoch 1808/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1809/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1810/2000, Train Loss: 0.0013, Test Loss: 0.1434\n",
      "Epoch 1811/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1812/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1813/2000, Train Loss: 0.0013, Test Loss: 0.1397\n",
      "Epoch 1814/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1815/2000, Train Loss: 0.0013, Test Loss: 0.1380\n",
      "Epoch 1816/2000, Train Loss: 0.0013, Test Loss: 0.1405\n",
      "Epoch 1817/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1818/2000, Train Loss: 0.0013, Test Loss: 0.1410\n",
      "Epoch 1819/2000, Train Loss: 0.0013, Test Loss: 0.1382\n",
      "Epoch 1820/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1821/2000, Train Loss: 0.0013, Test Loss: 0.1387\n",
      "Epoch 1822/2000, Train Loss: 0.0013, Test Loss: 0.1382\n",
      "Epoch 1823/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1824/2000, Train Loss: 0.0013, Test Loss: 0.1382\n",
      "Epoch 1825/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1826/2000, Train Loss: 0.0013, Test Loss: 0.1380\n",
      "Epoch 1827/2000, Train Loss: 0.0013, Test Loss: 0.1382\n",
      "Epoch 1828/2000, Train Loss: 0.0013, Test Loss: 0.1381\n",
      "Epoch 1829/2000, Train Loss: 0.0013, Test Loss: 0.1399\n",
      "Epoch 1830/2000, Train Loss: 0.0013, Test Loss: 0.1385\n",
      "Epoch 1831/2000, Train Loss: 0.0013, Test Loss: 0.1426\n",
      "Epoch 1832/2000, Train Loss: 0.0013, Test Loss: 0.1391\n",
      "Epoch 1833/2000, Train Loss: 0.0013, Test Loss: 0.1383\n",
      "Epoch 1834/2000, Train Loss: 0.0013, Test Loss: 0.1382\n",
      "Epoch 1835/2000, Train Loss: 0.0013, Test Loss: 0.1495\n",
      "Epoch 1836/2000, Train Loss: 0.0013, Test Loss: 0.1383\n",
      "Epoch 1837/2000, Train Loss: 0.0013, Test Loss: 0.1382\n",
      "Epoch 1838/2000, Train Loss: 0.0013, Test Loss: 0.1395\n",
      "Epoch 1839/2000, Train Loss: 0.0013, Test Loss: 0.1382\n",
      "Epoch 1840/2000, Train Loss: 0.0013, Test Loss: 0.1383\n",
      "Epoch 1841/2000, Train Loss: 0.0013, Test Loss: 0.1401\n",
      "Epoch 1842/2000, Train Loss: 0.0013, Test Loss: 0.1403\n",
      "Epoch 1843/2000, Train Loss: 0.0013, Test Loss: 0.1382\n",
      "Epoch 1844/2000, Train Loss: 0.0013, Test Loss: 0.1383\n",
      "Epoch 1845/2000, Train Loss: 0.0013, Test Loss: 0.1501\n",
      "Epoch 1846/2000, Train Loss: 0.0013, Test Loss: 0.1382\n",
      "Epoch 1847/2000, Train Loss: 0.0013, Test Loss: 0.1423\n",
      "Epoch 1848/2000, Train Loss: 0.0013, Test Loss: 0.1382\n",
      "Epoch 1849/2000, Train Loss: 0.0013, Test Loss: 0.1382\n",
      "Epoch 1850/2000, Train Loss: 0.0013, Test Loss: 0.1383\n",
      "Epoch 1851/2000, Train Loss: 0.0013, Test Loss: 0.1384\n",
      "Epoch 1852/2000, Train Loss: 0.0013, Test Loss: 0.1409\n",
      "Epoch 1853/2000, Train Loss: 0.0013, Test Loss: 0.1415\n",
      "Epoch 1854/2000, Train Loss: 0.0013, Test Loss: 0.1391\n",
      "Epoch 1855/2000, Train Loss: 0.0013, Test Loss: 0.1463\n",
      "Epoch 1856/2000, Train Loss: 0.0013, Test Loss: 0.1383\n",
      "Epoch 1857/2000, Train Loss: 0.0013, Test Loss: 0.1383\n",
      "Epoch 1858/2000, Train Loss: 0.0013, Test Loss: 0.1432\n",
      "Epoch 1859/2000, Train Loss: 0.0013, Test Loss: 0.1386\n",
      "Epoch 1860/2000, Train Loss: 0.0013, Test Loss: 0.1384\n",
      "Epoch 1861/2000, Train Loss: 0.0013, Test Loss: 0.1383\n",
      "Epoch 1862/2000, Train Loss: 0.0013, Test Loss: 0.1383\n",
      "Epoch 1863/2000, Train Loss: 0.0013, Test Loss: 0.1467\n",
      "Epoch 1864/2000, Train Loss: 0.0013, Test Loss: 0.1384\n",
      "Epoch 1865/2000, Train Loss: 0.0013, Test Loss: 0.1384\n",
      "Epoch 1866/2000, Train Loss: 0.0013, Test Loss: 0.1383\n",
      "Epoch 1867/2000, Train Loss: 0.0013, Test Loss: 0.1389\n",
      "Epoch 1868/2000, Train Loss: 0.0013, Test Loss: 0.1466\n",
      "Epoch 1869/2000, Train Loss: 0.0013, Test Loss: 0.1393\n",
      "Epoch 1870/2000, Train Loss: 0.0013, Test Loss: 0.1385\n",
      "Epoch 1871/2000, Train Loss: 0.0013, Test Loss: 0.1385\n",
      "Epoch 1872/2000, Train Loss: 0.0013, Test Loss: 0.1466\n",
      "Epoch 1873/2000, Train Loss: 0.0013, Test Loss: 0.1385\n",
      "Epoch 1874/2000, Train Loss: 0.0013, Test Loss: 0.1409\n",
      "Epoch 1875/2000, Train Loss: 0.0013, Test Loss: 0.1437\n",
      "Epoch 1876/2000, Train Loss: 0.0013, Test Loss: 0.1385\n",
      "Epoch 1877/2000, Train Loss: 0.0013, Test Loss: 0.1384\n",
      "Epoch 1878/2000, Train Loss: 0.0013, Test Loss: 0.1385\n",
      "Epoch 1879/2000, Train Loss: 0.0013, Test Loss: 0.1385\n",
      "Epoch 1880/2000, Train Loss: 0.0013, Test Loss: 0.1387\n",
      "Epoch 1881/2000, Train Loss: 0.0013, Test Loss: 0.1386\n",
      "Epoch 1882/2000, Train Loss: 0.0013, Test Loss: 0.1386\n",
      "Epoch 1883/2000, Train Loss: 0.0013, Test Loss: 0.1385\n",
      "Epoch 1884/2000, Train Loss: 0.0013, Test Loss: 0.1386\n",
      "Epoch 1885/2000, Train Loss: 0.0013, Test Loss: 0.1386\n",
      "Epoch 1886/2000, Train Loss: 0.0013, Test Loss: 0.1445\n",
      "Epoch 1887/2000, Train Loss: 0.0013, Test Loss: 0.1385\n",
      "Epoch 1888/2000, Train Loss: 0.0013, Test Loss: 0.1386\n",
      "Epoch 1889/2000, Train Loss: 0.0013, Test Loss: 0.1386\n",
      "Epoch 1890/2000, Train Loss: 0.0013, Test Loss: 0.1391\n",
      "Epoch 1891/2000, Train Loss: 0.0012, Test Loss: 0.1385\n",
      "Epoch 1892/2000, Train Loss: 0.0013, Test Loss: 0.1386\n",
      "Epoch 1893/2000, Train Loss: 0.0012, Test Loss: 0.1386\n",
      "Epoch 1894/2000, Train Loss: 0.0012, Test Loss: 0.1386\n",
      "Epoch 1895/2000, Train Loss: 0.0012, Test Loss: 0.1386\n",
      "Epoch 1896/2000, Train Loss: 0.0012, Test Loss: 0.1389\n",
      "Epoch 1897/2000, Train Loss: 0.0012, Test Loss: 0.1386\n",
      "Epoch 1898/2000, Train Loss: 0.0012, Test Loss: 0.1401\n",
      "Epoch 1899/2000, Train Loss: 0.0012, Test Loss: 0.1480\n",
      "Epoch 1900/2000, Train Loss: 0.0012, Test Loss: 0.1387\n",
      "Epoch 1901/2000, Train Loss: 0.0012, Test Loss: 0.1387\n",
      "Epoch 1902/2000, Train Loss: 0.0012, Test Loss: 0.1446\n",
      "Epoch 1903/2000, Train Loss: 0.0012, Test Loss: 0.1398\n",
      "Epoch 1904/2000, Train Loss: 0.0012, Test Loss: 0.1417\n",
      "Epoch 1905/2000, Train Loss: 0.0012, Test Loss: 0.1409\n",
      "Epoch 1906/2000, Train Loss: 0.0012, Test Loss: 0.1388\n",
      "Epoch 1907/2000, Train Loss: 0.0012, Test Loss: 0.1387\n",
      "Epoch 1908/2000, Train Loss: 0.0012, Test Loss: 0.1387\n",
      "Epoch 1909/2000, Train Loss: 0.0012, Test Loss: 0.1387\n",
      "Epoch 1910/2000, Train Loss: 0.0012, Test Loss: 0.1398\n",
      "Epoch 1911/2000, Train Loss: 0.0012, Test Loss: 0.1387\n",
      "Epoch 1912/2000, Train Loss: 0.0012, Test Loss: 0.1396\n",
      "Epoch 1913/2000, Train Loss: 0.0012, Test Loss: 0.1390\n",
      "Epoch 1914/2000, Train Loss: 0.0012, Test Loss: 0.1388\n",
      "Epoch 1915/2000, Train Loss: 0.0012, Test Loss: 0.1388\n",
      "Epoch 1916/2000, Train Loss: 0.0012, Test Loss: 0.1450\n",
      "Epoch 1917/2000, Train Loss: 0.0012, Test Loss: 0.1462\n",
      "Epoch 1918/2000, Train Loss: 0.0012, Test Loss: 0.1463\n",
      "Epoch 1919/2000, Train Loss: 0.0012, Test Loss: 0.1388\n",
      "Epoch 1920/2000, Train Loss: 0.0012, Test Loss: 0.1388\n",
      "Epoch 1921/2000, Train Loss: 0.0012, Test Loss: 0.1430\n",
      "Epoch 1922/2000, Train Loss: 0.0012, Test Loss: 0.1481\n",
      "Epoch 1923/2000, Train Loss: 0.0012, Test Loss: 0.1387\n",
      "Epoch 1924/2000, Train Loss: 0.0012, Test Loss: 0.1389\n",
      "Epoch 1925/2000, Train Loss: 0.0012, Test Loss: 0.1447\n",
      "Epoch 1926/2000, Train Loss: 0.0012, Test Loss: 0.1388\n",
      "Epoch 1927/2000, Train Loss: 0.0012, Test Loss: 0.1424\n",
      "Epoch 1928/2000, Train Loss: 0.0012, Test Loss: 0.1403\n",
      "Epoch 1929/2000, Train Loss: 0.0012, Test Loss: 0.1465\n",
      "Epoch 1930/2000, Train Loss: 0.0012, Test Loss: 0.1389\n",
      "Epoch 1931/2000, Train Loss: 0.0012, Test Loss: 0.1390\n",
      "Epoch 1932/2000, Train Loss: 0.0012, Test Loss: 0.1388\n",
      "Epoch 1933/2000, Train Loss: 0.0012, Test Loss: 0.1399\n",
      "Epoch 1934/2000, Train Loss: 0.0012, Test Loss: 0.1407\n",
      "Epoch 1935/2000, Train Loss: 0.0012, Test Loss: 0.1388\n",
      "Epoch 1936/2000, Train Loss: 0.0012, Test Loss: 0.1401\n",
      "Epoch 1937/2000, Train Loss: 0.0012, Test Loss: 0.1389\n",
      "Epoch 1938/2000, Train Loss: 0.0012, Test Loss: 0.1389\n",
      "Epoch 1939/2000, Train Loss: 0.0012, Test Loss: 0.1407\n",
      "Epoch 1940/2000, Train Loss: 0.0012, Test Loss: 0.1389\n",
      "Epoch 1941/2000, Train Loss: 0.0012, Test Loss: 0.1389\n",
      "Epoch 1942/2000, Train Loss: 0.0012, Test Loss: 0.1389\n",
      "Epoch 1943/2000, Train Loss: 0.0012, Test Loss: 0.1389\n",
      "Epoch 1944/2000, Train Loss: 0.0012, Test Loss: 0.1390\n",
      "Epoch 1945/2000, Train Loss: 0.0012, Test Loss: 0.1402\n",
      "Epoch 1946/2000, Train Loss: 0.0012, Test Loss: 0.1390\n",
      "Epoch 1947/2000, Train Loss: 0.0012, Test Loss: 0.1393\n",
      "Epoch 1948/2000, Train Loss: 0.0012, Test Loss: 0.1389\n",
      "Epoch 1949/2000, Train Loss: 0.0012, Test Loss: 0.1392\n",
      "Epoch 1950/2000, Train Loss: 0.0012, Test Loss: 0.1390\n",
      "Epoch 1951/2000, Train Loss: 0.0012, Test Loss: 0.1435\n",
      "Epoch 1952/2000, Train Loss: 0.0012, Test Loss: 0.1390\n",
      "Epoch 1953/2000, Train Loss: 0.0012, Test Loss: 0.1390\n",
      "Epoch 1954/2000, Train Loss: 0.0012, Test Loss: 0.1397\n",
      "Epoch 1955/2000, Train Loss: 0.0012, Test Loss: 0.1391\n",
      "Epoch 1956/2000, Train Loss: 0.0012, Test Loss: 0.1457\n",
      "Epoch 1957/2000, Train Loss: 0.0012, Test Loss: 0.1403\n",
      "Epoch 1958/2000, Train Loss: 0.0012, Test Loss: 0.1390\n",
      "Epoch 1959/2000, Train Loss: 0.0012, Test Loss: 0.1391\n",
      "Epoch 1960/2000, Train Loss: 0.0012, Test Loss: 0.1395\n",
      "Epoch 1961/2000, Train Loss: 0.0012, Test Loss: 0.1397\n",
      "Epoch 1962/2000, Train Loss: 0.0012, Test Loss: 0.1450\n",
      "Epoch 1963/2000, Train Loss: 0.0012, Test Loss: 0.1397\n",
      "Epoch 1964/2000, Train Loss: 0.0012, Test Loss: 0.1391\n",
      "Epoch 1965/2000, Train Loss: 0.0012, Test Loss: 0.1401\n",
      "Epoch 1966/2000, Train Loss: 0.0012, Test Loss: 0.1391\n",
      "Epoch 1967/2000, Train Loss: 0.0012, Test Loss: 0.1442\n",
      "Epoch 1968/2000, Train Loss: 0.0012, Test Loss: 0.1394\n",
      "Epoch 1969/2000, Train Loss: 0.0012, Test Loss: 0.1405\n",
      "Epoch 1970/2000, Train Loss: 0.0012, Test Loss: 0.1422\n",
      "Epoch 1971/2000, Train Loss: 0.0012, Test Loss: 0.1392\n",
      "Epoch 1972/2000, Train Loss: 0.0012, Test Loss: 0.1402\n",
      "Epoch 1973/2000, Train Loss: 0.0012, Test Loss: 0.1436\n",
      "Epoch 1974/2000, Train Loss: 0.0012, Test Loss: 0.1391\n",
      "Epoch 1975/2000, Train Loss: 0.0012, Test Loss: 0.1392\n",
      "Epoch 1976/2000, Train Loss: 0.0012, Test Loss: 0.1391\n",
      "Epoch 1977/2000, Train Loss: 0.0012, Test Loss: 0.1392\n",
      "Epoch 1978/2000, Train Loss: 0.0012, Test Loss: 0.1425\n",
      "Epoch 1979/2000, Train Loss: 0.0012, Test Loss: 0.1404\n",
      "Epoch 1980/2000, Train Loss: 0.0012, Test Loss: 0.1392\n",
      "Epoch 1981/2000, Train Loss: 0.0012, Test Loss: 0.1400\n",
      "Epoch 1982/2000, Train Loss: 0.0012, Test Loss: 0.1393\n",
      "Epoch 1983/2000, Train Loss: 0.0012, Test Loss: 0.1399\n",
      "Epoch 1984/2000, Train Loss: 0.0012, Test Loss: 0.1393\n",
      "Epoch 1985/2000, Train Loss: 0.0012, Test Loss: 0.1392\n",
      "Epoch 1986/2000, Train Loss: 0.0012, Test Loss: 0.1409\n",
      "Epoch 1987/2000, Train Loss: 0.0012, Test Loss: 0.1392\n",
      "Epoch 1988/2000, Train Loss: 0.0012, Test Loss: 0.1393\n",
      "Epoch 1989/2000, Train Loss: 0.0012, Test Loss: 0.1418\n",
      "Epoch 1990/2000, Train Loss: 0.0012, Test Loss: 0.1406\n",
      "Epoch 1991/2000, Train Loss: 0.0012, Test Loss: 0.1393\n",
      "Epoch 1992/2000, Train Loss: 0.0012, Test Loss: 0.1398\n",
      "Epoch 1993/2000, Train Loss: 0.0012, Test Loss: 0.1393\n",
      "Epoch 1994/2000, Train Loss: 0.0012, Test Loss: 0.1392\n",
      "Epoch 1995/2000, Train Loss: 0.0012, Test Loss: 0.1394\n",
      "Epoch 1996/2000, Train Loss: 0.0012, Test Loss: 0.1393\n",
      "Epoch 1997/2000, Train Loss: 0.0012, Test Loss: 0.1393\n",
      "Epoch 1998/2000, Train Loss: 0.0012, Test Loss: 0.1393\n",
      "Epoch 1999/2000, Train Loss: 0.0012, Test Loss: 0.1393\n",
      "Epoch 2000/2000, Train Loss: 0.0012, Test Loss: 0.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.9703</td></tr><tr><td>accuracy/train</td><td>1.0</td></tr><tr><td>batch_loss</td><td>0.00152</td></tr><tr><td>epoch</td><td>1999</td></tr><tr><td>loss/test</td><td>0.13928</td></tr><tr><td>loss/train</td><td>0.0012</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-glitter-265</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/hw0cpod1' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/hw0cpod1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240313_142136-hw0cpod1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240313_161136-u0skt7or</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/u0skt7or' target=\"_blank\">unique-shape-266</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/u0skt7or' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/u0skt7or</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Train Loss: 0.5117, Test Loss: 0.2641\n",
      "Epoch 2/2000, Train Loss: 0.2314, Test Loss: 0.1935\n",
      "Epoch 3/2000, Train Loss: 0.1759, Test Loss: 0.1742\n",
      "Epoch 4/2000, Train Loss: 0.1506, Test Loss: 0.1458\n",
      "Epoch 5/2000, Train Loss: 0.1300, Test Loss: 0.1374\n",
      "Epoch 6/2000, Train Loss: 0.1183, Test Loss: 0.1379\n",
      "Epoch 7/2000, Train Loss: 0.1089, Test Loss: 0.1259\n",
      "Epoch 8/2000, Train Loss: 0.1009, Test Loss: 0.1148\n",
      "Epoch 9/2000, Train Loss: 0.0928, Test Loss: 0.1114\n",
      "Epoch 10/2000, Train Loss: 0.0872, Test Loss: 0.1114\n",
      "Epoch 11/2000, Train Loss: 0.0825, Test Loss: 0.1055\n",
      "Epoch 12/2000, Train Loss: 0.0769, Test Loss: 0.1029\n",
      "Epoch 13/2000, Train Loss: 0.0731, Test Loss: 0.1014\n",
      "Epoch 14/2000, Train Loss: 0.0700, Test Loss: 0.0980\n",
      "Epoch 15/2000, Train Loss: 0.0667, Test Loss: 0.0979\n",
      "Epoch 16/2000, Train Loss: 0.0630, Test Loss: 0.0953\n",
      "Epoch 17/2000, Train Loss: 0.0611, Test Loss: 0.0977\n",
      "Epoch 18/2000, Train Loss: 0.0591, Test Loss: 0.0953\n",
      "Epoch 19/2000, Train Loss: 0.0556, Test Loss: 0.0957\n",
      "Epoch 20/2000, Train Loss: 0.0544, Test Loss: 0.0953\n",
      "Epoch 21/2000, Train Loss: 0.0520, Test Loss: 0.0950\n",
      "Epoch 22/2000, Train Loss: 0.0499, Test Loss: 0.0875\n",
      "Epoch 23/2000, Train Loss: 0.0486, Test Loss: 0.0891\n",
      "Epoch 24/2000, Train Loss: 0.0467, Test Loss: 0.0890\n",
      "Epoch 25/2000, Train Loss: 0.0460, Test Loss: 0.0905\n",
      "Epoch 26/2000, Train Loss: 0.0444, Test Loss: 0.0874\n",
      "Epoch 27/2000, Train Loss: 0.0430, Test Loss: 0.0862\n",
      "Epoch 28/2000, Train Loss: 0.0415, Test Loss: 0.0890\n",
      "Epoch 29/2000, Train Loss: 0.0404, Test Loss: 0.0858\n",
      "Epoch 30/2000, Train Loss: 0.0391, Test Loss: 0.0891\n",
      "Epoch 31/2000, Train Loss: 0.0380, Test Loss: 0.0892\n",
      "Epoch 32/2000, Train Loss: 0.0373, Test Loss: 0.0874\n",
      "Epoch 33/2000, Train Loss: 0.0363, Test Loss: 0.0842\n",
      "Epoch 34/2000, Train Loss: 0.0353, Test Loss: 0.0843\n",
      "Epoch 35/2000, Train Loss: 0.0347, Test Loss: 0.0845\n",
      "Epoch 36/2000, Train Loss: 0.0335, Test Loss: 0.0876\n",
      "Epoch 37/2000, Train Loss: 0.0330, Test Loss: 0.0837\n",
      "Epoch 38/2000, Train Loss: 0.0319, Test Loss: 0.0835\n",
      "Epoch 39/2000, Train Loss: 0.0311, Test Loss: 0.0845\n",
      "Epoch 40/2000, Train Loss: 0.0304, Test Loss: 0.0841\n",
      "Epoch 41/2000, Train Loss: 0.0295, Test Loss: 0.0843\n",
      "Epoch 42/2000, Train Loss: 0.0293, Test Loss: 0.0825\n",
      "Epoch 43/2000, Train Loss: 0.0283, Test Loss: 0.0839\n",
      "Epoch 44/2000, Train Loss: 0.0280, Test Loss: 0.0835\n",
      "Epoch 45/2000, Train Loss: 0.0274, Test Loss: 0.0813\n",
      "Epoch 46/2000, Train Loss: 0.0269, Test Loss: 0.0817\n",
      "Epoch 47/2000, Train Loss: 0.0265, Test Loss: 0.0837\n",
      "Epoch 48/2000, Train Loss: 0.0257, Test Loss: 0.0838\n",
      "Epoch 49/2000, Train Loss: 0.0253, Test Loss: 0.0864\n",
      "Epoch 50/2000, Train Loss: 0.0248, Test Loss: 0.0838\n",
      "Epoch 51/2000, Train Loss: 0.0242, Test Loss: 0.0819\n",
      "Epoch 52/2000, Train Loss: 0.0237, Test Loss: 0.0832\n",
      "Epoch 53/2000, Train Loss: 0.0233, Test Loss: 0.0840\n",
      "Epoch 54/2000, Train Loss: 0.0229, Test Loss: 0.0822\n",
      "Epoch 55/2000, Train Loss: 0.0224, Test Loss: 0.0807\n",
      "Epoch 56/2000, Train Loss: 0.0221, Test Loss: 0.0841\n",
      "Epoch 57/2000, Train Loss: 0.0218, Test Loss: 0.0830\n",
      "Epoch 58/2000, Train Loss: 0.0213, Test Loss: 0.0817\n",
      "Epoch 59/2000, Train Loss: 0.0209, Test Loss: 0.0852\n",
      "Epoch 60/2000, Train Loss: 0.0207, Test Loss: 0.0820\n",
      "Epoch 61/2000, Train Loss: 0.0204, Test Loss: 0.0860\n",
      "Epoch 62/2000, Train Loss: 0.0200, Test Loss: 0.0839\n",
      "Epoch 63/2000, Train Loss: 0.0196, Test Loss: 0.0812\n",
      "Epoch 64/2000, Train Loss: 0.0195, Test Loss: 0.0816\n",
      "Epoch 65/2000, Train Loss: 0.0191, Test Loss: 0.0823\n",
      "Epoch 66/2000, Train Loss: 0.0187, Test Loss: 0.0851\n",
      "Epoch 67/2000, Train Loss: 0.0186, Test Loss: 0.0825\n",
      "Epoch 68/2000, Train Loss: 0.0181, Test Loss: 0.0819\n",
      "Epoch 69/2000, Train Loss: 0.0180, Test Loss: 0.0809\n",
      "Epoch 70/2000, Train Loss: 0.0177, Test Loss: 0.0826\n",
      "Epoch 71/2000, Train Loss: 0.0174, Test Loss: 0.0829\n",
      "Epoch 72/2000, Train Loss: 0.0172, Test Loss: 0.0849\n",
      "Epoch 73/2000, Train Loss: 0.0170, Test Loss: 0.0809\n",
      "Epoch 74/2000, Train Loss: 0.0165, Test Loss: 0.0822\n",
      "Epoch 75/2000, Train Loss: 0.0164, Test Loss: 0.0822\n",
      "Epoch 76/2000, Train Loss: 0.0162, Test Loss: 0.0840\n",
      "Epoch 77/2000, Train Loss: 0.0159, Test Loss: 0.0817\n",
      "Epoch 78/2000, Train Loss: 0.0156, Test Loss: 0.0812\n",
      "Epoch 79/2000, Train Loss: 0.0155, Test Loss: 0.0822\n",
      "Epoch 80/2000, Train Loss: 0.0154, Test Loss: 0.0825\n",
      "Epoch 81/2000, Train Loss: 0.0151, Test Loss: 0.0844\n",
      "Epoch 82/2000, Train Loss: 0.0149, Test Loss: 0.0834\n",
      "Epoch 83/2000, Train Loss: 0.0146, Test Loss: 0.0842\n",
      "Epoch 84/2000, Train Loss: 0.0145, Test Loss: 0.0821\n",
      "Epoch 85/2000, Train Loss: 0.0145, Test Loss: 0.0821\n",
      "Epoch 86/2000, Train Loss: 0.0143, Test Loss: 0.0824\n",
      "Epoch 87/2000, Train Loss: 0.0140, Test Loss: 0.0836\n",
      "Epoch 88/2000, Train Loss: 0.0138, Test Loss: 0.0827\n",
      "Epoch 89/2000, Train Loss: 0.0137, Test Loss: 0.0821\n",
      "Epoch 90/2000, Train Loss: 0.0136, Test Loss: 0.0838\n",
      "Epoch 91/2000, Train Loss: 0.0133, Test Loss: 0.0840\n",
      "Epoch 92/2000, Train Loss: 0.0133, Test Loss: 0.0819\n",
      "Epoch 93/2000, Train Loss: 0.0130, Test Loss: 0.0840\n",
      "Epoch 94/2000, Train Loss: 0.0128, Test Loss: 0.0819\n",
      "Epoch 95/2000, Train Loss: 0.0128, Test Loss: 0.0824\n",
      "Epoch 96/2000, Train Loss: 0.0126, Test Loss: 0.0825\n",
      "Epoch 97/2000, Train Loss: 0.0125, Test Loss: 0.0820\n",
      "Epoch 98/2000, Train Loss: 0.0124, Test Loss: 0.0814\n",
      "Epoch 99/2000, Train Loss: 0.0122, Test Loss: 0.0849\n",
      "Epoch 100/2000, Train Loss: 0.0120, Test Loss: 0.0884\n",
      "Epoch 101/2000, Train Loss: 0.0120, Test Loss: 0.0825\n",
      "Epoch 102/2000, Train Loss: 0.0118, Test Loss: 0.0821\n",
      "Epoch 103/2000, Train Loss: 0.0117, Test Loss: 0.0839\n",
      "Epoch 104/2000, Train Loss: 0.0117, Test Loss: 0.0883\n",
      "Epoch 105/2000, Train Loss: 0.0115, Test Loss: 0.0823\n",
      "Epoch 106/2000, Train Loss: 0.0114, Test Loss: 0.0819\n",
      "Epoch 107/2000, Train Loss: 0.0112, Test Loss: 0.0823\n",
      "Epoch 108/2000, Train Loss: 0.0111, Test Loss: 0.0828\n",
      "Epoch 109/2000, Train Loss: 0.0110, Test Loss: 0.0827\n",
      "Epoch 110/2000, Train Loss: 0.0109, Test Loss: 0.0821\n",
      "Epoch 111/2000, Train Loss: 0.0108, Test Loss: 0.0823\n",
      "Epoch 112/2000, Train Loss: 0.0107, Test Loss: 0.0827\n",
      "Epoch 113/2000, Train Loss: 0.0106, Test Loss: 0.0838\n",
      "Epoch 114/2000, Train Loss: 0.0105, Test Loss: 0.0825\n",
      "Epoch 115/2000, Train Loss: 0.0104, Test Loss: 0.0825\n",
      "Epoch 116/2000, Train Loss: 0.0102, Test Loss: 0.0850\n",
      "Epoch 117/2000, Train Loss: 0.0102, Test Loss: 0.0829\n",
      "Epoch 118/2000, Train Loss: 0.0101, Test Loss: 0.0826\n",
      "Epoch 119/2000, Train Loss: 0.0100, Test Loss: 0.0835\n",
      "Epoch 120/2000, Train Loss: 0.0099, Test Loss: 0.0832\n",
      "Epoch 121/2000, Train Loss: 0.0099, Test Loss: 0.0851\n",
      "Epoch 122/2000, Train Loss: 0.0098, Test Loss: 0.0826\n",
      "Epoch 123/2000, Train Loss: 0.0096, Test Loss: 0.0908\n",
      "Epoch 124/2000, Train Loss: 0.0096, Test Loss: 0.0831\n",
      "Epoch 125/2000, Train Loss: 0.0095, Test Loss: 0.0879\n",
      "Epoch 126/2000, Train Loss: 0.0094, Test Loss: 0.0851\n",
      "Epoch 127/2000, Train Loss: 0.0093, Test Loss: 0.0829\n",
      "Epoch 128/2000, Train Loss: 0.0093, Test Loss: 0.0825\n",
      "Epoch 129/2000, Train Loss: 0.0092, Test Loss: 0.0827\n",
      "Epoch 130/2000, Train Loss: 0.0091, Test Loss: 0.0829\n",
      "Epoch 131/2000, Train Loss: 0.0090, Test Loss: 0.0860\n",
      "Epoch 132/2000, Train Loss: 0.0090, Test Loss: 0.0841\n",
      "Epoch 133/2000, Train Loss: 0.0089, Test Loss: 0.0831\n",
      "Epoch 134/2000, Train Loss: 0.0088, Test Loss: 0.0839\n",
      "Epoch 135/2000, Train Loss: 0.0087, Test Loss: 0.0825\n",
      "Epoch 136/2000, Train Loss: 0.0087, Test Loss: 0.0833\n",
      "Epoch 137/2000, Train Loss: 0.0086, Test Loss: 0.0822\n",
      "Epoch 138/2000, Train Loss: 0.0085, Test Loss: 0.0844\n",
      "Epoch 139/2000, Train Loss: 0.0085, Test Loss: 0.0836\n",
      "Epoch 140/2000, Train Loss: 0.0084, Test Loss: 0.0831\n",
      "Epoch 141/2000, Train Loss: 0.0084, Test Loss: 0.0839\n",
      "Epoch 142/2000, Train Loss: 0.0083, Test Loss: 0.0842\n",
      "Epoch 143/2000, Train Loss: 0.0082, Test Loss: 0.0833\n",
      "Epoch 144/2000, Train Loss: 0.0081, Test Loss: 0.0837\n",
      "Epoch 145/2000, Train Loss: 0.0081, Test Loss: 0.0860\n",
      "Epoch 146/2000, Train Loss: 0.0080, Test Loss: 0.0836\n",
      "Epoch 147/2000, Train Loss: 0.0080, Test Loss: 0.0842\n",
      "Epoch 148/2000, Train Loss: 0.0079, Test Loss: 0.0839\n",
      "Epoch 149/2000, Train Loss: 0.0079, Test Loss: 0.0843\n",
      "Epoch 150/2000, Train Loss: 0.0078, Test Loss: 0.0834\n",
      "Epoch 151/2000, Train Loss: 0.0078, Test Loss: 0.0834\n",
      "Epoch 152/2000, Train Loss: 0.0077, Test Loss: 0.0837\n",
      "Epoch 153/2000, Train Loss: 0.0077, Test Loss: 0.0844\n",
      "Epoch 154/2000, Train Loss: 0.0076, Test Loss: 0.0849\n",
      "Epoch 155/2000, Train Loss: 0.0076, Test Loss: 0.0840\n",
      "Epoch 156/2000, Train Loss: 0.0075, Test Loss: 0.0897\n",
      "Epoch 157/2000, Train Loss: 0.0074, Test Loss: 0.0835\n",
      "Epoch 158/2000, Train Loss: 0.0074, Test Loss: 0.0841\n",
      "Epoch 159/2000, Train Loss: 0.0073, Test Loss: 0.0840\n",
      "Epoch 160/2000, Train Loss: 0.0073, Test Loss: 0.0834\n",
      "Epoch 161/2000, Train Loss: 0.0073, Test Loss: 0.0838\n",
      "Epoch 162/2000, Train Loss: 0.0072, Test Loss: 0.0848\n",
      "Epoch 163/2000, Train Loss: 0.0072, Test Loss: 0.0849\n",
      "Epoch 164/2000, Train Loss: 0.0071, Test Loss: 0.0839\n",
      "Epoch 165/2000, Train Loss: 0.0070, Test Loss: 0.0839\n",
      "Epoch 166/2000, Train Loss: 0.0070, Test Loss: 0.0843\n",
      "Epoch 167/2000, Train Loss: 0.0070, Test Loss: 0.0902\n",
      "Epoch 168/2000, Train Loss: 0.0070, Test Loss: 0.0850\n",
      "Epoch 169/2000, Train Loss: 0.0069, Test Loss: 0.0833\n",
      "Epoch 170/2000, Train Loss: 0.0069, Test Loss: 0.0848\n",
      "Epoch 171/2000, Train Loss: 0.0068, Test Loss: 0.0844\n",
      "Epoch 172/2000, Train Loss: 0.0068, Test Loss: 0.0839\n",
      "Epoch 173/2000, Train Loss: 0.0067, Test Loss: 0.0848\n",
      "Epoch 174/2000, Train Loss: 0.0067, Test Loss: 0.0890\n",
      "Epoch 175/2000, Train Loss: 0.0066, Test Loss: 0.0855\n",
      "Epoch 176/2000, Train Loss: 0.0066, Test Loss: 0.0843\n",
      "Epoch 177/2000, Train Loss: 0.0066, Test Loss: 0.0849\n",
      "Epoch 178/2000, Train Loss: 0.0065, Test Loss: 0.0846\n",
      "Epoch 179/2000, Train Loss: 0.0065, Test Loss: 0.0849\n",
      "Epoch 180/2000, Train Loss: 0.0065, Test Loss: 0.0856\n",
      "Epoch 181/2000, Train Loss: 0.0064, Test Loss: 0.0912\n",
      "Epoch 182/2000, Train Loss: 0.0064, Test Loss: 0.0848\n",
      "Epoch 183/2000, Train Loss: 0.0064, Test Loss: 0.0844\n",
      "Epoch 184/2000, Train Loss: 0.0063, Test Loss: 0.0877\n",
      "Epoch 185/2000, Train Loss: 0.0063, Test Loss: 0.0849\n",
      "Epoch 186/2000, Train Loss: 0.0062, Test Loss: 0.0866\n",
      "Epoch 187/2000, Train Loss: 0.0062, Test Loss: 0.0845\n",
      "Epoch 188/2000, Train Loss: 0.0062, Test Loss: 0.0845\n",
      "Epoch 189/2000, Train Loss: 0.0061, Test Loss: 0.0859\n",
      "Epoch 190/2000, Train Loss: 0.0061, Test Loss: 0.0853\n",
      "Epoch 191/2000, Train Loss: 0.0061, Test Loss: 0.0856\n",
      "Epoch 192/2000, Train Loss: 0.0060, Test Loss: 0.0896\n",
      "Epoch 193/2000, Train Loss: 0.0060, Test Loss: 0.0855\n",
      "Epoch 194/2000, Train Loss: 0.0060, Test Loss: 0.0849\n",
      "Epoch 195/2000, Train Loss: 0.0059, Test Loss: 0.0869\n",
      "Epoch 196/2000, Train Loss: 0.0059, Test Loss: 0.0852\n",
      "Epoch 197/2000, Train Loss: 0.0059, Test Loss: 0.0900\n",
      "Epoch 198/2000, Train Loss: 0.0058, Test Loss: 0.0862\n",
      "Epoch 199/2000, Train Loss: 0.0058, Test Loss: 0.0863\n",
      "Epoch 200/2000, Train Loss: 0.0058, Test Loss: 0.0850\n",
      "Epoch 201/2000, Train Loss: 0.0058, Test Loss: 0.0850\n",
      "Epoch 202/2000, Train Loss: 0.0057, Test Loss: 0.0862\n",
      "Epoch 203/2000, Train Loss: 0.0057, Test Loss: 0.0882\n",
      "Epoch 204/2000, Train Loss: 0.0057, Test Loss: 0.0851\n",
      "Epoch 205/2000, Train Loss: 0.0056, Test Loss: 0.0863\n",
      "Epoch 206/2000, Train Loss: 0.0056, Test Loss: 0.0875\n",
      "Epoch 207/2000, Train Loss: 0.0056, Test Loss: 0.0884\n",
      "Epoch 208/2000, Train Loss: 0.0056, Test Loss: 0.0858\n",
      "Epoch 209/2000, Train Loss: 0.0055, Test Loss: 0.0862\n",
      "Epoch 210/2000, Train Loss: 0.0055, Test Loss: 0.0856\n",
      "Epoch 211/2000, Train Loss: 0.0055, Test Loss: 0.0879\n",
      "Epoch 212/2000, Train Loss: 0.0055, Test Loss: 0.0860\n",
      "Epoch 213/2000, Train Loss: 0.0054, Test Loss: 0.0918\n",
      "Epoch 214/2000, Train Loss: 0.0054, Test Loss: 0.0858\n",
      "Epoch 215/2000, Train Loss: 0.0054, Test Loss: 0.0854\n",
      "Epoch 216/2000, Train Loss: 0.0053, Test Loss: 0.0851\n",
      "Epoch 217/2000, Train Loss: 0.0053, Test Loss: 0.0900\n",
      "Epoch 218/2000, Train Loss: 0.0053, Test Loss: 0.0888\n",
      "Epoch 219/2000, Train Loss: 0.0053, Test Loss: 0.0859\n",
      "Epoch 220/2000, Train Loss: 0.0053, Test Loss: 0.0857\n",
      "Epoch 221/2000, Train Loss: 0.0052, Test Loss: 0.0858\n",
      "Epoch 222/2000, Train Loss: 0.0052, Test Loss: 0.0861\n",
      "Epoch 223/2000, Train Loss: 0.0052, Test Loss: 0.0865\n",
      "Epoch 224/2000, Train Loss: 0.0052, Test Loss: 0.0860\n",
      "Epoch 225/2000, Train Loss: 0.0051, Test Loss: 0.0903\n",
      "Epoch 226/2000, Train Loss: 0.0051, Test Loss: 0.0902\n",
      "Epoch 227/2000, Train Loss: 0.0051, Test Loss: 0.0857\n",
      "Epoch 228/2000, Train Loss: 0.0051, Test Loss: 0.0865\n",
      "Epoch 229/2000, Train Loss: 0.0051, Test Loss: 0.0875\n",
      "Epoch 230/2000, Train Loss: 0.0050, Test Loss: 0.0856\n",
      "Epoch 231/2000, Train Loss: 0.0050, Test Loss: 0.0860\n",
      "Epoch 232/2000, Train Loss: 0.0050, Test Loss: 0.0863\n",
      "Epoch 233/2000, Train Loss: 0.0050, Test Loss: 0.0888\n",
      "Epoch 234/2000, Train Loss: 0.0049, Test Loss: 0.0861\n",
      "Epoch 235/2000, Train Loss: 0.0050, Test Loss: 0.0860\n",
      "Epoch 236/2000, Train Loss: 0.0049, Test Loss: 0.0873\n",
      "Epoch 237/2000, Train Loss: 0.0049, Test Loss: 0.0865\n",
      "Epoch 238/2000, Train Loss: 0.0048, Test Loss: 0.0861\n",
      "Epoch 239/2000, Train Loss: 0.0048, Test Loss: 0.0866\n",
      "Epoch 240/2000, Train Loss: 0.0048, Test Loss: 0.0862\n",
      "Epoch 241/2000, Train Loss: 0.0048, Test Loss: 0.0874\n",
      "Epoch 242/2000, Train Loss: 0.0048, Test Loss: 0.0868\n",
      "Epoch 243/2000, Train Loss: 0.0048, Test Loss: 0.0871\n",
      "Epoch 244/2000, Train Loss: 0.0047, Test Loss: 0.0863\n",
      "Epoch 245/2000, Train Loss: 0.0047, Test Loss: 0.0865\n",
      "Epoch 246/2000, Train Loss: 0.0047, Test Loss: 0.0866\n",
      "Epoch 247/2000, Train Loss: 0.0047, Test Loss: 0.0867\n",
      "Epoch 248/2000, Train Loss: 0.0047, Test Loss: 0.0897\n",
      "Epoch 249/2000, Train Loss: 0.0046, Test Loss: 0.0865\n",
      "Epoch 250/2000, Train Loss: 0.0046, Test Loss: 0.0871\n",
      "Epoch 251/2000, Train Loss: 0.0046, Test Loss: 0.0868\n",
      "Epoch 252/2000, Train Loss: 0.0046, Test Loss: 0.0892\n",
      "Epoch 253/2000, Train Loss: 0.0046, Test Loss: 0.0866\n",
      "Epoch 254/2000, Train Loss: 0.0046, Test Loss: 0.0867\n",
      "Epoch 255/2000, Train Loss: 0.0045, Test Loss: 0.0865\n",
      "Epoch 256/2000, Train Loss: 0.0045, Test Loss: 0.0864\n",
      "Epoch 257/2000, Train Loss: 0.0045, Test Loss: 0.0868\n",
      "Epoch 258/2000, Train Loss: 0.0045, Test Loss: 0.0861\n",
      "Epoch 259/2000, Train Loss: 0.0045, Test Loss: 0.0900\n",
      "Epoch 260/2000, Train Loss: 0.0044, Test Loss: 0.0867\n",
      "Epoch 261/2000, Train Loss: 0.0044, Test Loss: 0.0876\n",
      "Epoch 262/2000, Train Loss: 0.0044, Test Loss: 0.0865\n",
      "Epoch 263/2000, Train Loss: 0.0044, Test Loss: 0.0897\n",
      "Epoch 264/2000, Train Loss: 0.0044, Test Loss: 0.0869\n",
      "Epoch 265/2000, Train Loss: 0.0044, Test Loss: 0.0890\n",
      "Epoch 266/2000, Train Loss: 0.0043, Test Loss: 0.0869\n",
      "Epoch 267/2000, Train Loss: 0.0043, Test Loss: 0.0872\n",
      "Epoch 268/2000, Train Loss: 0.0043, Test Loss: 0.0924\n",
      "Epoch 269/2000, Train Loss: 0.0043, Test Loss: 0.0874\n",
      "Epoch 270/2000, Train Loss: 0.0043, Test Loss: 0.0872\n",
      "Epoch 271/2000, Train Loss: 0.0043, Test Loss: 0.0878\n",
      "Epoch 272/2000, Train Loss: 0.0043, Test Loss: 0.0895\n",
      "Epoch 273/2000, Train Loss: 0.0043, Test Loss: 0.0896\n",
      "Epoch 274/2000, Train Loss: 0.0042, Test Loss: 0.0877\n",
      "Epoch 275/2000, Train Loss: 0.0042, Test Loss: 0.0872\n",
      "Epoch 276/2000, Train Loss: 0.0042, Test Loss: 0.0871\n",
      "Epoch 277/2000, Train Loss: 0.0042, Test Loss: 0.0871\n",
      "Epoch 278/2000, Train Loss: 0.0042, Test Loss: 0.0874\n",
      "Epoch 279/2000, Train Loss: 0.0042, Test Loss: 0.0879\n",
      "Epoch 280/2000, Train Loss: 0.0042, Test Loss: 0.0870\n",
      "Epoch 281/2000, Train Loss: 0.0041, Test Loss: 0.0911\n",
      "Epoch 282/2000, Train Loss: 0.0041, Test Loss: 0.0868\n",
      "Epoch 283/2000, Train Loss: 0.0041, Test Loss: 0.0875\n",
      "Epoch 284/2000, Train Loss: 0.0041, Test Loss: 0.0874\n",
      "Epoch 285/2000, Train Loss: 0.0041, Test Loss: 0.0891\n",
      "Epoch 286/2000, Train Loss: 0.0041, Test Loss: 0.0874\n",
      "Epoch 287/2000, Train Loss: 0.0040, Test Loss: 0.0878\n",
      "Epoch 288/2000, Train Loss: 0.0040, Test Loss: 0.0879\n",
      "Epoch 289/2000, Train Loss: 0.0040, Test Loss: 0.0879\n",
      "Epoch 290/2000, Train Loss: 0.0040, Test Loss: 0.0894\n",
      "Epoch 291/2000, Train Loss: 0.0040, Test Loss: 0.0876\n",
      "Epoch 292/2000, Train Loss: 0.0040, Test Loss: 0.0876\n",
      "Epoch 293/2000, Train Loss: 0.0040, Test Loss: 0.0876\n",
      "Epoch 294/2000, Train Loss: 0.0040, Test Loss: 0.0872\n",
      "Epoch 295/2000, Train Loss: 0.0039, Test Loss: 0.0878\n",
      "Epoch 296/2000, Train Loss: 0.0039, Test Loss: 0.0876\n",
      "Epoch 297/2000, Train Loss: 0.0039, Test Loss: 0.0882\n",
      "Epoch 298/2000, Train Loss: 0.0039, Test Loss: 0.0908\n",
      "Epoch 299/2000, Train Loss: 0.0039, Test Loss: 0.0878\n",
      "Epoch 300/2000, Train Loss: 0.0039, Test Loss: 0.0878\n",
      "Epoch 301/2000, Train Loss: 0.0039, Test Loss: 0.0889\n",
      "Epoch 302/2000, Train Loss: 0.0039, Test Loss: 0.0878\n",
      "Epoch 303/2000, Train Loss: 0.0038, Test Loss: 0.0882\n",
      "Epoch 304/2000, Train Loss: 0.0038, Test Loss: 0.0896\n",
      "Epoch 305/2000, Train Loss: 0.0038, Test Loss: 0.0932\n",
      "Epoch 306/2000, Train Loss: 0.0038, Test Loss: 0.0899\n",
      "Epoch 307/2000, Train Loss: 0.0038, Test Loss: 0.0888\n",
      "Epoch 308/2000, Train Loss: 0.0038, Test Loss: 0.0880\n",
      "Epoch 309/2000, Train Loss: 0.0038, Test Loss: 0.0875\n",
      "Epoch 310/2000, Train Loss: 0.0038, Test Loss: 0.0877\n",
      "Epoch 311/2000, Train Loss: 0.0038, Test Loss: 0.0879\n",
      "Epoch 312/2000, Train Loss: 0.0037, Test Loss: 0.0882\n",
      "Epoch 313/2000, Train Loss: 0.0037, Test Loss: 0.0882\n",
      "Epoch 314/2000, Train Loss: 0.0037, Test Loss: 0.0878\n",
      "Epoch 315/2000, Train Loss: 0.0037, Test Loss: 0.0880\n",
      "Epoch 316/2000, Train Loss: 0.0037, Test Loss: 0.0896\n",
      "Epoch 317/2000, Train Loss: 0.0037, Test Loss: 0.0885\n",
      "Epoch 318/2000, Train Loss: 0.0037, Test Loss: 0.0878\n",
      "Epoch 319/2000, Train Loss: 0.0037, Test Loss: 0.0881\n",
      "Epoch 320/2000, Train Loss: 0.0037, Test Loss: 0.0920\n",
      "Epoch 321/2000, Train Loss: 0.0036, Test Loss: 0.0881\n",
      "Epoch 322/2000, Train Loss: 0.0036, Test Loss: 0.0937\n",
      "Epoch 323/2000, Train Loss: 0.0036, Test Loss: 0.0884\n",
      "Epoch 324/2000, Train Loss: 0.0036, Test Loss: 0.0892\n",
      "Epoch 325/2000, Train Loss: 0.0036, Test Loss: 0.0881\n",
      "Epoch 326/2000, Train Loss: 0.0036, Test Loss: 0.0880\n",
      "Epoch 327/2000, Train Loss: 0.0036, Test Loss: 0.0926\n",
      "Epoch 328/2000, Train Loss: 0.0036, Test Loss: 0.0886\n",
      "Epoch 329/2000, Train Loss: 0.0036, Test Loss: 0.0935\n",
      "Epoch 330/2000, Train Loss: 0.0036, Test Loss: 0.0880\n",
      "Epoch 331/2000, Train Loss: 0.0035, Test Loss: 0.0884\n",
      "Epoch 332/2000, Train Loss: 0.0035, Test Loss: 0.0884\n",
      "Epoch 333/2000, Train Loss: 0.0035, Test Loss: 0.0885\n",
      "Epoch 334/2000, Train Loss: 0.0035, Test Loss: 0.0895\n",
      "Epoch 335/2000, Train Loss: 0.0035, Test Loss: 0.0881\n",
      "Epoch 336/2000, Train Loss: 0.0035, Test Loss: 0.0905\n",
      "Epoch 337/2000, Train Loss: 0.0035, Test Loss: 0.0885\n",
      "Epoch 338/2000, Train Loss: 0.0035, Test Loss: 0.0883\n",
      "Epoch 339/2000, Train Loss: 0.0035, Test Loss: 0.0883\n",
      "Epoch 340/2000, Train Loss: 0.0035, Test Loss: 0.0887\n",
      "Epoch 341/2000, Train Loss: 0.0034, Test Loss: 0.0926\n",
      "Epoch 342/2000, Train Loss: 0.0035, Test Loss: 0.0886\n",
      "Epoch 343/2000, Train Loss: 0.0034, Test Loss: 0.0895\n",
      "Epoch 344/2000, Train Loss: 0.0034, Test Loss: 0.0884\n",
      "Epoch 345/2000, Train Loss: 0.0034, Test Loss: 0.0894\n",
      "Epoch 346/2000, Train Loss: 0.0034, Test Loss: 0.0884\n",
      "Epoch 347/2000, Train Loss: 0.0034, Test Loss: 0.0923\n",
      "Epoch 348/2000, Train Loss: 0.0034, Test Loss: 0.0889\n",
      "Epoch 349/2000, Train Loss: 0.0034, Test Loss: 0.0896\n",
      "Epoch 350/2000, Train Loss: 0.0034, Test Loss: 0.0890\n",
      "Epoch 351/2000, Train Loss: 0.0034, Test Loss: 0.0888\n",
      "Epoch 352/2000, Train Loss: 0.0034, Test Loss: 0.0886\n",
      "Epoch 353/2000, Train Loss: 0.0033, Test Loss: 0.0887\n",
      "Epoch 354/2000, Train Loss: 0.0033, Test Loss: 0.0895\n",
      "Epoch 355/2000, Train Loss: 0.0033, Test Loss: 0.0888\n",
      "Epoch 356/2000, Train Loss: 0.0033, Test Loss: 0.0888\n",
      "Epoch 357/2000, Train Loss: 0.0033, Test Loss: 0.0901\n",
      "Epoch 358/2000, Train Loss: 0.0033, Test Loss: 0.0892\n",
      "Epoch 359/2000, Train Loss: 0.0033, Test Loss: 0.0890\n",
      "Epoch 360/2000, Train Loss: 0.0033, Test Loss: 0.0906\n",
      "Epoch 361/2000, Train Loss: 0.0033, Test Loss: 0.0896\n",
      "Epoch 362/2000, Train Loss: 0.0033, Test Loss: 0.0890\n",
      "Epoch 363/2000, Train Loss: 0.0033, Test Loss: 0.0888\n",
      "Epoch 364/2000, Train Loss: 0.0033, Test Loss: 0.0900\n",
      "Epoch 365/2000, Train Loss: 0.0032, Test Loss: 0.0889\n",
      "Epoch 366/2000, Train Loss: 0.0032, Test Loss: 0.0917\n",
      "Epoch 367/2000, Train Loss: 0.0032, Test Loss: 0.0896\n",
      "Epoch 368/2000, Train Loss: 0.0032, Test Loss: 0.0888\n",
      "Epoch 369/2000, Train Loss: 0.0032, Test Loss: 0.0889\n",
      "Epoch 370/2000, Train Loss: 0.0032, Test Loss: 0.0892\n",
      "Epoch 371/2000, Train Loss: 0.0032, Test Loss: 0.0891\n",
      "Epoch 372/2000, Train Loss: 0.0032, Test Loss: 0.0891\n",
      "Epoch 373/2000, Train Loss: 0.0032, Test Loss: 0.0892\n",
      "Epoch 374/2000, Train Loss: 0.0032, Test Loss: 0.0895\n",
      "Epoch 375/2000, Train Loss: 0.0032, Test Loss: 0.0894\n",
      "Epoch 376/2000, Train Loss: 0.0032, Test Loss: 0.0928\n",
      "Epoch 377/2000, Train Loss: 0.0032, Test Loss: 0.0892\n",
      "Epoch 378/2000, Train Loss: 0.0031, Test Loss: 0.0892\n",
      "Epoch 379/2000, Train Loss: 0.0031, Test Loss: 0.0926\n",
      "Epoch 380/2000, Train Loss: 0.0031, Test Loss: 0.0904\n",
      "Epoch 381/2000, Train Loss: 0.0031, Test Loss: 0.0894\n",
      "Epoch 382/2000, Train Loss: 0.0031, Test Loss: 0.0895\n",
      "Epoch 383/2000, Train Loss: 0.0031, Test Loss: 0.0931\n",
      "Epoch 384/2000, Train Loss: 0.0031, Test Loss: 0.0898\n",
      "Epoch 385/2000, Train Loss: 0.0031, Test Loss: 0.0894\n",
      "Epoch 386/2000, Train Loss: 0.0031, Test Loss: 0.0901\n",
      "Epoch 387/2000, Train Loss: 0.0031, Test Loss: 0.0895\n",
      "Epoch 388/2000, Train Loss: 0.0031, Test Loss: 0.0898\n",
      "Epoch 389/2000, Train Loss: 0.0031, Test Loss: 0.0898\n",
      "Epoch 390/2000, Train Loss: 0.0031, Test Loss: 0.0893\n",
      "Epoch 391/2000, Train Loss: 0.0031, Test Loss: 0.0902\n",
      "Epoch 392/2000, Train Loss: 0.0031, Test Loss: 0.0897\n",
      "Epoch 393/2000, Train Loss: 0.0030, Test Loss: 0.0892\n",
      "Epoch 394/2000, Train Loss: 0.0030, Test Loss: 0.0894\n",
      "Epoch 395/2000, Train Loss: 0.0030, Test Loss: 0.0894\n",
      "Epoch 396/2000, Train Loss: 0.0030, Test Loss: 0.0899\n",
      "Epoch 397/2000, Train Loss: 0.0030, Test Loss: 0.0893\n",
      "Epoch 398/2000, Train Loss: 0.0030, Test Loss: 0.0896\n",
      "Epoch 399/2000, Train Loss: 0.0030, Test Loss: 0.0902\n",
      "Epoch 400/2000, Train Loss: 0.0030, Test Loss: 0.0897\n",
      "Epoch 401/2000, Train Loss: 0.0030, Test Loss: 0.0906\n",
      "Epoch 402/2000, Train Loss: 0.0030, Test Loss: 0.0896\n",
      "Epoch 403/2000, Train Loss: 0.0030, Test Loss: 0.0895\n",
      "Epoch 404/2000, Train Loss: 0.0030, Test Loss: 0.0919\n",
      "Epoch 405/2000, Train Loss: 0.0030, Test Loss: 0.0906\n",
      "Epoch 406/2000, Train Loss: 0.0030, Test Loss: 0.0898\n",
      "Epoch 407/2000, Train Loss: 0.0029, Test Loss: 0.0902\n",
      "Epoch 408/2000, Train Loss: 0.0029, Test Loss: 0.0902\n",
      "Epoch 409/2000, Train Loss: 0.0029, Test Loss: 0.0897\n",
      "Epoch 410/2000, Train Loss: 0.0029, Test Loss: 0.0898\n",
      "Epoch 411/2000, Train Loss: 0.0029, Test Loss: 0.0898\n",
      "Epoch 412/2000, Train Loss: 0.0029, Test Loss: 0.0898\n",
      "Epoch 413/2000, Train Loss: 0.0029, Test Loss: 0.0904\n",
      "Epoch 414/2000, Train Loss: 0.0029, Test Loss: 0.0915\n",
      "Epoch 415/2000, Train Loss: 0.0029, Test Loss: 0.0899\n",
      "Epoch 416/2000, Train Loss: 0.0029, Test Loss: 0.0898\n",
      "Epoch 417/2000, Train Loss: 0.0029, Test Loss: 0.0903\n",
      "Epoch 418/2000, Train Loss: 0.0029, Test Loss: 0.0897\n",
      "Epoch 419/2000, Train Loss: 0.0029, Test Loss: 0.0914\n",
      "Epoch 420/2000, Train Loss: 0.0029, Test Loss: 0.0954\n",
      "Epoch 421/2000, Train Loss: 0.0029, Test Loss: 0.0904\n",
      "Epoch 422/2000, Train Loss: 0.0029, Test Loss: 0.0900\n",
      "Epoch 423/2000, Train Loss: 0.0028, Test Loss: 0.0903\n",
      "Epoch 424/2000, Train Loss: 0.0028, Test Loss: 0.0900\n",
      "Epoch 425/2000, Train Loss: 0.0028, Test Loss: 0.0903\n",
      "Epoch 426/2000, Train Loss: 0.0028, Test Loss: 0.0900\n",
      "Epoch 427/2000, Train Loss: 0.0028, Test Loss: 0.0897\n",
      "Epoch 428/2000, Train Loss: 0.0028, Test Loss: 0.0912\n",
      "Epoch 429/2000, Train Loss: 0.0028, Test Loss: 0.0904\n",
      "Epoch 430/2000, Train Loss: 0.0028, Test Loss: 0.0900\n",
      "Epoch 431/2000, Train Loss: 0.0028, Test Loss: 0.0937\n",
      "Epoch 432/2000, Train Loss: 0.0028, Test Loss: 0.0899\n",
      "Epoch 433/2000, Train Loss: 0.0028, Test Loss: 0.0903\n",
      "Epoch 434/2000, Train Loss: 0.0028, Test Loss: 0.0902\n",
      "Epoch 435/2000, Train Loss: 0.0028, Test Loss: 0.0901\n",
      "Epoch 436/2000, Train Loss: 0.0028, Test Loss: 0.0903\n",
      "Epoch 437/2000, Train Loss: 0.0028, Test Loss: 0.0906\n",
      "Epoch 438/2000, Train Loss: 0.0028, Test Loss: 0.0902\n",
      "Epoch 439/2000, Train Loss: 0.0028, Test Loss: 0.0902\n",
      "Epoch 440/2000, Train Loss: 0.0028, Test Loss: 0.0913\n",
      "Epoch 441/2000, Train Loss: 0.0027, Test Loss: 0.0914\n",
      "Epoch 442/2000, Train Loss: 0.0027, Test Loss: 0.0916\n",
      "Epoch 443/2000, Train Loss: 0.0027, Test Loss: 0.0920\n",
      "Epoch 444/2000, Train Loss: 0.0027, Test Loss: 0.0907\n",
      "Epoch 445/2000, Train Loss: 0.0027, Test Loss: 0.0902\n",
      "Epoch 446/2000, Train Loss: 0.0027, Test Loss: 0.0903\n",
      "Epoch 447/2000, Train Loss: 0.0027, Test Loss: 0.0900\n",
      "Epoch 448/2000, Train Loss: 0.0027, Test Loss: 0.0900\n",
      "Epoch 449/2000, Train Loss: 0.0027, Test Loss: 0.0903\n",
      "Epoch 450/2000, Train Loss: 0.0027, Test Loss: 0.0953\n",
      "Epoch 451/2000, Train Loss: 0.0027, Test Loss: 0.0904\n",
      "Epoch 452/2000, Train Loss: 0.0027, Test Loss: 0.0907\n",
      "Epoch 453/2000, Train Loss: 0.0027, Test Loss: 0.0901\n",
      "Epoch 454/2000, Train Loss: 0.0027, Test Loss: 0.0902\n",
      "Epoch 455/2000, Train Loss: 0.0027, Test Loss: 0.0922\n",
      "Epoch 456/2000, Train Loss: 0.0027, Test Loss: 0.1015\n",
      "Epoch 457/2000, Train Loss: 0.0027, Test Loss: 0.0904\n",
      "Epoch 458/2000, Train Loss: 0.0027, Test Loss: 0.0905\n",
      "Epoch 459/2000, Train Loss: 0.0027, Test Loss: 0.0910\n",
      "Epoch 460/2000, Train Loss: 0.0027, Test Loss: 0.0906\n",
      "Epoch 461/2000, Train Loss: 0.0026, Test Loss: 0.0963\n",
      "Epoch 462/2000, Train Loss: 0.0026, Test Loss: 0.0902\n",
      "Epoch 463/2000, Train Loss: 0.0026, Test Loss: 0.0905\n",
      "Epoch 464/2000, Train Loss: 0.0026, Test Loss: 0.0914\n",
      "Epoch 465/2000, Train Loss: 0.0026, Test Loss: 0.0911\n",
      "Epoch 466/2000, Train Loss: 0.0026, Test Loss: 0.0906\n",
      "Epoch 467/2000, Train Loss: 0.0026, Test Loss: 0.0905\n",
      "Epoch 468/2000, Train Loss: 0.0026, Test Loss: 0.0906\n",
      "Epoch 469/2000, Train Loss: 0.0026, Test Loss: 0.0910\n",
      "Epoch 470/2000, Train Loss: 0.0026, Test Loss: 0.0907\n",
      "Epoch 471/2000, Train Loss: 0.0026, Test Loss: 0.0907\n",
      "Epoch 472/2000, Train Loss: 0.0026, Test Loss: 0.0908\n",
      "Epoch 473/2000, Train Loss: 0.0026, Test Loss: 0.0904\n",
      "Epoch 474/2000, Train Loss: 0.0026, Test Loss: 0.0908\n",
      "Epoch 475/2000, Train Loss: 0.0026, Test Loss: 0.0910\n",
      "Epoch 476/2000, Train Loss: 0.0026, Test Loss: 0.0917\n",
      "Epoch 477/2000, Train Loss: 0.0026, Test Loss: 0.0905\n",
      "Epoch 478/2000, Train Loss: 0.0026, Test Loss: 0.0906\n",
      "Epoch 479/2000, Train Loss: 0.0026, Test Loss: 0.0935\n",
      "Epoch 480/2000, Train Loss: 0.0026, Test Loss: 0.0907\n",
      "Epoch 481/2000, Train Loss: 0.0026, Test Loss: 0.0913\n",
      "Epoch 482/2000, Train Loss: 0.0025, Test Loss: 0.0907\n",
      "Epoch 483/2000, Train Loss: 0.0025, Test Loss: 0.0916\n",
      "Epoch 484/2000, Train Loss: 0.0025, Test Loss: 0.0909\n",
      "Epoch 485/2000, Train Loss: 0.0025, Test Loss: 0.0907\n",
      "Epoch 486/2000, Train Loss: 0.0025, Test Loss: 0.0908\n",
      "Epoch 487/2000, Train Loss: 0.0025, Test Loss: 0.0907\n",
      "Epoch 488/2000, Train Loss: 0.0025, Test Loss: 0.0906\n",
      "Epoch 489/2000, Train Loss: 0.0025, Test Loss: 0.0906\n",
      "Epoch 490/2000, Train Loss: 0.0025, Test Loss: 0.0908\n",
      "Epoch 491/2000, Train Loss: 0.0025, Test Loss: 0.0911\n",
      "Epoch 492/2000, Train Loss: 0.0025, Test Loss: 0.0908\n",
      "Epoch 493/2000, Train Loss: 0.0025, Test Loss: 0.0918\n",
      "Epoch 494/2000, Train Loss: 0.0025, Test Loss: 0.0960\n",
      "Epoch 495/2000, Train Loss: 0.0025, Test Loss: 0.0973\n",
      "Epoch 496/2000, Train Loss: 0.0025, Test Loss: 0.0910\n",
      "Epoch 497/2000, Train Loss: 0.0025, Test Loss: 0.0909\n",
      "Epoch 498/2000, Train Loss: 0.0025, Test Loss: 0.0918\n",
      "Epoch 499/2000, Train Loss: 0.0025, Test Loss: 0.0912\n",
      "Epoch 500/2000, Train Loss: 0.0025, Test Loss: 0.0909\n",
      "Epoch 501/2000, Train Loss: 0.0025, Test Loss: 0.0915\n",
      "Epoch 502/2000, Train Loss: 0.0025, Test Loss: 0.0911\n",
      "Epoch 503/2000, Train Loss: 0.0025, Test Loss: 0.0912\n",
      "Epoch 504/2000, Train Loss: 0.0025, Test Loss: 0.0952\n",
      "Epoch 505/2000, Train Loss: 0.0025, Test Loss: 0.0913\n",
      "Epoch 506/2000, Train Loss: 0.0024, Test Loss: 0.0916\n",
      "Epoch 507/2000, Train Loss: 0.0024, Test Loss: 0.0908\n",
      "Epoch 508/2000, Train Loss: 0.0024, Test Loss: 0.0913\n",
      "Epoch 509/2000, Train Loss: 0.0024, Test Loss: 0.0940\n",
      "Epoch 510/2000, Train Loss: 0.0024, Test Loss: 0.0913\n",
      "Epoch 511/2000, Train Loss: 0.0024, Test Loss: 0.0982\n",
      "Epoch 512/2000, Train Loss: 0.0024, Test Loss: 0.0929\n",
      "Epoch 513/2000, Train Loss: 0.0024, Test Loss: 0.0965\n",
      "Epoch 514/2000, Train Loss: 0.0024, Test Loss: 0.0911\n",
      "Epoch 515/2000, Train Loss: 0.0024, Test Loss: 0.0911\n",
      "Epoch 516/2000, Train Loss: 0.0024, Test Loss: 0.0913\n",
      "Epoch 517/2000, Train Loss: 0.0024, Test Loss: 0.0922\n",
      "Epoch 518/2000, Train Loss: 0.0024, Test Loss: 0.0935\n",
      "Epoch 519/2000, Train Loss: 0.0024, Test Loss: 0.0952\n",
      "Epoch 520/2000, Train Loss: 0.0024, Test Loss: 0.0913\n",
      "Epoch 521/2000, Train Loss: 0.0024, Test Loss: 0.0912\n",
      "Epoch 522/2000, Train Loss: 0.0024, Test Loss: 0.0918\n",
      "Epoch 523/2000, Train Loss: 0.0024, Test Loss: 0.0912\n",
      "Epoch 524/2000, Train Loss: 0.0024, Test Loss: 0.0911\n",
      "Epoch 525/2000, Train Loss: 0.0024, Test Loss: 0.0913\n",
      "Epoch 526/2000, Train Loss: 0.0024, Test Loss: 0.0923\n",
      "Epoch 527/2000, Train Loss: 0.0024, Test Loss: 0.0914\n",
      "Epoch 528/2000, Train Loss: 0.0024, Test Loss: 0.0960\n",
      "Epoch 529/2000, Train Loss: 0.0024, Test Loss: 0.0914\n",
      "Epoch 530/2000, Train Loss: 0.0023, Test Loss: 0.0913\n",
      "Epoch 531/2000, Train Loss: 0.0023, Test Loss: 0.0918\n",
      "Epoch 532/2000, Train Loss: 0.0023, Test Loss: 0.0916\n",
      "Epoch 533/2000, Train Loss: 0.0023, Test Loss: 0.0915\n",
      "Epoch 534/2000, Train Loss: 0.0023, Test Loss: 0.0914\n",
      "Epoch 535/2000, Train Loss: 0.0023, Test Loss: 0.0913\n",
      "Epoch 536/2000, Train Loss: 0.0023, Test Loss: 0.0916\n",
      "Epoch 537/2000, Train Loss: 0.0023, Test Loss: 0.0929\n",
      "Epoch 538/2000, Train Loss: 0.0023, Test Loss: 0.0918\n",
      "Epoch 539/2000, Train Loss: 0.0023, Test Loss: 0.0915\n",
      "Epoch 540/2000, Train Loss: 0.0023, Test Loss: 0.0916\n",
      "Epoch 541/2000, Train Loss: 0.0023, Test Loss: 0.0915\n",
      "Epoch 542/2000, Train Loss: 0.0023, Test Loss: 0.0915\n",
      "Epoch 543/2000, Train Loss: 0.0023, Test Loss: 0.0917\n",
      "Epoch 544/2000, Train Loss: 0.0023, Test Loss: 0.0917\n",
      "Epoch 545/2000, Train Loss: 0.0023, Test Loss: 0.0918\n",
      "Epoch 546/2000, Train Loss: 0.0023, Test Loss: 0.0930\n",
      "Epoch 547/2000, Train Loss: 0.0023, Test Loss: 0.0919\n",
      "Epoch 548/2000, Train Loss: 0.0023, Test Loss: 0.0916\n",
      "Epoch 549/2000, Train Loss: 0.0023, Test Loss: 0.0916\n",
      "Epoch 550/2000, Train Loss: 0.0023, Test Loss: 0.0967\n",
      "Epoch 551/2000, Train Loss: 0.0023, Test Loss: 0.0922\n",
      "Epoch 552/2000, Train Loss: 0.0023, Test Loss: 0.0938\n",
      "Epoch 553/2000, Train Loss: 0.0023, Test Loss: 0.0917\n",
      "Epoch 554/2000, Train Loss: 0.0023, Test Loss: 0.0916\n",
      "Epoch 555/2000, Train Loss: 0.0023, Test Loss: 0.0946\n",
      "Epoch 556/2000, Train Loss: 0.0023, Test Loss: 0.0919\n",
      "Epoch 557/2000, Train Loss: 0.0023, Test Loss: 0.0920\n",
      "Epoch 558/2000, Train Loss: 0.0023, Test Loss: 0.0915\n",
      "Epoch 559/2000, Train Loss: 0.0023, Test Loss: 0.0918\n",
      "Epoch 560/2000, Train Loss: 0.0022, Test Loss: 0.0918\n",
      "Epoch 561/2000, Train Loss: 0.0022, Test Loss: 0.0980\n",
      "Epoch 562/2000, Train Loss: 0.0022, Test Loss: 0.0919\n",
      "Epoch 563/2000, Train Loss: 0.0022, Test Loss: 0.0923\n",
      "Epoch 564/2000, Train Loss: 0.0022, Test Loss: 0.0921\n",
      "Epoch 565/2000, Train Loss: 0.0022, Test Loss: 0.0985\n",
      "Epoch 566/2000, Train Loss: 0.0022, Test Loss: 0.0962\n",
      "Epoch 567/2000, Train Loss: 0.0022, Test Loss: 0.0918\n",
      "Epoch 568/2000, Train Loss: 0.0022, Test Loss: 0.0919\n",
      "Epoch 569/2000, Train Loss: 0.0022, Test Loss: 0.0940\n",
      "Epoch 570/2000, Train Loss: 0.0022, Test Loss: 0.0918\n",
      "Epoch 571/2000, Train Loss: 0.0022, Test Loss: 0.0971\n",
      "Epoch 572/2000, Train Loss: 0.0022, Test Loss: 0.0920\n",
      "Epoch 573/2000, Train Loss: 0.0022, Test Loss: 0.0931\n",
      "Epoch 574/2000, Train Loss: 0.0022, Test Loss: 0.0928\n",
      "Epoch 575/2000, Train Loss: 0.0022, Test Loss: 0.0929\n",
      "Epoch 576/2000, Train Loss: 0.0022, Test Loss: 0.0933\n",
      "Epoch 577/2000, Train Loss: 0.0022, Test Loss: 0.0924\n",
      "Epoch 578/2000, Train Loss: 0.0022, Test Loss: 0.0919\n",
      "Epoch 579/2000, Train Loss: 0.0022, Test Loss: 0.0921\n",
      "Epoch 580/2000, Train Loss: 0.0022, Test Loss: 0.0921\n",
      "Epoch 581/2000, Train Loss: 0.0022, Test Loss: 0.0921\n",
      "Epoch 582/2000, Train Loss: 0.0022, Test Loss: 0.0940\n",
      "Epoch 583/2000, Train Loss: 0.0022, Test Loss: 0.0922\n",
      "Epoch 584/2000, Train Loss: 0.0022, Test Loss: 0.0920\n",
      "Epoch 585/2000, Train Loss: 0.0022, Test Loss: 0.0922\n",
      "Epoch 586/2000, Train Loss: 0.0022, Test Loss: 0.0920\n",
      "Epoch 587/2000, Train Loss: 0.0022, Test Loss: 0.0923\n",
      "Epoch 588/2000, Train Loss: 0.0022, Test Loss: 0.0922\n",
      "Epoch 589/2000, Train Loss: 0.0022, Test Loss: 0.0922\n",
      "Epoch 590/2000, Train Loss: 0.0021, Test Loss: 0.0921\n",
      "Epoch 591/2000, Train Loss: 0.0021, Test Loss: 0.0919\n",
      "Epoch 592/2000, Train Loss: 0.0021, Test Loss: 0.0923\n",
      "Epoch 593/2000, Train Loss: 0.0021, Test Loss: 0.0968\n",
      "Epoch 594/2000, Train Loss: 0.0021, Test Loss: 0.0954\n",
      "Epoch 595/2000, Train Loss: 0.0021, Test Loss: 0.0924\n",
      "Epoch 596/2000, Train Loss: 0.0021, Test Loss: 0.0923\n",
      "Epoch 597/2000, Train Loss: 0.0021, Test Loss: 0.0922\n",
      "Epoch 598/2000, Train Loss: 0.0021, Test Loss: 0.0923\n",
      "Epoch 599/2000, Train Loss: 0.0021, Test Loss: 0.0925\n",
      "Epoch 600/2000, Train Loss: 0.0021, Test Loss: 0.0936\n",
      "Epoch 601/2000, Train Loss: 0.0021, Test Loss: 0.0925\n",
      "Epoch 602/2000, Train Loss: 0.0021, Test Loss: 0.0922\n",
      "Epoch 603/2000, Train Loss: 0.0021, Test Loss: 0.0960\n",
      "Epoch 604/2000, Train Loss: 0.0021, Test Loss: 0.0920\n",
      "Epoch 605/2000, Train Loss: 0.0021, Test Loss: 0.0987\n",
      "Epoch 606/2000, Train Loss: 0.0021, Test Loss: 0.0925\n",
      "Epoch 607/2000, Train Loss: 0.0021, Test Loss: 0.0921\n",
      "Epoch 608/2000, Train Loss: 0.0021, Test Loss: 0.0968\n",
      "Epoch 609/2000, Train Loss: 0.0021, Test Loss: 0.0922\n",
      "Epoch 610/2000, Train Loss: 0.0021, Test Loss: 0.0923\n",
      "Epoch 611/2000, Train Loss: 0.0021, Test Loss: 0.0928\n",
      "Epoch 612/2000, Train Loss: 0.0021, Test Loss: 0.0925\n",
      "Epoch 613/2000, Train Loss: 0.0021, Test Loss: 0.0923\n",
      "Epoch 614/2000, Train Loss: 0.0021, Test Loss: 0.0945\n",
      "Epoch 615/2000, Train Loss: 0.0021, Test Loss: 0.0968\n",
      "Epoch 616/2000, Train Loss: 0.0021, Test Loss: 0.0933\n",
      "Epoch 617/2000, Train Loss: 0.0021, Test Loss: 0.0929\n",
      "Epoch 618/2000, Train Loss: 0.0021, Test Loss: 0.0924\n",
      "Epoch 619/2000, Train Loss: 0.0021, Test Loss: 0.0922\n",
      "Epoch 620/2000, Train Loss: 0.0021, Test Loss: 0.0924\n",
      "Epoch 621/2000, Train Loss: 0.0021, Test Loss: 0.0957\n",
      "Epoch 622/2000, Train Loss: 0.0021, Test Loss: 0.0925\n",
      "Epoch 623/2000, Train Loss: 0.0021, Test Loss: 0.0924\n",
      "Epoch 624/2000, Train Loss: 0.0021, Test Loss: 0.0924\n",
      "Epoch 625/2000, Train Loss: 0.0021, Test Loss: 0.0924\n",
      "Epoch 626/2000, Train Loss: 0.0020, Test Loss: 0.0949\n",
      "Epoch 627/2000, Train Loss: 0.0020, Test Loss: 0.0926\n",
      "Epoch 628/2000, Train Loss: 0.0020, Test Loss: 0.0957\n",
      "Epoch 629/2000, Train Loss: 0.0020, Test Loss: 0.0925\n",
      "Epoch 630/2000, Train Loss: 0.0020, Test Loss: 0.0933\n",
      "Epoch 631/2000, Train Loss: 0.0020, Test Loss: 0.0939\n",
      "Epoch 632/2000, Train Loss: 0.0020, Test Loss: 0.0925\n",
      "Epoch 633/2000, Train Loss: 0.0020, Test Loss: 0.0927\n",
      "Epoch 634/2000, Train Loss: 0.0020, Test Loss: 0.0950\n",
      "Epoch 635/2000, Train Loss: 0.0020, Test Loss: 0.0931\n",
      "Epoch 636/2000, Train Loss: 0.0020, Test Loss: 0.0937\n",
      "Epoch 637/2000, Train Loss: 0.0020, Test Loss: 0.0925\n",
      "Epoch 638/2000, Train Loss: 0.0020, Test Loss: 0.0930\n",
      "Epoch 639/2000, Train Loss: 0.0020, Test Loss: 0.0938\n",
      "Epoch 640/2000, Train Loss: 0.0020, Test Loss: 0.0930\n",
      "Epoch 641/2000, Train Loss: 0.0020, Test Loss: 0.0956\n",
      "Epoch 642/2000, Train Loss: 0.0020, Test Loss: 0.0934\n",
      "Epoch 643/2000, Train Loss: 0.0020, Test Loss: 0.0927\n",
      "Epoch 644/2000, Train Loss: 0.0020, Test Loss: 0.0927\n",
      "Epoch 645/2000, Train Loss: 0.0020, Test Loss: 0.0929\n",
      "Epoch 646/2000, Train Loss: 0.0020, Test Loss: 0.0935\n",
      "Epoch 647/2000, Train Loss: 0.0020, Test Loss: 0.0931\n",
      "Epoch 648/2000, Train Loss: 0.0020, Test Loss: 0.0930\n",
      "Epoch 649/2000, Train Loss: 0.0020, Test Loss: 0.0965\n",
      "Epoch 650/2000, Train Loss: 0.0020, Test Loss: 0.0927\n",
      "Epoch 651/2000, Train Loss: 0.0020, Test Loss: 0.0926\n",
      "Epoch 652/2000, Train Loss: 0.0020, Test Loss: 0.0927\n",
      "Epoch 653/2000, Train Loss: 0.0020, Test Loss: 0.0939\n",
      "Epoch 654/2000, Train Loss: 0.0020, Test Loss: 0.0979\n",
      "Epoch 655/2000, Train Loss: 0.0020, Test Loss: 0.0930\n",
      "Epoch 656/2000, Train Loss: 0.0020, Test Loss: 0.0929\n",
      "Epoch 657/2000, Train Loss: 0.0020, Test Loss: 0.0930\n",
      "Epoch 658/2000, Train Loss: 0.0020, Test Loss: 0.0934\n",
      "Epoch 659/2000, Train Loss: 0.0020, Test Loss: 0.0928\n",
      "Epoch 660/2000, Train Loss: 0.0020, Test Loss: 0.0927\n",
      "Epoch 661/2000, Train Loss: 0.0020, Test Loss: 0.0933\n",
      "Epoch 662/2000, Train Loss: 0.0020, Test Loss: 0.0967\n",
      "Epoch 663/2000, Train Loss: 0.0020, Test Loss: 0.0928\n",
      "Epoch 664/2000, Train Loss: 0.0020, Test Loss: 0.0929\n",
      "Epoch 665/2000, Train Loss: 0.0020, Test Loss: 0.0931\n",
      "Epoch 666/2000, Train Loss: 0.0020, Test Loss: 0.0939\n",
      "Epoch 667/2000, Train Loss: 0.0019, Test Loss: 0.0932\n",
      "Epoch 668/2000, Train Loss: 0.0019, Test Loss: 0.0931\n",
      "Epoch 669/2000, Train Loss: 0.0019, Test Loss: 0.0955\n",
      "Epoch 670/2000, Train Loss: 0.0019, Test Loss: 0.0931\n",
      "Epoch 671/2000, Train Loss: 0.0019, Test Loss: 0.0930\n",
      "Epoch 672/2000, Train Loss: 0.0019, Test Loss: 0.0931\n",
      "Epoch 673/2000, Train Loss: 0.0019, Test Loss: 0.0948\n",
      "Epoch 674/2000, Train Loss: 0.0019, Test Loss: 0.0931\n",
      "Epoch 675/2000, Train Loss: 0.0019, Test Loss: 0.0930\n",
      "Epoch 676/2000, Train Loss: 0.0019, Test Loss: 0.0967\n",
      "Epoch 677/2000, Train Loss: 0.0019, Test Loss: 0.0928\n",
      "Epoch 678/2000, Train Loss: 0.0019, Test Loss: 0.0930\n",
      "Epoch 679/2000, Train Loss: 0.0019, Test Loss: 0.0930\n",
      "Epoch 680/2000, Train Loss: 0.0019, Test Loss: 0.0942\n",
      "Epoch 681/2000, Train Loss: 0.0019, Test Loss: 0.0932\n",
      "Epoch 682/2000, Train Loss: 0.0019, Test Loss: 0.0933\n",
      "Epoch 683/2000, Train Loss: 0.0019, Test Loss: 0.0965\n",
      "Epoch 684/2000, Train Loss: 0.0019, Test Loss: 0.0930\n",
      "Epoch 685/2000, Train Loss: 0.0019, Test Loss: 0.0931\n",
      "Epoch 686/2000, Train Loss: 0.0019, Test Loss: 0.0930\n",
      "Epoch 687/2000, Train Loss: 0.0019, Test Loss: 0.0983\n",
      "Epoch 688/2000, Train Loss: 0.0019, Test Loss: 0.0972\n",
      "Epoch 689/2000, Train Loss: 0.0019, Test Loss: 0.0952\n",
      "Epoch 690/2000, Train Loss: 0.0019, Test Loss: 0.0932\n",
      "Epoch 691/2000, Train Loss: 0.0019, Test Loss: 0.0932\n",
      "Epoch 692/2000, Train Loss: 0.0019, Test Loss: 0.0951\n",
      "Epoch 693/2000, Train Loss: 0.0019, Test Loss: 0.0931\n",
      "Epoch 694/2000, Train Loss: 0.0019, Test Loss: 0.0984\n",
      "Epoch 695/2000, Train Loss: 0.0019, Test Loss: 0.0961\n",
      "Epoch 696/2000, Train Loss: 0.0019, Test Loss: 0.0930\n",
      "Epoch 697/2000, Train Loss: 0.0019, Test Loss: 0.0939\n",
      "Epoch 698/2000, Train Loss: 0.0019, Test Loss: 0.0933\n",
      "Epoch 699/2000, Train Loss: 0.0019, Test Loss: 0.0933\n",
      "Epoch 700/2000, Train Loss: 0.0019, Test Loss: 0.0935\n",
      "Epoch 701/2000, Train Loss: 0.0019, Test Loss: 0.0933\n",
      "Epoch 702/2000, Train Loss: 0.0019, Test Loss: 0.0941\n",
      "Epoch 703/2000, Train Loss: 0.0019, Test Loss: 0.0931\n",
      "Epoch 704/2000, Train Loss: 0.0019, Test Loss: 0.0944\n",
      "Epoch 705/2000, Train Loss: 0.0019, Test Loss: 0.0966\n",
      "Epoch 706/2000, Train Loss: 0.0019, Test Loss: 0.0933\n",
      "Epoch 707/2000, Train Loss: 0.0019, Test Loss: 0.0933\n",
      "Epoch 708/2000, Train Loss: 0.0019, Test Loss: 0.0956\n",
      "Epoch 709/2000, Train Loss: 0.0019, Test Loss: 0.0934\n",
      "Epoch 710/2000, Train Loss: 0.0019, Test Loss: 0.0932\n",
      "Epoch 711/2000, Train Loss: 0.0019, Test Loss: 0.0934\n",
      "Epoch 712/2000, Train Loss: 0.0018, Test Loss: 0.0939\n",
      "Epoch 713/2000, Train Loss: 0.0018, Test Loss: 0.0933\n",
      "Epoch 714/2000, Train Loss: 0.0018, Test Loss: 0.0934\n",
      "Epoch 715/2000, Train Loss: 0.0018, Test Loss: 0.0937\n",
      "Epoch 716/2000, Train Loss: 0.0018, Test Loss: 0.0940\n",
      "Epoch 717/2000, Train Loss: 0.0018, Test Loss: 0.0964\n",
      "Epoch 718/2000, Train Loss: 0.0018, Test Loss: 0.0969\n",
      "Epoch 719/2000, Train Loss: 0.0018, Test Loss: 0.0934\n",
      "Epoch 720/2000, Train Loss: 0.0018, Test Loss: 0.0933\n",
      "Epoch 721/2000, Train Loss: 0.0018, Test Loss: 0.0935\n",
      "Epoch 722/2000, Train Loss: 0.0018, Test Loss: 0.0934\n",
      "Epoch 723/2000, Train Loss: 0.0018, Test Loss: 0.0936\n",
      "Epoch 724/2000, Train Loss: 0.0018, Test Loss: 0.0974\n",
      "Epoch 725/2000, Train Loss: 0.0018, Test Loss: 0.0937\n",
      "Epoch 726/2000, Train Loss: 0.0018, Test Loss: 0.0934\n",
      "Epoch 727/2000, Train Loss: 0.0018, Test Loss: 0.0934\n",
      "Epoch 728/2000, Train Loss: 0.0018, Test Loss: 0.0936\n",
      "Epoch 729/2000, Train Loss: 0.0018, Test Loss: 0.0973\n",
      "Epoch 730/2000, Train Loss: 0.0018, Test Loss: 0.0934\n",
      "Epoch 731/2000, Train Loss: 0.0018, Test Loss: 0.0936\n",
      "Epoch 732/2000, Train Loss: 0.0018, Test Loss: 0.0935\n",
      "Epoch 733/2000, Train Loss: 0.0018, Test Loss: 0.0938\n",
      "Epoch 734/2000, Train Loss: 0.0018, Test Loss: 0.0973\n",
      "Epoch 735/2000, Train Loss: 0.0018, Test Loss: 0.0936\n",
      "Epoch 736/2000, Train Loss: 0.0018, Test Loss: 0.0936\n",
      "Epoch 737/2000, Train Loss: 0.0018, Test Loss: 0.0937\n",
      "Epoch 738/2000, Train Loss: 0.0018, Test Loss: 0.0954\n",
      "Epoch 739/2000, Train Loss: 0.0018, Test Loss: 0.0974\n",
      "Epoch 740/2000, Train Loss: 0.0018, Test Loss: 0.0936\n",
      "Epoch 741/2000, Train Loss: 0.0018, Test Loss: 0.0936\n",
      "Epoch 742/2000, Train Loss: 0.0018, Test Loss: 0.0938\n",
      "Epoch 743/2000, Train Loss: 0.0018, Test Loss: 0.0951\n",
      "Epoch 744/2000, Train Loss: 0.0018, Test Loss: 0.0940\n",
      "Epoch 745/2000, Train Loss: 0.0018, Test Loss: 0.0935\n",
      "Epoch 746/2000, Train Loss: 0.0018, Test Loss: 0.0937\n",
      "Epoch 747/2000, Train Loss: 0.0018, Test Loss: 0.0937\n",
      "Epoch 748/2000, Train Loss: 0.0018, Test Loss: 0.0937\n",
      "Epoch 749/2000, Train Loss: 0.0018, Test Loss: 0.0952\n",
      "Epoch 750/2000, Train Loss: 0.0018, Test Loss: 0.0936\n",
      "Epoch 751/2000, Train Loss: 0.0018, Test Loss: 0.0942\n",
      "Epoch 752/2000, Train Loss: 0.0018, Test Loss: 0.0970\n",
      "Epoch 753/2000, Train Loss: 0.0018, Test Loss: 0.0938\n",
      "Epoch 754/2000, Train Loss: 0.0018, Test Loss: 0.0937\n",
      "Epoch 755/2000, Train Loss: 0.0018, Test Loss: 0.0936\n",
      "Epoch 756/2000, Train Loss: 0.0018, Test Loss: 0.0938\n",
      "Epoch 757/2000, Train Loss: 0.0018, Test Loss: 0.0938\n",
      "Epoch 758/2000, Train Loss: 0.0018, Test Loss: 0.0938\n",
      "Epoch 759/2000, Train Loss: 0.0018, Test Loss: 0.0939\n",
      "Epoch 760/2000, Train Loss: 0.0018, Test Loss: 0.0992\n",
      "Epoch 761/2000, Train Loss: 0.0018, Test Loss: 0.0940\n",
      "Epoch 762/2000, Train Loss: 0.0018, Test Loss: 0.0939\n",
      "Epoch 763/2000, Train Loss: 0.0017, Test Loss: 0.0976\n",
      "Epoch 764/2000, Train Loss: 0.0018, Test Loss: 0.0938\n",
      "Epoch 765/2000, Train Loss: 0.0017, Test Loss: 0.0940\n",
      "Epoch 766/2000, Train Loss: 0.0017, Test Loss: 0.0938\n",
      "Epoch 767/2000, Train Loss: 0.0017, Test Loss: 0.0941\n",
      "Epoch 768/2000, Train Loss: 0.0017, Test Loss: 0.0937\n",
      "Epoch 769/2000, Train Loss: 0.0017, Test Loss: 0.0938\n",
      "Epoch 770/2000, Train Loss: 0.0017, Test Loss: 0.0940\n",
      "Epoch 771/2000, Train Loss: 0.0017, Test Loss: 0.0939\n",
      "Epoch 772/2000, Train Loss: 0.0017, Test Loss: 0.0973\n",
      "Epoch 773/2000, Train Loss: 0.0017, Test Loss: 0.0941\n",
      "Epoch 774/2000, Train Loss: 0.0017, Test Loss: 0.0940\n",
      "Epoch 775/2000, Train Loss: 0.0017, Test Loss: 0.0947\n",
      "Epoch 776/2000, Train Loss: 0.0017, Test Loss: 0.0945\n",
      "Epoch 777/2000, Train Loss: 0.0017, Test Loss: 0.0940\n",
      "Epoch 778/2000, Train Loss: 0.0017, Test Loss: 0.0939\n",
      "Epoch 779/2000, Train Loss: 0.0017, Test Loss: 0.0939\n",
      "Epoch 780/2000, Train Loss: 0.0017, Test Loss: 0.0939\n",
      "Epoch 781/2000, Train Loss: 0.0017, Test Loss: 0.0939\n",
      "Epoch 782/2000, Train Loss: 0.0017, Test Loss: 0.0945\n",
      "Epoch 783/2000, Train Loss: 0.0017, Test Loss: 0.0940\n",
      "Epoch 784/2000, Train Loss: 0.0017, Test Loss: 0.0942\n",
      "Epoch 785/2000, Train Loss: 0.0017, Test Loss: 0.0946\n",
      "Epoch 786/2000, Train Loss: 0.0017, Test Loss: 0.0942\n",
      "Epoch 787/2000, Train Loss: 0.0017, Test Loss: 0.0986\n",
      "Epoch 788/2000, Train Loss: 0.0017, Test Loss: 0.0970\n",
      "Epoch 789/2000, Train Loss: 0.0017, Test Loss: 0.0940\n",
      "Epoch 790/2000, Train Loss: 0.0017, Test Loss: 0.0940\n",
      "Epoch 791/2000, Train Loss: 0.0017, Test Loss: 0.0956\n",
      "Epoch 792/2000, Train Loss: 0.0017, Test Loss: 0.0982\n",
      "Epoch 793/2000, Train Loss: 0.0017, Test Loss: 0.0941\n",
      "Epoch 794/2000, Train Loss: 0.0017, Test Loss: 0.1027\n",
      "Epoch 795/2000, Train Loss: 0.0017, Test Loss: 0.0940\n",
      "Epoch 796/2000, Train Loss: 0.0017, Test Loss: 0.0942\n",
      "Epoch 797/2000, Train Loss: 0.0017, Test Loss: 0.0941\n",
      "Epoch 798/2000, Train Loss: 0.0017, Test Loss: 0.0951\n",
      "Epoch 799/2000, Train Loss: 0.0017, Test Loss: 0.0944\n",
      "Epoch 800/2000, Train Loss: 0.0017, Test Loss: 0.0951\n",
      "Epoch 801/2000, Train Loss: 0.0017, Test Loss: 0.0942\n",
      "Epoch 802/2000, Train Loss: 0.0017, Test Loss: 0.0942\n",
      "Epoch 803/2000, Train Loss: 0.0017, Test Loss: 0.0941\n",
      "Epoch 804/2000, Train Loss: 0.0017, Test Loss: 0.0941\n",
      "Epoch 805/2000, Train Loss: 0.0017, Test Loss: 0.0952\n",
      "Epoch 806/2000, Train Loss: 0.0017, Test Loss: 0.0940\n",
      "Epoch 807/2000, Train Loss: 0.0017, Test Loss: 0.0942\n",
      "Epoch 808/2000, Train Loss: 0.0017, Test Loss: 0.0946\n",
      "Epoch 809/2000, Train Loss: 0.0017, Test Loss: 0.0948\n",
      "Epoch 810/2000, Train Loss: 0.0017, Test Loss: 0.0977\n",
      "Epoch 811/2000, Train Loss: 0.0017, Test Loss: 0.0946\n",
      "Epoch 812/2000, Train Loss: 0.0017, Test Loss: 0.0955\n",
      "Epoch 813/2000, Train Loss: 0.0017, Test Loss: 0.0947\n",
      "Epoch 814/2000, Train Loss: 0.0017, Test Loss: 0.0969\n",
      "Epoch 815/2000, Train Loss: 0.0017, Test Loss: 0.0985\n",
      "Epoch 816/2000, Train Loss: 0.0017, Test Loss: 0.0942\n",
      "Epoch 817/2000, Train Loss: 0.0017, Test Loss: 0.0942\n",
      "Epoch 818/2000, Train Loss: 0.0017, Test Loss: 0.0948\n",
      "Epoch 819/2000, Train Loss: 0.0017, Test Loss: 0.0946\n",
      "Epoch 820/2000, Train Loss: 0.0017, Test Loss: 0.0956\n",
      "Epoch 821/2000, Train Loss: 0.0017, Test Loss: 0.0943\n",
      "Epoch 822/2000, Train Loss: 0.0016, Test Loss: 0.0944\n",
      "Epoch 823/2000, Train Loss: 0.0017, Test Loss: 0.0943\n",
      "Epoch 824/2000, Train Loss: 0.0016, Test Loss: 0.0945\n",
      "Epoch 825/2000, Train Loss: 0.0016, Test Loss: 0.0946\n",
      "Epoch 826/2000, Train Loss: 0.0016, Test Loss: 0.0943\n",
      "Epoch 827/2000, Train Loss: 0.0016, Test Loss: 0.0944\n",
      "Epoch 828/2000, Train Loss: 0.0016, Test Loss: 0.0944\n",
      "Epoch 829/2000, Train Loss: 0.0016, Test Loss: 0.0991\n",
      "Epoch 830/2000, Train Loss: 0.0016, Test Loss: 0.0944\n",
      "Epoch 831/2000, Train Loss: 0.0016, Test Loss: 0.0943\n",
      "Epoch 832/2000, Train Loss: 0.0016, Test Loss: 0.0947\n",
      "Epoch 833/2000, Train Loss: 0.0016, Test Loss: 0.0944\n",
      "Epoch 834/2000, Train Loss: 0.0016, Test Loss: 0.0945\n",
      "Epoch 835/2000, Train Loss: 0.0016, Test Loss: 0.0945\n",
      "Epoch 836/2000, Train Loss: 0.0016, Test Loss: 0.0945\n",
      "Epoch 837/2000, Train Loss: 0.0016, Test Loss: 0.0999\n",
      "Epoch 838/2000, Train Loss: 0.0016, Test Loss: 0.0952\n",
      "Epoch 839/2000, Train Loss: 0.0016, Test Loss: 0.0946\n",
      "Epoch 840/2000, Train Loss: 0.0016, Test Loss: 0.0946\n",
      "Epoch 841/2000, Train Loss: 0.0016, Test Loss: 0.0957\n",
      "Epoch 842/2000, Train Loss: 0.0016, Test Loss: 0.0948\n",
      "Epoch 843/2000, Train Loss: 0.0016, Test Loss: 0.0944\n",
      "Epoch 844/2000, Train Loss: 0.0016, Test Loss: 0.0944\n",
      "Epoch 845/2000, Train Loss: 0.0016, Test Loss: 0.0950\n",
      "Epoch 846/2000, Train Loss: 0.0016, Test Loss: 0.0945\n",
      "Epoch 847/2000, Train Loss: 0.0016, Test Loss: 0.0945\n",
      "Epoch 848/2000, Train Loss: 0.0016, Test Loss: 0.0945\n",
      "Epoch 849/2000, Train Loss: 0.0016, Test Loss: 0.0947\n",
      "Epoch 850/2000, Train Loss: 0.0016, Test Loss: 0.0956\n",
      "Epoch 851/2000, Train Loss: 0.0016, Test Loss: 0.0954\n",
      "Epoch 852/2000, Train Loss: 0.0016, Test Loss: 0.0945\n",
      "Epoch 853/2000, Train Loss: 0.0016, Test Loss: 0.0953\n",
      "Epoch 854/2000, Train Loss: 0.0016, Test Loss: 0.0946\n",
      "Epoch 855/2000, Train Loss: 0.0016, Test Loss: 0.0963\n",
      "Epoch 856/2000, Train Loss: 0.0016, Test Loss: 0.0947\n",
      "Epoch 857/2000, Train Loss: 0.0016, Test Loss: 0.0948\n",
      "Epoch 858/2000, Train Loss: 0.0016, Test Loss: 0.0976\n",
      "Epoch 859/2000, Train Loss: 0.0016, Test Loss: 0.0947\n",
      "Epoch 860/2000, Train Loss: 0.0016, Test Loss: 0.0975\n",
      "Epoch 861/2000, Train Loss: 0.0016, Test Loss: 0.0952\n",
      "Epoch 862/2000, Train Loss: 0.0016, Test Loss: 0.0953\n",
      "Epoch 863/2000, Train Loss: 0.0016, Test Loss: 0.0990\n",
      "Epoch 864/2000, Train Loss: 0.0016, Test Loss: 0.0947\n",
      "Epoch 865/2000, Train Loss: 0.0016, Test Loss: 0.0947\n",
      "Epoch 866/2000, Train Loss: 0.0016, Test Loss: 0.1000\n",
      "Epoch 867/2000, Train Loss: 0.0016, Test Loss: 0.0979\n",
      "Epoch 868/2000, Train Loss: 0.0016, Test Loss: 0.0946\n",
      "Epoch 869/2000, Train Loss: 0.0016, Test Loss: 0.0948\n",
      "Epoch 870/2000, Train Loss: 0.0016, Test Loss: 0.0986\n",
      "Epoch 871/2000, Train Loss: 0.0016, Test Loss: 0.0951\n",
      "Epoch 872/2000, Train Loss: 0.0016, Test Loss: 0.0948\n",
      "Epoch 873/2000, Train Loss: 0.0016, Test Loss: 0.0947\n",
      "Epoch 874/2000, Train Loss: 0.0016, Test Loss: 0.1054\n",
      "Epoch 875/2000, Train Loss: 0.0016, Test Loss: 0.0951\n",
      "Epoch 876/2000, Train Loss: 0.0016, Test Loss: 0.0956\n",
      "Epoch 877/2000, Train Loss: 0.0016, Test Loss: 0.0955\n",
      "Epoch 878/2000, Train Loss: 0.0016, Test Loss: 0.0948\n",
      "Epoch 879/2000, Train Loss: 0.0016, Test Loss: 0.0958\n",
      "Epoch 880/2000, Train Loss: 0.0016, Test Loss: 0.0954\n",
      "Epoch 881/2000, Train Loss: 0.0016, Test Loss: 0.0947\n",
      "Epoch 882/2000, Train Loss: 0.0016, Test Loss: 0.0947\n",
      "Epoch 883/2000, Train Loss: 0.0016, Test Loss: 0.0947\n",
      "Epoch 884/2000, Train Loss: 0.0016, Test Loss: 0.0949\n",
      "Epoch 885/2000, Train Loss: 0.0016, Test Loss: 0.0951\n",
      "Epoch 886/2000, Train Loss: 0.0016, Test Loss: 0.0947\n",
      "Epoch 887/2000, Train Loss: 0.0016, Test Loss: 0.1003\n",
      "Epoch 888/2000, Train Loss: 0.0016, Test Loss: 0.0946\n",
      "Epoch 889/2000, Train Loss: 0.0016, Test Loss: 0.0949\n",
      "Epoch 890/2000, Train Loss: 0.0015, Test Loss: 0.0951\n",
      "Epoch 891/2000, Train Loss: 0.0015, Test Loss: 0.0951\n",
      "Epoch 892/2000, Train Loss: 0.0015, Test Loss: 0.0948\n",
      "Epoch 893/2000, Train Loss: 0.0015, Test Loss: 0.0949\n",
      "Epoch 894/2000, Train Loss: 0.0015, Test Loss: 0.0949\n",
      "Epoch 895/2000, Train Loss: 0.0015, Test Loss: 0.0970\n",
      "Epoch 896/2000, Train Loss: 0.0015, Test Loss: 0.0956\n",
      "Epoch 897/2000, Train Loss: 0.0015, Test Loss: 0.0950\n",
      "Epoch 898/2000, Train Loss: 0.0015, Test Loss: 0.0961\n",
      "Epoch 899/2000, Train Loss: 0.0015, Test Loss: 0.0950\n",
      "Epoch 900/2000, Train Loss: 0.0015, Test Loss: 0.1001\n",
      "Epoch 901/2000, Train Loss: 0.0015, Test Loss: 0.0969\n",
      "Epoch 902/2000, Train Loss: 0.0015, Test Loss: 0.0953\n",
      "Epoch 903/2000, Train Loss: 0.0015, Test Loss: 0.0951\n",
      "Epoch 904/2000, Train Loss: 0.0015, Test Loss: 0.0955\n",
      "Epoch 905/2000, Train Loss: 0.0015, Test Loss: 0.0950\n",
      "Epoch 906/2000, Train Loss: 0.0015, Test Loss: 0.0950\n",
      "Epoch 907/2000, Train Loss: 0.0015, Test Loss: 0.0952\n",
      "Epoch 908/2000, Train Loss: 0.0015, Test Loss: 0.0950\n",
      "Epoch 909/2000, Train Loss: 0.0015, Test Loss: 0.0994\n",
      "Epoch 910/2000, Train Loss: 0.0015, Test Loss: 0.0950\n",
      "Epoch 911/2000, Train Loss: 0.0015, Test Loss: 0.0997\n",
      "Epoch 912/2000, Train Loss: 0.0015, Test Loss: 0.1056\n",
      "Epoch 913/2000, Train Loss: 0.0015, Test Loss: 0.1038\n",
      "Epoch 914/2000, Train Loss: 0.0015, Test Loss: 0.0952\n",
      "Epoch 915/2000, Train Loss: 0.0015, Test Loss: 0.0949\n",
      "Epoch 916/2000, Train Loss: 0.0015, Test Loss: 0.0963\n",
      "Epoch 917/2000, Train Loss: 0.0015, Test Loss: 0.0951\n",
      "Epoch 918/2000, Train Loss: 0.0015, Test Loss: 0.0983\n",
      "Epoch 919/2000, Train Loss: 0.0015, Test Loss: 0.0952\n",
      "Epoch 920/2000, Train Loss: 0.0015, Test Loss: 0.0960\n",
      "Epoch 921/2000, Train Loss: 0.0015, Test Loss: 0.0950\n",
      "Epoch 922/2000, Train Loss: 0.0015, Test Loss: 0.0952\n",
      "Epoch 923/2000, Train Loss: 0.0015, Test Loss: 0.0952\n",
      "Epoch 924/2000, Train Loss: 0.0015, Test Loss: 0.0952\n",
      "Epoch 925/2000, Train Loss: 0.0015, Test Loss: 0.0955\n",
      "Epoch 926/2000, Train Loss: 0.0015, Test Loss: 0.0952\n",
      "Epoch 927/2000, Train Loss: 0.0015, Test Loss: 0.0957\n",
      "Epoch 928/2000, Train Loss: 0.0015, Test Loss: 0.0952\n",
      "Epoch 929/2000, Train Loss: 0.0015, Test Loss: 0.0951\n",
      "Epoch 930/2000, Train Loss: 0.0015, Test Loss: 0.0970\n",
      "Epoch 931/2000, Train Loss: 0.0015, Test Loss: 0.0953\n",
      "Epoch 932/2000, Train Loss: 0.0015, Test Loss: 0.0959\n",
      "Epoch 933/2000, Train Loss: 0.0015, Test Loss: 0.0954\n",
      "Epoch 934/2000, Train Loss: 0.0015, Test Loss: 0.0951\n",
      "Epoch 935/2000, Train Loss: 0.0015, Test Loss: 0.1012\n",
      "Epoch 936/2000, Train Loss: 0.0015, Test Loss: 0.0979\n",
      "Epoch 937/2000, Train Loss: 0.0015, Test Loss: 0.0951\n",
      "Epoch 938/2000, Train Loss: 0.0015, Test Loss: 0.0953\n",
      "Epoch 939/2000, Train Loss: 0.0015, Test Loss: 0.0991\n",
      "Epoch 940/2000, Train Loss: 0.0015, Test Loss: 0.0957\n",
      "Epoch 941/2000, Train Loss: 0.0015, Test Loss: 0.0953\n",
      "Epoch 942/2000, Train Loss: 0.0015, Test Loss: 0.0954\n",
      "Epoch 943/2000, Train Loss: 0.0015, Test Loss: 0.0966\n",
      "Epoch 944/2000, Train Loss: 0.0015, Test Loss: 0.0954\n",
      "Epoch 945/2000, Train Loss: 0.0015, Test Loss: 0.0952\n",
      "Epoch 946/2000, Train Loss: 0.0015, Test Loss: 0.0953\n",
      "Epoch 947/2000, Train Loss: 0.0015, Test Loss: 0.0953\n",
      "Epoch 948/2000, Train Loss: 0.0015, Test Loss: 0.0968\n",
      "Epoch 949/2000, Train Loss: 0.0015, Test Loss: 0.0953\n",
      "Epoch 950/2000, Train Loss: 0.0015, Test Loss: 0.0952\n",
      "Epoch 951/2000, Train Loss: 0.0015, Test Loss: 0.0954\n",
      "Epoch 952/2000, Train Loss: 0.0015, Test Loss: 0.1000\n",
      "Epoch 953/2000, Train Loss: 0.0015, Test Loss: 0.0967\n",
      "Epoch 954/2000, Train Loss: 0.0015, Test Loss: 0.0966\n",
      "Epoch 955/2000, Train Loss: 0.0015, Test Loss: 0.0957\n",
      "Epoch 956/2000, Train Loss: 0.0015, Test Loss: 0.0972\n",
      "Epoch 957/2000, Train Loss: 0.0015, Test Loss: 0.0956\n",
      "Epoch 958/2000, Train Loss: 0.0015, Test Loss: 0.0954\n",
      "Epoch 959/2000, Train Loss: 0.0015, Test Loss: 0.0958\n",
      "Epoch 960/2000, Train Loss: 0.0015, Test Loss: 0.0954\n",
      "Epoch 961/2000, Train Loss: 0.0015, Test Loss: 0.0955\n",
      "Epoch 962/2000, Train Loss: 0.0015, Test Loss: 0.0953\n",
      "Epoch 963/2000, Train Loss: 0.0015, Test Loss: 0.0955\n",
      "Epoch 964/2000, Train Loss: 0.0015, Test Loss: 0.0954\n",
      "Epoch 965/2000, Train Loss: 0.0015, Test Loss: 0.0967\n",
      "Epoch 966/2000, Train Loss: 0.0015, Test Loss: 0.0955\n",
      "Epoch 967/2000, Train Loss: 0.0015, Test Loss: 0.0956\n",
      "Epoch 968/2000, Train Loss: 0.0015, Test Loss: 0.0955\n",
      "Epoch 969/2000, Train Loss: 0.0015, Test Loss: 0.0954\n",
      "Epoch 970/2000, Train Loss: 0.0015, Test Loss: 0.0959\n",
      "Epoch 971/2000, Train Loss: 0.0014, Test Loss: 0.0955\n",
      "Epoch 972/2000, Train Loss: 0.0015, Test Loss: 0.0954\n",
      "Epoch 973/2000, Train Loss: 0.0014, Test Loss: 0.0955\n",
      "Epoch 974/2000, Train Loss: 0.0014, Test Loss: 0.0956\n",
      "Epoch 975/2000, Train Loss: 0.0014, Test Loss: 0.0956\n",
      "Epoch 976/2000, Train Loss: 0.0014, Test Loss: 0.0956\n",
      "Epoch 977/2000, Train Loss: 0.0014, Test Loss: 0.0956\n",
      "Epoch 978/2000, Train Loss: 0.0014, Test Loss: 0.0991\n",
      "Epoch 979/2000, Train Loss: 0.0014, Test Loss: 0.0983\n",
      "Epoch 980/2000, Train Loss: 0.0014, Test Loss: 0.0956\n",
      "Epoch 981/2000, Train Loss: 0.0014, Test Loss: 0.0968\n",
      "Epoch 982/2000, Train Loss: 0.0014, Test Loss: 0.0955\n",
      "Epoch 983/2000, Train Loss: 0.0014, Test Loss: 0.0959\n",
      "Epoch 984/2000, Train Loss: 0.0014, Test Loss: 0.0992\n",
      "Epoch 985/2000, Train Loss: 0.0014, Test Loss: 0.0956\n",
      "Epoch 986/2000, Train Loss: 0.0014, Test Loss: 0.1014\n",
      "Epoch 987/2000, Train Loss: 0.0014, Test Loss: 0.0957\n",
      "Epoch 988/2000, Train Loss: 0.0014, Test Loss: 0.0968\n",
      "Epoch 989/2000, Train Loss: 0.0014, Test Loss: 0.0955\n",
      "Epoch 990/2000, Train Loss: 0.0014, Test Loss: 0.0957\n",
      "Epoch 991/2000, Train Loss: 0.0014, Test Loss: 0.1044\n",
      "Epoch 992/2000, Train Loss: 0.0014, Test Loss: 0.0957\n",
      "Epoch 993/2000, Train Loss: 0.0014, Test Loss: 0.1030\n",
      "Epoch 994/2000, Train Loss: 0.0014, Test Loss: 0.0956\n",
      "Epoch 995/2000, Train Loss: 0.0014, Test Loss: 0.0962\n",
      "Epoch 996/2000, Train Loss: 0.0014, Test Loss: 0.0956\n",
      "Epoch 997/2000, Train Loss: 0.0014, Test Loss: 0.0999\n",
      "Epoch 998/2000, Train Loss: 0.0014, Test Loss: 0.0966\n",
      "Epoch 999/2000, Train Loss: 0.0014, Test Loss: 0.0963\n",
      "Epoch 1000/2000, Train Loss: 0.0014, Test Loss: 0.0957\n",
      "Epoch 1001/2000, Train Loss: 0.0014, Test Loss: 0.0957\n",
      "Epoch 1002/2000, Train Loss: 0.0014, Test Loss: 0.0957\n",
      "Epoch 1003/2000, Train Loss: 0.0014, Test Loss: 0.0957\n",
      "Epoch 1004/2000, Train Loss: 0.0014, Test Loss: 0.0999\n",
      "Epoch 1005/2000, Train Loss: 0.0014, Test Loss: 0.0993\n",
      "Epoch 1006/2000, Train Loss: 0.0014, Test Loss: 0.0956\n",
      "Epoch 1007/2000, Train Loss: 0.0014, Test Loss: 0.0990\n",
      "Epoch 1008/2000, Train Loss: 0.0014, Test Loss: 0.0956\n",
      "Epoch 1009/2000, Train Loss: 0.0014, Test Loss: 0.0987\n",
      "Epoch 1010/2000, Train Loss: 0.0014, Test Loss: 0.1010\n",
      "Epoch 1011/2000, Train Loss: 0.0014, Test Loss: 0.0959\n",
      "Epoch 1012/2000, Train Loss: 0.0014, Test Loss: 0.0958\n",
      "Epoch 1013/2000, Train Loss: 0.0014, Test Loss: 0.0961\n",
      "Epoch 1014/2000, Train Loss: 0.0014, Test Loss: 0.0961\n",
      "Epoch 1015/2000, Train Loss: 0.0014, Test Loss: 0.0957\n",
      "Epoch 1016/2000, Train Loss: 0.0014, Test Loss: 0.1038\n",
      "Epoch 1017/2000, Train Loss: 0.0014, Test Loss: 0.0970\n",
      "Epoch 1018/2000, Train Loss: 0.0014, Test Loss: 0.0958\n",
      "Epoch 1019/2000, Train Loss: 0.0014, Test Loss: 0.0958\n",
      "Epoch 1020/2000, Train Loss: 0.0014, Test Loss: 0.0958\n",
      "Epoch 1021/2000, Train Loss: 0.0014, Test Loss: 0.0983\n",
      "Epoch 1022/2000, Train Loss: 0.0014, Test Loss: 0.0960\n",
      "Epoch 1023/2000, Train Loss: 0.0014, Test Loss: 0.0982\n",
      "Epoch 1024/2000, Train Loss: 0.0014, Test Loss: 0.0966\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n",
      "\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m FCNN(input_size, hidden_size, output_size)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''if previous_model:\u001b[39;00m\n",
      "\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    initialize_with_weight_reuse(model, previous_model, hidden_size)\u001b[39;00m\n",
      "\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mprint('Started traing for model')\u001b[39;00m\n",
      "\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mtrain_network(model, train_loader, input_size, hidden_size, output_size)\u001b[39;00m\n",
      "\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03mprevious_model = model'''\u001b[39;00m\n",
      "\u001b[0;32m---> 14\u001b[0m \u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[0;32mIn[10], line 38\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(model, train_loader, input_size, hidden_size, output_size)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "\u001b[1;32m     37\u001b[0m predictions \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;32m---> 38\u001b[0m train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;32m     39\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;32m     40\u001b[0m batch_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_size = 28 * 28  # MNIST images are 28x28\n",
    "output_size = 10  # 10 classes\n",
    "hidden_sizes = [2, 4, 8, 16, 32 ,64, 128]  # Example sizes\n",
    "\n",
    "previous_model = None\n",
    "for k in range (len(hidden_sizes)):\n",
    "    hidden_size = hidden_sizes[k]\n",
    "    model = FCNN(input_size, hidden_size, output_size).to(device)\n",
    "    '''if previous_model:\n",
    "        initialize_with_weight_reuse(model, previous_model, hidden_size)\n",
    "    print('Started traing for model')\n",
    "    train_network(model, train_loader, input_size, hidden_size, output_size)\n",
    "    previous_model = model'''\n",
    "    train_network(model, train_loader, input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed learning rate, 4000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 400\n",
    "lr = 0.002\n",
    "use_adam_op = True\n",
    "def train_network(model, train_loader, input_size, hidden_size, output_size):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.95) if not use_adam_op else optim.Adam(model.parameters(), lr=lr)\n",
    "    #scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "    wandb.init(project=\"SLT of Double Descent\", \n",
    "    config = {'epochs': epochs,\n",
    "              'classes': num_classes,\n",
    "              'learning_rate': lr,\n",
    "              'use_label_noise': use_label_noise,\n",
    "              'dataset': \"MNIST\",\n",
    "              'architecture': \"FCNN\",\n",
    "              'model_width': count_parameters(model),\n",
    "              'augmented': augmented,\n",
    "              'adam optimizer': use_adam_op})\n",
    "\n",
    "    wandb.watch(model)\n",
    "    config = wandb.config\n",
    "\n",
    "    test_losses = []\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    step = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        for _, data in enumerate(train_loader):\n",
    "            images, labels = data\n",
    "            images = images.view(-1, input_size)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            batch_loss = criterion(outputs, labels)\n",
    "            predictions = outputs.argmax(axis=-1)\n",
    "            train_acc += torch.sum(predictions == labels).item()\n",
    "            train_loss += batch_loss.item()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            step += 1\n",
    "\n",
    "            wandb.log({'batch_loss': batch_loss.item()}, step=step)\n",
    "\n",
    "        # Calculate average training loss for the epoch\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= 40000\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # Validation (or test) loop\n",
    "        model.eval()\n",
    "\n",
    "        test_loss = 0.0\n",
    "        test_acc = 0.0\n",
    "        with torch.no_grad():\n",
    "            for k, test_data in enumerate(test_loader):\n",
    "                test_images, test_labels = test_data\n",
    "                test_images = test_images.view(-1, input_size)\n",
    "                test_images = test_images.to(device)\n",
    "                test_labels = test_labels.to(device)\n",
    "\n",
    "                outputs = model(test_images)\n",
    "                batch_test_loss = criterion(outputs, test_labels)\n",
    "                test_loss += batch_test_loss.item()\n",
    "\n",
    "                predictions = outputs.argmax(axis=-1)\n",
    "                test_acc += torch.sum(predictions == test_labels).item()\n",
    "\n",
    "        # Let's calculate average test loss for the epoch\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc /= len(test_loader.dataset.data)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        torch.save(test_accs, rlcts_path + 'test_accs_'+ str(hidden_size)+'.pt')\n",
    "        torch.save(test_losses, rlcts_path + 'test_losses_'+ str(hidden_size)+'.pt')\n",
    "\n",
    "        wandb.log({'epoch': epoch,\n",
    "                   'loss/train': train_loss,\n",
    "                   'loss/test': test_loss,\n",
    "                   'accuracy/train': train_acc,\n",
    "                   'accuracy/test': test_acc\n",
    "                   }, step=step)\n",
    "\n",
    "        # Print or log the training and test losses for each epoch\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "        #scheduler.step()\n",
    "        \n",
    "        # Implement stopping condition based on classification error or epoch limit\n",
    "        # Note: Simplified, as the full stopping condition is not detailed here\n",
    "    wandb.finish()\n",
    "    torch.save(model.state_dict(), mwdd_path + 'fccnn_'+str(hidden_size)+'_fixed.pth')\n",
    "    print(f\"Training completed for hidden size: {hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:nkr55q5w) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.1135</td></tr><tr><td>accuracy/train</td><td>0.11238</td></tr><tr><td>batch_loss</td><td>2.30383</td></tr><tr><td>epoch</td><td>77</td></tr><tr><td>loss/test</td><td>2.30107</td></tr><tr><td>loss/train</td><td>2.30137</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swift-grass-276</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/nkr55q5w' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/nkr55q5w</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240314_000629-nkr55q5w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:nkr55q5w). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240314_001438-bw1bp65v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/bw1bp65v' target=\"_blank\">easy-voice-277</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/bw1bp65v' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/bw1bp65v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Train Loss: 2.3235, Test Loss: 2.3033\n",
      "Epoch 2/400, Train Loss: 2.3021, Test Loss: 2.3010\n",
      "Epoch 3/400, Train Loss: 2.3013, Test Loss: 2.3005\n",
      "Epoch 4/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 5/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 6/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 7/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 8/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 9/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 10/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 11/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 12/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 13/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 14/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 15/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 16/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 17/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 18/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 19/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 20/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 21/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 22/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 23/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 24/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 25/400, Train Loss: 2.3013, Test Loss: 2.3006\n",
      "Epoch 26/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 27/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 28/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 29/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 30/400, Train Loss: 2.3012, Test Loss: 2.3007\n",
      "Epoch 31/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 32/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 33/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 34/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 35/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 36/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 37/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 38/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 39/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 40/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 41/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 42/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 43/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 44/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 45/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 46/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 47/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 48/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 49/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 50/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 51/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 52/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 53/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 54/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 55/400, Train Loss: 2.3013, Test Loss: 2.3014\n",
      "Epoch 56/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 57/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 58/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 59/400, Train Loss: 2.3013, Test Loss: 2.3014\n",
      "Epoch 60/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 61/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 62/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 63/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 64/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 65/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 66/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 67/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 68/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 69/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 70/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 71/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 72/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 73/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 74/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 75/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 76/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 77/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 78/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 79/400, Train Loss: 2.3012, Test Loss: 2.3014\n",
      "Epoch 80/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 81/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 82/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 83/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 84/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 85/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 86/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 87/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 88/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 89/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 90/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 91/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 92/400, Train Loss: 2.3012, Test Loss: 2.3015\n",
      "Epoch 93/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 94/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 95/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 96/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 97/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 98/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 99/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 100/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 101/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 102/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 103/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 104/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 105/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 106/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 107/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 108/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 109/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 110/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 111/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 112/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 113/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 114/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 115/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 116/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 117/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 118/400, Train Loss: 2.3012, Test Loss: 2.3014\n",
      "Epoch 119/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 120/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 121/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 122/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 123/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 124/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 125/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 126/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 127/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 128/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 129/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 130/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 131/400, Train Loss: 2.3013, Test Loss: 2.3014\n",
      "Epoch 132/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 133/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 134/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 135/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 136/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 137/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 138/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 139/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 140/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 141/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 142/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 143/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 144/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 145/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 146/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 147/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 148/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 149/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 150/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 151/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 152/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 153/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 154/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 155/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 156/400, Train Loss: 2.3013, Test Loss: 2.3015\n",
      "Epoch 157/400, Train Loss: 2.3013, Test Loss: 2.3014\n",
      "Epoch 158/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 159/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 160/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 161/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 162/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 163/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 164/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 165/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 166/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 167/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 168/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 169/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 170/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 171/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 172/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 173/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 174/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 175/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 176/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 177/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 178/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 179/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 180/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 181/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 182/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 183/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 184/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 185/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 186/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 187/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 188/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 189/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 190/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 191/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 192/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 193/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 194/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 195/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 196/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 197/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 198/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 199/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 200/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 201/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 202/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 203/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 204/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 205/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 206/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 207/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 208/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 209/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 210/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 211/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 212/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 213/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 214/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 215/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 216/400, Train Loss: 2.3012, Test Loss: 2.3015\n",
      "Epoch 217/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 218/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 219/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 220/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 221/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 222/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 223/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 224/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 225/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 226/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 227/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 228/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 229/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 230/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 231/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 232/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 233/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 234/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 235/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 236/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 237/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 238/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 239/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 240/400, Train Loss: 2.3013, Test Loss: 2.3006\n",
      "Epoch 241/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 242/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 243/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 244/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 245/400, Train Loss: 2.3013, Test Loss: 2.3014\n",
      "Epoch 246/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 247/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 248/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 249/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 250/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 251/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 252/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 253/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 254/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 255/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 256/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 257/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 258/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 259/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 260/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 261/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 262/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 263/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 264/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 265/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 266/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 267/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 268/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 269/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 270/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 271/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 272/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 273/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 274/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 275/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 276/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 277/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 278/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 279/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 280/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 281/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 282/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 283/400, Train Loss: 2.3013, Test Loss: 2.3006\n",
      "Epoch 284/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 285/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 286/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 287/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 288/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 289/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 290/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 291/400, Train Loss: 2.3012, Test Loss: 2.3014\n",
      "Epoch 292/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 293/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 294/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 295/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 296/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 297/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 298/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 299/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 300/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 301/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 302/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 303/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 304/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 305/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 306/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 307/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 308/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 309/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 310/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 311/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 312/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 313/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 314/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 315/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 316/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 317/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 318/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 319/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 320/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 321/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 322/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 323/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 324/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 325/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 326/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 327/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 328/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 329/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 330/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 331/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 332/400, Train Loss: 2.3013, Test Loss: 2.3006\n",
      "Epoch 333/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 334/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 335/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 336/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 337/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 338/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 339/400, Train Loss: 2.3012, Test Loss: 2.3014\n",
      "Epoch 340/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 341/400, Train Loss: 2.3013, Test Loss: 2.3014\n",
      "Epoch 342/400, Train Loss: 2.3012, Test Loss: 2.3014\n",
      "Epoch 343/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 344/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 345/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 346/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 347/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 348/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 349/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 350/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 351/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 352/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 353/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 354/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 355/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 356/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 357/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 358/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 359/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 360/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 361/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 362/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 363/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 364/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 365/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 366/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 367/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 368/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 369/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 370/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 371/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 372/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 373/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 374/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 375/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 376/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 377/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 378/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 379/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 380/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 381/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 382/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 383/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 384/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 385/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 386/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 387/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 388/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 389/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 390/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 391/400, Train Loss: 2.3013, Test Loss: 2.3006\n",
      "Epoch 392/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 393/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 394/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 395/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 396/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 397/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 398/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 399/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 400/400, Train Loss: 2.3013, Test Loss: 2.3010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.1135</td></tr><tr><td>accuracy/train</td><td>0.11238</td></tr><tr><td>batch_loss</td><td>2.3041</td></tr><tr><td>epoch</td><td>399</td></tr><tr><td>loss/test</td><td>2.30098</td></tr><tr><td>loss/train</td><td>2.30125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">easy-voice-277</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/bw1bp65v' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/bw1bp65v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240314_001438-bw1bp65v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240314_005247-5rex962i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/5rex962i' target=\"_blank\">wild-firebrand-278</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/5rex962i' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/5rex962i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Train Loss: 2.3132, Test Loss: 2.3023\n",
      "Epoch 2/400, Train Loss: 2.3016, Test Loss: 2.3010\n",
      "Epoch 3/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 4/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 5/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 6/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 7/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 8/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 9/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 10/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 11/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 12/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 13/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 14/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 15/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 16/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 17/400, Train Loss: 2.3012, Test Loss: 2.3014\n",
      "Epoch 18/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 19/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 20/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 21/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 22/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 23/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 24/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 25/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 26/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 27/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 28/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 29/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 30/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 31/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 32/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 33/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 34/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 35/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 36/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 37/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 38/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 39/400, Train Loss: 2.3014, Test Loss: 2.3010\n",
      "Epoch 40/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 41/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 42/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 43/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 44/400, Train Loss: 2.3012, Test Loss: 2.3007\n",
      "Epoch 45/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 46/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 47/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 48/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 49/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 50/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 51/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 52/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 53/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 54/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 55/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 56/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 57/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 58/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 59/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 60/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 61/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 62/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 63/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 64/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 65/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 66/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 67/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 68/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 69/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 70/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 71/400, Train Loss: 2.3013, Test Loss: 2.3012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 73/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 74/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 75/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 76/400, Train Loss: 2.3013, Test Loss: 2.3006\n",
      "Epoch 77/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 78/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 79/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 80/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 81/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 82/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 83/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 84/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 85/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 86/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 87/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 88/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 89/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 90/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 91/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 92/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 93/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 94/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 95/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 96/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 97/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 98/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 99/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 100/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 101/400, Train Loss: 2.3013, Test Loss: 2.3006\n",
      "Epoch 102/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 103/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 104/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 105/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 106/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 107/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 108/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 109/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 110/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 111/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 112/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 113/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 114/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 115/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 116/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 117/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 118/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 119/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 120/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 121/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 122/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 123/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 124/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 125/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 126/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 127/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 128/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 129/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 130/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 131/400, Train Loss: 2.3013, Test Loss: 2.3006\n",
      "Epoch 132/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 133/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 134/400, Train Loss: 2.3012, Test Loss: 2.3014\n",
      "Epoch 135/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 136/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 137/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 138/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 139/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 140/400, Train Loss: 2.3013, Test Loss: 2.3006\n",
      "Epoch 141/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 142/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 143/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 144/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 145/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 146/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 147/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 148/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 149/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 150/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 151/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 152/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 153/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 154/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 155/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 156/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 157/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 158/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 159/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 160/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 161/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 162/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 163/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 164/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 165/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 166/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 167/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 168/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 169/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 170/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 171/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 172/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 173/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 174/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 175/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 176/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 177/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 178/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 179/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 180/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 181/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 182/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 183/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 184/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 185/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 186/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 187/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 188/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 189/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 190/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 191/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 192/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 193/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 194/400, Train Loss: 2.3013, Test Loss: 2.3015\n",
      "Epoch 195/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 196/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 197/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 198/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 199/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 200/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 201/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 202/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 203/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 204/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 205/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 206/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 207/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 208/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 209/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 210/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 211/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 212/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 213/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 214/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 215/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 216/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 217/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 218/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 219/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 220/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 221/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 222/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 223/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 224/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 225/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 226/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 227/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 228/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 229/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 230/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 231/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 232/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 233/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 234/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 235/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 236/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 237/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 238/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 239/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 240/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 241/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 242/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 243/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 244/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 245/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 246/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 247/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 248/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 249/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 250/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 251/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 252/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 253/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 254/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 255/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 256/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 257/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 258/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 259/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 260/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 261/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 262/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 263/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 264/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 265/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 266/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 267/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 268/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 269/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 270/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 271/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 272/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 273/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 274/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 275/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 276/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 277/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 278/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 279/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 280/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 281/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 282/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 283/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 284/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 285/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 286/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 287/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 288/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 289/400, Train Loss: 2.3012, Test Loss: 2.3007\n",
      "Epoch 290/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 291/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 292/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 293/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 294/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 295/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 296/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 297/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 298/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 299/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 300/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 301/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 302/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 303/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 304/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 305/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 306/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 307/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 308/400, Train Loss: 2.3013, Test Loss: 2.3006\n",
      "Epoch 309/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 310/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 311/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 312/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 313/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 314/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 315/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 316/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 317/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 318/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 319/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 320/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 321/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 322/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 323/400, Train Loss: 2.3012, Test Loss: 2.3014\n",
      "Epoch 324/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 325/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 326/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 327/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 328/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 329/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 330/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 331/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 332/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 333/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 334/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 335/400, Train Loss: 2.3012, Test Loss: 2.3013\n",
      "Epoch 336/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 337/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 338/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 339/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 340/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 341/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 342/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 343/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 344/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 345/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 346/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 347/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 348/400, Train Loss: 2.3013, Test Loss: 2.3013\n",
      "Epoch 349/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 350/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 351/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 352/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 353/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 354/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 355/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 356/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 357/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 358/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 359/400, Train Loss: 2.3013, Test Loss: 2.3006\n",
      "Epoch 360/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 361/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 362/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 363/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 364/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 365/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 366/400, Train Loss: 2.3013, Test Loss: 2.3007\n",
      "Epoch 367/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 368/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 369/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 370/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 371/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 372/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 373/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 374/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 375/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 376/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 377/400, Train Loss: 2.3012, Test Loss: 2.3008\n",
      "Epoch 378/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 379/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 380/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 381/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 382/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 383/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 384/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 385/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 386/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 387/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 388/400, Train Loss: 2.3013, Test Loss: 2.3011\n",
      "Epoch 389/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 390/400, Train Loss: 2.3012, Test Loss: 2.3009\n",
      "Epoch 391/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 392/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 393/400, Train Loss: 2.3013, Test Loss: 2.3008\n",
      "Epoch 394/400, Train Loss: 2.3012, Test Loss: 2.3012\n",
      "Epoch 395/400, Train Loss: 2.3013, Test Loss: 2.3010\n",
      "Epoch 396/400, Train Loss: 2.3012, Test Loss: 2.3010\n",
      "Epoch 397/400, Train Loss: 2.3013, Test Loss: 2.3012\n",
      "Epoch 398/400, Train Loss: 2.3012, Test Loss: 2.3011\n",
      "Epoch 399/400, Train Loss: 2.3013, Test Loss: 2.3009\n",
      "Epoch 400/400, Train Loss: 2.3013, Test Loss: 2.3008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.1135</td></tr><tr><td>accuracy/train</td><td>0.11238</td></tr><tr><td>batch_loss</td><td>2.30775</td></tr><tr><td>epoch</td><td>399</td></tr><tr><td>loss/test</td><td>2.30079</td></tr><tr><td>loss/train</td><td>2.30129</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wild-firebrand-278</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/5rex962i' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/5rex962i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240314_005247-5rex962i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240314_013030-d8or7jab</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/d8or7jab' target=\"_blank\">mudslide-pie-279</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/d8or7jab' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/d8or7jab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Train Loss: 1.0635, Test Loss: 0.7412\n",
      "Epoch 2/400, Train Loss: 0.6470, Test Loss: 0.5869\n",
      "Epoch 3/400, Train Loss: 0.5792, Test Loss: 0.5527\n",
      "Epoch 4/400, Train Loss: 0.5456, Test Loss: 0.5317\n",
      "Epoch 5/400, Train Loss: 0.5293, Test Loss: 0.5041\n",
      "Epoch 6/400, Train Loss: 0.5148, Test Loss: 0.5257\n",
      "Epoch 7/400, Train Loss: 0.5060, Test Loss: 0.4908\n",
      "Epoch 8/400, Train Loss: 0.4976, Test Loss: 0.4875\n",
      "Epoch 9/400, Train Loss: 0.4926, Test Loss: 0.4805\n",
      "Epoch 10/400, Train Loss: 0.4892, Test Loss: 0.4866\n",
      "Epoch 11/400, Train Loss: 0.4837, Test Loss: 0.4881\n",
      "Epoch 12/400, Train Loss: 0.4810, Test Loss: 0.4769\n",
      "Epoch 13/400, Train Loss: 0.4791, Test Loss: 0.4689\n",
      "Epoch 14/400, Train Loss: 0.4748, Test Loss: 0.4754\n",
      "Epoch 15/400, Train Loss: 0.4731, Test Loss: 0.4862\n",
      "Epoch 16/400, Train Loss: 0.4698, Test Loss: 0.4725\n",
      "Epoch 17/400, Train Loss: 0.4674, Test Loss: 0.4838\n",
      "Epoch 18/400, Train Loss: 0.4689, Test Loss: 0.4683\n",
      "Epoch 19/400, Train Loss: 0.4690, Test Loss: 0.4772\n",
      "Epoch 20/400, Train Loss: 0.4630, Test Loss: 0.4856\n",
      "Epoch 21/400, Train Loss: 0.4607, Test Loss: 0.4817\n",
      "Epoch 22/400, Train Loss: 0.4622, Test Loss: 0.4685\n",
      "Epoch 23/400, Train Loss: 0.4579, Test Loss: 0.4639\n",
      "Epoch 24/400, Train Loss: 0.4596, Test Loss: 0.4615\n",
      "Epoch 25/400, Train Loss: 0.4579, Test Loss: 0.4611\n",
      "Epoch 26/400, Train Loss: 0.4542, Test Loss: 0.4667\n",
      "Epoch 27/400, Train Loss: 0.4556, Test Loss: 0.4586\n",
      "Epoch 28/400, Train Loss: 0.4543, Test Loss: 0.4678\n",
      "Epoch 29/400, Train Loss: 0.4559, Test Loss: 0.4605\n",
      "Epoch 30/400, Train Loss: 0.4541, Test Loss: 0.4804\n",
      "Epoch 31/400, Train Loss: 0.4524, Test Loss: 0.4675\n",
      "Epoch 32/400, Train Loss: 0.4507, Test Loss: 0.4610\n",
      "Epoch 33/400, Train Loss: 0.4507, Test Loss: 0.4615\n",
      "Epoch 34/400, Train Loss: 0.4544, Test Loss: 0.4743\n",
      "Epoch 35/400, Train Loss: 0.4523, Test Loss: 0.4597\n",
      "Epoch 36/400, Train Loss: 0.4486, Test Loss: 0.4564\n",
      "Epoch 37/400, Train Loss: 0.4480, Test Loss: 0.4533\n",
      "Epoch 38/400, Train Loss: 0.4455, Test Loss: 0.4617\n",
      "Epoch 39/400, Train Loss: 0.4498, Test Loss: 0.4619\n",
      "Epoch 40/400, Train Loss: 0.4444, Test Loss: 0.4570\n",
      "Epoch 41/400, Train Loss: 0.4443, Test Loss: 0.4759\n",
      "Epoch 42/400, Train Loss: 0.4482, Test Loss: 0.4643\n",
      "Epoch 43/400, Train Loss: 0.4448, Test Loss: 0.4712\n",
      "Epoch 44/400, Train Loss: 0.4448, Test Loss: 0.4718\n",
      "Epoch 45/400, Train Loss: 0.4425, Test Loss: 0.4620\n",
      "Epoch 46/400, Train Loss: 0.4470, Test Loss: 0.4525\n",
      "Epoch 47/400, Train Loss: 0.4428, Test Loss: 0.4827\n",
      "Epoch 48/400, Train Loss: 0.4418, Test Loss: 0.4680\n",
      "Epoch 49/400, Train Loss: 0.4424, Test Loss: 0.4549\n",
      "Epoch 50/400, Train Loss: 0.4434, Test Loss: 0.4626\n",
      "Epoch 51/400, Train Loss: 0.4414, Test Loss: 0.4702\n",
      "Epoch 52/400, Train Loss: 0.4459, Test Loss: 0.4593\n",
      "Epoch 53/400, Train Loss: 0.4419, Test Loss: 0.4714\n",
      "Epoch 54/400, Train Loss: 0.4401, Test Loss: 0.4716\n",
      "Epoch 55/400, Train Loss: 0.4408, Test Loss: 0.4475\n",
      "Epoch 56/400, Train Loss: 0.4406, Test Loss: 0.4601\n",
      "Epoch 57/400, Train Loss: 0.4388, Test Loss: 0.4587\n",
      "Epoch 58/400, Train Loss: 0.4399, Test Loss: 0.4560\n",
      "Epoch 59/400, Train Loss: 0.4381, Test Loss: 0.4536\n",
      "Epoch 60/400, Train Loss: 0.4375, Test Loss: 0.4776\n",
      "Epoch 61/400, Train Loss: 0.4396, Test Loss: 0.4649\n",
      "Epoch 62/400, Train Loss: 0.4385, Test Loss: 0.4558\n",
      "Epoch 63/400, Train Loss: 0.4385, Test Loss: 0.4533\n",
      "Epoch 64/400, Train Loss: 0.4389, Test Loss: 0.4634\n",
      "Epoch 65/400, Train Loss: 0.4366, Test Loss: 0.4571\n",
      "Epoch 66/400, Train Loss: 0.4361, Test Loss: 0.4689\n",
      "Epoch 67/400, Train Loss: 0.4375, Test Loss: 0.4542\n",
      "Epoch 68/400, Train Loss: 0.4375, Test Loss: 0.4783\n",
      "Epoch 69/400, Train Loss: 0.4354, Test Loss: 0.4512\n",
      "Epoch 70/400, Train Loss: 0.4365, Test Loss: 0.4581\n",
      "Epoch 71/400, Train Loss: 0.4351, Test Loss: 0.4518\n",
      "Epoch 72/400, Train Loss: 0.4372, Test Loss: 0.4578\n",
      "Epoch 73/400, Train Loss: 0.4340, Test Loss: 0.4997\n",
      "Epoch 74/400, Train Loss: 0.4341, Test Loss: 0.4564\n",
      "Epoch 75/400, Train Loss: 0.4350, Test Loss: 0.4744\n",
      "Epoch 76/400, Train Loss: 0.4356, Test Loss: 0.4606\n",
      "Epoch 77/400, Train Loss: 0.4337, Test Loss: 0.4646\n",
      "Epoch 78/400, Train Loss: 0.4356, Test Loss: 0.4561\n",
      "Epoch 79/400, Train Loss: 0.4350, Test Loss: 0.4603\n",
      "Epoch 80/400, Train Loss: 0.4349, Test Loss: 0.4717\n",
      "Epoch 81/400, Train Loss: 0.4337, Test Loss: 0.4576\n",
      "Epoch 82/400, Train Loss: 0.4332, Test Loss: 0.4620\n",
      "Epoch 83/400, Train Loss: 0.4330, Test Loss: 0.4486\n",
      "Epoch 84/400, Train Loss: 0.4320, Test Loss: 0.4591\n",
      "Epoch 85/400, Train Loss: 0.4319, Test Loss: 0.4529\n",
      "Epoch 86/400, Train Loss: 0.4353, Test Loss: 0.4747\n",
      "Epoch 87/400, Train Loss: 0.4335, Test Loss: 0.4583\n",
      "Epoch 88/400, Train Loss: 0.4324, Test Loss: 0.4492\n",
      "Epoch 89/400, Train Loss: 0.4318, Test Loss: 0.4694\n",
      "Epoch 90/400, Train Loss: 0.4301, Test Loss: 0.4639\n",
      "Epoch 91/400, Train Loss: 0.4322, Test Loss: 0.4558\n",
      "Epoch 92/400, Train Loss: 0.4308, Test Loss: 0.4583\n",
      "Epoch 93/400, Train Loss: 0.4296, Test Loss: 0.4495\n",
      "Epoch 94/400, Train Loss: 0.4363, Test Loss: 0.4520\n",
      "Epoch 95/400, Train Loss: 0.4288, Test Loss: 0.4756\n",
      "Epoch 96/400, Train Loss: 0.4314, Test Loss: 0.4617\n",
      "Epoch 97/400, Train Loss: 0.4311, Test Loss: 0.4724\n",
      "Epoch 98/400, Train Loss: 0.4293, Test Loss: 0.4626\n",
      "Epoch 99/400, Train Loss: 0.4318, Test Loss: 0.4688\n",
      "Epoch 100/400, Train Loss: 0.4359, Test Loss: 0.4508\n",
      "Epoch 101/400, Train Loss: 0.4292, Test Loss: 0.4509\n",
      "Epoch 102/400, Train Loss: 0.4307, Test Loss: 0.4547\n",
      "Epoch 103/400, Train Loss: 0.4306, Test Loss: 0.4718\n",
      "Epoch 104/400, Train Loss: 0.4281, Test Loss: 0.4695\n",
      "Epoch 105/400, Train Loss: 0.4295, Test Loss: 0.4597\n",
      "Epoch 106/400, Train Loss: 0.4294, Test Loss: 0.4562\n",
      "Epoch 107/400, Train Loss: 0.4303, Test Loss: 0.4643\n",
      "Epoch 108/400, Train Loss: 0.4285, Test Loss: 0.4496\n",
      "Epoch 109/400, Train Loss: 0.4294, Test Loss: 0.4499\n",
      "Epoch 110/400, Train Loss: 0.4303, Test Loss: 0.4519\n",
      "Epoch 111/400, Train Loss: 0.4288, Test Loss: 0.4689\n",
      "Epoch 112/400, Train Loss: 0.4285, Test Loss: 0.4550\n",
      "Epoch 113/400, Train Loss: 0.4300, Test Loss: 0.4531\n",
      "Epoch 114/400, Train Loss: 0.4272, Test Loss: 0.4538\n",
      "Epoch 115/400, Train Loss: 0.4265, Test Loss: 0.4604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/400, Train Loss: 0.4291, Test Loss: 0.4878\n",
      "Epoch 117/400, Train Loss: 0.4290, Test Loss: 0.4641\n",
      "Epoch 118/400, Train Loss: 0.4267, Test Loss: 0.4597\n",
      "Epoch 119/400, Train Loss: 0.4286, Test Loss: 0.4654\n",
      "Epoch 120/400, Train Loss: 0.4288, Test Loss: 0.4498\n",
      "Epoch 121/400, Train Loss: 0.4268, Test Loss: 0.4487\n",
      "Epoch 122/400, Train Loss: 0.4262, Test Loss: 0.4594\n",
      "Epoch 123/400, Train Loss: 0.4272, Test Loss: 0.4623\n",
      "Epoch 124/400, Train Loss: 0.4304, Test Loss: 0.4507\n",
      "Epoch 125/400, Train Loss: 0.4282, Test Loss: 0.4552\n",
      "Epoch 126/400, Train Loss: 0.4285, Test Loss: 0.4870\n",
      "Epoch 127/400, Train Loss: 0.4293, Test Loss: 0.4569\n",
      "Epoch 128/400, Train Loss: 0.4269, Test Loss: 0.4693\n",
      "Epoch 129/400, Train Loss: 0.4272, Test Loss: 0.4469\n",
      "Epoch 130/400, Train Loss: 0.4258, Test Loss: 0.4587\n",
      "Epoch 131/400, Train Loss: 0.4258, Test Loss: 0.4586\n",
      "Epoch 132/400, Train Loss: 0.4257, Test Loss: 0.4568\n",
      "Epoch 133/400, Train Loss: 0.4235, Test Loss: 0.4679\n",
      "Epoch 134/400, Train Loss: 0.4278, Test Loss: 0.4520\n",
      "Epoch 135/400, Train Loss: 0.4259, Test Loss: 0.4534\n",
      "Epoch 136/400, Train Loss: 0.4252, Test Loss: 0.4753\n",
      "Epoch 137/400, Train Loss: 0.4268, Test Loss: 0.4513\n",
      "Epoch 138/400, Train Loss: 0.4285, Test Loss: 0.4654\n",
      "Epoch 139/400, Train Loss: 0.4252, Test Loss: 0.4545\n",
      "Epoch 140/400, Train Loss: 0.4250, Test Loss: 0.4589\n",
      "Epoch 141/400, Train Loss: 0.4261, Test Loss: 0.4576\n",
      "Epoch 142/400, Train Loss: 0.4237, Test Loss: 0.4494\n",
      "Epoch 143/400, Train Loss: 0.4269, Test Loss: 0.4508\n",
      "Epoch 144/400, Train Loss: 0.4232, Test Loss: 0.4563\n",
      "Epoch 145/400, Train Loss: 0.4253, Test Loss: 0.4625\n",
      "Epoch 146/400, Train Loss: 0.4256, Test Loss: 0.4616\n",
      "Epoch 147/400, Train Loss: 0.4250, Test Loss: 0.4569\n",
      "Epoch 148/400, Train Loss: 0.4262, Test Loss: 0.4512\n",
      "Epoch 149/400, Train Loss: 0.4245, Test Loss: 0.4558\n",
      "Epoch 150/400, Train Loss: 0.4257, Test Loss: 0.4914\n",
      "Epoch 151/400, Train Loss: 0.4239, Test Loss: 0.4558\n",
      "Epoch 152/400, Train Loss: 0.4230, Test Loss: 0.4973\n",
      "Epoch 153/400, Train Loss: 0.4263, Test Loss: 0.4663\n",
      "Epoch 154/400, Train Loss: 0.4253, Test Loss: 0.4603\n",
      "Epoch 155/400, Train Loss: 0.4234, Test Loss: 0.4653\n",
      "Epoch 156/400, Train Loss: 0.4240, Test Loss: 0.4607\n",
      "Epoch 157/400, Train Loss: 0.4257, Test Loss: 0.4473\n",
      "Epoch 158/400, Train Loss: 0.4242, Test Loss: 0.4514\n",
      "Epoch 159/400, Train Loss: 0.4243, Test Loss: 0.4578\n",
      "Epoch 160/400, Train Loss: 0.4236, Test Loss: 0.4535\n",
      "Epoch 161/400, Train Loss: 0.4260, Test Loss: 0.4562\n",
      "Epoch 162/400, Train Loss: 0.4261, Test Loss: 0.4551\n",
      "Epoch 163/400, Train Loss: 0.4239, Test Loss: 0.4566\n",
      "Epoch 164/400, Train Loss: 0.4228, Test Loss: 0.4487\n",
      "Epoch 165/400, Train Loss: 0.4254, Test Loss: 0.4593\n",
      "Epoch 166/400, Train Loss: 0.4223, Test Loss: 0.4480\n",
      "Epoch 167/400, Train Loss: 0.4237, Test Loss: 0.4620\n",
      "Epoch 168/400, Train Loss: 0.4263, Test Loss: 0.4566\n",
      "Epoch 169/400, Train Loss: 0.4234, Test Loss: 0.4511\n",
      "Epoch 170/400, Train Loss: 0.4244, Test Loss: 0.4727\n",
      "Epoch 171/400, Train Loss: 0.4220, Test Loss: 0.4519\n",
      "Epoch 172/400, Train Loss: 0.4223, Test Loss: 0.4577\n",
      "Epoch 173/400, Train Loss: 0.4232, Test Loss: 0.4501\n",
      "Epoch 174/400, Train Loss: 0.4232, Test Loss: 0.4523\n",
      "Epoch 175/400, Train Loss: 0.4232, Test Loss: 0.4592\n",
      "Epoch 176/400, Train Loss: 0.4240, Test Loss: 0.4849\n",
      "Epoch 177/400, Train Loss: 0.4229, Test Loss: 0.4585\n",
      "Epoch 178/400, Train Loss: 0.4230, Test Loss: 0.4540\n",
      "Epoch 179/400, Train Loss: 0.4214, Test Loss: 0.4477\n",
      "Epoch 180/400, Train Loss: 0.4219, Test Loss: 0.4802\n",
      "Epoch 181/400, Train Loss: 0.4219, Test Loss: 0.4527\n",
      "Epoch 182/400, Train Loss: 0.4227, Test Loss: 0.4555\n",
      "Epoch 183/400, Train Loss: 0.4225, Test Loss: 0.4508\n",
      "Epoch 184/400, Train Loss: 0.4228, Test Loss: 0.4601\n",
      "Epoch 185/400, Train Loss: 0.4234, Test Loss: 0.4541\n",
      "Epoch 186/400, Train Loss: 0.4204, Test Loss: 0.4469\n",
      "Epoch 187/400, Train Loss: 0.4208, Test Loss: 0.4594\n",
      "Epoch 188/400, Train Loss: 0.4213, Test Loss: 0.4634\n",
      "Epoch 189/400, Train Loss: 0.4233, Test Loss: 0.4725\n",
      "Epoch 190/400, Train Loss: 0.4212, Test Loss: 0.4528\n",
      "Epoch 191/400, Train Loss: 0.4214, Test Loss: 0.4580\n",
      "Epoch 192/400, Train Loss: 0.4224, Test Loss: 0.4815\n",
      "Epoch 193/400, Train Loss: 0.4221, Test Loss: 0.4617\n",
      "Epoch 194/400, Train Loss: 0.4219, Test Loss: 0.4623\n",
      "Epoch 195/400, Train Loss: 0.4211, Test Loss: 0.4588\n",
      "Epoch 196/400, Train Loss: 0.4223, Test Loss: 0.4552\n",
      "Epoch 197/400, Train Loss: 0.4194, Test Loss: 0.4514\n",
      "Epoch 198/400, Train Loss: 0.4208, Test Loss: 0.4595\n",
      "Epoch 199/400, Train Loss: 0.4196, Test Loss: 0.4642\n",
      "Epoch 200/400, Train Loss: 0.4223, Test Loss: 0.4662\n",
      "Epoch 201/400, Train Loss: 0.4208, Test Loss: 0.4490\n",
      "Epoch 202/400, Train Loss: 0.4220, Test Loss: 0.4612\n",
      "Epoch 203/400, Train Loss: 0.4213, Test Loss: 0.4722\n",
      "Epoch 204/400, Train Loss: 0.4207, Test Loss: 0.4563\n",
      "Epoch 205/400, Train Loss: 0.4222, Test Loss: 0.4634\n",
      "Epoch 206/400, Train Loss: 0.4226, Test Loss: 0.4584\n",
      "Epoch 207/400, Train Loss: 0.4189, Test Loss: 0.4471\n",
      "Epoch 208/400, Train Loss: 0.4194, Test Loss: 0.4600\n",
      "Epoch 209/400, Train Loss: 0.4208, Test Loss: 0.4683\n",
      "Epoch 210/400, Train Loss: 0.4207, Test Loss: 0.4550\n",
      "Epoch 211/400, Train Loss: 0.4195, Test Loss: 0.4512\n",
      "Epoch 212/400, Train Loss: 0.4220, Test Loss: 0.4594\n",
      "Epoch 213/400, Train Loss: 0.4194, Test Loss: 0.4694\n",
      "Epoch 214/400, Train Loss: 0.4199, Test Loss: 0.4698\n",
      "Epoch 215/400, Train Loss: 0.4207, Test Loss: 0.4575\n",
      "Epoch 216/400, Train Loss: 0.4201, Test Loss: 0.4478\n",
      "Epoch 217/400, Train Loss: 0.4206, Test Loss: 0.4476\n",
      "Epoch 218/400, Train Loss: 0.4223, Test Loss: 0.4534\n",
      "Epoch 219/400, Train Loss: 0.4194, Test Loss: 0.4666\n",
      "Epoch 220/400, Train Loss: 0.4200, Test Loss: 0.4519\n",
      "Epoch 221/400, Train Loss: 0.4192, Test Loss: 0.4485\n",
      "Epoch 222/400, Train Loss: 0.4182, Test Loss: 0.4474\n",
      "Epoch 223/400, Train Loss: 0.4199, Test Loss: 0.4538\n",
      "Epoch 224/400, Train Loss: 0.4188, Test Loss: 0.4500\n",
      "Epoch 225/400, Train Loss: 0.4195, Test Loss: 0.4635\n",
      "Epoch 226/400, Train Loss: 0.4204, Test Loss: 0.4440\n",
      "Epoch 227/400, Train Loss: 0.4185, Test Loss: 0.4707\n",
      "Epoch 228/400, Train Loss: 0.4213, Test Loss: 0.4545\n",
      "Epoch 229/400, Train Loss: 0.4195, Test Loss: 0.4538\n",
      "Epoch 230/400, Train Loss: 0.4208, Test Loss: 0.4552\n",
      "Epoch 231/400, Train Loss: 0.4172, Test Loss: 0.4551\n",
      "Epoch 232/400, Train Loss: 0.4179, Test Loss: 0.4598\n",
      "Epoch 233/400, Train Loss: 0.4189, Test Loss: 0.4593\n",
      "Epoch 234/400, Train Loss: 0.4212, Test Loss: 0.4496\n",
      "Epoch 235/400, Train Loss: 0.4196, Test Loss: 0.4507\n",
      "Epoch 236/400, Train Loss: 0.4201, Test Loss: 0.4484\n",
      "Epoch 237/400, Train Loss: 0.4191, Test Loss: 0.4519\n",
      "Epoch 238/400, Train Loss: 0.4171, Test Loss: 0.4591\n",
      "Epoch 239/400, Train Loss: 0.4190, Test Loss: 0.4557\n",
      "Epoch 240/400, Train Loss: 0.4169, Test Loss: 0.4529\n",
      "Epoch 241/400, Train Loss: 0.4186, Test Loss: 0.4646\n",
      "Epoch 242/400, Train Loss: 0.4197, Test Loss: 0.4550\n",
      "Epoch 243/400, Train Loss: 0.4165, Test Loss: 0.4573\n",
      "Epoch 244/400, Train Loss: 0.4190, Test Loss: 0.4533\n",
      "Epoch 245/400, Train Loss: 0.4175, Test Loss: 0.4540\n",
      "Epoch 246/400, Train Loss: 0.4195, Test Loss: 0.4626\n",
      "Epoch 247/400, Train Loss: 0.4185, Test Loss: 0.4571\n",
      "Epoch 248/400, Train Loss: 0.4183, Test Loss: 0.4612\n",
      "Epoch 249/400, Train Loss: 0.4194, Test Loss: 0.4682\n",
      "Epoch 250/400, Train Loss: 0.4198, Test Loss: 0.4649\n",
      "Epoch 251/400, Train Loss: 0.4200, Test Loss: 0.4551\n",
      "Epoch 252/400, Train Loss: 0.4175, Test Loss: 0.4575\n",
      "Epoch 253/400, Train Loss: 0.4184, Test Loss: 0.4806\n",
      "Epoch 254/400, Train Loss: 0.4168, Test Loss: 0.4712\n",
      "Epoch 255/400, Train Loss: 0.4169, Test Loss: 0.4548\n",
      "Epoch 256/400, Train Loss: 0.4182, Test Loss: 0.4501\n",
      "Epoch 257/400, Train Loss: 0.4200, Test Loss: 0.4609\n",
      "Epoch 258/400, Train Loss: 0.4187, Test Loss: 0.4555\n",
      "Epoch 259/400, Train Loss: 0.4176, Test Loss: 0.4540\n",
      "Epoch 260/400, Train Loss: 0.4188, Test Loss: 0.4609\n",
      "Epoch 261/400, Train Loss: 0.4183, Test Loss: 0.4669\n",
      "Epoch 262/400, Train Loss: 0.4211, Test Loss: 0.4664\n",
      "Epoch 263/400, Train Loss: 0.4163, Test Loss: 0.4493\n",
      "Epoch 264/400, Train Loss: 0.4181, Test Loss: 0.4540\n",
      "Epoch 265/400, Train Loss: 0.4184, Test Loss: 0.4608\n",
      "Epoch 266/400, Train Loss: 0.4187, Test Loss: 0.4609\n",
      "Epoch 267/400, Train Loss: 0.4176, Test Loss: 0.4555\n",
      "Epoch 268/400, Train Loss: 0.4190, Test Loss: 0.4644\n",
      "Epoch 269/400, Train Loss: 0.4211, Test Loss: 0.4660\n",
      "Epoch 270/400, Train Loss: 0.4183, Test Loss: 0.4587\n",
      "Epoch 271/400, Train Loss: 0.4177, Test Loss: 0.4727\n",
      "Epoch 272/400, Train Loss: 0.4174, Test Loss: 0.4521\n",
      "Epoch 273/400, Train Loss: 0.4178, Test Loss: 0.4789\n",
      "Epoch 274/400, Train Loss: 0.4198, Test Loss: 0.4561\n",
      "Epoch 275/400, Train Loss: 0.4150, Test Loss: 0.4608\n",
      "Epoch 276/400, Train Loss: 0.4175, Test Loss: 0.4535\n",
      "Epoch 277/400, Train Loss: 0.4157, Test Loss: 0.4509\n",
      "Epoch 278/400, Train Loss: 0.4161, Test Loss: 0.4645\n",
      "Epoch 279/400, Train Loss: 0.4159, Test Loss: 0.4535\n",
      "Epoch 280/400, Train Loss: 0.4165, Test Loss: 0.4574\n",
      "Epoch 281/400, Train Loss: 0.4167, Test Loss: 0.4520\n",
      "Epoch 282/400, Train Loss: 0.4170, Test Loss: 0.4600\n",
      "Epoch 283/400, Train Loss: 0.4156, Test Loss: 0.4584\n",
      "Epoch 284/400, Train Loss: 0.4168, Test Loss: 0.4567\n",
      "Epoch 285/400, Train Loss: 0.4163, Test Loss: 0.4517\n",
      "Epoch 286/400, Train Loss: 0.4160, Test Loss: 0.4656\n",
      "Epoch 287/400, Train Loss: 0.4162, Test Loss: 0.4639\n",
      "Epoch 288/400, Train Loss: 0.4155, Test Loss: 0.4624\n",
      "Epoch 289/400, Train Loss: 0.4148, Test Loss: 0.4569\n",
      "Epoch 290/400, Train Loss: 0.4180, Test Loss: 0.4724\n",
      "Epoch 291/400, Train Loss: 0.4145, Test Loss: 0.4532\n",
      "Epoch 292/400, Train Loss: 0.4161, Test Loss: 0.4546\n",
      "Epoch 293/400, Train Loss: 0.4171, Test Loss: 0.4567\n",
      "Epoch 294/400, Train Loss: 0.4192, Test Loss: 0.4531\n",
      "Epoch 295/400, Train Loss: 0.4174, Test Loss: 0.4521\n",
      "Epoch 296/400, Train Loss: 0.4154, Test Loss: 0.4520\n",
      "Epoch 297/400, Train Loss: 0.4160, Test Loss: 0.4588\n",
      "Epoch 298/400, Train Loss: 0.4166, Test Loss: 0.4648\n",
      "Epoch 299/400, Train Loss: 0.4177, Test Loss: 0.4498\n",
      "Epoch 300/400, Train Loss: 0.4162, Test Loss: 0.4582\n",
      "Epoch 301/400, Train Loss: 0.4159, Test Loss: 0.4614\n",
      "Epoch 302/400, Train Loss: 0.4153, Test Loss: 0.4559\n",
      "Epoch 303/400, Train Loss: 0.4145, Test Loss: 0.4728\n",
      "Epoch 304/400, Train Loss: 0.4184, Test Loss: 0.4522\n",
      "Epoch 305/400, Train Loss: 0.4168, Test Loss: 0.4616\n",
      "Epoch 306/400, Train Loss: 0.4155, Test Loss: 0.4541\n",
      "Epoch 307/400, Train Loss: 0.4143, Test Loss: 0.4619\n",
      "Epoch 308/400, Train Loss: 0.4165, Test Loss: 0.4638\n",
      "Epoch 309/400, Train Loss: 0.4161, Test Loss: 0.4584\n",
      "Epoch 310/400, Train Loss: 0.4175, Test Loss: 0.4554\n",
      "Epoch 311/400, Train Loss: 0.4162, Test Loss: 0.4651\n",
      "Epoch 312/400, Train Loss: 0.4151, Test Loss: 0.4588\n",
      "Epoch 313/400, Train Loss: 0.4142, Test Loss: 0.4546\n",
      "Epoch 314/400, Train Loss: 0.4176, Test Loss: 0.4539\n",
      "Epoch 315/400, Train Loss: 0.4158, Test Loss: 0.4518\n",
      "Epoch 316/400, Train Loss: 0.4169, Test Loss: 0.4498\n",
      "Epoch 317/400, Train Loss: 0.4162, Test Loss: 0.4606\n",
      "Epoch 318/400, Train Loss: 0.4154, Test Loss: 0.4490\n",
      "Epoch 319/400, Train Loss: 0.4148, Test Loss: 0.4635\n",
      "Epoch 320/400, Train Loss: 0.4159, Test Loss: 0.4699\n",
      "Epoch 321/400, Train Loss: 0.4165, Test Loss: 0.4518\n",
      "Epoch 322/400, Train Loss: 0.4158, Test Loss: 0.4470\n",
      "Epoch 323/400, Train Loss: 0.4144, Test Loss: 0.4601\n",
      "Epoch 324/400, Train Loss: 0.4160, Test Loss: 0.4659\n",
      "Epoch 325/400, Train Loss: 0.4140, Test Loss: 0.4692\n",
      "Epoch 326/400, Train Loss: 0.4162, Test Loss: 0.4449\n",
      "Epoch 327/400, Train Loss: 0.4148, Test Loss: 0.4623\n",
      "Epoch 328/400, Train Loss: 0.4142, Test Loss: 0.4576\n",
      "Epoch 329/400, Train Loss: 0.4157, Test Loss: 0.4579\n",
      "Epoch 330/400, Train Loss: 0.4167, Test Loss: 0.4495\n",
      "Epoch 331/400, Train Loss: 0.4150, Test Loss: 0.4535\n",
      "Epoch 332/400, Train Loss: 0.4161, Test Loss: 0.4539\n",
      "Epoch 333/400, Train Loss: 0.4132, Test Loss: 0.4605\n",
      "Epoch 334/400, Train Loss: 0.4142, Test Loss: 0.4657\n",
      "Epoch 335/400, Train Loss: 0.4155, Test Loss: 0.4625\n",
      "Epoch 336/400, Train Loss: 0.4147, Test Loss: 0.4596\n",
      "Epoch 337/400, Train Loss: 0.4138, Test Loss: 0.4654\n",
      "Epoch 338/400, Train Loss: 0.4156, Test Loss: 0.4564\n",
      "Epoch 339/400, Train Loss: 0.4173, Test Loss: 0.4648\n",
      "Epoch 340/400, Train Loss: 0.4153, Test Loss: 0.4663\n",
      "Epoch 341/400, Train Loss: 0.4159, Test Loss: 0.4552\n",
      "Epoch 342/400, Train Loss: 0.4172, Test Loss: 0.4451\n",
      "Epoch 343/400, Train Loss: 0.4127, Test Loss: 0.4571\n",
      "Epoch 344/400, Train Loss: 0.4135, Test Loss: 0.4594\n",
      "Epoch 345/400, Train Loss: 0.4146, Test Loss: 0.4695\n",
      "Epoch 346/400, Train Loss: 0.4151, Test Loss: 0.4495\n",
      "Epoch 347/400, Train Loss: 0.4137, Test Loss: 0.4565\n",
      "Epoch 348/400, Train Loss: 0.4152, Test Loss: 0.4531\n",
      "Epoch 349/400, Train Loss: 0.4133, Test Loss: 0.4697\n",
      "Epoch 350/400, Train Loss: 0.4133, Test Loss: 0.4515\n",
      "Epoch 351/400, Train Loss: 0.4153, Test Loss: 0.4658\n",
      "Epoch 352/400, Train Loss: 0.4176, Test Loss: 0.4616\n",
      "Epoch 353/400, Train Loss: 0.4136, Test Loss: 0.4516\n",
      "Epoch 354/400, Train Loss: 0.4137, Test Loss: 0.4604\n",
      "Epoch 355/400, Train Loss: 0.4135, Test Loss: 0.4705\n",
      "Epoch 356/400, Train Loss: 0.4165, Test Loss: 0.4526\n",
      "Epoch 357/400, Train Loss: 0.4158, Test Loss: 0.4584\n",
      "Epoch 358/400, Train Loss: 0.4138, Test Loss: 0.4537\n",
      "Epoch 359/400, Train Loss: 0.4134, Test Loss: 0.4540\n",
      "Epoch 360/400, Train Loss: 0.4143, Test Loss: 0.4505\n",
      "Epoch 361/400, Train Loss: 0.4141, Test Loss: 0.4504\n",
      "Epoch 362/400, Train Loss: 0.4147, Test Loss: 0.4503\n",
      "Epoch 363/400, Train Loss: 0.4158, Test Loss: 0.4546\n",
      "Epoch 364/400, Train Loss: 0.4145, Test Loss: 0.4556\n",
      "Epoch 365/400, Train Loss: 0.4153, Test Loss: 0.4476\n",
      "Epoch 366/400, Train Loss: 0.4135, Test Loss: 0.4621\n",
      "Epoch 367/400, Train Loss: 0.4140, Test Loss: 0.4592\n",
      "Epoch 368/400, Train Loss: 0.4123, Test Loss: 0.4518\n",
      "Epoch 369/400, Train Loss: 0.4155, Test Loss: 0.4623\n",
      "Epoch 370/400, Train Loss: 0.4147, Test Loss: 0.4641\n",
      "Epoch 371/400, Train Loss: 0.4136, Test Loss: 0.4513\n",
      "Epoch 372/400, Train Loss: 0.4158, Test Loss: 0.4584\n",
      "Epoch 373/400, Train Loss: 0.4144, Test Loss: 0.4543\n",
      "Epoch 374/400, Train Loss: 0.4140, Test Loss: 0.4612\n",
      "Epoch 375/400, Train Loss: 0.4134, Test Loss: 0.4625\n",
      "Epoch 376/400, Train Loss: 0.4147, Test Loss: 0.4569\n",
      "Epoch 377/400, Train Loss: 0.4157, Test Loss: 0.4555\n",
      "Epoch 378/400, Train Loss: 0.4126, Test Loss: 0.4507\n",
      "Epoch 379/400, Train Loss: 0.4128, Test Loss: 0.4599\n",
      "Epoch 380/400, Train Loss: 0.4146, Test Loss: 0.4558\n",
      "Epoch 381/400, Train Loss: 0.4135, Test Loss: 0.4594\n",
      "Epoch 382/400, Train Loss: 0.4124, Test Loss: 0.4644\n",
      "Epoch 383/400, Train Loss: 0.4147, Test Loss: 0.4518\n",
      "Epoch 384/400, Train Loss: 0.4144, Test Loss: 0.4527\n",
      "Epoch 385/400, Train Loss: 0.4141, Test Loss: 0.4602\n",
      "Epoch 386/400, Train Loss: 0.4121, Test Loss: 0.4486\n",
      "Epoch 387/400, Train Loss: 0.4127, Test Loss: 0.4567\n",
      "Epoch 388/400, Train Loss: 0.4153, Test Loss: 0.4625\n",
      "Epoch 389/400, Train Loss: 0.4136, Test Loss: 0.4583\n",
      "Epoch 390/400, Train Loss: 0.4122, Test Loss: 0.4539\n",
      "Epoch 391/400, Train Loss: 0.4121, Test Loss: 0.4614\n",
      "Epoch 392/400, Train Loss: 0.4127, Test Loss: 0.4636\n",
      "Epoch 393/400, Train Loss: 0.4141, Test Loss: 0.4582\n",
      "Epoch 394/400, Train Loss: 0.4130, Test Loss: 0.4540\n",
      "Epoch 395/400, Train Loss: 0.4124, Test Loss: 0.4590\n",
      "Epoch 396/400, Train Loss: 0.4129, Test Loss: 0.4560\n",
      "Epoch 397/400, Train Loss: 0.4138, Test Loss: 0.4505\n",
      "Epoch 398/400, Train Loss: 0.4113, Test Loss: 0.4579\n",
      "Epoch 399/400, Train Loss: 0.4151, Test Loss: 0.4546\n",
      "Epoch 400/400, Train Loss: 0.4135, Test Loss: 0.4513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.8723</td></tr><tr><td>accuracy/train</td><td>0.88072</td></tr><tr><td>batch_loss</td><td>0.37154</td></tr><tr><td>epoch</td><td>399</td></tr><tr><td>loss/test</td><td>0.45131</td></tr><tr><td>loss/train</td><td>0.41348</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mudslide-pie-279</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/d8or7jab' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/d8or7jab</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240314_013030-d8or7jab/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240314_105753-98i29j89</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/98i29j89' target=\"_blank\">key-lime-pie-280</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/98i29j89' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/98i29j89</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Train Loss: 0.9031, Test Loss: 0.5339\n",
      "Epoch 2/400, Train Loss: 0.5101, Test Loss: 0.4500\n",
      "Epoch 3/400, Train Loss: 0.4586, Test Loss: 0.4303\n",
      "Epoch 4/400, Train Loss: 0.4289, Test Loss: 0.4056\n",
      "Epoch 5/400, Train Loss: 0.4097, Test Loss: 0.4107\n",
      "Epoch 6/400, Train Loss: 0.3931, Test Loss: 0.3766\n",
      "Epoch 7/400, Train Loss: 0.3800, Test Loss: 0.3651\n",
      "Epoch 8/400, Train Loss: 0.3715, Test Loss: 0.3738\n",
      "Epoch 9/400, Train Loss: 0.3599, Test Loss: 0.3633\n",
      "Epoch 10/400, Train Loss: 0.3554, Test Loss: 0.3489\n",
      "Epoch 11/400, Train Loss: 0.3479, Test Loss: 0.3679\n",
      "Epoch 12/400, Train Loss: 0.3436, Test Loss: 0.3510\n",
      "Epoch 13/400, Train Loss: 0.3403, Test Loss: 0.3506\n",
      "Epoch 14/400, Train Loss: 0.3355, Test Loss: 0.3553\n",
      "Epoch 15/400, Train Loss: 0.3345, Test Loss: 0.3474\n",
      "Epoch 16/400, Train Loss: 0.3315, Test Loss: 0.3441\n",
      "Epoch 17/400, Train Loss: 0.3312, Test Loss: 0.3299\n",
      "Epoch 18/400, Train Loss: 0.3252, Test Loss: 0.3472\n",
      "Epoch 19/400, Train Loss: 0.3244, Test Loss: 0.3521\n",
      "Epoch 20/400, Train Loss: 0.3229, Test Loss: 0.3320\n",
      "Epoch 21/400, Train Loss: 0.3180, Test Loss: 0.3326\n",
      "Epoch 22/400, Train Loss: 0.3193, Test Loss: 0.3417\n",
      "Epoch 23/400, Train Loss: 0.3161, Test Loss: 0.3273\n",
      "Epoch 24/400, Train Loss: 0.3129, Test Loss: 0.3346\n",
      "Epoch 25/400, Train Loss: 0.3139, Test Loss: 0.3272\n",
      "Epoch 26/400, Train Loss: 0.3127, Test Loss: 0.3258\n",
      "Epoch 27/400, Train Loss: 0.3117, Test Loss: 0.3280\n",
      "Epoch 28/400, Train Loss: 0.3128, Test Loss: 0.3438\n",
      "Epoch 29/400, Train Loss: 0.3131, Test Loss: 0.3256\n",
      "Epoch 30/400, Train Loss: 0.3117, Test Loss: 0.3404\n",
      "Epoch 31/400, Train Loss: 0.3073, Test Loss: 0.3287\n",
      "Epoch 32/400, Train Loss: 0.3078, Test Loss: 0.3320\n",
      "Epoch 33/400, Train Loss: 0.3055, Test Loss: 0.3246\n",
      "Epoch 34/400, Train Loss: 0.3078, Test Loss: 0.3325\n",
      "Epoch 35/400, Train Loss: 0.3092, Test Loss: 0.3274\n",
      "Epoch 36/400, Train Loss: 0.3052, Test Loss: 0.3344\n",
      "Epoch 37/400, Train Loss: 0.3037, Test Loss: 0.3340\n",
      "Epoch 38/400, Train Loss: 0.3043, Test Loss: 0.3358\n",
      "Epoch 39/400, Train Loss: 0.3022, Test Loss: 0.3302\n",
      "Epoch 40/400, Train Loss: 0.3025, Test Loss: 0.3216\n",
      "Epoch 41/400, Train Loss: 0.3014, Test Loss: 0.3197\n",
      "Epoch 42/400, Train Loss: 0.3057, Test Loss: 0.3323\n",
      "Epoch 43/400, Train Loss: 0.3003, Test Loss: 0.3260\n",
      "Epoch 44/400, Train Loss: 0.3002, Test Loss: 0.3302\n",
      "Epoch 45/400, Train Loss: 0.2986, Test Loss: 0.3355\n",
      "Epoch 46/400, Train Loss: 0.2970, Test Loss: 0.3195\n",
      "Epoch 47/400, Train Loss: 0.2999, Test Loss: 0.3246\n",
      "Epoch 48/400, Train Loss: 0.2956, Test Loss: 0.3326\n",
      "Epoch 49/400, Train Loss: 0.2982, Test Loss: 0.3301\n",
      "Epoch 50/400, Train Loss: 0.2976, Test Loss: 0.3251\n",
      "Epoch 51/400, Train Loss: 0.2956, Test Loss: 0.3243\n",
      "Epoch 52/400, Train Loss: 0.2952, Test Loss: 0.3223\n",
      "Epoch 53/400, Train Loss: 0.2945, Test Loss: 0.3213\n",
      "Epoch 54/400, Train Loss: 0.2953, Test Loss: 0.3232\n",
      "Epoch 55/400, Train Loss: 0.2936, Test Loss: 0.3193\n",
      "Epoch 56/400, Train Loss: 0.2922, Test Loss: 0.3440\n",
      "Epoch 57/400, Train Loss: 0.2933, Test Loss: 0.3231\n",
      "Epoch 58/400, Train Loss: 0.2937, Test Loss: 0.3253\n",
      "Epoch 59/400, Train Loss: 0.2908, Test Loss: 0.3245\n",
      "Epoch 60/400, Train Loss: 0.2927, Test Loss: 0.3146\n",
      "Epoch 61/400, Train Loss: 0.2901, Test Loss: 0.3239\n",
      "Epoch 62/400, Train Loss: 0.2941, Test Loss: 0.3230\n",
      "Epoch 63/400, Train Loss: 0.2939, Test Loss: 0.3306\n",
      "Epoch 64/400, Train Loss: 0.2916, Test Loss: 0.3233\n",
      "Epoch 65/400, Train Loss: 0.2884, Test Loss: 0.3187\n",
      "Epoch 66/400, Train Loss: 0.2892, Test Loss: 0.3224\n",
      "Epoch 67/400, Train Loss: 0.2897, Test Loss: 0.3209\n",
      "Epoch 68/400, Train Loss: 0.2912, Test Loss: 0.3193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/400, Train Loss: 0.2885, Test Loss: 0.3175\n",
      "Epoch 70/400, Train Loss: 0.2901, Test Loss: 0.3317\n",
      "Epoch 71/400, Train Loss: 0.2922, Test Loss: 0.3218\n",
      "Epoch 72/400, Train Loss: 0.2877, Test Loss: 0.3273\n",
      "Epoch 73/400, Train Loss: 0.2857, Test Loss: 0.3229\n",
      "Epoch 74/400, Train Loss: 0.2879, Test Loss: 0.3349\n",
      "Epoch 75/400, Train Loss: 0.2903, Test Loss: 0.3238\n",
      "Epoch 76/400, Train Loss: 0.2900, Test Loss: 0.3235\n",
      "Epoch 77/400, Train Loss: 0.2865, Test Loss: 0.3316\n",
      "Epoch 78/400, Train Loss: 0.2878, Test Loss: 0.3248\n",
      "Epoch 79/400, Train Loss: 0.2879, Test Loss: 0.3207\n",
      "Epoch 80/400, Train Loss: 0.2840, Test Loss: 0.3363\n",
      "Epoch 81/400, Train Loss: 0.2855, Test Loss: 0.3464\n",
      "Epoch 82/400, Train Loss: 0.2856, Test Loss: 0.3171\n",
      "Epoch 83/400, Train Loss: 0.2852, Test Loss: 0.3238\n",
      "Epoch 84/400, Train Loss: 0.2834, Test Loss: 0.3130\n",
      "Epoch 85/400, Train Loss: 0.2842, Test Loss: 0.3254\n",
      "Epoch 86/400, Train Loss: 0.2851, Test Loss: 0.3229\n",
      "Epoch 87/400, Train Loss: 0.2851, Test Loss: 0.3182\n",
      "Epoch 88/400, Train Loss: 0.2849, Test Loss: 0.3235\n",
      "Epoch 89/400, Train Loss: 0.2847, Test Loss: 0.3216\n",
      "Epoch 90/400, Train Loss: 0.2825, Test Loss: 0.3223\n",
      "Epoch 91/400, Train Loss: 0.2817, Test Loss: 0.3216\n",
      "Epoch 92/400, Train Loss: 0.2841, Test Loss: 0.3223\n",
      "Epoch 93/400, Train Loss: 0.2818, Test Loss: 0.3191\n",
      "Epoch 94/400, Train Loss: 0.2821, Test Loss: 0.3212\n",
      "Epoch 95/400, Train Loss: 0.2831, Test Loss: 0.3397\n",
      "Epoch 96/400, Train Loss: 0.2818, Test Loss: 0.3355\n",
      "Epoch 97/400, Train Loss: 0.2807, Test Loss: 0.3162\n",
      "Epoch 98/400, Train Loss: 0.2803, Test Loss: 0.3296\n",
      "Epoch 99/400, Train Loss: 0.2827, Test Loss: 0.3257\n",
      "Epoch 100/400, Train Loss: 0.2845, Test Loss: 0.3180\n",
      "Epoch 101/400, Train Loss: 0.2796, Test Loss: 0.3227\n",
      "Epoch 102/400, Train Loss: 0.2812, Test Loss: 0.3348\n",
      "Epoch 103/400, Train Loss: 0.2822, Test Loss: 0.3319\n",
      "Epoch 104/400, Train Loss: 0.2796, Test Loss: 0.3265\n",
      "Epoch 105/400, Train Loss: 0.2812, Test Loss: 0.3198\n",
      "Epoch 106/400, Train Loss: 0.2801, Test Loss: 0.3276\n",
      "Epoch 107/400, Train Loss: 0.2807, Test Loss: 0.3389\n",
      "Epoch 108/400, Train Loss: 0.2816, Test Loss: 0.3273\n",
      "Epoch 109/400, Train Loss: 0.2788, Test Loss: 0.3240\n",
      "Epoch 110/400, Train Loss: 0.2794, Test Loss: 0.3297\n",
      "Epoch 111/400, Train Loss: 0.2788, Test Loss: 0.3200\n",
      "Epoch 112/400, Train Loss: 0.2777, Test Loss: 0.3318\n",
      "Epoch 113/400, Train Loss: 0.2790, Test Loss: 0.3230\n",
      "Epoch 114/400, Train Loss: 0.2798, Test Loss: 0.3265\n",
      "Epoch 115/400, Train Loss: 0.2793, Test Loss: 0.3370\n",
      "Epoch 116/400, Train Loss: 0.2769, Test Loss: 0.3152\n",
      "Epoch 117/400, Train Loss: 0.2772, Test Loss: 0.3368\n",
      "Epoch 118/400, Train Loss: 0.2801, Test Loss: 0.3227\n",
      "Epoch 119/400, Train Loss: 0.2766, Test Loss: 0.3257\n",
      "Epoch 120/400, Train Loss: 0.2783, Test Loss: 0.3162\n",
      "Epoch 121/400, Train Loss: 0.2762, Test Loss: 0.3233\n",
      "Epoch 122/400, Train Loss: 0.2767, Test Loss: 0.3444\n",
      "Epoch 123/400, Train Loss: 0.2776, Test Loss: 0.3305\n",
      "Epoch 124/400, Train Loss: 0.2793, Test Loss: 0.3205\n",
      "Epoch 125/400, Train Loss: 0.2762, Test Loss: 0.3218\n",
      "Epoch 126/400, Train Loss: 0.2773, Test Loss: 0.3191\n",
      "Epoch 127/400, Train Loss: 0.2760, Test Loss: 0.3247\n",
      "Epoch 128/400, Train Loss: 0.2745, Test Loss: 0.3262\n",
      "Epoch 129/400, Train Loss: 0.2774, Test Loss: 0.3271\n",
      "Epoch 130/400, Train Loss: 0.2726, Test Loss: 0.3321\n",
      "Epoch 131/400, Train Loss: 0.2751, Test Loss: 0.3270\n",
      "Epoch 132/400, Train Loss: 0.2772, Test Loss: 0.3313\n",
      "Epoch 133/400, Train Loss: 0.2757, Test Loss: 0.3322\n",
      "Epoch 134/400, Train Loss: 0.2760, Test Loss: 0.3236\n",
      "Epoch 135/400, Train Loss: 0.2757, Test Loss: 0.3263\n",
      "Epoch 136/400, Train Loss: 0.2754, Test Loss: 0.3165\n",
      "Epoch 137/400, Train Loss: 0.2739, Test Loss: 0.3117\n",
      "Epoch 138/400, Train Loss: 0.2735, Test Loss: 0.3201\n",
      "Epoch 139/400, Train Loss: 0.2744, Test Loss: 0.3279\n",
      "Epoch 140/400, Train Loss: 0.2748, Test Loss: 0.3304\n",
      "Epoch 141/400, Train Loss: 0.2764, Test Loss: 0.3306\n",
      "Epoch 142/400, Train Loss: 0.2737, Test Loss: 0.3285\n",
      "Epoch 143/400, Train Loss: 0.2751, Test Loss: 0.3272\n",
      "Epoch 144/400, Train Loss: 0.2744, Test Loss: 0.3173\n",
      "Epoch 145/400, Train Loss: 0.2742, Test Loss: 0.3193\n",
      "Epoch 146/400, Train Loss: 0.2716, Test Loss: 0.3241\n",
      "Epoch 147/400, Train Loss: 0.2740, Test Loss: 0.3195\n",
      "Epoch 148/400, Train Loss: 0.2737, Test Loss: 0.3374\n",
      "Epoch 149/400, Train Loss: 0.2737, Test Loss: 0.3329\n",
      "Epoch 150/400, Train Loss: 0.2720, Test Loss: 0.3276\n",
      "Epoch 151/400, Train Loss: 0.2732, Test Loss: 0.3308\n",
      "Epoch 152/400, Train Loss: 0.2744, Test Loss: 0.3336\n",
      "Epoch 153/400, Train Loss: 0.2711, Test Loss: 0.3236\n",
      "Epoch 154/400, Train Loss: 0.2725, Test Loss: 0.3390\n",
      "Epoch 155/400, Train Loss: 0.2725, Test Loss: 0.3225\n",
      "Epoch 156/400, Train Loss: 0.2734, Test Loss: 0.3265\n",
      "Epoch 157/400, Train Loss: 0.2735, Test Loss: 0.3292\n",
      "Epoch 158/400, Train Loss: 0.2729, Test Loss: 0.3199\n",
      "Epoch 159/400, Train Loss: 0.2718, Test Loss: 0.3141\n",
      "Epoch 160/400, Train Loss: 0.2719, Test Loss: 0.3158\n",
      "Epoch 161/400, Train Loss: 0.2727, Test Loss: 0.3175\n",
      "Epoch 162/400, Train Loss: 0.2719, Test Loss: 0.3190\n",
      "Epoch 163/400, Train Loss: 0.2708, Test Loss: 0.3234\n",
      "Epoch 164/400, Train Loss: 0.2714, Test Loss: 0.3210\n",
      "Epoch 165/400, Train Loss: 0.2708, Test Loss: 0.3346\n",
      "Epoch 166/400, Train Loss: 0.2730, Test Loss: 0.3224\n",
      "Epoch 167/400, Train Loss: 0.2712, Test Loss: 0.3265\n",
      "Epoch 168/400, Train Loss: 0.2730, Test Loss: 0.3229\n",
      "Epoch 169/400, Train Loss: 0.2719, Test Loss: 0.3249\n",
      "Epoch 170/400, Train Loss: 0.2691, Test Loss: 0.3279\n",
      "Epoch 171/400, Train Loss: 0.2696, Test Loss: 0.3204\n",
      "Epoch 172/400, Train Loss: 0.2693, Test Loss: 0.3342\n",
      "Epoch 173/400, Train Loss: 0.2693, Test Loss: 0.3173\n",
      "Epoch 174/400, Train Loss: 0.2695, Test Loss: 0.3195\n",
      "Epoch 175/400, Train Loss: 0.2713, Test Loss: 0.3214\n",
      "Epoch 176/400, Train Loss: 0.2709, Test Loss: 0.3228\n",
      "Epoch 177/400, Train Loss: 0.2688, Test Loss: 0.3181\n",
      "Epoch 178/400, Train Loss: 0.2691, Test Loss: 0.3198\n",
      "Epoch 179/400, Train Loss: 0.2690, Test Loss: 0.3183\n",
      "Epoch 180/400, Train Loss: 0.2714, Test Loss: 0.3332\n",
      "Epoch 181/400, Train Loss: 0.2687, Test Loss: 0.3271\n",
      "Epoch 182/400, Train Loss: 0.2689, Test Loss: 0.3255\n",
      "Epoch 183/400, Train Loss: 0.2690, Test Loss: 0.3321\n",
      "Epoch 184/400, Train Loss: 0.2707, Test Loss: 0.3245\n",
      "Epoch 185/400, Train Loss: 0.2676, Test Loss: 0.3261\n",
      "Epoch 186/400, Train Loss: 0.2711, Test Loss: 0.3281\n",
      "Epoch 187/400, Train Loss: 0.2691, Test Loss: 0.3137\n",
      "Epoch 188/400, Train Loss: 0.2684, Test Loss: 0.3276\n",
      "Epoch 189/400, Train Loss: 0.2709, Test Loss: 0.3364\n",
      "Epoch 190/400, Train Loss: 0.2667, Test Loss: 0.3254\n",
      "Epoch 191/400, Train Loss: 0.2689, Test Loss: 0.3501\n",
      "Epoch 192/400, Train Loss: 0.2688, Test Loss: 0.3313\n",
      "Epoch 193/400, Train Loss: 0.2671, Test Loss: 0.3321\n",
      "Epoch 194/400, Train Loss: 0.2679, Test Loss: 0.3186\n",
      "Epoch 195/400, Train Loss: 0.2677, Test Loss: 0.3168\n",
      "Epoch 196/400, Train Loss: 0.2679, Test Loss: 0.3288\n",
      "Epoch 197/400, Train Loss: 0.2657, Test Loss: 0.3221\n",
      "Epoch 198/400, Train Loss: 0.2665, Test Loss: 0.3268\n",
      "Epoch 199/400, Train Loss: 0.2689, Test Loss: 0.3309\n",
      "Epoch 200/400, Train Loss: 0.2666, Test Loss: 0.3499\n",
      "Epoch 201/400, Train Loss: 0.2676, Test Loss: 0.3224\n",
      "Epoch 202/400, Train Loss: 0.2680, Test Loss: 0.3149\n",
      "Epoch 203/400, Train Loss: 0.2660, Test Loss: 0.3304\n",
      "Epoch 204/400, Train Loss: 0.2650, Test Loss: 0.3235\n",
      "Epoch 205/400, Train Loss: 0.2687, Test Loss: 0.3231\n",
      "Epoch 206/400, Train Loss: 0.2650, Test Loss: 0.3276\n",
      "Epoch 207/400, Train Loss: 0.2666, Test Loss: 0.3350\n",
      "Epoch 208/400, Train Loss: 0.2660, Test Loss: 0.3387\n",
      "Epoch 209/400, Train Loss: 0.2666, Test Loss: 0.3343\n",
      "Epoch 210/400, Train Loss: 0.2687, Test Loss: 0.3344\n",
      "Epoch 211/400, Train Loss: 0.2668, Test Loss: 0.3430\n",
      "Epoch 212/400, Train Loss: 0.2657, Test Loss: 0.3233\n",
      "Epoch 213/400, Train Loss: 0.2680, Test Loss: 0.3220\n",
      "Epoch 214/400, Train Loss: 0.2668, Test Loss: 0.3234\n",
      "Epoch 215/400, Train Loss: 0.2667, Test Loss: 0.3277\n",
      "Epoch 216/400, Train Loss: 0.2670, Test Loss: 0.3250\n",
      "Epoch 217/400, Train Loss: 0.2638, Test Loss: 0.3265\n",
      "Epoch 218/400, Train Loss: 0.2657, Test Loss: 0.3422\n",
      "Epoch 219/400, Train Loss: 0.2658, Test Loss: 0.3329\n",
      "Epoch 220/400, Train Loss: 0.2646, Test Loss: 0.3171\n",
      "Epoch 221/400, Train Loss: 0.2677, Test Loss: 0.3305\n",
      "Epoch 222/400, Train Loss: 0.2651, Test Loss: 0.3160\n",
      "Epoch 223/400, Train Loss: 0.2651, Test Loss: 0.3357\n",
      "Epoch 224/400, Train Loss: 0.2681, Test Loss: 0.3198\n",
      "Epoch 225/400, Train Loss: 0.2635, Test Loss: 0.3246\n",
      "Epoch 226/400, Train Loss: 0.2662, Test Loss: 0.3191\n",
      "Epoch 227/400, Train Loss: 0.2650, Test Loss: 0.3150\n",
      "Epoch 228/400, Train Loss: 0.2651, Test Loss: 0.3220\n",
      "Epoch 229/400, Train Loss: 0.2654, Test Loss: 0.3393\n",
      "Epoch 230/400, Train Loss: 0.2647, Test Loss: 0.3245\n",
      "Epoch 231/400, Train Loss: 0.2635, Test Loss: 0.3164\n",
      "Epoch 232/400, Train Loss: 0.2622, Test Loss: 0.3184\n",
      "Epoch 233/400, Train Loss: 0.2630, Test Loss: 0.3206\n",
      "Epoch 234/400, Train Loss: 0.2632, Test Loss: 0.3429\n",
      "Epoch 235/400, Train Loss: 0.2618, Test Loss: 0.3238\n",
      "Epoch 236/400, Train Loss: 0.2640, Test Loss: 0.3306\n",
      "Epoch 237/400, Train Loss: 0.2635, Test Loss: 0.3201\n",
      "Epoch 238/400, Train Loss: 0.2651, Test Loss: 0.3294\n",
      "Epoch 239/400, Train Loss: 0.2621, Test Loss: 0.3248\n",
      "Epoch 240/400, Train Loss: 0.2660, Test Loss: 0.3329\n",
      "Epoch 241/400, Train Loss: 0.2606, Test Loss: 0.3210\n",
      "Epoch 242/400, Train Loss: 0.2639, Test Loss: 0.3234\n",
      "Epoch 243/400, Train Loss: 0.2622, Test Loss: 0.3324\n",
      "Epoch 244/400, Train Loss: 0.2640, Test Loss: 0.3274\n",
      "Epoch 245/400, Train Loss: 0.2636, Test Loss: 0.3167\n",
      "Epoch 246/400, Train Loss: 0.2631, Test Loss: 0.3252\n",
      "Epoch 247/400, Train Loss: 0.2616, Test Loss: 0.3476\n",
      "Epoch 248/400, Train Loss: 0.2618, Test Loss: 0.3322\n",
      "Epoch 249/400, Train Loss: 0.2658, Test Loss: 0.3213\n",
      "Epoch 250/400, Train Loss: 0.2616, Test Loss: 0.3129\n",
      "Epoch 251/400, Train Loss: 0.2623, Test Loss: 0.3307\n",
      "Epoch 252/400, Train Loss: 0.2608, Test Loss: 0.3342\n",
      "Epoch 253/400, Train Loss: 0.2633, Test Loss: 0.3576\n",
      "Epoch 254/400, Train Loss: 0.2626, Test Loss: 0.3254\n",
      "Epoch 255/400, Train Loss: 0.2615, Test Loss: 0.3302\n",
      "Epoch 256/400, Train Loss: 0.2628, Test Loss: 0.3220\n",
      "Epoch 257/400, Train Loss: 0.2622, Test Loss: 0.3232\n",
      "Epoch 258/400, Train Loss: 0.2649, Test Loss: 0.3299\n",
      "Epoch 259/400, Train Loss: 0.2616, Test Loss: 0.3305\n",
      "Epoch 260/400, Train Loss: 0.2622, Test Loss: 0.3196\n",
      "Epoch 261/400, Train Loss: 0.2606, Test Loss: 0.3289\n",
      "Epoch 262/400, Train Loss: 0.2609, Test Loss: 0.3175\n",
      "Epoch 263/400, Train Loss: 0.2604, Test Loss: 0.3247\n",
      "Epoch 264/400, Train Loss: 0.2646, Test Loss: 0.3196\n",
      "Epoch 265/400, Train Loss: 0.2621, Test Loss: 0.3288\n",
      "Epoch 266/400, Train Loss: 0.2603, Test Loss: 0.3283\n",
      "Epoch 267/400, Train Loss: 0.2602, Test Loss: 0.3193\n",
      "Epoch 268/400, Train Loss: 0.2596, Test Loss: 0.3221\n",
      "Epoch 269/400, Train Loss: 0.2623, Test Loss: 0.3202\n",
      "Epoch 270/400, Train Loss: 0.2612, Test Loss: 0.3189\n",
      "Epoch 271/400, Train Loss: 0.2616, Test Loss: 0.3287\n",
      "Epoch 272/400, Train Loss: 0.2613, Test Loss: 0.3266\n",
      "Epoch 273/400, Train Loss: 0.2604, Test Loss: 0.3189\n",
      "Epoch 274/400, Train Loss: 0.2619, Test Loss: 0.3238\n",
      "Epoch 275/400, Train Loss: 0.2599, Test Loss: 0.3438\n",
      "Epoch 276/400, Train Loss: 0.2605, Test Loss: 0.3348\n",
      "Epoch 277/400, Train Loss: 0.2611, Test Loss: 0.3153\n",
      "Epoch 278/400, Train Loss: 0.2623, Test Loss: 0.3237\n",
      "Epoch 279/400, Train Loss: 0.2605, Test Loss: 0.3217\n",
      "Epoch 280/400, Train Loss: 0.2606, Test Loss: 0.3260\n",
      "Epoch 281/400, Train Loss: 0.2608, Test Loss: 0.3318\n",
      "Epoch 282/400, Train Loss: 0.2607, Test Loss: 0.3284\n",
      "Epoch 283/400, Train Loss: 0.2618, Test Loss: 0.3259\n",
      "Epoch 284/400, Train Loss: 0.2622, Test Loss: 0.3157\n",
      "Epoch 285/400, Train Loss: 0.2595, Test Loss: 0.3349\n",
      "Epoch 286/400, Train Loss: 0.2582, Test Loss: 0.3332\n",
      "Epoch 287/400, Train Loss: 0.2619, Test Loss: 0.3415\n",
      "Epoch 288/400, Train Loss: 0.2588, Test Loss: 0.3211\n",
      "Epoch 289/400, Train Loss: 0.2619, Test Loss: 0.3387\n",
      "Epoch 290/400, Train Loss: 0.2606, Test Loss: 0.3224\n",
      "Epoch 291/400, Train Loss: 0.2582, Test Loss: 0.3303\n",
      "Epoch 292/400, Train Loss: 0.2592, Test Loss: 0.3271\n",
      "Epoch 293/400, Train Loss: 0.2596, Test Loss: 0.3294\n",
      "Epoch 294/400, Train Loss: 0.2596, Test Loss: 0.3342\n",
      "Epoch 295/400, Train Loss: 0.2605, Test Loss: 0.3210\n",
      "Epoch 296/400, Train Loss: 0.2599, Test Loss: 0.3224\n",
      "Epoch 297/400, Train Loss: 0.2588, Test Loss: 0.3264\n",
      "Epoch 298/400, Train Loss: 0.2603, Test Loss: 0.3211\n",
      "Epoch 299/400, Train Loss: 0.2595, Test Loss: 0.3177\n",
      "Epoch 300/400, Train Loss: 0.2583, Test Loss: 0.3283\n",
      "Epoch 301/400, Train Loss: 0.2572, Test Loss: 0.3323\n",
      "Epoch 302/400, Train Loss: 0.2586, Test Loss: 0.3435\n",
      "Epoch 303/400, Train Loss: 0.2604, Test Loss: 0.3213\n",
      "Epoch 304/400, Train Loss: 0.2611, Test Loss: 0.3208\n",
      "Epoch 305/400, Train Loss: 0.2585, Test Loss: 0.3233\n",
      "Epoch 306/400, Train Loss: 0.2587, Test Loss: 0.3242\n",
      "Epoch 307/400, Train Loss: 0.2598, Test Loss: 0.3199\n",
      "Epoch 308/400, Train Loss: 0.2589, Test Loss: 0.3242\n",
      "Epoch 309/400, Train Loss: 0.2574, Test Loss: 0.3273\n",
      "Epoch 310/400, Train Loss: 0.2575, Test Loss: 0.3273\n",
      "Epoch 311/400, Train Loss: 0.2580, Test Loss: 0.3290\n",
      "Epoch 312/400, Train Loss: 0.2595, Test Loss: 0.3226\n",
      "Epoch 313/400, Train Loss: 0.2602, Test Loss: 0.3256\n",
      "Epoch 314/400, Train Loss: 0.2572, Test Loss: 0.3326\n",
      "Epoch 315/400, Train Loss: 0.2575, Test Loss: 0.3304\n",
      "Epoch 316/400, Train Loss: 0.2576, Test Loss: 0.3308\n",
      "Epoch 317/400, Train Loss: 0.2553, Test Loss: 0.3203\n",
      "Epoch 318/400, Train Loss: 0.2572, Test Loss: 0.3256\n",
      "Epoch 319/400, Train Loss: 0.2549, Test Loss: 0.3223\n",
      "Epoch 320/400, Train Loss: 0.2566, Test Loss: 0.3268\n",
      "Epoch 321/400, Train Loss: 0.2594, Test Loss: 0.3209\n",
      "Epoch 322/400, Train Loss: 0.2574, Test Loss: 0.3276\n",
      "Epoch 323/400, Train Loss: 0.2587, Test Loss: 0.3248\n",
      "Epoch 324/400, Train Loss: 0.2579, Test Loss: 0.3335\n",
      "Epoch 325/400, Train Loss: 0.2597, Test Loss: 0.3335\n",
      "Epoch 326/400, Train Loss: 0.2568, Test Loss: 0.3256\n",
      "Epoch 327/400, Train Loss: 0.2566, Test Loss: 0.3325\n",
      "Epoch 328/400, Train Loss: 0.2577, Test Loss: 0.3397\n",
      "Epoch 329/400, Train Loss: 0.2570, Test Loss: 0.3346\n",
      "Epoch 330/400, Train Loss: 0.2562, Test Loss: 0.3195\n",
      "Epoch 331/400, Train Loss: 0.2566, Test Loss: 0.3311\n",
      "Epoch 332/400, Train Loss: 0.2563, Test Loss: 0.3298\n",
      "Epoch 333/400, Train Loss: 0.2569, Test Loss: 0.3259\n",
      "Epoch 334/400, Train Loss: 0.2562, Test Loss: 0.3291\n",
      "Epoch 335/400, Train Loss: 0.2547, Test Loss: 0.3253\n",
      "Epoch 336/400, Train Loss: 0.2578, Test Loss: 0.3233\n",
      "Epoch 337/400, Train Loss: 0.2566, Test Loss: 0.3182\n",
      "Epoch 338/400, Train Loss: 0.2566, Test Loss: 0.3521\n",
      "Epoch 339/400, Train Loss: 0.2567, Test Loss: 0.3481\n",
      "Epoch 340/400, Train Loss: 0.2582, Test Loss: 0.3157\n",
      "Epoch 341/400, Train Loss: 0.2568, Test Loss: 0.3268\n",
      "Epoch 342/400, Train Loss: 0.2564, Test Loss: 0.3359\n",
      "Epoch 343/400, Train Loss: 0.2572, Test Loss: 0.3215\n",
      "Epoch 344/400, Train Loss: 0.2543, Test Loss: 0.3315\n",
      "Epoch 345/400, Train Loss: 0.2549, Test Loss: 0.3304\n",
      "Epoch 346/400, Train Loss: 0.2571, Test Loss: 0.3369\n",
      "Epoch 347/400, Train Loss: 0.2561, Test Loss: 0.3258\n",
      "Epoch 348/400, Train Loss: 0.2566, Test Loss: 0.3415\n",
      "Epoch 349/400, Train Loss: 0.2580, Test Loss: 0.3251\n",
      "Epoch 350/400, Train Loss: 0.2574, Test Loss: 0.3279\n",
      "Epoch 351/400, Train Loss: 0.2535, Test Loss: 0.3456\n",
      "Epoch 352/400, Train Loss: 0.2567, Test Loss: 0.3436\n",
      "Epoch 353/400, Train Loss: 0.2551, Test Loss: 0.3211\n",
      "Epoch 354/400, Train Loss: 0.2541, Test Loss: 0.3263\n",
      "Epoch 355/400, Train Loss: 0.2552, Test Loss: 0.3168\n",
      "Epoch 356/400, Train Loss: 0.2564, Test Loss: 0.3239\n",
      "Epoch 357/400, Train Loss: 0.2544, Test Loss: 0.3326\n",
      "Epoch 358/400, Train Loss: 0.2567, Test Loss: 0.3247\n",
      "Epoch 359/400, Train Loss: 0.2542, Test Loss: 0.3681\n",
      "Epoch 360/400, Train Loss: 0.2546, Test Loss: 0.3184\n",
      "Epoch 361/400, Train Loss: 0.2553, Test Loss: 0.3274\n",
      "Epoch 362/400, Train Loss: 0.2547, Test Loss: 0.3378\n",
      "Epoch 363/400, Train Loss: 0.2567, Test Loss: 0.3249\n",
      "Epoch 364/400, Train Loss: 0.2533, Test Loss: 0.3421\n",
      "Epoch 365/400, Train Loss: 0.2548, Test Loss: 0.3316\n",
      "Epoch 366/400, Train Loss: 0.2556, Test Loss: 0.3348\n",
      "Epoch 367/400, Train Loss: 0.2543, Test Loss: 0.3292\n",
      "Epoch 368/400, Train Loss: 0.2549, Test Loss: 0.3269\n",
      "Epoch 369/400, Train Loss: 0.2544, Test Loss: 0.3243\n",
      "Epoch 370/400, Train Loss: 0.2555, Test Loss: 0.3332\n",
      "Epoch 371/400, Train Loss: 0.2552, Test Loss: 0.3396\n",
      "Epoch 372/400, Train Loss: 0.2539, Test Loss: 0.3414\n",
      "Epoch 373/400, Train Loss: 0.2552, Test Loss: 0.3264\n",
      "Epoch 374/400, Train Loss: 0.2548, Test Loss: 0.3300\n",
      "Epoch 375/400, Train Loss: 0.2551, Test Loss: 0.3263\n",
      "Epoch 376/400, Train Loss: 0.2546, Test Loss: 0.3302\n",
      "Epoch 377/400, Train Loss: 0.2551, Test Loss: 0.3245\n",
      "Epoch 378/400, Train Loss: 0.2562, Test Loss: 0.3281\n",
      "Epoch 379/400, Train Loss: 0.2557, Test Loss: 0.3310\n",
      "Epoch 380/400, Train Loss: 0.2541, Test Loss: 0.3257\n",
      "Epoch 381/400, Train Loss: 0.2540, Test Loss: 0.3401\n",
      "Epoch 382/400, Train Loss: 0.2561, Test Loss: 0.3249\n",
      "Epoch 383/400, Train Loss: 0.2516, Test Loss: 0.3299\n",
      "Epoch 384/400, Train Loss: 0.2546, Test Loss: 0.3267\n",
      "Epoch 385/400, Train Loss: 0.2544, Test Loss: 0.3452\n",
      "Epoch 386/400, Train Loss: 0.2529, Test Loss: 0.3514\n",
      "Epoch 387/400, Train Loss: 0.2527, Test Loss: 0.3234\n",
      "Epoch 388/400, Train Loss: 0.2562, Test Loss: 0.3290\n",
      "Epoch 389/400, Train Loss: 0.2534, Test Loss: 0.3290\n",
      "Epoch 390/400, Train Loss: 0.2532, Test Loss: 0.3507\n",
      "Epoch 391/400, Train Loss: 0.2539, Test Loss: 0.3263\n",
      "Epoch 392/400, Train Loss: 0.2533, Test Loss: 0.3411\n",
      "Epoch 393/400, Train Loss: 0.2533, Test Loss: 0.3386\n",
      "Epoch 394/400, Train Loss: 0.2589, Test Loss: 0.3238\n",
      "Epoch 395/400, Train Loss: 0.2556, Test Loss: 0.3263\n",
      "Epoch 396/400, Train Loss: 0.2531, Test Loss: 0.3250\n",
      "Epoch 397/400, Train Loss: 0.2533, Test Loss: 0.3268\n",
      "Epoch 398/400, Train Loss: 0.2520, Test Loss: 0.3263\n",
      "Epoch 399/400, Train Loss: 0.2532, Test Loss: 0.3200\n",
      "Epoch 400/400, Train Loss: 0.2514, Test Loss: 0.3223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.9085</td></tr><tr><td>accuracy/train</td><td>0.9258</td></tr><tr><td>batch_loss</td><td>0.11748</td></tr><tr><td>epoch</td><td>399</td></tr><tr><td>loss/test</td><td>0.32227</td></tr><tr><td>loss/train</td><td>0.25145</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">key-lime-pie-280</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/98i29j89' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/98i29j89</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240314_105753-98i29j89/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240314_112439-48j4vjai</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/48j4vjai' target=\"_blank\">mocha-cobbler-281</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/48j4vjai' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/48j4vjai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Train Loss: 0.6912, Test Loss: 0.3607\n",
      "Epoch 2/400, Train Loss: 0.3552, Test Loss: 0.3194\n",
      "Epoch 3/400, Train Loss: 0.3243, Test Loss: 0.3016\n",
      "Epoch 4/400, Train Loss: 0.3058, Test Loss: 0.3072\n",
      "Epoch 5/400, Train Loss: 0.2972, Test Loss: 0.2838\n",
      "Epoch 6/400, Train Loss: 0.2870, Test Loss: 0.2852\n",
      "Epoch 7/400, Train Loss: 0.2788, Test Loss: 0.2819\n",
      "Epoch 8/400, Train Loss: 0.2744, Test Loss: 0.2836\n",
      "Epoch 9/400, Train Loss: 0.2684, Test Loss: 0.2786\n",
      "Epoch 10/400, Train Loss: 0.2667, Test Loss: 0.2712\n",
      "Epoch 11/400, Train Loss: 0.2585, Test Loss: 0.2659\n",
      "Epoch 12/400, Train Loss: 0.2547, Test Loss: 0.2694\n",
      "Epoch 13/400, Train Loss: 0.2533, Test Loss: 0.2696\n",
      "Epoch 14/400, Train Loss: 0.2497, Test Loss: 0.2715\n",
      "Epoch 15/400, Train Loss: 0.2477, Test Loss: 0.2796\n",
      "Epoch 16/400, Train Loss: 0.2441, Test Loss: 0.2527\n",
      "Epoch 17/400, Train Loss: 0.2391, Test Loss: 0.2716\n",
      "Epoch 18/400, Train Loss: 0.2393, Test Loss: 0.2576\n",
      "Epoch 19/400, Train Loss: 0.2362, Test Loss: 0.2493\n",
      "Epoch 20/400, Train Loss: 0.2372, Test Loss: 0.2649\n",
      "Epoch 21/400, Train Loss: 0.2298, Test Loss: 0.2641\n",
      "Epoch 22/400, Train Loss: 0.2333, Test Loss: 0.2555\n",
      "Epoch 23/400, Train Loss: 0.2314, Test Loss: 0.2581\n",
      "Epoch 24/400, Train Loss: 0.2271, Test Loss: 0.2701\n",
      "Epoch 25/400, Train Loss: 0.2250, Test Loss: 0.2459\n",
      "Epoch 26/400, Train Loss: 0.2247, Test Loss: 0.2453\n",
      "Epoch 27/400, Train Loss: 0.2224, Test Loss: 0.2580\n",
      "Epoch 28/400, Train Loss: 0.2222, Test Loss: 0.2551\n",
      "Epoch 29/400, Train Loss: 0.2215, Test Loss: 0.2570\n",
      "Epoch 30/400, Train Loss: 0.2219, Test Loss: 0.2539\n",
      "Epoch 31/400, Train Loss: 0.2159, Test Loss: 0.2404\n",
      "Epoch 32/400, Train Loss: 0.2178, Test Loss: 0.2485\n",
      "Epoch 33/400, Train Loss: 0.2160, Test Loss: 0.2563\n",
      "Epoch 34/400, Train Loss: 0.2174, Test Loss: 0.2491\n",
      "Epoch 35/400, Train Loss: 0.2146, Test Loss: 0.2413\n",
      "Epoch 36/400, Train Loss: 0.2139, Test Loss: 0.2537\n",
      "Epoch 37/400, Train Loss: 0.2118, Test Loss: 0.2667\n",
      "Epoch 38/400, Train Loss: 0.2139, Test Loss: 0.2724\n",
      "Epoch 39/400, Train Loss: 0.2132, Test Loss: 0.2544\n",
      "Epoch 40/400, Train Loss: 0.2100, Test Loss: 0.2515\n",
      "Epoch 41/400, Train Loss: 0.2108, Test Loss: 0.2548\n",
      "Epoch 42/400, Train Loss: 0.2100, Test Loss: 0.2647\n",
      "Epoch 43/400, Train Loss: 0.2083, Test Loss: 0.2392\n",
      "Epoch 44/400, Train Loss: 0.2067, Test Loss: 0.2639\n",
      "Epoch 45/400, Train Loss: 0.2107, Test Loss: 0.2490\n",
      "Epoch 46/400, Train Loss: 0.2098, Test Loss: 0.2443\n",
      "Epoch 47/400, Train Loss: 0.2056, Test Loss: 0.2592\n",
      "Epoch 48/400, Train Loss: 0.2077, Test Loss: 0.2667\n",
      "Epoch 49/400, Train Loss: 0.2051, Test Loss: 0.2534\n",
      "Epoch 50/400, Train Loss: 0.2082, Test Loss: 0.2543\n",
      "Epoch 51/400, Train Loss: 0.2052, Test Loss: 0.2437\n",
      "Epoch 52/400, Train Loss: 0.2055, Test Loss: 0.2622\n",
      "Epoch 53/400, Train Loss: 0.2048, Test Loss: 0.2480\n",
      "Epoch 54/400, Train Loss: 0.2032, Test Loss: 0.2422\n",
      "Epoch 55/400, Train Loss: 0.2020, Test Loss: 0.2493\n",
      "Epoch 56/400, Train Loss: 0.2023, Test Loss: 0.2492\n",
      "Epoch 57/400, Train Loss: 0.2007, Test Loss: 0.2500\n",
      "Epoch 58/400, Train Loss: 0.2005, Test Loss: 0.2505\n",
      "Epoch 59/400, Train Loss: 0.2004, Test Loss: 0.2487\n",
      "Epoch 60/400, Train Loss: 0.1980, Test Loss: 0.2406\n",
      "Epoch 61/400, Train Loss: 0.1985, Test Loss: 0.2509\n",
      "Epoch 62/400, Train Loss: 0.1995, Test Loss: 0.2461\n",
      "Epoch 63/400, Train Loss: 0.1960, Test Loss: 0.2571\n",
      "Epoch 64/400, Train Loss: 0.1985, Test Loss: 0.2409\n",
      "Epoch 65/400, Train Loss: 0.1973, Test Loss: 0.2398\n",
      "Epoch 66/400, Train Loss: 0.1974, Test Loss: 0.2506\n",
      "Epoch 67/400, Train Loss: 0.1979, Test Loss: 0.2651\n",
      "Epoch 68/400, Train Loss: 0.1968, Test Loss: 0.2586\n",
      "Epoch 69/400, Train Loss: 0.1938, Test Loss: 0.2436\n",
      "Epoch 70/400, Train Loss: 0.1957, Test Loss: 0.2455\n",
      "Epoch 71/400, Train Loss: 0.1956, Test Loss: 0.2543\n",
      "Epoch 72/400, Train Loss: 0.1938, Test Loss: 0.2456\n",
      "Epoch 73/400, Train Loss: 0.1947, Test Loss: 0.2760\n",
      "Epoch 74/400, Train Loss: 0.1964, Test Loss: 0.2507\n",
      "Epoch 75/400, Train Loss: 0.1960, Test Loss: 0.2453\n",
      "Epoch 76/400, Train Loss: 0.1938, Test Loss: 0.2479\n",
      "Epoch 77/400, Train Loss: 0.1917, Test Loss: 0.2564\n",
      "Epoch 78/400, Train Loss: 0.1960, Test Loss: 0.2444\n",
      "Epoch 79/400, Train Loss: 0.1919, Test Loss: 0.2474\n",
      "Epoch 80/400, Train Loss: 0.1919, Test Loss: 0.2408\n",
      "Epoch 81/400, Train Loss: 0.1942, Test Loss: 0.2579\n",
      "Epoch 82/400, Train Loss: 0.1926, Test Loss: 0.2468\n",
      "Epoch 83/400, Train Loss: 0.1890, Test Loss: 0.2588\n",
      "Epoch 84/400, Train Loss: 0.1935, Test Loss: 0.2563\n",
      "Epoch 85/400, Train Loss: 0.1920, Test Loss: 0.2589\n",
      "Epoch 86/400, Train Loss: 0.1910, Test Loss: 0.2624\n",
      "Epoch 87/400, Train Loss: 0.1897, Test Loss: 0.2430\n",
      "Epoch 88/400, Train Loss: 0.1909, Test Loss: 0.2520\n",
      "Epoch 89/400, Train Loss: 0.1904, Test Loss: 0.2738\n",
      "Epoch 90/400, Train Loss: 0.1930, Test Loss: 0.2686\n",
      "Epoch 91/400, Train Loss: 0.1914, Test Loss: 0.2590\n",
      "Epoch 92/400, Train Loss: 0.1876, Test Loss: 0.2471\n",
      "Epoch 93/400, Train Loss: 0.1899, Test Loss: 0.2419\n",
      "Epoch 94/400, Train Loss: 0.1886, Test Loss: 0.2600\n",
      "Epoch 95/400, Train Loss: 0.1875, Test Loss: 0.2519\n",
      "Epoch 96/400, Train Loss: 0.1877, Test Loss: 0.2532\n",
      "Epoch 97/400, Train Loss: 0.1859, Test Loss: 0.2414\n",
      "Epoch 98/400, Train Loss: 0.1864, Test Loss: 0.2579\n",
      "Epoch 99/400, Train Loss: 0.1846, Test Loss: 0.2433\n",
      "Epoch 100/400, Train Loss: 0.1863, Test Loss: 0.2507\n",
      "Epoch 101/400, Train Loss: 0.1874, Test Loss: 0.2480\n",
      "Epoch 102/400, Train Loss: 0.1905, Test Loss: 0.2484\n",
      "Epoch 103/400, Train Loss: 0.1856, Test Loss: 0.2482\n",
      "Epoch 104/400, Train Loss: 0.1846, Test Loss: 0.2653\n",
      "Epoch 105/400, Train Loss: 0.1902, Test Loss: 0.2808\n",
      "Epoch 106/400, Train Loss: 0.1853, Test Loss: 0.2489\n",
      "Epoch 107/400, Train Loss: 0.1850, Test Loss: 0.2583\n",
      "Epoch 108/400, Train Loss: 0.1860, Test Loss: 0.2688\n",
      "Epoch 109/400, Train Loss: 0.1846, Test Loss: 0.2481\n",
      "Epoch 110/400, Train Loss: 0.1846, Test Loss: 0.2556\n",
      "Epoch 111/400, Train Loss: 0.1852, Test Loss: 0.2527\n",
      "Epoch 112/400, Train Loss: 0.1836, Test Loss: 0.2504\n",
      "Epoch 113/400, Train Loss: 0.1840, Test Loss: 0.2637\n",
      "Epoch 114/400, Train Loss: 0.1847, Test Loss: 0.2521\n",
      "Epoch 115/400, Train Loss: 0.1820, Test Loss: 0.2566\n",
      "Epoch 116/400, Train Loss: 0.1826, Test Loss: 0.2703\n",
      "Epoch 117/400, Train Loss: 0.1822, Test Loss: 0.2574\n",
      "Epoch 118/400, Train Loss: 0.1836, Test Loss: 0.2701\n",
      "Epoch 119/400, Train Loss: 0.1836, Test Loss: 0.2483\n",
      "Epoch 120/400, Train Loss: 0.1831, Test Loss: 0.2670\n",
      "Epoch 121/400, Train Loss: 0.1851, Test Loss: 0.2530\n",
      "Epoch 122/400, Train Loss: 0.1833, Test Loss: 0.2556\n",
      "Epoch 123/400, Train Loss: 0.1822, Test Loss: 0.2597\n",
      "Epoch 124/400, Train Loss: 0.1845, Test Loss: 0.2573\n",
      "Epoch 125/400, Train Loss: 0.1826, Test Loss: 0.2675\n",
      "Epoch 126/400, Train Loss: 0.1812, Test Loss: 0.2544\n",
      "Epoch 127/400, Train Loss: 0.1804, Test Loss: 0.2601\n",
      "Epoch 128/400, Train Loss: 0.1822, Test Loss: 0.2593\n",
      "Epoch 129/400, Train Loss: 0.1815, Test Loss: 0.2540\n",
      "Epoch 130/400, Train Loss: 0.1818, Test Loss: 0.2570\n",
      "Epoch 131/400, Train Loss: 0.1818, Test Loss: 0.2587\n",
      "Epoch 132/400, Train Loss: 0.1816, Test Loss: 0.2570\n",
      "Epoch 133/400, Train Loss: 0.1809, Test Loss: 0.2584\n",
      "Epoch 134/400, Train Loss: 0.1834, Test Loss: 0.2582\n",
      "Epoch 135/400, Train Loss: 0.1793, Test Loss: 0.2618\n",
      "Epoch 136/400, Train Loss: 0.1836, Test Loss: 0.2646\n",
      "Epoch 137/400, Train Loss: 0.1779, Test Loss: 0.2623\n",
      "Epoch 138/400, Train Loss: 0.1814, Test Loss: 0.2598\n",
      "Epoch 139/400, Train Loss: 0.1781, Test Loss: 0.2606\n",
      "Epoch 140/400, Train Loss: 0.1785, Test Loss: 0.2563\n",
      "Epoch 141/400, Train Loss: 0.1794, Test Loss: 0.2595\n",
      "Epoch 142/400, Train Loss: 0.1829, Test Loss: 0.2758\n",
      "Epoch 143/400, Train Loss: 0.1796, Test Loss: 0.2728\n",
      "Epoch 144/400, Train Loss: 0.1777, Test Loss: 0.2634\n",
      "Epoch 145/400, Train Loss: 0.1802, Test Loss: 0.2657\n",
      "Epoch 146/400, Train Loss: 0.1797, Test Loss: 0.2739\n",
      "Epoch 147/400, Train Loss: 0.1772, Test Loss: 0.2547\n",
      "Epoch 148/400, Train Loss: 0.1782, Test Loss: 0.2650\n",
      "Epoch 149/400, Train Loss: 0.1775, Test Loss: 0.2799\n",
      "Epoch 150/400, Train Loss: 0.1770, Test Loss: 0.2550\n",
      "Epoch 151/400, Train Loss: 0.1768, Test Loss: 0.2635\n",
      "Epoch 152/400, Train Loss: 0.1810, Test Loss: 0.2753\n",
      "Epoch 153/400, Train Loss: 0.1799, Test Loss: 0.2710\n",
      "Epoch 154/400, Train Loss: 0.1792, Test Loss: 0.2688\n",
      "Epoch 155/400, Train Loss: 0.1788, Test Loss: 0.2796\n",
      "Epoch 156/400, Train Loss: 0.1762, Test Loss: 0.2647\n",
      "Epoch 157/400, Train Loss: 0.1749, Test Loss: 0.2772\n",
      "Epoch 158/400, Train Loss: 0.1784, Test Loss: 0.2659\n",
      "Epoch 159/400, Train Loss: 0.1771, Test Loss: 0.2650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/400, Train Loss: 0.1799, Test Loss: 0.2618\n",
      "Epoch 161/400, Train Loss: 0.1753, Test Loss: 0.2569\n",
      "Epoch 162/400, Train Loss: 0.1733, Test Loss: 0.2790\n",
      "Epoch 163/400, Train Loss: 0.1766, Test Loss: 0.2754\n",
      "Epoch 164/400, Train Loss: 0.1787, Test Loss: 0.2670\n",
      "Epoch 165/400, Train Loss: 0.1745, Test Loss: 0.2833\n",
      "Epoch 166/400, Train Loss: 0.1764, Test Loss: 0.2606\n",
      "Epoch 167/400, Train Loss: 0.1737, Test Loss: 0.2763\n",
      "Epoch 168/400, Train Loss: 0.1781, Test Loss: 0.2693\n",
      "Epoch 169/400, Train Loss: 0.1734, Test Loss: 0.2783\n",
      "Epoch 170/400, Train Loss: 0.1761, Test Loss: 0.2645\n",
      "Epoch 171/400, Train Loss: 0.1738, Test Loss: 0.2673\n",
      "Epoch 172/400, Train Loss: 0.1755, Test Loss: 0.2634\n",
      "Epoch 173/400, Train Loss: 0.1742, Test Loss: 0.2751\n",
      "Epoch 174/400, Train Loss: 0.1744, Test Loss: 0.2740\n",
      "Epoch 175/400, Train Loss: 0.1756, Test Loss: 0.2689\n",
      "Epoch 176/400, Train Loss: 0.1779, Test Loss: 0.2838\n",
      "Epoch 177/400, Train Loss: 0.1754, Test Loss: 0.2693\n",
      "Epoch 178/400, Train Loss: 0.1735, Test Loss: 0.2607\n",
      "Epoch 179/400, Train Loss: 0.1739, Test Loss: 0.2851\n",
      "Epoch 180/400, Train Loss: 0.1752, Test Loss: 0.2676\n",
      "Epoch 181/400, Train Loss: 0.1727, Test Loss: 0.2930\n",
      "Epoch 182/400, Train Loss: 0.1744, Test Loss: 0.2731\n",
      "Epoch 183/400, Train Loss: 0.1763, Test Loss: 0.2718\n",
      "Epoch 184/400, Train Loss: 0.1753, Test Loss: 0.2678\n",
      "Epoch 185/400, Train Loss: 0.1729, Test Loss: 0.2665\n",
      "Epoch 186/400, Train Loss: 0.1742, Test Loss: 0.2669\n",
      "Epoch 187/400, Train Loss: 0.1728, Test Loss: 0.2716\n",
      "Epoch 188/400, Train Loss: 0.1723, Test Loss: 0.2679\n",
      "Epoch 189/400, Train Loss: 0.1729, Test Loss: 0.2656\n",
      "Epoch 190/400, Train Loss: 0.1750, Test Loss: 0.2737\n",
      "Epoch 191/400, Train Loss: 0.1738, Test Loss: 0.2733\n",
      "Epoch 192/400, Train Loss: 0.1722, Test Loss: 0.2694\n",
      "Epoch 193/400, Train Loss: 0.1718, Test Loss: 0.2614\n",
      "Epoch 194/400, Train Loss: 0.1715, Test Loss: 0.2839\n",
      "Epoch 195/400, Train Loss: 0.1741, Test Loss: 0.2706\n",
      "Epoch 196/400, Train Loss: 0.1694, Test Loss: 0.2684\n",
      "Epoch 197/400, Train Loss: 0.1749, Test Loss: 0.2848\n",
      "Epoch 198/400, Train Loss: 0.1717, Test Loss: 0.2608\n",
      "Epoch 199/400, Train Loss: 0.1745, Test Loss: 0.2674\n",
      "Epoch 200/400, Train Loss: 0.1722, Test Loss: 0.2744\n",
      "Epoch 201/400, Train Loss: 0.1739, Test Loss: 0.2785\n",
      "Epoch 202/400, Train Loss: 0.1708, Test Loss: 0.2805\n",
      "Epoch 203/400, Train Loss: 0.1733, Test Loss: 0.2900\n",
      "Epoch 204/400, Train Loss: 0.1700, Test Loss: 0.2840\n",
      "Epoch 205/400, Train Loss: 0.1713, Test Loss: 0.2837\n",
      "Epoch 206/400, Train Loss: 0.1727, Test Loss: 0.2897\n",
      "Epoch 207/400, Train Loss: 0.1714, Test Loss: 0.2708\n",
      "Epoch 208/400, Train Loss: 0.1691, Test Loss: 0.2710\n",
      "Epoch 209/400, Train Loss: 0.1717, Test Loss: 0.2724\n",
      "Epoch 210/400, Train Loss: 0.1698, Test Loss: 0.2748\n",
      "Epoch 211/400, Train Loss: 0.1693, Test Loss: 0.2682\n",
      "Epoch 212/400, Train Loss: 0.1714, Test Loss: 0.2764\n",
      "Epoch 213/400, Train Loss: 0.1708, Test Loss: 0.2861\n",
      "Epoch 214/400, Train Loss: 0.1763, Test Loss: 0.2712\n",
      "Epoch 215/400, Train Loss: 0.1676, Test Loss: 0.2713\n",
      "Epoch 216/400, Train Loss: 0.1693, Test Loss: 0.2845\n",
      "Epoch 217/400, Train Loss: 0.1727, Test Loss: 0.2693\n",
      "Epoch 218/400, Train Loss: 0.1723, Test Loss: 0.2770\n",
      "Epoch 219/400, Train Loss: 0.1688, Test Loss: 0.2682\n",
      "Epoch 220/400, Train Loss: 0.1692, Test Loss: 0.2848\n",
      "Epoch 221/400, Train Loss: 0.1687, Test Loss: 0.2707\n",
      "Epoch 222/400, Train Loss: 0.1695, Test Loss: 0.2862\n",
      "Epoch 223/400, Train Loss: 0.1681, Test Loss: 0.2763\n",
      "Epoch 224/400, Train Loss: 0.1705, Test Loss: 0.2793\n",
      "Epoch 225/400, Train Loss: 0.1702, Test Loss: 0.2702\n",
      "Epoch 226/400, Train Loss: 0.1721, Test Loss: 0.2866\n",
      "Epoch 227/400, Train Loss: 0.1696, Test Loss: 0.2679\n",
      "Epoch 228/400, Train Loss: 0.1680, Test Loss: 0.2962\n",
      "Epoch 229/400, Train Loss: 0.1716, Test Loss: 0.2688\n",
      "Epoch 230/400, Train Loss: 0.1708, Test Loss: 0.2806\n",
      "Epoch 231/400, Train Loss: 0.1662, Test Loss: 0.2741\n",
      "Epoch 232/400, Train Loss: 0.1695, Test Loss: 0.2850\n",
      "Epoch 233/400, Train Loss: 0.1721, Test Loss: 0.2813\n",
      "Epoch 234/400, Train Loss: 0.1690, Test Loss: 0.2975\n",
      "Epoch 235/400, Train Loss: 0.1709, Test Loss: 0.2777\n",
      "Epoch 236/400, Train Loss: 0.1673, Test Loss: 0.2740\n",
      "Epoch 237/400, Train Loss: 0.1681, Test Loss: 0.2759\n",
      "Epoch 238/400, Train Loss: 0.1688, Test Loss: 0.2678\n",
      "Epoch 239/400, Train Loss: 0.1665, Test Loss: 0.2794\n",
      "Epoch 240/400, Train Loss: 0.1662, Test Loss: 0.2798\n",
      "Epoch 241/400, Train Loss: 0.1680, Test Loss: 0.2934\n",
      "Epoch 242/400, Train Loss: 0.1691, Test Loss: 0.2748\n",
      "Epoch 243/400, Train Loss: 0.1700, Test Loss: 0.2681\n",
      "Epoch 244/400, Train Loss: 0.1666, Test Loss: 0.2800\n",
      "Epoch 245/400, Train Loss: 0.1690, Test Loss: 0.2921\n",
      "Epoch 246/400, Train Loss: 0.1689, Test Loss: 0.3023\n",
      "Epoch 247/400, Train Loss: 0.1684, Test Loss: 0.2795\n",
      "Epoch 248/400, Train Loss: 0.1678, Test Loss: 0.2912\n",
      "Epoch 249/400, Train Loss: 0.1686, Test Loss: 0.2857\n",
      "Epoch 250/400, Train Loss: 0.1656, Test Loss: 0.2828\n",
      "Epoch 251/400, Train Loss: 0.1666, Test Loss: 0.2721\n",
      "Epoch 252/400, Train Loss: 0.1712, Test Loss: 0.3000\n",
      "Epoch 253/400, Train Loss: 0.1697, Test Loss: 0.2710\n",
      "Epoch 254/400, Train Loss: 0.1658, Test Loss: 0.2862\n",
      "Epoch 255/400, Train Loss: 0.1662, Test Loss: 0.2957\n",
      "Epoch 256/400, Train Loss: 0.1661, Test Loss: 0.2846\n",
      "Epoch 257/400, Train Loss: 0.1667, Test Loss: 0.2838\n",
      "Epoch 258/400, Train Loss: 0.1695, Test Loss: 0.2849\n",
      "Epoch 259/400, Train Loss: 0.1659, Test Loss: 0.2785\n",
      "Epoch 260/400, Train Loss: 0.1650, Test Loss: 0.2768\n",
      "Epoch 261/400, Train Loss: 0.1665, Test Loss: 0.2817\n",
      "Epoch 262/400, Train Loss: 0.1683, Test Loss: 0.2851\n",
      "Epoch 263/400, Train Loss: 0.1680, Test Loss: 0.2762\n",
      "Epoch 264/400, Train Loss: 0.1672, Test Loss: 0.2859\n",
      "Epoch 265/400, Train Loss: 0.1672, Test Loss: 0.2966\n",
      "Epoch 266/400, Train Loss: 0.1697, Test Loss: 0.2881\n",
      "Epoch 267/400, Train Loss: 0.1664, Test Loss: 0.2770\n",
      "Epoch 268/400, Train Loss: 0.1674, Test Loss: 0.2752\n",
      "Epoch 269/400, Train Loss: 0.1672, Test Loss: 0.2721\n",
      "Epoch 270/400, Train Loss: 0.1677, Test Loss: 0.2812\n",
      "Epoch 271/400, Train Loss: 0.1646, Test Loss: 0.2760\n",
      "Epoch 272/400, Train Loss: 0.1647, Test Loss: 0.2753\n",
      "Epoch 273/400, Train Loss: 0.1659, Test Loss: 0.2923\n",
      "Epoch 274/400, Train Loss: 0.1642, Test Loss: 0.2865\n",
      "Epoch 275/400, Train Loss: 0.1666, Test Loss: 0.2801\n",
      "Epoch 276/400, Train Loss: 0.1653, Test Loss: 0.2999\n",
      "Epoch 277/400, Train Loss: 0.1635, Test Loss: 0.2740\n",
      "Epoch 278/400, Train Loss: 0.1665, Test Loss: 0.2771\n",
      "Epoch 279/400, Train Loss: 0.1656, Test Loss: 0.2812\n",
      "Epoch 280/400, Train Loss: 0.1650, Test Loss: 0.2733\n",
      "Epoch 281/400, Train Loss: 0.1622, Test Loss: 0.2878\n",
      "Epoch 282/400, Train Loss: 0.1673, Test Loss: 0.2841\n",
      "Epoch 283/400, Train Loss: 0.1659, Test Loss: 0.2955\n",
      "Epoch 284/400, Train Loss: 0.1648, Test Loss: 0.3047\n",
      "Epoch 285/400, Train Loss: 0.1656, Test Loss: 0.2858\n",
      "Epoch 286/400, Train Loss: 0.1638, Test Loss: 0.2829\n",
      "Epoch 287/400, Train Loss: 0.1638, Test Loss: 0.2882\n",
      "Epoch 288/400, Train Loss: 0.1638, Test Loss: 0.2745\n",
      "Epoch 289/400, Train Loss: 0.1669, Test Loss: 0.2824\n",
      "Epoch 290/400, Train Loss: 0.1635, Test Loss: 0.2930\n",
      "Epoch 291/400, Train Loss: 0.1653, Test Loss: 0.3033\n",
      "Epoch 292/400, Train Loss: 0.1626, Test Loss: 0.2853\n",
      "Epoch 293/400, Train Loss: 0.1649, Test Loss: 0.2825\n",
      "Epoch 294/400, Train Loss: 0.1642, Test Loss: 0.2951\n",
      "Epoch 295/400, Train Loss: 0.1667, Test Loss: 0.2927\n",
      "Epoch 296/400, Train Loss: 0.1646, Test Loss: 0.2879\n",
      "Epoch 297/400, Train Loss: 0.1639, Test Loss: 0.2890\n",
      "Epoch 298/400, Train Loss: 0.1630, Test Loss: 0.3024\n",
      "Epoch 299/400, Train Loss: 0.1628, Test Loss: 0.2814\n",
      "Epoch 300/400, Train Loss: 0.1651, Test Loss: 0.2859\n",
      "Epoch 301/400, Train Loss: 0.1633, Test Loss: 0.2911\n",
      "Epoch 302/400, Train Loss: 0.1628, Test Loss: 0.3019\n",
      "Epoch 303/400, Train Loss: 0.1629, Test Loss: 0.3009\n",
      "Epoch 304/400, Train Loss: 0.1649, Test Loss: 0.3072\n",
      "Epoch 305/400, Train Loss: 0.1672, Test Loss: 0.2868\n",
      "Epoch 306/400, Train Loss: 0.1650, Test Loss: 0.2916\n",
      "Epoch 307/400, Train Loss: 0.1619, Test Loss: 0.2892\n",
      "Epoch 308/400, Train Loss: 0.1605, Test Loss: 0.2814\n",
      "Epoch 309/400, Train Loss: 0.1618, Test Loss: 0.2912\n",
      "Epoch 310/400, Train Loss: 0.1629, Test Loss: 0.2945\n",
      "Epoch 311/400, Train Loss: 0.1639, Test Loss: 0.2995\n",
      "Epoch 312/400, Train Loss: 0.1605, Test Loss: 0.3245\n",
      "Epoch 313/400, Train Loss: 0.1648, Test Loss: 0.2881\n",
      "Epoch 314/400, Train Loss: 0.1614, Test Loss: 0.2919\n",
      "Epoch 315/400, Train Loss: 0.1611, Test Loss: 0.2982\n",
      "Epoch 316/400, Train Loss: 0.1619, Test Loss: 0.2984\n",
      "Epoch 317/400, Train Loss: 0.1625, Test Loss: 0.2849\n",
      "Epoch 318/400, Train Loss: 0.1605, Test Loss: 0.2948\n",
      "Epoch 319/400, Train Loss: 0.1617, Test Loss: 0.2825\n",
      "Epoch 320/400, Train Loss: 0.1619, Test Loss: 0.2968\n",
      "Epoch 321/400, Train Loss: 0.1618, Test Loss: 0.2845\n",
      "Epoch 322/400, Train Loss: 0.1636, Test Loss: 0.2875\n",
      "Epoch 323/400, Train Loss: 0.1620, Test Loss: 0.2886\n",
      "Epoch 324/400, Train Loss: 0.1632, Test Loss: 0.2954\n",
      "Epoch 325/400, Train Loss: 0.1594, Test Loss: 0.2920\n",
      "Epoch 326/400, Train Loss: 0.1621, Test Loss: 0.3029\n",
      "Epoch 327/400, Train Loss: 0.1635, Test Loss: 0.2895\n",
      "Epoch 328/400, Train Loss: 0.1624, Test Loss: 0.2846\n",
      "Epoch 329/400, Train Loss: 0.1633, Test Loss: 0.3003\n",
      "Epoch 330/400, Train Loss: 0.1628, Test Loss: 0.3027\n",
      "Epoch 331/400, Train Loss: 0.1608, Test Loss: 0.2867\n",
      "Epoch 332/400, Train Loss: 0.1629, Test Loss: 0.2907\n",
      "Epoch 333/400, Train Loss: 0.1623, Test Loss: 0.2935\n",
      "Epoch 334/400, Train Loss: 0.1607, Test Loss: 0.3055\n",
      "Epoch 335/400, Train Loss: 0.1627, Test Loss: 0.2982\n",
      "Epoch 336/400, Train Loss: 0.1627, Test Loss: 0.2921\n",
      "Epoch 337/400, Train Loss: 0.1625, Test Loss: 0.2918\n",
      "Epoch 338/400, Train Loss: 0.1600, Test Loss: 0.2888\n",
      "Epoch 339/400, Train Loss: 0.1631, Test Loss: 0.2864\n",
      "Epoch 340/400, Train Loss: 0.1612, Test Loss: 0.2930\n",
      "Epoch 341/400, Train Loss: 0.1637, Test Loss: 0.3007\n",
      "Epoch 342/400, Train Loss: 0.1598, Test Loss: 0.2930\n",
      "Epoch 343/400, Train Loss: 0.1635, Test Loss: 0.2993\n",
      "Epoch 344/400, Train Loss: 0.1609, Test Loss: 0.2986\n",
      "Epoch 345/400, Train Loss: 0.1614, Test Loss: 0.2944\n",
      "Epoch 346/400, Train Loss: 0.1612, Test Loss: 0.2876\n",
      "Epoch 347/400, Train Loss: 0.1610, Test Loss: 0.3095\n",
      "Epoch 348/400, Train Loss: 0.1606, Test Loss: 0.3082\n",
      "Epoch 349/400, Train Loss: 0.1616, Test Loss: 0.2965\n",
      "Epoch 350/400, Train Loss: 0.1619, Test Loss: 0.3110\n",
      "Epoch 351/400, Train Loss: 0.1627, Test Loss: 0.3131\n",
      "Epoch 352/400, Train Loss: 0.1601, Test Loss: 0.2865\n",
      "Epoch 353/400, Train Loss: 0.1613, Test Loss: 0.2923\n",
      "Epoch 354/400, Train Loss: 0.1602, Test Loss: 0.2867\n",
      "Epoch 355/400, Train Loss: 0.1617, Test Loss: 0.2981\n",
      "Epoch 356/400, Train Loss: 0.1599, Test Loss: 0.3067\n",
      "Epoch 357/400, Train Loss: 0.1623, Test Loss: 0.2914\n",
      "Epoch 358/400, Train Loss: 0.1606, Test Loss: 0.3025\n",
      "Epoch 359/400, Train Loss: 0.1597, Test Loss: 0.2912\n",
      "Epoch 360/400, Train Loss: 0.1597, Test Loss: 0.2899\n",
      "Epoch 361/400, Train Loss: 0.1610, Test Loss: 0.2963\n",
      "Epoch 362/400, Train Loss: 0.1599, Test Loss: 0.2981\n",
      "Epoch 363/400, Train Loss: 0.1596, Test Loss: 0.2947\n",
      "Epoch 364/400, Train Loss: 0.1608, Test Loss: 0.3108\n",
      "Epoch 365/400, Train Loss: 0.1605, Test Loss: 0.3015\n",
      "Epoch 366/400, Train Loss: 0.1608, Test Loss: 0.3172\n",
      "Epoch 367/400, Train Loss: 0.1606, Test Loss: 0.3008\n",
      "Epoch 368/400, Train Loss: 0.1609, Test Loss: 0.2959\n",
      "Epoch 369/400, Train Loss: 0.1601, Test Loss: 0.3029\n",
      "Epoch 370/400, Train Loss: 0.1585, Test Loss: 0.3034\n",
      "Epoch 371/400, Train Loss: 0.1583, Test Loss: 0.2946\n",
      "Epoch 372/400, Train Loss: 0.1597, Test Loss: 0.2956\n",
      "Epoch 373/400, Train Loss: 0.1581, Test Loss: 0.3046\n",
      "Epoch 374/400, Train Loss: 0.1571, Test Loss: 0.2949\n",
      "Epoch 375/400, Train Loss: 0.1595, Test Loss: 0.3002\n",
      "Epoch 376/400, Train Loss: 0.1587, Test Loss: 0.2915\n",
      "Epoch 377/400, Train Loss: 0.1606, Test Loss: 0.3187\n",
      "Epoch 378/400, Train Loss: 0.1595, Test Loss: 0.3093\n",
      "Epoch 379/400, Train Loss: 0.1587, Test Loss: 0.3152\n",
      "Epoch 380/400, Train Loss: 0.1620, Test Loss: 0.3070\n",
      "Epoch 381/400, Train Loss: 0.1598, Test Loss: 0.3020\n",
      "Epoch 382/400, Train Loss: 0.1609, Test Loss: 0.3146\n",
      "Epoch 383/400, Train Loss: 0.1570, Test Loss: 0.3090\n",
      "Epoch 384/400, Train Loss: 0.1585, Test Loss: 0.2975\n",
      "Epoch 385/400, Train Loss: 0.1590, Test Loss: 0.3057\n",
      "Epoch 386/400, Train Loss: 0.1589, Test Loss: 0.2928\n",
      "Epoch 387/400, Train Loss: 0.1617, Test Loss: 0.3021\n",
      "Epoch 388/400, Train Loss: 0.1585, Test Loss: 0.3073\n",
      "Epoch 389/400, Train Loss: 0.1572, Test Loss: 0.3132\n",
      "Epoch 390/400, Train Loss: 0.1583, Test Loss: 0.3011\n",
      "Epoch 391/400, Train Loss: 0.1591, Test Loss: 0.2995\n",
      "Epoch 392/400, Train Loss: 0.1602, Test Loss: 0.2922\n",
      "Epoch 393/400, Train Loss: 0.1581, Test Loss: 0.2919\n",
      "Epoch 394/400, Train Loss: 0.1573, Test Loss: 0.3134\n",
      "Epoch 395/400, Train Loss: 0.1583, Test Loss: 0.3062\n",
      "Epoch 396/400, Train Loss: 0.1587, Test Loss: 0.2991\n",
      "Epoch 397/400, Train Loss: 0.1595, Test Loss: 0.3006\n",
      "Epoch 398/400, Train Loss: 0.1562, Test Loss: 0.2936\n",
      "Epoch 399/400, Train Loss: 0.1548, Test Loss: 0.3026\n",
      "Epoch 400/400, Train Loss: 0.1606, Test Loss: 0.3032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.9257</td></tr><tr><td>accuracy/train</td><td>0.9507</td></tr><tr><td>batch_loss</td><td>0.06031</td></tr><tr><td>epoch</td><td>399</td></tr><tr><td>loss/test</td><td>0.30324</td></tr><tr><td>loss/train</td><td>0.1606</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mocha-cobbler-281</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/48j4vjai' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/48j4vjai</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240314_112439-48j4vjai/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240314_114959-9lrhefbu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/9lrhefbu' target=\"_blank\">derby-tart-282</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/9lrhefbu' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/9lrhefbu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Train Loss: 0.5138, Test Loss: 0.3291\n",
      "Epoch 2/400, Train Loss: 0.2922, Test Loss: 0.2527\n",
      "Epoch 3/400, Train Loss: 0.2437, Test Loss: 0.2143\n",
      "Epoch 4/400, Train Loss: 0.2098, Test Loss: 0.2112\n",
      "Epoch 5/400, Train Loss: 0.1815, Test Loss: 0.1751\n",
      "Epoch 6/400, Train Loss: 0.1622, Test Loss: 0.1597\n",
      "Epoch 7/400, Train Loss: 0.1455, Test Loss: 0.1496\n",
      "Epoch 8/400, Train Loss: 0.1385, Test Loss: 0.1456\n",
      "Epoch 9/400, Train Loss: 0.1270, Test Loss: 0.1358\n",
      "Epoch 10/400, Train Loss: 0.1151, Test Loss: 0.1415\n",
      "Epoch 11/400, Train Loss: 0.1128, Test Loss: 0.1367\n",
      "Epoch 12/400, Train Loss: 0.1058, Test Loss: 0.1486\n",
      "Epoch 13/400, Train Loss: 0.1024, Test Loss: 0.1330\n",
      "Epoch 14/400, Train Loss: 0.0965, Test Loss: 0.1348\n",
      "Epoch 15/400, Train Loss: 0.0944, Test Loss: 0.1314\n",
      "Epoch 16/400, Train Loss: 0.0898, Test Loss: 0.1529\n",
      "Epoch 17/400, Train Loss: 0.0848, Test Loss: 0.1248\n",
      "Epoch 18/400, Train Loss: 0.0831, Test Loss: 0.1332\n",
      "Epoch 19/400, Train Loss: 0.0791, Test Loss: 0.1387\n",
      "Epoch 20/400, Train Loss: 0.0776, Test Loss: 0.1480\n",
      "Epoch 21/400, Train Loss: 0.0760, Test Loss: 0.1394\n",
      "Epoch 22/400, Train Loss: 0.0725, Test Loss: 0.1393\n",
      "Epoch 23/400, Train Loss: 0.0704, Test Loss: 0.1276\n",
      "Epoch 24/400, Train Loss: 0.0693, Test Loss: 0.1367\n",
      "Epoch 25/400, Train Loss: 0.0643, Test Loss: 0.1693\n",
      "Epoch 26/400, Train Loss: 0.0696, Test Loss: 0.1570\n",
      "Epoch 27/400, Train Loss: 0.0616, Test Loss: 0.1480\n",
      "Epoch 28/400, Train Loss: 0.0602, Test Loss: 0.1557\n",
      "Epoch 29/400, Train Loss: 0.0595, Test Loss: 0.1519\n",
      "Epoch 30/400, Train Loss: 0.0568, Test Loss: 0.1508\n",
      "Epoch 31/400, Train Loss: 0.0561, Test Loss: 0.1533\n",
      "Epoch 32/400, Train Loss: 0.0534, Test Loss: 0.1470\n",
      "Epoch 33/400, Train Loss: 0.0539, Test Loss: 0.1522\n",
      "Epoch 34/400, Train Loss: 0.0523, Test Loss: 0.1463\n",
      "Epoch 35/400, Train Loss: 0.0485, Test Loss: 0.1535\n",
      "Epoch 36/400, Train Loss: 0.0463, Test Loss: 0.1803\n",
      "Epoch 37/400, Train Loss: 0.0478, Test Loss: 0.1580\n",
      "Epoch 38/400, Train Loss: 0.0465, Test Loss: 0.1538\n",
      "Epoch 39/400, Train Loss: 0.0443, Test Loss: 0.1697\n",
      "Epoch 40/400, Train Loss: 0.0474, Test Loss: 0.1520\n",
      "Epoch 41/400, Train Loss: 0.0427, Test Loss: 0.1550\n",
      "Epoch 42/400, Train Loss: 0.0452, Test Loss: 0.1558\n",
      "Epoch 43/400, Train Loss: 0.0429, Test Loss: 0.1700\n",
      "Epoch 44/400, Train Loss: 0.0436, Test Loss: 0.1854\n",
      "Epoch 45/400, Train Loss: 0.0443, Test Loss: 0.1826\n",
      "Epoch 46/400, Train Loss: 0.0398, Test Loss: 0.1902\n",
      "Epoch 47/400, Train Loss: 0.0382, Test Loss: 0.1954\n",
      "Epoch 48/400, Train Loss: 0.0369, Test Loss: 0.1689\n",
      "Epoch 49/400, Train Loss: 0.0314, Test Loss: 0.1699\n",
      "Epoch 50/400, Train Loss: 0.0339, Test Loss: 0.1944\n",
      "Epoch 51/400, Train Loss: 0.0350, Test Loss: 0.1763\n",
      "Epoch 52/400, Train Loss: 0.0414, Test Loss: 0.1842\n",
      "Epoch 53/400, Train Loss: 0.0345, Test Loss: 0.2002\n",
      "Epoch 54/400, Train Loss: 0.0313, Test Loss: 0.1814\n",
      "Epoch 55/400, Train Loss: 0.0407, Test Loss: 0.1909\n",
      "Epoch 56/400, Train Loss: 0.0315, Test Loss: 0.1950\n",
      "Epoch 57/400, Train Loss: 0.0351, Test Loss: 0.2018\n",
      "Epoch 58/400, Train Loss: 0.0268, Test Loss: 0.2015\n",
      "Epoch 59/400, Train Loss: 0.0286, Test Loss: 0.1975\n",
      "Epoch 60/400, Train Loss: 0.0325, Test Loss: 0.1939\n",
      "Epoch 61/400, Train Loss: 0.0292, Test Loss: 0.1958\n",
      "Epoch 62/400, Train Loss: 0.0272, Test Loss: 0.1874\n",
      "Epoch 63/400, Train Loss: 0.0273, Test Loss: 0.1995\n",
      "Epoch 64/400, Train Loss: 0.0279, Test Loss: 0.2026\n",
      "Epoch 65/400, Train Loss: 0.0274, Test Loss: 0.2001\n",
      "Epoch 66/400, Train Loss: 0.0270, Test Loss: 0.1910\n",
      "Epoch 67/400, Train Loss: 0.0179, Test Loss: 0.2145\n",
      "Epoch 68/400, Train Loss: 0.0329, Test Loss: 0.2215\n",
      "Epoch 69/400, Train Loss: 0.0286, Test Loss: 0.2113\n",
      "Epoch 70/400, Train Loss: 0.0281, Test Loss: 0.2145\n",
      "Epoch 71/400, Train Loss: 0.0290, Test Loss: 0.2163\n",
      "Epoch 72/400, Train Loss: 0.0228, Test Loss: 0.2472\n",
      "Epoch 73/400, Train Loss: 0.0171, Test Loss: 0.2379\n",
      "Epoch 74/400, Train Loss: 0.0268, Test Loss: 0.2485\n",
      "Epoch 75/400, Train Loss: 0.0228, Test Loss: 0.2294\n",
      "Epoch 76/400, Train Loss: 0.0214, Test Loss: 0.2298\n",
      "Epoch 77/400, Train Loss: 0.0315, Test Loss: 0.2335\n",
      "Epoch 78/400, Train Loss: 0.0221, Test Loss: 0.2371\n",
      "Epoch 79/400, Train Loss: 0.0227, Test Loss: 0.2288\n",
      "Epoch 80/400, Train Loss: 0.0199, Test Loss: 0.2196\n",
      "Epoch 81/400, Train Loss: 0.0286, Test Loss: 0.2658\n",
      "Epoch 82/400, Train Loss: 0.0191, Test Loss: 0.2368\n",
      "Epoch 83/400, Train Loss: 0.0189, Test Loss: 0.2520\n",
      "Epoch 84/400, Train Loss: 0.0155, Test Loss: 0.2429\n",
      "Epoch 85/400, Train Loss: 0.0274, Test Loss: 0.2604\n",
      "Epoch 86/400, Train Loss: 0.0212, Test Loss: 0.2882\n",
      "Epoch 87/400, Train Loss: 0.0248, Test Loss: 0.2492\n",
      "Epoch 88/400, Train Loss: 0.0167, Test Loss: 0.2425\n",
      "Epoch 89/400, Train Loss: 0.0168, Test Loss: 0.2461\n",
      "Epoch 90/400, Train Loss: 0.0195, Test Loss: 0.2596\n",
      "Epoch 91/400, Train Loss: 0.0158, Test Loss: 0.2389\n",
      "Epoch 92/400, Train Loss: 0.0259, Test Loss: 0.2521\n",
      "Epoch 93/400, Train Loss: 0.0231, Test Loss: 0.2487\n",
      "Epoch 94/400, Train Loss: 0.0141, Test Loss: 0.2421\n",
      "Epoch 95/400, Train Loss: 0.0157, Test Loss: 0.2732\n",
      "Epoch 96/400, Train Loss: 0.0116, Test Loss: 0.2558\n",
      "Epoch 97/400, Train Loss: 0.0201, Test Loss: 0.2624\n",
      "Epoch 98/400, Train Loss: 0.0170, Test Loss: 0.3304\n",
      "Epoch 99/400, Train Loss: 0.0167, Test Loss: 0.2610\n",
      "Epoch 100/400, Train Loss: 0.0173, Test Loss: 0.2600\n",
      "Epoch 101/400, Train Loss: 0.0204, Test Loss: 0.2789\n",
      "Epoch 102/400, Train Loss: 0.0189, Test Loss: 0.2646\n",
      "Epoch 103/400, Train Loss: 0.0151, Test Loss: 0.2815\n",
      "Epoch 104/400, Train Loss: 0.0165, Test Loss: 0.2767\n",
      "Epoch 105/400, Train Loss: 0.0225, Test Loss: 0.2908\n",
      "Epoch 106/400, Train Loss: 0.0127, Test Loss: 0.2750\n",
      "Epoch 107/400, Train Loss: 0.0088, Test Loss: 0.2975\n",
      "Epoch 108/400, Train Loss: 0.0068, Test Loss: 0.2682\n",
      "Epoch 109/400, Train Loss: 0.0299, Test Loss: 0.3040\n",
      "Epoch 110/400, Train Loss: 0.0213, Test Loss: 0.2820\n",
      "Epoch 111/400, Train Loss: 0.0126, Test Loss: 0.2819\n",
      "Epoch 112/400, Train Loss: 0.0176, Test Loss: 0.3069\n",
      "Epoch 113/400, Train Loss: 0.0121, Test Loss: 0.2699\n",
      "Epoch 114/400, Train Loss: 0.0145, Test Loss: 0.2897\n",
      "Epoch 115/400, Train Loss: 0.0207, Test Loss: 0.2985\n",
      "Epoch 116/400, Train Loss: 0.0219, Test Loss: 0.2832\n",
      "Epoch 117/400, Train Loss: 0.0108, Test Loss: 0.3373\n",
      "Epoch 118/400, Train Loss: 0.0142, Test Loss: 0.3339\n",
      "Epoch 119/400, Train Loss: 0.0108, Test Loss: 0.2918\n",
      "Epoch 120/400, Train Loss: 0.0110, Test Loss: 0.3509\n",
      "Epoch 121/400, Train Loss: 0.0243, Test Loss: 0.3722\n",
      "Epoch 122/400, Train Loss: 0.0184, Test Loss: 0.3083\n",
      "Epoch 123/400, Train Loss: 0.0108, Test Loss: 0.2931\n",
      "Epoch 124/400, Train Loss: 0.0070, Test Loss: 0.2861\n",
      "Epoch 125/400, Train Loss: 0.0139, Test Loss: 0.3129\n",
      "Epoch 126/400, Train Loss: 0.0402, Test Loss: 0.3287\n",
      "Epoch 127/400, Train Loss: 0.0114, Test Loss: 0.3179\n",
      "Epoch 128/400, Train Loss: 0.0058, Test Loss: 0.2941\n",
      "Epoch 129/400, Train Loss: 0.0123, Test Loss: 0.3037\n",
      "Epoch 130/400, Train Loss: 0.0251, Test Loss: 0.3223\n",
      "Epoch 131/400, Train Loss: 0.0156, Test Loss: 0.3164\n",
      "Epoch 132/400, Train Loss: 0.0156, Test Loss: 0.3302\n",
      "Epoch 133/400, Train Loss: 0.0130, Test Loss: 0.3137\n",
      "Epoch 134/400, Train Loss: 0.0063, Test Loss: 0.3043\n",
      "Epoch 135/400, Train Loss: 0.0224, Test Loss: 0.3121\n",
      "Epoch 136/400, Train Loss: 0.0129, Test Loss: 0.3096\n",
      "Epoch 137/400, Train Loss: 0.0092, Test Loss: 0.3286\n",
      "Epoch 138/400, Train Loss: 0.0147, Test Loss: 0.3490\n",
      "Epoch 139/400, Train Loss: 0.0140, Test Loss: 0.3366\n",
      "Epoch 140/400, Train Loss: 0.0136, Test Loss: 0.3352\n",
      "Epoch 141/400, Train Loss: 0.0204, Test Loss: 0.3118\n",
      "Epoch 142/400, Train Loss: 0.0069, Test Loss: 0.3063\n",
      "Epoch 143/400, Train Loss: 0.0070, Test Loss: 0.3415\n",
      "Epoch 144/400, Train Loss: 0.0254, Test Loss: 0.3255\n",
      "Epoch 145/400, Train Loss: 0.0160, Test Loss: 0.3348\n",
      "Epoch 146/400, Train Loss: 0.0057, Test Loss: 0.3085\n",
      "Epoch 147/400, Train Loss: 0.0038, Test Loss: 0.3100\n",
      "Epoch 148/400, Train Loss: 0.0101, Test Loss: 0.3687\n",
      "Epoch 149/400, Train Loss: 0.0218, Test Loss: 0.3427\n",
      "Epoch 150/400, Train Loss: 0.0157, Test Loss: 0.3600\n",
      "Epoch 151/400, Train Loss: 0.0305, Test Loss: 0.3607\n",
      "Epoch 152/400, Train Loss: 0.0085, Test Loss: 0.3069\n",
      "Epoch 153/400, Train Loss: 0.0022, Test Loss: 0.3398\n",
      "Epoch 154/400, Train Loss: 0.0100, Test Loss: 0.3560\n",
      "Epoch 155/400, Train Loss: 0.0272, Test Loss: 0.3610\n",
      "Epoch 156/400, Train Loss: 0.0141, Test Loss: 0.3956\n",
      "Epoch 157/400, Train Loss: 0.0099, Test Loss: 0.3634\n",
      "Epoch 158/400, Train Loss: 0.0075, Test Loss: 0.3289\n",
      "Epoch 159/400, Train Loss: 0.0028, Test Loss: 0.3456\n",
      "Epoch 160/400, Train Loss: 0.0211, Test Loss: 0.3754\n",
      "Epoch 161/400, Train Loss: 0.0180, Test Loss: 0.3663\n",
      "Epoch 162/400, Train Loss: 0.0153, Test Loss: 0.3287\n",
      "Epoch 163/400, Train Loss: 0.0112, Test Loss: 0.3281\n",
      "Epoch 164/400, Train Loss: 0.0056, Test Loss: 0.3452\n",
      "Epoch 165/400, Train Loss: 0.0036, Test Loss: 0.3434\n",
      "Epoch 166/400, Train Loss: 0.0164, Test Loss: 0.4140\n",
      "Epoch 167/400, Train Loss: 0.0207, Test Loss: 0.3505\n",
      "Epoch 168/400, Train Loss: 0.0150, Test Loss: 0.3534\n",
      "Epoch 169/400, Train Loss: 0.0152, Test Loss: 0.3608\n",
      "Epoch 170/400, Train Loss: 0.0059, Test Loss: 0.3623\n",
      "Epoch 171/400, Train Loss: 0.0013, Test Loss: 0.3251\n",
      "Epoch 172/400, Train Loss: 0.0005, Test Loss: 0.3298\n",
      "Epoch 173/400, Train Loss: 0.0003, Test Loss: 0.3301\n",
      "Epoch 174/400, Train Loss: 0.0002, Test Loss: 0.3411\n",
      "Epoch 175/400, Train Loss: 0.0002, Test Loss: 0.3354\n",
      "Epoch 176/400, Train Loss: 0.0481, Test Loss: 0.4015\n",
      "Epoch 177/400, Train Loss: 0.0357, Test Loss: 0.3615\n",
      "Epoch 178/400, Train Loss: 0.0143, Test Loss: 0.3631\n",
      "Epoch 179/400, Train Loss: 0.0087, Test Loss: 0.3604\n",
      "Epoch 180/400, Train Loss: 0.0060, Test Loss: 0.3874\n",
      "Epoch 181/400, Train Loss: 0.0189, Test Loss: 0.3686\n",
      "Epoch 182/400, Train Loss: 0.0073, Test Loss: 0.3477\n",
      "Epoch 183/400, Train Loss: 0.0023, Test Loss: 0.3394\n",
      "Epoch 184/400, Train Loss: 0.0095, Test Loss: 0.4417\n",
      "Epoch 185/400, Train Loss: 0.0264, Test Loss: 0.4063\n",
      "Epoch 186/400, Train Loss: 0.0116, Test Loss: 0.3610\n",
      "Epoch 187/400, Train Loss: 0.0070, Test Loss: 0.3559\n",
      "Epoch 188/400, Train Loss: 0.0140, Test Loss: 0.3637\n",
      "Epoch 189/400, Train Loss: 0.0149, Test Loss: 0.4116\n",
      "Epoch 190/400, Train Loss: 0.0176, Test Loss: 0.4102\n",
      "Epoch 191/400, Train Loss: 0.0200, Test Loss: 0.3682\n",
      "Epoch 192/400, Train Loss: 0.0078, Test Loss: 0.3929\n",
      "Epoch 193/400, Train Loss: 0.0046, Test Loss: 0.3554\n",
      "Epoch 194/400, Train Loss: 0.0013, Test Loss: 0.3637\n",
      "Epoch 195/400, Train Loss: 0.0008, Test Loss: 0.3537\n",
      "Epoch 196/400, Train Loss: 0.0226, Test Loss: 0.4277\n",
      "Epoch 197/400, Train Loss: 0.0236, Test Loss: 0.3707\n",
      "Epoch 198/400, Train Loss: 0.0081, Test Loss: 0.3848\n",
      "Epoch 199/400, Train Loss: 0.0047, Test Loss: 0.3714\n",
      "Epoch 200/400, Train Loss: 0.0079, Test Loss: 0.4156\n",
      "Epoch 201/400, Train Loss: 0.0170, Test Loss: 0.4143\n",
      "Epoch 202/400, Train Loss: 0.0160, Test Loss: 0.4020\n",
      "Epoch 203/400, Train Loss: 0.0093, Test Loss: 0.3863\n",
      "Epoch 204/400, Train Loss: 0.0057, Test Loss: 0.3933\n",
      "Epoch 205/400, Train Loss: 0.0142, Test Loss: 0.3958\n",
      "Epoch 206/400, Train Loss: 0.0098, Test Loss: 0.3790\n",
      "Epoch 207/400, Train Loss: 0.0081, Test Loss: 0.4002\n",
      "Epoch 208/400, Train Loss: 0.0178, Test Loss: 0.4361\n",
      "Epoch 209/400, Train Loss: 0.0122, Test Loss: 0.3991\n",
      "Epoch 210/400, Train Loss: 0.0066, Test Loss: 0.4257\n",
      "Epoch 211/400, Train Loss: 0.0100, Test Loss: 0.3831\n",
      "Epoch 212/400, Train Loss: 0.0089, Test Loss: 0.3775\n",
      "Epoch 213/400, Train Loss: 0.0117, Test Loss: 0.3935\n",
      "Epoch 214/400, Train Loss: 0.0104, Test Loss: 0.4137\n",
      "Epoch 215/400, Train Loss: 0.0099, Test Loss: 0.4569\n",
      "Epoch 216/400, Train Loss: 0.0172, Test Loss: 0.4099\n",
      "Epoch 217/400, Train Loss: 0.0096, Test Loss: 0.4102\n",
      "Epoch 218/400, Train Loss: 0.0064, Test Loss: 0.3878\n",
      "Epoch 219/400, Train Loss: 0.0026, Test Loss: 0.4119\n",
      "Epoch 220/400, Train Loss: 0.0136, Test Loss: 0.4010\n",
      "Epoch 221/400, Train Loss: 0.0108, Test Loss: 0.4122\n",
      "Epoch 222/400, Train Loss: 0.0216, Test Loss: 0.4567\n",
      "Epoch 223/400, Train Loss: 0.0085, Test Loss: 0.4158\n",
      "Epoch 224/400, Train Loss: 0.0063, Test Loss: 0.4309\n",
      "Epoch 225/400, Train Loss: 0.0024, Test Loss: 0.3881\n",
      "Epoch 226/400, Train Loss: 0.0002, Test Loss: 0.3866\n",
      "Epoch 227/400, Train Loss: 0.0001, Test Loss: 0.3957\n",
      "Epoch 228/400, Train Loss: 0.0001, Test Loss: 0.3910\n",
      "Epoch 229/400, Train Loss: 0.0001, Test Loss: 0.3893\n",
      "Epoch 230/400, Train Loss: 0.0001, Test Loss: 0.3915\n",
      "Epoch 231/400, Train Loss: 0.0001, Test Loss: 0.3899\n",
      "Epoch 232/400, Train Loss: 0.0001, Test Loss: 0.3898\n",
      "Epoch 233/400, Train Loss: 0.0001, Test Loss: 0.3915\n",
      "Epoch 234/400, Train Loss: 0.0001, Test Loss: 0.3989\n",
      "Epoch 235/400, Train Loss: 0.0001, Test Loss: 0.3946\n",
      "Epoch 236/400, Train Loss: 0.0001, Test Loss: 0.3990\n",
      "Epoch 237/400, Train Loss: 0.0001, Test Loss: 0.3933\n",
      "Epoch 238/400, Train Loss: 0.0004, Test Loss: 0.5754\n",
      "Epoch 239/400, Train Loss: 0.1014, Test Loss: 0.4826\n",
      "Epoch 240/400, Train Loss: 0.0150, Test Loss: 0.4156\n",
      "Epoch 241/400, Train Loss: 0.0040, Test Loss: 0.4391\n",
      "Epoch 242/400, Train Loss: 0.0052, Test Loss: 0.4402\n",
      "Epoch 243/400, Train Loss: 0.0124, Test Loss: 0.4385\n",
      "Epoch 244/400, Train Loss: 0.0158, Test Loss: 0.4101\n",
      "Epoch 245/400, Train Loss: 0.0012, Test Loss: 0.3930\n",
      "Epoch 246/400, Train Loss: 0.0008, Test Loss: 0.3986\n",
      "Epoch 247/400, Train Loss: 0.0002, Test Loss: 0.3956\n",
      "Epoch 248/400, Train Loss: 0.0001, Test Loss: 0.4130\n",
      "Epoch 249/400, Train Loss: 0.0001, Test Loss: 0.4197\n",
      "Epoch 250/400, Train Loss: 0.0001, Test Loss: 0.3924\n",
      "Epoch 251/400, Train Loss: 0.0001, Test Loss: 0.3999\n",
      "Epoch 252/400, Train Loss: 0.0001, Test Loss: 0.3949\n",
      "Epoch 253/400, Train Loss: 0.0001, Test Loss: 0.3942\n",
      "Epoch 254/400, Train Loss: 0.0001, Test Loss: 0.3997\n",
      "Epoch 255/400, Train Loss: 0.0001, Test Loss: 0.3955\n",
      "Epoch 256/400, Train Loss: 0.0001, Test Loss: 0.3975\n",
      "Epoch 257/400, Train Loss: 0.0001, Test Loss: 0.3958\n",
      "Epoch 258/400, Train Loss: 0.0000, Test Loss: 0.4064\n",
      "Epoch 259/400, Train Loss: 0.0927, Test Loss: 0.4255\n",
      "Epoch 260/400, Train Loss: 0.0164, Test Loss: 0.4094\n",
      "Epoch 261/400, Train Loss: 0.0048, Test Loss: 0.4293\n",
      "Epoch 262/400, Train Loss: 0.0081, Test Loss: 0.4321\n",
      "Epoch 263/400, Train Loss: 0.0049, Test Loss: 0.4138\n",
      "Epoch 264/400, Train Loss: 0.0034, Test Loss: 0.4522\n",
      "Epoch 265/400, Train Loss: 0.0192, Test Loss: 0.4456\n",
      "Epoch 266/400, Train Loss: 0.0127, Test Loss: 0.4243\n",
      "Epoch 267/400, Train Loss: 0.0150, Test Loss: 0.4376\n",
      "Epoch 268/400, Train Loss: 0.0084, Test Loss: 0.4358\n",
      "Epoch 269/400, Train Loss: 0.0042, Test Loss: 0.4156\n",
      "Epoch 270/400, Train Loss: 0.0161, Test Loss: 0.4426\n",
      "Epoch 271/400, Train Loss: 0.0199, Test Loss: 0.4678\n",
      "Epoch 272/400, Train Loss: 0.0103, Test Loss: 0.4435\n",
      "Epoch 273/400, Train Loss: 0.0068, Test Loss: 0.4085\n",
      "Epoch 274/400, Train Loss: 0.0116, Test Loss: 0.4807\n",
      "Epoch 275/400, Train Loss: 0.0056, Test Loss: 0.4405\n",
      "Epoch 276/400, Train Loss: 0.0009, Test Loss: 0.4119\n",
      "Epoch 277/400, Train Loss: 0.0002, Test Loss: 0.3969\n",
      "Epoch 278/400, Train Loss: 0.0001, Test Loss: 0.4061\n",
      "Epoch 279/400, Train Loss: 0.0001, Test Loss: 0.4204\n",
      "Epoch 280/400, Train Loss: 0.0001, Test Loss: 0.3952\n",
      "Epoch 281/400, Train Loss: 0.0001, Test Loss: 0.3950\n",
      "Epoch 282/400, Train Loss: 0.0000, Test Loss: 0.3960\n",
      "Epoch 283/400, Train Loss: 0.0000, Test Loss: 0.3996\n",
      "Epoch 284/400, Train Loss: 0.0000, Test Loss: 0.4227\n",
      "Epoch 285/400, Train Loss: 0.0000, Test Loss: 0.4325\n",
      "Epoch 286/400, Train Loss: 0.0000, Test Loss: 0.4099\n",
      "Epoch 287/400, Train Loss: 0.0000, Test Loss: 0.4028\n",
      "Epoch 288/400, Train Loss: 0.0000, Test Loss: 0.3984\n",
      "Epoch 289/400, Train Loss: 0.0000, Test Loss: 0.4146\n",
      "Epoch 290/400, Train Loss: 0.0000, Test Loss: 0.4183\n",
      "Epoch 291/400, Train Loss: 0.0000, Test Loss: 0.4090\n",
      "Epoch 292/400, Train Loss: 0.0000, Test Loss: 0.4261\n",
      "Epoch 293/400, Train Loss: 0.0000, Test Loss: 0.4032\n",
      "Epoch 294/400, Train Loss: 0.0000, Test Loss: 0.4033\n",
      "Epoch 295/400, Train Loss: 0.0492, Test Loss: 0.8706\n",
      "Epoch 296/400, Train Loss: 0.0629, Test Loss: 0.4530\n",
      "Epoch 297/400, Train Loss: 0.0083, Test Loss: 0.4823\n",
      "Epoch 298/400, Train Loss: 0.0064, Test Loss: 0.4468\n",
      "Epoch 299/400, Train Loss: 0.0043, Test Loss: 0.4484\n",
      "Epoch 300/400, Train Loss: 0.0079, Test Loss: 0.4557\n",
      "Epoch 301/400, Train Loss: 0.0158, Test Loss: 0.5053\n",
      "Epoch 302/400, Train Loss: 0.0074, Test Loss: 0.4512\n",
      "Epoch 303/400, Train Loss: 0.0083, Test Loss: 0.4400\n",
      "Epoch 304/400, Train Loss: 0.0064, Test Loss: 0.4522\n",
      "Epoch 305/400, Train Loss: 0.0035, Test Loss: 0.4563\n",
      "Epoch 306/400, Train Loss: 0.0092, Test Loss: 0.4953\n",
      "Epoch 307/400, Train Loss: 0.0252, Test Loss: 0.4712\n",
      "Epoch 308/400, Train Loss: 0.0090, Test Loss: 0.4565\n",
      "Epoch 309/400, Train Loss: 0.0109, Test Loss: 0.4602\n",
      "Epoch 310/400, Train Loss: 0.0047, Test Loss: 0.4244\n",
      "Epoch 311/400, Train Loss: 0.0025, Test Loss: 0.4910\n",
      "Epoch 312/400, Train Loss: 0.0130, Test Loss: 0.5010\n",
      "Epoch 313/400, Train Loss: 0.0175, Test Loss: 0.4730\n",
      "Epoch 314/400, Train Loss: 0.0083, Test Loss: 0.4514\n",
      "Epoch 315/400, Train Loss: 0.0020, Test Loss: 0.4398\n",
      "Epoch 316/400, Train Loss: 0.0002, Test Loss: 0.4204\n",
      "Epoch 317/400, Train Loss: 0.0001, Test Loss: 0.4286\n",
      "Epoch 318/400, Train Loss: 0.0000, Test Loss: 0.4211\n",
      "Epoch 319/400, Train Loss: 0.0000, Test Loss: 0.4204\n",
      "Epoch 320/400, Train Loss: 0.0000, Test Loss: 0.4391\n",
      "Epoch 321/400, Train Loss: 0.0000, Test Loss: 0.4195\n",
      "Epoch 322/400, Train Loss: 0.0000, Test Loss: 0.4196\n",
      "Epoch 323/400, Train Loss: 0.0000, Test Loss: 0.4300\n",
      "Epoch 324/400, Train Loss: 0.0000, Test Loss: 0.4201\n",
      "Epoch 325/400, Train Loss: 0.0000, Test Loss: 0.4221\n",
      "Epoch 326/400, Train Loss: 0.0000, Test Loss: 0.4215\n",
      "Epoch 327/400, Train Loss: 0.0000, Test Loss: 0.4322\n",
      "Epoch 328/400, Train Loss: 0.0000, Test Loss: 0.4227\n",
      "Epoch 329/400, Train Loss: 0.0000, Test Loss: 0.4220\n",
      "Epoch 330/400, Train Loss: 0.0000, Test Loss: 0.4285\n",
      "Epoch 331/400, Train Loss: 0.0000, Test Loss: 0.4224\n",
      "Epoch 332/400, Train Loss: 0.0000, Test Loss: 0.4223\n",
      "Epoch 333/400, Train Loss: 0.0000, Test Loss: 0.4221\n",
      "Epoch 334/400, Train Loss: 0.0000, Test Loss: 0.4243\n",
      "Epoch 335/400, Train Loss: 0.0843, Test Loss: 0.5023\n",
      "Epoch 336/400, Train Loss: 0.0102, Test Loss: 0.4730\n",
      "Epoch 337/400, Train Loss: 0.0087, Test Loss: 0.5100\n",
      "Epoch 338/400, Train Loss: 0.0160, Test Loss: 0.4468\n",
      "Epoch 339/400, Train Loss: 0.0049, Test Loss: 0.4649\n",
      "Epoch 340/400, Train Loss: 0.0080, Test Loss: 0.4616\n",
      "Epoch 341/400, Train Loss: 0.0095, Test Loss: 0.5021\n",
      "Epoch 342/400, Train Loss: 0.0093, Test Loss: 0.4457\n",
      "Epoch 343/400, Train Loss: 0.0097, Test Loss: 0.5028\n",
      "Epoch 344/400, Train Loss: 0.0035, Test Loss: 0.4514\n",
      "Epoch 345/400, Train Loss: 0.0097, Test Loss: 0.4891\n",
      "Epoch 346/400, Train Loss: 0.0138, Test Loss: 0.4661\n",
      "Epoch 347/400, Train Loss: 0.0089, Test Loss: 0.4628\n",
      "Epoch 348/400, Train Loss: 0.0072, Test Loss: 0.4629\n",
      "Epoch 349/400, Train Loss: 0.0109, Test Loss: 0.5856\n",
      "Epoch 350/400, Train Loss: 0.0062, Test Loss: 0.4750\n",
      "Epoch 351/400, Train Loss: 0.0202, Test Loss: 0.4865\n",
      "Epoch 352/400, Train Loss: 0.0108, Test Loss: 0.4650\n",
      "Epoch 353/400, Train Loss: 0.0037, Test Loss: 0.4556\n",
      "Epoch 354/400, Train Loss: 0.0105, Test Loss: 0.4835\n",
      "Epoch 355/400, Train Loss: 0.0060, Test Loss: 0.5652\n",
      "Epoch 356/400, Train Loss: 0.0154, Test Loss: 0.5032\n",
      "Epoch 357/400, Train Loss: 0.0127, Test Loss: 0.5042\n",
      "Epoch 358/400, Train Loss: 0.0061, Test Loss: 0.5151\n",
      "Epoch 359/400, Train Loss: 0.0008, Test Loss: 0.4778\n",
      "Epoch 360/400, Train Loss: 0.0001, Test Loss: 0.4506\n",
      "Epoch 361/400, Train Loss: 0.0000, Test Loss: 0.4505\n",
      "Epoch 362/400, Train Loss: 0.0000, Test Loss: 0.4504\n",
      "Epoch 363/400, Train Loss: 0.0000, Test Loss: 0.4646\n",
      "Epoch 364/400, Train Loss: 0.0000, Test Loss: 0.4518\n",
      "Epoch 365/400, Train Loss: 0.0000, Test Loss: 0.4507\n",
      "Epoch 366/400, Train Loss: 0.0000, Test Loss: 0.4501\n",
      "Epoch 367/400, Train Loss: 0.0000, Test Loss: 0.4505\n",
      "Epoch 368/400, Train Loss: 0.0000, Test Loss: 0.4616\n",
      "Epoch 369/400, Train Loss: 0.0000, Test Loss: 0.4509\n",
      "Epoch 370/400, Train Loss: 0.0000, Test Loss: 0.4668\n",
      "Epoch 371/400, Train Loss: 0.0000, Test Loss: 0.4506\n",
      "Epoch 372/400, Train Loss: 0.0000, Test Loss: 0.4495\n",
      "Epoch 373/400, Train Loss: 0.0000, Test Loss: 0.4536\n",
      "Epoch 374/400, Train Loss: 0.0000, Test Loss: 0.4559\n",
      "Epoch 375/400, Train Loss: 0.0000, Test Loss: 0.4503\n",
      "Epoch 376/400, Train Loss: 0.0000, Test Loss: 0.4517\n",
      "Epoch 377/400, Train Loss: 0.0000, Test Loss: 0.4521\n",
      "Epoch 378/400, Train Loss: 0.0000, Test Loss: 0.4678\n",
      "Epoch 379/400, Train Loss: 0.0000, Test Loss: 0.4504\n",
      "Epoch 380/400, Train Loss: 0.0000, Test Loss: 0.4537\n",
      "Epoch 381/400, Train Loss: 0.0000, Test Loss: 0.4532\n",
      "Epoch 382/400, Train Loss: 0.0000, Test Loss: 0.4587\n",
      "Epoch 383/400, Train Loss: 0.0000, Test Loss: 0.4933\n",
      "Epoch 384/400, Train Loss: 0.0798, Test Loss: 0.5316\n",
      "Epoch 385/400, Train Loss: 0.0207, Test Loss: 0.5179\n",
      "Epoch 386/400, Train Loss: 0.0072, Test Loss: 0.4833\n",
      "Epoch 387/400, Train Loss: 0.0014, Test Loss: 0.4703\n",
      "Epoch 388/400, Train Loss: 0.0013, Test Loss: 0.4661\n",
      "Epoch 389/400, Train Loss: 0.0172, Test Loss: 0.4799\n",
      "Epoch 390/400, Train Loss: 0.0116, Test Loss: 0.5288\n",
      "Epoch 391/400, Train Loss: 0.0070, Test Loss: 0.4685\n",
      "Epoch 392/400, Train Loss: 0.0100, Test Loss: 0.4758\n",
      "Epoch 393/400, Train Loss: 0.0040, Test Loss: 0.4940\n",
      "Epoch 394/400, Train Loss: 0.0239, Test Loss: 0.5728\n",
      "Epoch 395/400, Train Loss: 0.0075, Test Loss: 0.5267\n",
      "Epoch 396/400, Train Loss: 0.0055, Test Loss: 0.5171\n",
      "Epoch 397/400, Train Loss: 0.0079, Test Loss: 0.4773\n",
      "Epoch 398/400, Train Loss: 0.0054, Test Loss: 0.4707\n",
      "Epoch 399/400, Train Loss: 0.0062, Test Loss: 0.4960\n",
      "Epoch 400/400, Train Loss: 0.0106, Test Loss: 0.6352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.9496</td></tr><tr><td>accuracy/train</td><td>0.99672</td></tr><tr><td>batch_loss</td><td>0.00638</td></tr><tr><td>epoch</td><td>399</td></tr><tr><td>loss/test</td><td>0.63521</td></tr><tr><td>loss/train</td><td>0.01057</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">derby-tart-282</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/9lrhefbu' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/9lrhefbu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240314_114959-9lrhefbu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240314_121452-mw35olr7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/mw35olr7' target=\"_blank\">cinnamon-pastry-283</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/mw35olr7' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/mw35olr7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Train Loss: 0.4593, Test Loss: 0.2533\n",
      "Epoch 2/400, Train Loss: 0.2388, Test Loss: 0.1929\n",
      "Epoch 3/400, Train Loss: 0.1813, Test Loss: 0.1684\n",
      "Epoch 4/400, Train Loss: 0.1476, Test Loss: 0.1676\n",
      "Epoch 5/400, Train Loss: 0.1281, Test Loss: 0.1515\n",
      "Epoch 6/400, Train Loss: 0.1160, Test Loss: 0.1165\n",
      "Epoch 7/400, Train Loss: 0.0971, Test Loss: 0.1191\n",
      "Epoch 8/400, Train Loss: 0.0925, Test Loss: 0.1247\n",
      "Epoch 9/400, Train Loss: 0.0815, Test Loss: 0.1129\n",
      "Epoch 10/400, Train Loss: 0.0746, Test Loss: 0.1235\n",
      "Epoch 11/400, Train Loss: 0.0728, Test Loss: 0.1086\n",
      "Epoch 12/400, Train Loss: 0.0642, Test Loss: 0.1013\n",
      "Epoch 13/400, Train Loss: 0.0581, Test Loss: 0.1046\n",
      "Epoch 14/400, Train Loss: 0.0524, Test Loss: 0.1011\n",
      "Epoch 15/400, Train Loss: 0.0502, Test Loss: 0.1085\n",
      "Epoch 16/400, Train Loss: 0.0541, Test Loss: 0.1076\n",
      "Epoch 17/400, Train Loss: 0.0477, Test Loss: 0.1207\n",
      "Epoch 18/400, Train Loss: 0.0469, Test Loss: 0.1133\n",
      "Epoch 19/400, Train Loss: 0.0441, Test Loss: 0.1075\n",
      "Epoch 20/400, Train Loss: 0.0379, Test Loss: 0.1154\n",
      "Epoch 21/400, Train Loss: 0.0365, Test Loss: 0.1127\n",
      "Epoch 22/400, Train Loss: 0.0311, Test Loss: 0.1187\n",
      "Epoch 23/400, Train Loss: 0.0325, Test Loss: 0.1431\n",
      "Epoch 24/400, Train Loss: 0.0374, Test Loss: 0.1330\n",
      "Epoch 25/400, Train Loss: 0.0336, Test Loss: 0.1206\n",
      "Epoch 26/400, Train Loss: 0.0257, Test Loss: 0.1331\n",
      "Epoch 27/400, Train Loss: 0.0280, Test Loss: 0.1363\n",
      "Epoch 28/400, Train Loss: 0.0306, Test Loss: 0.1487\n",
      "Epoch 29/400, Train Loss: 0.0250, Test Loss: 0.1254\n",
      "Epoch 30/400, Train Loss: 0.0241, Test Loss: 0.1313\n",
      "Epoch 31/400, Train Loss: 0.0216, Test Loss: 0.1304\n",
      "Epoch 32/400, Train Loss: 0.0285, Test Loss: 0.1869\n",
      "Epoch 33/400, Train Loss: 0.0300, Test Loss: 0.1346\n",
      "Epoch 34/400, Train Loss: 0.0205, Test Loss: 0.1463\n",
      "Epoch 35/400, Train Loss: 0.0221, Test Loss: 0.1652\n",
      "Epoch 36/400, Train Loss: 0.0202, Test Loss: 0.1488\n",
      "Epoch 37/400, Train Loss: 0.0196, Test Loss: 0.1522\n",
      "Epoch 38/400, Train Loss: 0.0237, Test Loss: 0.1690\n",
      "Epoch 39/400, Train Loss: 0.0199, Test Loss: 0.2065\n",
      "Epoch 40/400, Train Loss: 0.0163, Test Loss: 0.1453\n",
      "Epoch 41/400, Train Loss: 0.0134, Test Loss: 0.1686\n",
      "Epoch 42/400, Train Loss: 0.0268, Test Loss: 0.1520\n",
      "Epoch 43/400, Train Loss: 0.0267, Test Loss: 0.1797\n",
      "Epoch 44/400, Train Loss: 0.0133, Test Loss: 0.1697\n",
      "Epoch 45/400, Train Loss: 0.0171, Test Loss: 0.1527\n",
      "Epoch 46/400, Train Loss: 0.0112, Test Loss: 0.1748\n",
      "Epoch 47/400, Train Loss: 0.0171, Test Loss: 0.1606\n",
      "Epoch 48/400, Train Loss: 0.0169, Test Loss: 0.1565\n",
      "Epoch 49/400, Train Loss: 0.0224, Test Loss: 0.1747\n",
      "Epoch 50/400, Train Loss: 0.0202, Test Loss: 0.1608\n",
      "Epoch 51/400, Train Loss: 0.0107, Test Loss: 0.1733\n",
      "Epoch 52/400, Train Loss: 0.0223, Test Loss: 0.1917\n",
      "Epoch 53/400, Train Loss: 0.0182, Test Loss: 0.1706\n",
      "Epoch 54/400, Train Loss: 0.0096, Test Loss: 0.1878\n",
      "Epoch 55/400, Train Loss: 0.0094, Test Loss: 0.1696\n",
      "Epoch 56/400, Train Loss: 0.0204, Test Loss: 0.1901\n",
      "Epoch 57/400, Train Loss: 0.0183, Test Loss: 0.2022\n",
      "Epoch 58/400, Train Loss: 0.0102, Test Loss: 0.1730\n",
      "Epoch 59/400, Train Loss: 0.0092, Test Loss: 0.2142\n",
      "Epoch 60/400, Train Loss: 0.0252, Test Loss: 0.2053\n",
      "Epoch 61/400, Train Loss: 0.0127, Test Loss: 0.1934\n",
      "Epoch 62/400, Train Loss: 0.0084, Test Loss: 0.1901\n",
      "Epoch 63/400, Train Loss: 0.0212, Test Loss: 0.1945\n",
      "Epoch 64/400, Train Loss: 0.0098, Test Loss: 0.2074\n",
      "Epoch 65/400, Train Loss: 0.0172, Test Loss: 0.1815\n",
      "Epoch 66/400, Train Loss: 0.0079, Test Loss: 0.1930\n",
      "Epoch 67/400, Train Loss: 0.0290, Test Loss: 0.2111\n",
      "Epoch 68/400, Train Loss: 0.0119, Test Loss: 0.2066\n",
      "Epoch 69/400, Train Loss: 0.0093, Test Loss: 0.2235\n",
      "Epoch 70/400, Train Loss: 0.0174, Test Loss: 0.2047\n",
      "Epoch 71/400, Train Loss: 0.0124, Test Loss: 0.2263\n",
      "Epoch 72/400, Train Loss: 0.0213, Test Loss: 0.2030\n",
      "Epoch 73/400, Train Loss: 0.0103, Test Loss: 0.1986\n",
      "Epoch 74/400, Train Loss: 0.0091, Test Loss: 0.1983\n",
      "Epoch 75/400, Train Loss: 0.0102, Test Loss: 0.2151\n",
      "Epoch 76/400, Train Loss: 0.0156, Test Loss: 0.1958\n",
      "Epoch 77/400, Train Loss: 0.0144, Test Loss: 0.2391\n",
      "Epoch 78/400, Train Loss: 0.0117, Test Loss: 0.2039\n",
      "Epoch 79/400, Train Loss: 0.0144, Test Loss: 0.2540\n",
      "Epoch 80/400, Train Loss: 0.0072, Test Loss: 0.2152\n",
      "Epoch 81/400, Train Loss: 0.0168, Test Loss: 0.2889\n",
      "Epoch 82/400, Train Loss: 0.0146, Test Loss: 0.2257\n",
      "Epoch 83/400, Train Loss: 0.0083, Test Loss: 0.2480\n",
      "Epoch 84/400, Train Loss: 0.0195, Test Loss: 0.2112\n",
      "Epoch 85/400, Train Loss: 0.0080, Test Loss: 0.2041\n",
      "Epoch 86/400, Train Loss: 0.0048, Test Loss: 0.2468\n",
      "Epoch 87/400, Train Loss: 0.0046, Test Loss: 0.2332\n",
      "Epoch 88/400, Train Loss: 0.0325, Test Loss: 0.2430\n",
      "Epoch 89/400, Train Loss: 0.0167, Test Loss: 0.2516\n",
      "Epoch 90/400, Train Loss: 0.0095, Test Loss: 0.2360\n",
      "Epoch 91/400, Train Loss: 0.0182, Test Loss: 0.2068\n",
      "Epoch 92/400, Train Loss: 0.0044, Test Loss: 0.2114\n",
      "Epoch 93/400, Train Loss: 0.0029, Test Loss: 0.2736\n",
      "Epoch 94/400, Train Loss: 0.0210, Test Loss: 0.2412\n",
      "Epoch 95/400, Train Loss: 0.0143, Test Loss: 0.2780\n",
      "Epoch 96/400, Train Loss: 0.0075, Test Loss: 0.2506\n",
      "Epoch 97/400, Train Loss: 0.0182, Test Loss: 0.2508\n",
      "Epoch 98/400, Train Loss: 0.0119, Test Loss: 0.2837\n",
      "Epoch 99/400, Train Loss: 0.0074, Test Loss: 0.2497\n",
      "Epoch 100/400, Train Loss: 0.0116, Test Loss: 0.2599\n",
      "Epoch 101/400, Train Loss: 0.0037, Test Loss: 0.2080\n",
      "Epoch 102/400, Train Loss: 0.0118, Test Loss: 0.3077\n",
      "Epoch 103/400, Train Loss: 0.0192, Test Loss: 0.2445\n",
      "Epoch 104/400, Train Loss: 0.0079, Test Loss: 0.2478\n",
      "Epoch 105/400, Train Loss: 0.0079, Test Loss: 0.2703\n",
      "Epoch 106/400, Train Loss: 0.0104, Test Loss: 0.2811\n",
      "Epoch 107/400, Train Loss: 0.0122, Test Loss: 0.2692\n",
      "Epoch 108/400, Train Loss: 0.0118, Test Loss: 0.2935\n",
      "Epoch 109/400, Train Loss: 0.0119, Test Loss: 0.2534\n",
      "Epoch 110/400, Train Loss: 0.0076, Test Loss: 0.2566\n",
      "Epoch 111/400, Train Loss: 0.0064, Test Loss: 0.3210\n",
      "Epoch 112/400, Train Loss: 0.0146, Test Loss: 0.2903\n",
      "Epoch 113/400, Train Loss: 0.0112, Test Loss: 0.2739\n",
      "Epoch 114/400, Train Loss: 0.0120, Test Loss: 0.2464\n",
      "Epoch 115/400, Train Loss: 0.0049, Test Loss: 0.2586\n",
      "Epoch 116/400, Train Loss: 0.0133, Test Loss: 0.2707\n",
      "Epoch 117/400, Train Loss: 0.0135, Test Loss: 0.2587\n",
      "Epoch 118/400, Train Loss: 0.0046, Test Loss: 0.2950\n",
      "Epoch 119/400, Train Loss: 0.0061, Test Loss: 0.2603\n",
      "Epoch 120/400, Train Loss: 0.0132, Test Loss: 0.2696\n",
      "Epoch 121/400, Train Loss: 0.0106, Test Loss: 0.2906\n",
      "Epoch 122/400, Train Loss: 0.0242, Test Loss: 0.2640\n",
      "Epoch 123/400, Train Loss: 0.0101, Test Loss: 0.2597\n",
      "Epoch 124/400, Train Loss: 0.0030, Test Loss: 0.2933\n",
      "Epoch 125/400, Train Loss: 0.0088, Test Loss: 0.2860\n",
      "Epoch 126/400, Train Loss: 0.0202, Test Loss: 0.3072\n",
      "Epoch 127/400, Train Loss: 0.0094, Test Loss: 0.2670\n",
      "Epoch 128/400, Train Loss: 0.0063, Test Loss: 0.2514\n",
      "Epoch 129/400, Train Loss: 0.0025, Test Loss: 0.3194\n",
      "Epoch 130/400, Train Loss: 0.0231, Test Loss: 0.3389\n",
      "Epoch 131/400, Train Loss: 0.0089, Test Loss: 0.2955\n",
      "Epoch 132/400, Train Loss: 0.0053, Test Loss: 0.2894\n",
      "Epoch 133/400, Train Loss: 0.0025, Test Loss: 0.3001\n",
      "Epoch 134/400, Train Loss: 0.0127, Test Loss: 0.3022\n",
      "Epoch 135/400, Train Loss: 0.0161, Test Loss: 0.3085\n",
      "Epoch 136/400, Train Loss: 0.0120, Test Loss: 0.3067\n",
      "Epoch 137/400, Train Loss: 0.0081, Test Loss: 0.2855\n",
      "Epoch 138/400, Train Loss: 0.0142, Test Loss: 0.2945\n",
      "Epoch 139/400, Train Loss: 0.0098, Test Loss: 0.3001\n",
      "Epoch 140/400, Train Loss: 0.0050, Test Loss: 0.2804\n",
      "Epoch 141/400, Train Loss: 0.0179, Test Loss: 0.3248\n",
      "Epoch 142/400, Train Loss: 0.0080, Test Loss: 0.2795\n",
      "Epoch 143/400, Train Loss: 0.0087, Test Loss: 0.3045\n",
      "Epoch 144/400, Train Loss: 0.0038, Test Loss: 0.3316\n",
      "Epoch 145/400, Train Loss: 0.0145, Test Loss: 0.3170\n",
      "Epoch 146/400, Train Loss: 0.0111, Test Loss: 0.3167\n",
      "Epoch 147/400, Train Loss: 0.0070, Test Loss: 0.2853\n",
      "Epoch 148/400, Train Loss: 0.0046, Test Loss: 0.2972\n",
      "Epoch 149/400, Train Loss: 0.0003, Test Loss: 0.3040\n",
      "Epoch 150/400, Train Loss: 0.0000, Test Loss: 0.2850\n",
      "Epoch 151/400, Train Loss: 0.0000, Test Loss: 0.2719\n",
      "Epoch 152/400, Train Loss: 0.0000, Test Loss: 0.2721\n",
      "Epoch 153/400, Train Loss: 0.0000, Test Loss: 0.2722\n",
      "Epoch 154/400, Train Loss: 0.0000, Test Loss: 0.2724\n",
      "Epoch 155/400, Train Loss: 0.0000, Test Loss: 0.2931\n",
      "Epoch 156/400, Train Loss: 0.0000, Test Loss: 0.2725\n",
      "Epoch 157/400, Train Loss: 0.0000, Test Loss: 0.2783\n",
      "Epoch 158/400, Train Loss: 0.0000, Test Loss: 0.2727\n",
      "Epoch 159/400, Train Loss: 0.0000, Test Loss: 0.2730\n",
      "Epoch 160/400, Train Loss: 0.0000, Test Loss: 0.2735\n",
      "Epoch 161/400, Train Loss: 0.0000, Test Loss: 0.2733\n",
      "Epoch 162/400, Train Loss: 0.0000, Test Loss: 0.2734\n",
      "Epoch 163/400, Train Loss: 0.0000, Test Loss: 0.2737\n",
      "Epoch 164/400, Train Loss: 0.0000, Test Loss: 0.2742\n",
      "Epoch 165/400, Train Loss: 0.0000, Test Loss: 0.2744\n",
      "Epoch 166/400, Train Loss: 0.0000, Test Loss: 0.2746\n",
      "Epoch 167/400, Train Loss: 0.0000, Test Loss: 0.2743\n",
      "Epoch 168/400, Train Loss: 0.0000, Test Loss: 0.2750\n",
      "Epoch 169/400, Train Loss: 0.0000, Test Loss: 0.2750\n",
      "Epoch 170/400, Train Loss: 0.0000, Test Loss: 0.2793\n",
      "Epoch 171/400, Train Loss: 0.0000, Test Loss: 0.2824\n",
      "Epoch 172/400, Train Loss: 0.0000, Test Loss: 0.2753\n",
      "Epoch 173/400, Train Loss: 0.0000, Test Loss: 0.2844\n",
      "Epoch 174/400, Train Loss: 0.0863, Test Loss: 0.3574\n",
      "Epoch 175/400, Train Loss: 0.0165, Test Loss: 0.3258\n",
      "Epoch 176/400, Train Loss: 0.0082, Test Loss: 0.3220\n",
      "Epoch 177/400, Train Loss: 0.0046, Test Loss: 0.3049\n",
      "Epoch 178/400, Train Loss: 0.0052, Test Loss: 0.3238\n",
      "Epoch 179/400, Train Loss: 0.0100, Test Loss: 0.3934\n",
      "Epoch 180/400, Train Loss: 0.0125, Test Loss: 0.3566\n",
      "Epoch 181/400, Train Loss: 0.0106, Test Loss: 0.2971\n",
      "Epoch 182/400, Train Loss: 0.0064, Test Loss: 0.3363\n",
      "Epoch 183/400, Train Loss: 0.0094, Test Loss: 0.3228\n",
      "Epoch 184/400, Train Loss: 0.0095, Test Loss: 0.3361\n",
      "Epoch 185/400, Train Loss: 0.0045, Test Loss: 0.3303\n",
      "Epoch 186/400, Train Loss: 0.0075, Test Loss: 0.3187\n",
      "Epoch 187/400, Train Loss: 0.0152, Test Loss: 0.3371\n",
      "Epoch 188/400, Train Loss: 0.0155, Test Loss: 0.3331\n",
      "Epoch 189/400, Train Loss: 0.0024, Test Loss: 0.3149\n",
      "Epoch 190/400, Train Loss: 0.0053, Test Loss: 0.3164\n",
      "Epoch 191/400, Train Loss: 0.0178, Test Loss: 0.3635\n",
      "Epoch 192/400, Train Loss: 0.0103, Test Loss: 0.3404\n",
      "Epoch 193/400, Train Loss: 0.0103, Test Loss: 0.3698\n",
      "Epoch 194/400, Train Loss: 0.0085, Test Loss: 0.3255\n",
      "Epoch 195/400, Train Loss: 0.0031, Test Loss: 0.3053\n",
      "Epoch 196/400, Train Loss: 0.0006, Test Loss: 0.3034\n",
      "Epoch 197/400, Train Loss: 0.0000, Test Loss: 0.2957\n",
      "Epoch 198/400, Train Loss: 0.0000, Test Loss: 0.2948\n",
      "Epoch 199/400, Train Loss: 0.0000, Test Loss: 0.3029\n",
      "Epoch 200/400, Train Loss: 0.0000, Test Loss: 0.2942\n",
      "Epoch 201/400, Train Loss: 0.0000, Test Loss: 0.3272\n",
      "Epoch 202/400, Train Loss: 0.0000, Test Loss: 0.2940\n",
      "Epoch 203/400, Train Loss: 0.0000, Test Loss: 0.2941\n",
      "Epoch 204/400, Train Loss: 0.0000, Test Loss: 0.2939\n",
      "Epoch 205/400, Train Loss: 0.0000, Test Loss: 0.2938\n",
      "Epoch 206/400, Train Loss: 0.0000, Test Loss: 0.2940\n",
      "Epoch 207/400, Train Loss: 0.0000, Test Loss: 0.3187\n",
      "Epoch 208/400, Train Loss: 0.0000, Test Loss: 0.2940\n",
      "Epoch 209/400, Train Loss: 0.0000, Test Loss: 0.2941\n",
      "Epoch 210/400, Train Loss: 0.0000, Test Loss: 0.2942\n",
      "Epoch 211/400, Train Loss: 0.0000, Test Loss: 0.2943\n",
      "Epoch 212/400, Train Loss: 0.0000, Test Loss: 0.3165\n",
      "Epoch 213/400, Train Loss: 0.0000, Test Loss: 0.2945\n",
      "Epoch 214/400, Train Loss: 0.0000, Test Loss: 0.2988\n",
      "Epoch 215/400, Train Loss: 0.0000, Test Loss: 0.2951\n",
      "Epoch 216/400, Train Loss: 0.0000, Test Loss: 0.2949\n",
      "Epoch 217/400, Train Loss: 0.0000, Test Loss: 0.2954\n",
      "Epoch 218/400, Train Loss: 0.0000, Test Loss: 0.2958\n",
      "Epoch 219/400, Train Loss: 0.0000, Test Loss: 0.2950\n",
      "Epoch 220/400, Train Loss: 0.0000, Test Loss: 0.2963\n",
      "Epoch 221/400, Train Loss: 0.0000, Test Loss: 0.2960\n",
      "Epoch 222/400, Train Loss: 0.0000, Test Loss: 0.2951\n",
      "Epoch 223/400, Train Loss: 0.0000, Test Loss: 0.2959\n",
      "Epoch 224/400, Train Loss: 0.0000, Test Loss: 0.2951\n",
      "Epoch 225/400, Train Loss: 0.0000, Test Loss: 0.3051\n",
      "Epoch 226/400, Train Loss: 0.0000, Test Loss: 0.2982\n",
      "Epoch 227/400, Train Loss: 0.0000, Test Loss: 0.2969\n",
      "Epoch 228/400, Train Loss: 0.0000, Test Loss: 0.2985\n",
      "Epoch 229/400, Train Loss: 0.0000, Test Loss: 0.2984\n",
      "Epoch 230/400, Train Loss: 0.0000, Test Loss: 0.2982\n",
      "Epoch 231/400, Train Loss: 0.0000, Test Loss: 0.2997\n",
      "Epoch 232/400, Train Loss: 0.0000, Test Loss: 0.3010\n",
      "Epoch 233/400, Train Loss: 0.0000, Test Loss: 0.3050\n",
      "Epoch 234/400, Train Loss: 0.0000, Test Loss: 0.3077\n",
      "Epoch 235/400, Train Loss: 0.0000, Test Loss: 0.3002\n",
      "Epoch 236/400, Train Loss: 0.0437, Test Loss: 0.4856\n",
      "Epoch 237/400, Train Loss: 0.0393, Test Loss: 0.3886\n",
      "Epoch 238/400, Train Loss: 0.0081, Test Loss: 0.3508\n",
      "Epoch 239/400, Train Loss: 0.0013, Test Loss: 0.3315\n",
      "Epoch 240/400, Train Loss: 0.0146, Test Loss: 0.3530\n",
      "Epoch 241/400, Train Loss: 0.0049, Test Loss: 0.3381\n",
      "Epoch 242/400, Train Loss: 0.0125, Test Loss: 0.3757\n",
      "Epoch 243/400, Train Loss: 0.0148, Test Loss: 0.3527\n",
      "Epoch 244/400, Train Loss: 0.0032, Test Loss: 0.3219\n",
      "Epoch 245/400, Train Loss: 0.0010, Test Loss: 0.3641\n",
      "Epoch 246/400, Train Loss: 0.0106, Test Loss: 0.3460\n",
      "Epoch 247/400, Train Loss: 0.0100, Test Loss: 0.4632\n",
      "Epoch 248/400, Train Loss: 0.0105, Test Loss: 0.4199\n",
      "Epoch 249/400, Train Loss: 0.0094, Test Loss: 0.3860\n",
      "Epoch 250/400, Train Loss: 0.0065, Test Loss: 0.3756\n",
      "Epoch 251/400, Train Loss: 0.0113, Test Loss: 0.4315\n",
      "Epoch 252/400, Train Loss: 0.0136, Test Loss: 0.3596\n",
      "Epoch 253/400, Train Loss: 0.0095, Test Loss: 0.3418\n",
      "Epoch 254/400, Train Loss: 0.0054, Test Loss: 0.3951\n",
      "Epoch 255/400, Train Loss: 0.0037, Test Loss: 0.3546\n",
      "Epoch 256/400, Train Loss: 0.0154, Test Loss: 0.3741\n",
      "Epoch 257/400, Train Loss: 0.0079, Test Loss: 0.3635\n",
      "Epoch 258/400, Train Loss: 0.0075, Test Loss: 0.3742\n",
      "Epoch 259/400, Train Loss: 0.0041, Test Loss: 0.3671\n",
      "Epoch 260/400, Train Loss: 0.0126, Test Loss: 0.4019\n",
      "Epoch 261/400, Train Loss: 0.0129, Test Loss: 0.4348\n",
      "Epoch 262/400, Train Loss: 0.0082, Test Loss: 0.4170\n",
      "Epoch 263/400, Train Loss: 0.0107, Test Loss: 0.4153\n",
      "Epoch 264/400, Train Loss: 0.0091, Test Loss: 0.3931\n",
      "Epoch 265/400, Train Loss: 0.0028, Test Loss: 0.3508\n",
      "Epoch 266/400, Train Loss: 0.0006, Test Loss: 0.3497\n",
      "Epoch 267/400, Train Loss: 0.0111, Test Loss: 0.4068\n",
      "Epoch 268/400, Train Loss: 0.0144, Test Loss: 0.4412\n",
      "Epoch 269/400, Train Loss: 0.0081, Test Loss: 0.3941\n",
      "Epoch 270/400, Train Loss: 0.0079, Test Loss: 0.3705\n",
      "Epoch 271/400, Train Loss: 0.0057, Test Loss: 0.3921\n",
      "Epoch 272/400, Train Loss: 0.0117, Test Loss: 0.4284\n",
      "Epoch 273/400, Train Loss: 0.0116, Test Loss: 0.4195\n",
      "Epoch 274/400, Train Loss: 0.0102, Test Loss: 0.4430\n",
      "Epoch 275/400, Train Loss: 0.0029, Test Loss: 0.3806\n",
      "Epoch 276/400, Train Loss: 0.0090, Test Loss: 0.4062\n",
      "Epoch 277/400, Train Loss: 0.0094, Test Loss: 0.4351\n",
      "Epoch 278/400, Train Loss: 0.0106, Test Loss: 0.3998\n",
      "Epoch 279/400, Train Loss: 0.0067, Test Loss: 0.4256\n",
      "Epoch 280/400, Train Loss: 0.0116, Test Loss: 0.4771\n",
      "Epoch 281/400, Train Loss: 0.0061, Test Loss: 0.3848\n",
      "Epoch 282/400, Train Loss: 0.0003, Test Loss: 0.3815\n",
      "Epoch 283/400, Train Loss: 0.0005, Test Loss: 0.4156\n",
      "Epoch 284/400, Train Loss: 0.0251, Test Loss: 0.5082\n",
      "Epoch 285/400, Train Loss: 0.0079, Test Loss: 0.4205\n",
      "Epoch 286/400, Train Loss: 0.0084, Test Loss: 0.3894\n",
      "Epoch 287/400, Train Loss: 0.0072, Test Loss: 0.4110\n",
      "Epoch 288/400, Train Loss: 0.0033, Test Loss: 0.3954\n",
      "Epoch 289/400, Train Loss: 0.0162, Test Loss: 0.4705\n",
      "Epoch 290/400, Train Loss: 0.0172, Test Loss: 0.4181\n",
      "Epoch 291/400, Train Loss: 0.0049, Test Loss: 0.4403\n",
      "Epoch 292/400, Train Loss: 0.0038, Test Loss: 0.4442\n",
      "Epoch 293/400, Train Loss: 0.0043, Test Loss: 0.4169\n",
      "Epoch 294/400, Train Loss: 0.0084, Test Loss: 0.4768\n",
      "Epoch 295/400, Train Loss: 0.0115, Test Loss: 0.4848\n",
      "Epoch 296/400, Train Loss: 0.0090, Test Loss: 0.4298\n",
      "Epoch 297/400, Train Loss: 0.0029, Test Loss: 0.4215\n",
      "Epoch 298/400, Train Loss: 0.0072, Test Loss: 0.4581\n",
      "Epoch 299/400, Train Loss: 0.0140, Test Loss: 0.4778\n",
      "Epoch 300/400, Train Loss: 0.0091, Test Loss: 0.4966\n",
      "Epoch 301/400, Train Loss: 0.0080, Test Loss: 0.5010\n",
      "Epoch 302/400, Train Loss: 0.0122, Test Loss: 0.4251\n",
      "Epoch 303/400, Train Loss: 0.0027, Test Loss: 0.4555\n",
      "Epoch 304/400, Train Loss: 0.0055, Test Loss: 0.4313\n",
      "Epoch 305/400, Train Loss: 0.0080, Test Loss: 0.5364\n",
      "Epoch 306/400, Train Loss: 0.0199, Test Loss: 0.4582\n",
      "Epoch 307/400, Train Loss: 0.0062, Test Loss: 0.4331\n",
      "Epoch 308/400, Train Loss: 0.0056, Test Loss: 0.4678\n",
      "Epoch 309/400, Train Loss: 0.0078, Test Loss: 0.4824\n",
      "Epoch 310/400, Train Loss: 0.0087, Test Loss: 0.4254\n",
      "Epoch 311/400, Train Loss: 0.0032, Test Loss: 0.4479\n",
      "Epoch 312/400, Train Loss: 0.0194, Test Loss: 0.5304\n",
      "Epoch 313/400, Train Loss: 0.0120, Test Loss: 0.4766\n",
      "Epoch 314/400, Train Loss: 0.0055, Test Loss: 0.5167\n",
      "Epoch 315/400, Train Loss: 0.0057, Test Loss: 0.4987\n",
      "Epoch 316/400, Train Loss: 0.0066, Test Loss: 0.4731\n",
      "Epoch 317/400, Train Loss: 0.0049, Test Loss: 0.4504\n",
      "Epoch 318/400, Train Loss: 0.0117, Test Loss: 0.4691\n",
      "Epoch 319/400, Train Loss: 0.0141, Test Loss: 0.4754\n",
      "Epoch 320/400, Train Loss: 0.0076, Test Loss: 0.5028\n",
      "Epoch 321/400, Train Loss: 0.0074, Test Loss: 0.4305\n",
      "Epoch 322/400, Train Loss: 0.0008, Test Loss: 0.4481\n",
      "Epoch 323/400, Train Loss: 0.0000, Test Loss: 0.4132\n",
      "Epoch 324/400, Train Loss: 0.0000, Test Loss: 0.4116\n",
      "Epoch 325/400, Train Loss: 0.0000, Test Loss: 0.4111\n",
      "Epoch 326/400, Train Loss: 0.0000, Test Loss: 0.4113\n",
      "Epoch 327/400, Train Loss: 0.0000, Test Loss: 0.4113\n",
      "Epoch 328/400, Train Loss: 0.0000, Test Loss: 0.4158\n",
      "Epoch 329/400, Train Loss: 0.0000, Test Loss: 0.4115\n",
      "Epoch 330/400, Train Loss: 0.0000, Test Loss: 0.4116\n",
      "Epoch 331/400, Train Loss: 0.0000, Test Loss: 0.4117\n",
      "Epoch 332/400, Train Loss: 0.0000, Test Loss: 0.4118\n",
      "Epoch 333/400, Train Loss: 0.0000, Test Loss: 0.4119\n",
      "Epoch 334/400, Train Loss: 0.0000, Test Loss: 0.4167\n",
      "Epoch 335/400, Train Loss: 0.0000, Test Loss: 0.4266\n",
      "Epoch 336/400, Train Loss: 0.0000, Test Loss: 0.4123\n",
      "Epoch 337/400, Train Loss: 0.0000, Test Loss: 0.4124\n",
      "Epoch 338/400, Train Loss: 0.0000, Test Loss: 0.4134\n",
      "Epoch 339/400, Train Loss: 0.0000, Test Loss: 0.4127\n",
      "Epoch 340/400, Train Loss: 0.0000, Test Loss: 0.4128\n",
      "Epoch 341/400, Train Loss: 0.0000, Test Loss: 0.4129\n",
      "Epoch 342/400, Train Loss: 0.0000, Test Loss: 0.4130\n",
      "Epoch 343/400, Train Loss: 0.0000, Test Loss: 0.4132\n",
      "Epoch 344/400, Train Loss: 0.0000, Test Loss: 0.4134\n",
      "Epoch 345/400, Train Loss: 0.0000, Test Loss: 0.4137\n",
      "Epoch 346/400, Train Loss: 0.0000, Test Loss: 0.4280\n",
      "Epoch 347/400, Train Loss: 0.0000, Test Loss: 0.4139\n",
      "Epoch 348/400, Train Loss: 0.0000, Test Loss: 0.4708\n",
      "Epoch 349/400, Train Loss: 0.0000, Test Loss: 0.4140\n",
      "Epoch 350/400, Train Loss: 0.0000, Test Loss: 0.4144\n",
      "Epoch 351/400, Train Loss: 0.0000, Test Loss: 0.4145\n",
      "Epoch 352/400, Train Loss: 0.0000, Test Loss: 0.4144\n",
      "Epoch 353/400, Train Loss: 0.0000, Test Loss: 0.4147\n",
      "Epoch 354/400, Train Loss: 0.0000, Test Loss: 0.4244\n",
      "Epoch 355/400, Train Loss: 0.0000, Test Loss: 0.4151\n",
      "Epoch 356/400, Train Loss: 0.0000, Test Loss: 0.4152\n",
      "Epoch 357/400, Train Loss: 0.0000, Test Loss: 0.4151\n",
      "Epoch 358/400, Train Loss: 0.0000, Test Loss: 0.4150\n",
      "Epoch 359/400, Train Loss: 0.0000, Test Loss: 0.4154\n",
      "Epoch 360/400, Train Loss: 0.0000, Test Loss: 0.4290\n",
      "Epoch 361/400, Train Loss: 0.0000, Test Loss: 0.4164\n",
      "Epoch 362/400, Train Loss: 0.0000, Test Loss: 0.4162\n",
      "Epoch 363/400, Train Loss: 0.0000, Test Loss: 0.4163\n",
      "Epoch 364/400, Train Loss: 0.0000, Test Loss: 0.4485\n",
      "Epoch 365/400, Train Loss: 0.0000, Test Loss: 0.4170\n",
      "Epoch 366/400, Train Loss: 0.0000, Test Loss: 0.4173\n",
      "Epoch 367/400, Train Loss: 0.0000, Test Loss: 0.4183\n",
      "Epoch 368/400, Train Loss: 0.0000, Test Loss: 0.4461\n",
      "Epoch 369/400, Train Loss: 0.0000, Test Loss: 0.4339\n",
      "Epoch 370/400, Train Loss: 0.0000, Test Loss: 0.4304\n",
      "Epoch 371/400, Train Loss: 0.0000, Test Loss: 0.4195\n",
      "Epoch 372/400, Train Loss: 0.0000, Test Loss: 0.4192\n",
      "Epoch 373/400, Train Loss: 0.0000, Test Loss: 0.4562\n",
      "Epoch 374/400, Train Loss: 0.0000, Test Loss: 0.4212\n",
      "Epoch 375/400, Train Loss: 0.0000, Test Loss: 0.4310\n",
      "Epoch 376/400, Train Loss: 0.0000, Test Loss: 0.4216\n",
      "Epoch 377/400, Train Loss: 0.0000, Test Loss: 0.4215\n",
      "Epoch 378/400, Train Loss: 0.0000, Test Loss: 0.4223\n",
      "Epoch 379/400, Train Loss: 0.0000, Test Loss: 0.4219\n",
      "Epoch 380/400, Train Loss: 0.0000, Test Loss: 0.4223\n",
      "Epoch 381/400, Train Loss: 0.0000, Test Loss: 0.4238\n",
      "Epoch 382/400, Train Loss: 0.0000, Test Loss: 0.4375\n",
      "Epoch 383/400, Train Loss: 0.0000, Test Loss: 0.4250\n",
      "Epoch 384/400, Train Loss: 0.0000, Test Loss: 0.4248\n",
      "Epoch 385/400, Train Loss: 0.0000, Test Loss: 0.4245\n",
      "Epoch 386/400, Train Loss: 0.0000, Test Loss: 0.4258\n",
      "Epoch 387/400, Train Loss: 0.0000, Test Loss: 0.4256\n",
      "Epoch 388/400, Train Loss: 0.0000, Test Loss: 0.4257\n",
      "Epoch 389/400, Train Loss: 0.0000, Test Loss: 0.4254\n",
      "Epoch 390/400, Train Loss: 0.0000, Test Loss: 0.4272\n",
      "Epoch 391/400, Train Loss: 0.0000, Test Loss: 0.4269\n",
      "Epoch 392/400, Train Loss: 0.0000, Test Loss: 0.4771\n",
      "Epoch 393/400, Train Loss: 0.0000, Test Loss: 0.4316\n",
      "Epoch 394/400, Train Loss: 0.0632, Test Loss: 0.6309\n",
      "Epoch 395/400, Train Loss: 0.0195, Test Loss: 0.4915\n",
      "Epoch 396/400, Train Loss: 0.0132, Test Loss: 0.4624\n",
      "Epoch 397/400, Train Loss: 0.0070, Test Loss: 0.4394\n",
      "Epoch 398/400, Train Loss: 0.0009, Test Loss: 0.4504\n",
      "Epoch 399/400, Train Loss: 0.0044, Test Loss: 0.4783\n",
      "Epoch 400/400, Train Loss: 0.0244, Test Loss: 0.5157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.9698</td></tr><tr><td>accuracy/train</td><td>0.99623</td></tr><tr><td>batch_loss</td><td>0.00023</td></tr><tr><td>epoch</td><td>399</td></tr><tr><td>loss/test</td><td>0.51566</td></tr><tr><td>loss/train</td><td>0.02435</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cinnamon-pastry-283</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/mw35olr7' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/mw35olr7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240314_121452-mw35olr7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sienkadounia/lab/ai-futures/Project/wandb/run-20240314_124041-azj803hf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/azj803hf' target=\"_blank\">apple-cobbler-284</a></strong> to <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/azj803hf' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/azj803hf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Train Loss: 0.4057, Test Loss: 0.2001\n",
      "Epoch 2/400, Train Loss: 0.1794, Test Loss: 0.1435\n",
      "Epoch 3/400, Train Loss: 0.1321, Test Loss: 0.1180\n",
      "Epoch 4/400, Train Loss: 0.1033, Test Loss: 0.1199\n",
      "Epoch 5/400, Train Loss: 0.0877, Test Loss: 0.0997\n",
      "Epoch 6/400, Train Loss: 0.0752, Test Loss: 0.0991\n",
      "Epoch 7/400, Train Loss: 0.0673, Test Loss: 0.1271\n",
      "Epoch 8/400, Train Loss: 0.0607, Test Loss: 0.0965\n",
      "Epoch 9/400, Train Loss: 0.0507, Test Loss: 0.0953\n",
      "Epoch 10/400, Train Loss: 0.0485, Test Loss: 0.1077\n",
      "Epoch 11/400, Train Loss: 0.0479, Test Loss: 0.1378\n",
      "Epoch 12/400, Train Loss: 0.0413, Test Loss: 0.1180\n",
      "Epoch 13/400, Train Loss: 0.0372, Test Loss: 0.1196\n",
      "Epoch 14/400, Train Loss: 0.0409, Test Loss: 0.1111\n",
      "Epoch 15/400, Train Loss: 0.0313, Test Loss: 0.1135\n",
      "Epoch 16/400, Train Loss: 0.0328, Test Loss: 0.1206\n",
      "Epoch 17/400, Train Loss: 0.0302, Test Loss: 0.1140\n",
      "Epoch 18/400, Train Loss: 0.0308, Test Loss: 0.1334\n",
      "Epoch 19/400, Train Loss: 0.0272, Test Loss: 0.1242\n",
      "Epoch 20/400, Train Loss: 0.0260, Test Loss: 0.1499\n",
      "Epoch 21/400, Train Loss: 0.0345, Test Loss: 0.1611\n",
      "Epoch 22/400, Train Loss: 0.0244, Test Loss: 0.1367\n",
      "Epoch 23/400, Train Loss: 0.0236, Test Loss: 0.1267\n",
      "Epoch 24/400, Train Loss: 0.0251, Test Loss: 0.1556\n",
      "Epoch 25/400, Train Loss: 0.0189, Test Loss: 0.1445\n",
      "Epoch 26/400, Train Loss: 0.0236, Test Loss: 0.1607\n",
      "Epoch 27/400, Train Loss: 0.0253, Test Loss: 0.1676\n",
      "Epoch 28/400, Train Loss: 0.0209, Test Loss: 0.1761\n",
      "Epoch 29/400, Train Loss: 0.0194, Test Loss: 0.1346\n",
      "Epoch 30/400, Train Loss: 0.0170, Test Loss: 0.1544\n",
      "Epoch 31/400, Train Loss: 0.0204, Test Loss: 0.1439\n",
      "Epoch 32/400, Train Loss: 0.0215, Test Loss: 0.1396\n",
      "Epoch 33/400, Train Loss: 0.0237, Test Loss: 0.1356\n",
      "Epoch 34/400, Train Loss: 0.0168, Test Loss: 0.1477\n",
      "Epoch 35/400, Train Loss: 0.0186, Test Loss: 0.1474\n",
      "Epoch 36/400, Train Loss: 0.0156, Test Loss: 0.1784\n",
      "Epoch 37/400, Train Loss: 0.0165, Test Loss: 0.1431\n",
      "Epoch 38/400, Train Loss: 0.0196, Test Loss: 0.1687\n",
      "Epoch 39/400, Train Loss: 0.0185, Test Loss: 0.1633\n",
      "Epoch 40/400, Train Loss: 0.0190, Test Loss: 0.1797\n",
      "Epoch 41/400, Train Loss: 0.0151, Test Loss: 0.1651\n",
      "Epoch 42/400, Train Loss: 0.0108, Test Loss: 0.1764\n",
      "Epoch 43/400, Train Loss: 0.0231, Test Loss: 0.1972\n",
      "Epoch 44/400, Train Loss: 0.0223, Test Loss: 0.1830\n",
      "Epoch 45/400, Train Loss: 0.0149, Test Loss: 0.1568\n",
      "Epoch 46/400, Train Loss: 0.0098, Test Loss: 0.1508\n",
      "Epoch 47/400, Train Loss: 0.0124, Test Loss: 0.2304\n",
      "Epoch 48/400, Train Loss: 0.0234, Test Loss: 0.2009\n",
      "Epoch 49/400, Train Loss: 0.0106, Test Loss: 0.1904\n",
      "Epoch 50/400, Train Loss: 0.0193, Test Loss: 0.2241\n",
      "Epoch 51/400, Train Loss: 0.0262, Test Loss: 0.1902\n",
      "Epoch 52/400, Train Loss: 0.0145, Test Loss: 0.1627\n",
      "Epoch 53/400, Train Loss: 0.0072, Test Loss: 0.1653\n",
      "Epoch 54/400, Train Loss: 0.0131, Test Loss: 0.2154\n",
      "Epoch 55/400, Train Loss: 0.0165, Test Loss: 0.1911\n",
      "Epoch 56/400, Train Loss: 0.0191, Test Loss: 0.2512\n",
      "Epoch 57/400, Train Loss: 0.0150, Test Loss: 0.2242\n",
      "Epoch 58/400, Train Loss: 0.0088, Test Loss: 0.1887\n",
      "Epoch 59/400, Train Loss: 0.0106, Test Loss: 0.2001\n",
      "Epoch 60/400, Train Loss: 0.0114, Test Loss: 0.1888\n",
      "Epoch 61/400, Train Loss: 0.0109, Test Loss: 0.2000\n",
      "Epoch 62/400, Train Loss: 0.0098, Test Loss: 0.2434\n",
      "Epoch 63/400, Train Loss: 0.0177, Test Loss: 0.2333\n",
      "Epoch 64/400, Train Loss: 0.0229, Test Loss: 0.2242\n",
      "Epoch 65/400, Train Loss: 0.0107, Test Loss: 0.2675\n",
      "Epoch 66/400, Train Loss: 0.0112, Test Loss: 0.2193\n",
      "Epoch 67/400, Train Loss: 0.0128, Test Loss: 0.1991\n",
      "Epoch 68/400, Train Loss: 0.0178, Test Loss: 0.2237\n",
      "Epoch 69/400, Train Loss: 0.0079, Test Loss: 0.2014\n",
      "Epoch 70/400, Train Loss: 0.0068, Test Loss: 0.2398\n",
      "Epoch 71/400, Train Loss: 0.0184, Test Loss: 0.2562\n",
      "Epoch 72/400, Train Loss: 0.0140, Test Loss: 0.2436\n",
      "Epoch 73/400, Train Loss: 0.0222, Test Loss: 0.2243\n",
      "Epoch 74/400, Train Loss: 0.0120, Test Loss: 0.2398\n",
      "Epoch 75/400, Train Loss: 0.0083, Test Loss: 0.2313\n",
      "Epoch 76/400, Train Loss: 0.0181, Test Loss: 0.2477\n",
      "Epoch 77/400, Train Loss: 0.0145, Test Loss: 0.2244\n",
      "Epoch 78/400, Train Loss: 0.0094, Test Loss: 0.2499\n",
      "Epoch 79/400, Train Loss: 0.0130, Test Loss: 0.2464\n",
      "Epoch 80/400, Train Loss: 0.0181, Test Loss: 0.2511\n",
      "Epoch 81/400, Train Loss: 0.0131, Test Loss: 0.2223\n",
      "Epoch 82/400, Train Loss: 0.0125, Test Loss: 0.2218\n",
      "Epoch 83/400, Train Loss: 0.0166, Test Loss: 0.2724\n",
      "Epoch 84/400, Train Loss: 0.0097, Test Loss: 0.2394\n",
      "Epoch 85/400, Train Loss: 0.0067, Test Loss: 0.2553\n",
      "Epoch 86/400, Train Loss: 0.0076, Test Loss: 0.2753\n",
      "Epoch 87/400, Train Loss: 0.0198, Test Loss: 0.3007\n",
      "Epoch 88/400, Train Loss: 0.0098, Test Loss: 0.2756\n",
      "Epoch 89/400, Train Loss: 0.0110, Test Loss: 0.2607\n",
      "Epoch 90/400, Train Loss: 0.0147, Test Loss: 0.2522\n",
      "Epoch 91/400, Train Loss: 0.0091, Test Loss: 0.2450\n",
      "Epoch 92/400, Train Loss: 0.0085, Test Loss: 0.2493\n",
      "Epoch 93/400, Train Loss: 0.0188, Test Loss: 0.3102\n",
      "Epoch 94/400, Train Loss: 0.0074, Test Loss: 0.2348\n",
      "Epoch 95/400, Train Loss: 0.0086, Test Loss: 0.2421\n",
      "Epoch 96/400, Train Loss: 0.0169, Test Loss: 0.3146\n",
      "Epoch 97/400, Train Loss: 0.0106, Test Loss: 0.2568\n",
      "Epoch 98/400, Train Loss: 0.0134, Test Loss: 0.3017\n",
      "Epoch 99/400, Train Loss: 0.0212, Test Loss: 0.2815\n",
      "Epoch 100/400, Train Loss: 0.0056, Test Loss: 0.2740\n",
      "Epoch 101/400, Train Loss: 0.0044, Test Loss: 0.2996\n",
      "Epoch 102/400, Train Loss: 0.0085, Test Loss: 0.2880\n",
      "Epoch 103/400, Train Loss: 0.0149, Test Loss: 0.3518\n",
      "Epoch 104/400, Train Loss: 0.0109, Test Loss: 0.3315\n",
      "Epoch 105/400, Train Loss: 0.0151, Test Loss: 0.3381\n",
      "Epoch 106/400, Train Loss: 0.0131, Test Loss: 0.2831\n",
      "Epoch 107/400, Train Loss: 0.0107, Test Loss: 0.2597\n",
      "Epoch 108/400, Train Loss: 0.0097, Test Loss: 0.3681\n",
      "Epoch 109/400, Train Loss: 0.0120, Test Loss: 0.2747\n",
      "Epoch 110/400, Train Loss: 0.0046, Test Loss: 0.2950\n",
      "Epoch 111/400, Train Loss: 0.0174, Test Loss: 0.3467\n",
      "Epoch 112/400, Train Loss: 0.0128, Test Loss: 0.3342\n",
      "Epoch 113/400, Train Loss: 0.0113, Test Loss: 0.2741\n",
      "Epoch 114/400, Train Loss: 0.0076, Test Loss: 0.2983\n",
      "Epoch 115/400, Train Loss: 0.0044, Test Loss: 0.2929\n",
      "Epoch 116/400, Train Loss: 0.0152, Test Loss: 0.3184\n",
      "Epoch 117/400, Train Loss: 0.0135, Test Loss: 0.3140\n",
      "Epoch 118/400, Train Loss: 0.0169, Test Loss: 0.3341\n",
      "Epoch 119/400, Train Loss: 0.0144, Test Loss: 0.3059\n",
      "Epoch 120/400, Train Loss: 0.0037, Test Loss: 0.2704\n",
      "Epoch 121/400, Train Loss: 0.0056, Test Loss: 0.3111\n",
      "Epoch 122/400, Train Loss: 0.0068, Test Loss: 0.3186\n",
      "Epoch 123/400, Train Loss: 0.0219, Test Loss: 0.3402\n",
      "Epoch 124/400, Train Loss: 0.0122, Test Loss: 0.3386\n",
      "Epoch 125/400, Train Loss: 0.0064, Test Loss: 0.2897\n",
      "Epoch 126/400, Train Loss: 0.0032, Test Loss: 0.3447\n",
      "Epoch 127/400, Train Loss: 0.0151, Test Loss: 0.3314\n",
      "Epoch 128/400, Train Loss: 0.0129, Test Loss: 0.3510\n",
      "Epoch 129/400, Train Loss: 0.0088, Test Loss: 0.3625\n",
      "Epoch 130/400, Train Loss: 0.0149, Test Loss: 0.4041\n",
      "Epoch 131/400, Train Loss: 0.0170, Test Loss: 0.3688\n",
      "Epoch 132/400, Train Loss: 0.0104, Test Loss: 0.3190\n",
      "Epoch 133/400, Train Loss: 0.0046, Test Loss: 0.3018\n",
      "Epoch 134/400, Train Loss: 0.0059, Test Loss: 0.3627\n",
      "Epoch 135/400, Train Loss: 0.0054, Test Loss: 0.3191\n",
      "Epoch 136/400, Train Loss: 0.0194, Test Loss: 0.4034\n",
      "Epoch 137/400, Train Loss: 0.0169, Test Loss: 0.3872\n",
      "Epoch 138/400, Train Loss: 0.0050, Test Loss: 0.3807\n",
      "Epoch 139/400, Train Loss: 0.0082, Test Loss: 0.3496\n",
      "Epoch 140/400, Train Loss: 0.0089, Test Loss: 0.3739\n",
      "Epoch 141/400, Train Loss: 0.0174, Test Loss: 0.3472\n",
      "Epoch 142/400, Train Loss: 0.0086, Test Loss: 0.3383\n",
      "Epoch 143/400, Train Loss: 0.0093, Test Loss: 0.3230\n",
      "Epoch 144/400, Train Loss: 0.0119, Test Loss: 0.3514\n",
      "Epoch 145/400, Train Loss: 0.0107, Test Loss: 0.3621\n",
      "Epoch 146/400, Train Loss: 0.0134, Test Loss: 0.3314\n",
      "Epoch 147/400, Train Loss: 0.0124, Test Loss: 0.3526\n",
      "Epoch 148/400, Train Loss: 0.0034, Test Loss: 0.3143\n",
      "Epoch 149/400, Train Loss: 0.0084, Test Loss: 0.4046\n",
      "Epoch 150/400, Train Loss: 0.0128, Test Loss: 0.4236\n",
      "Epoch 151/400, Train Loss: 0.0123, Test Loss: 0.3409\n",
      "Epoch 152/400, Train Loss: 0.0091, Test Loss: 0.3435\n",
      "Epoch 153/400, Train Loss: 0.0102, Test Loss: 0.3564\n",
      "Epoch 154/400, Train Loss: 0.0065, Test Loss: 0.3670\n",
      "Epoch 155/400, Train Loss: 0.0132, Test Loss: 0.3769\n",
      "Epoch 156/400, Train Loss: 0.0094, Test Loss: 0.4113\n",
      "Epoch 157/400, Train Loss: 0.0105, Test Loss: 0.3329\n",
      "Epoch 158/400, Train Loss: 0.0057, Test Loss: 0.3946\n",
      "Epoch 159/400, Train Loss: 0.0043, Test Loss: 0.4268\n",
      "Epoch 160/400, Train Loss: 0.0100, Test Loss: 0.4128\n",
      "Epoch 161/400, Train Loss: 0.0161, Test Loss: 0.4247\n",
      "Epoch 162/400, Train Loss: 0.0098, Test Loss: 0.3962\n",
      "Epoch 163/400, Train Loss: 0.0063, Test Loss: 0.4337\n",
      "Epoch 164/400, Train Loss: 0.0113, Test Loss: 0.3574\n",
      "Epoch 165/400, Train Loss: 0.0134, Test Loss: 0.3694\n",
      "Epoch 166/400, Train Loss: 0.0075, Test Loss: 0.3640\n",
      "Epoch 167/400, Train Loss: 0.0091, Test Loss: 0.3914\n",
      "Epoch 168/400, Train Loss: 0.0095, Test Loss: 0.3712\n",
      "Epoch 169/400, Train Loss: 0.0122, Test Loss: 0.3702\n",
      "Epoch 170/400, Train Loss: 0.0114, Test Loss: 0.4299\n",
      "Epoch 171/400, Train Loss: 0.0099, Test Loss: 0.4180\n",
      "Epoch 172/400, Train Loss: 0.0141, Test Loss: 0.4089\n",
      "Epoch 173/400, Train Loss: 0.0075, Test Loss: 0.4052\n",
      "Epoch 174/400, Train Loss: 0.0091, Test Loss: 0.4646\n",
      "Epoch 175/400, Train Loss: 0.0152, Test Loss: 0.3980\n",
      "Epoch 176/400, Train Loss: 0.0089, Test Loss: 0.4284\n",
      "Epoch 177/400, Train Loss: 0.0044, Test Loss: 0.3641\n",
      "Epoch 178/400, Train Loss: 0.0060, Test Loss: 0.4912\n",
      "Epoch 179/400, Train Loss: 0.0178, Test Loss: 0.4549\n",
      "Epoch 180/400, Train Loss: 0.0087, Test Loss: 0.3990\n",
      "Epoch 181/400, Train Loss: 0.0075, Test Loss: 0.4249\n",
      "Epoch 182/400, Train Loss: 0.0146, Test Loss: 0.4264\n",
      "Epoch 183/400, Train Loss: 0.0100, Test Loss: 0.4105\n",
      "Epoch 184/400, Train Loss: 0.0088, Test Loss: 0.4236\n",
      "Epoch 185/400, Train Loss: 0.0075, Test Loss: 0.3981\n",
      "Epoch 186/400, Train Loss: 0.0037, Test Loss: 0.5524\n",
      "Epoch 187/400, Train Loss: 0.0148, Test Loss: 0.4457\n",
      "Epoch 188/400, Train Loss: 0.0101, Test Loss: 0.3879\n",
      "Epoch 189/400, Train Loss: 0.0060, Test Loss: 0.4003\n",
      "Epoch 190/400, Train Loss: 0.0044, Test Loss: 0.4026\n",
      "Epoch 191/400, Train Loss: 0.0068, Test Loss: 0.4782\n",
      "Epoch 192/400, Train Loss: 0.0176, Test Loss: 0.4352\n",
      "Epoch 193/400, Train Loss: 0.0100, Test Loss: 0.4868\n",
      "Epoch 194/400, Train Loss: 0.0071, Test Loss: 0.3922\n",
      "Epoch 195/400, Train Loss: 0.0133, Test Loss: 0.4319\n",
      "Epoch 196/400, Train Loss: 0.0086, Test Loss: 0.4244\n",
      "Epoch 197/400, Train Loss: 0.0074, Test Loss: 0.4975\n",
      "Epoch 198/400, Train Loss: 0.0127, Test Loss: 0.4553\n",
      "Epoch 199/400, Train Loss: 0.0100, Test Loss: 0.4666\n",
      "Epoch 200/400, Train Loss: 0.0050, Test Loss: 0.3908\n",
      "Epoch 201/400, Train Loss: 0.0030, Test Loss: 0.4672\n",
      "Epoch 202/400, Train Loss: 0.0125, Test Loss: 0.4305\n",
      "Epoch 203/400, Train Loss: 0.0255, Test Loss: 0.4551\n",
      "Epoch 204/400, Train Loss: 0.0113, Test Loss: 0.4755\n",
      "Epoch 205/400, Train Loss: 0.0038, Test Loss: 0.4442\n",
      "Epoch 206/400, Train Loss: 0.0010, Test Loss: 0.4045\n",
      "Epoch 207/400, Train Loss: 0.0191, Test Loss: 0.5128\n",
      "Epoch 208/400, Train Loss: 0.0076, Test Loss: 0.4297\n",
      "Epoch 209/400, Train Loss: 0.0039, Test Loss: 0.4210\n",
      "Epoch 210/400, Train Loss: 0.0126, Test Loss: 0.4704\n",
      "Epoch 211/400, Train Loss: 0.0105, Test Loss: 0.4843\n",
      "Epoch 212/400, Train Loss: 0.0103, Test Loss: 0.5525\n",
      "Epoch 213/400, Train Loss: 0.0114, Test Loss: 0.4457\n",
      "Epoch 214/400, Train Loss: 0.0033, Test Loss: 0.4730\n",
      "Epoch 215/400, Train Loss: 0.0130, Test Loss: 0.4843\n",
      "Epoch 216/400, Train Loss: 0.0124, Test Loss: 0.5417\n",
      "Epoch 217/400, Train Loss: 0.0100, Test Loss: 0.5089\n",
      "Epoch 218/400, Train Loss: 0.0029, Test Loss: 0.5248\n",
      "Epoch 219/400, Train Loss: 0.0058, Test Loss: 0.4351\n",
      "Epoch 220/400, Train Loss: 0.0157, Test Loss: 0.4675\n",
      "Epoch 221/400, Train Loss: 0.0101, Test Loss: 0.5406\n",
      "Epoch 222/400, Train Loss: 0.0169, Test Loss: 0.4934\n",
      "Epoch 223/400, Train Loss: 0.0047, Test Loss: 0.4871\n",
      "Epoch 224/400, Train Loss: 0.0108, Test Loss: 0.4723\n",
      "Epoch 225/400, Train Loss: 0.0043, Test Loss: 0.5180\n",
      "Epoch 226/400, Train Loss: 0.0092, Test Loss: 0.4770\n",
      "Epoch 227/400, Train Loss: 0.0106, Test Loss: 0.5408\n",
      "Epoch 228/400, Train Loss: 0.0104, Test Loss: 0.5555\n",
      "Epoch 229/400, Train Loss: 0.0117, Test Loss: 0.4850\n",
      "Epoch 230/400, Train Loss: 0.0095, Test Loss: 0.4333\n",
      "Epoch 231/400, Train Loss: 0.0030, Test Loss: 0.4426\n",
      "Epoch 232/400, Train Loss: 0.0058, Test Loss: 0.5021\n",
      "Epoch 233/400, Train Loss: 0.0162, Test Loss: 0.6278\n",
      "Epoch 234/400, Train Loss: 0.0065, Test Loss: 0.5256\n",
      "Epoch 235/400, Train Loss: 0.0084, Test Loss: 0.5652\n",
      "Epoch 236/400, Train Loss: 0.0118, Test Loss: 0.5420\n",
      "Epoch 237/400, Train Loss: 0.0090, Test Loss: 0.5791\n",
      "Epoch 238/400, Train Loss: 0.0121, Test Loss: 0.6023\n",
      "Epoch 239/400, Train Loss: 0.0118, Test Loss: 0.5173\n",
      "Epoch 240/400, Train Loss: 0.0081, Test Loss: 0.5489\n",
      "Epoch 241/400, Train Loss: 0.0063, Test Loss: 0.5112\n",
      "Epoch 242/400, Train Loss: 0.0068, Test Loss: 0.5351\n",
      "Epoch 243/400, Train Loss: 0.0183, Test Loss: 0.5298\n",
      "Epoch 244/400, Train Loss: 0.0066, Test Loss: 0.5001\n",
      "Epoch 245/400, Train Loss: 0.0066, Test Loss: 0.5307\n",
      "Epoch 246/400, Train Loss: 0.0103, Test Loss: 0.5150\n",
      "Epoch 247/400, Train Loss: 0.0101, Test Loss: 0.5821\n",
      "Epoch 248/400, Train Loss: 0.0053, Test Loss: 0.5426\n",
      "Epoch 249/400, Train Loss: 0.0105, Test Loss: 0.5717\n",
      "Epoch 250/400, Train Loss: 0.0109, Test Loss: 0.5131\n",
      "Epoch 251/400, Train Loss: 0.0037, Test Loss: 0.5362\n",
      "Epoch 252/400, Train Loss: 0.0157, Test Loss: 0.5321\n",
      "Epoch 253/400, Train Loss: 0.0085, Test Loss: 0.5531\n",
      "Epoch 254/400, Train Loss: 0.0119, Test Loss: 0.5565\n",
      "Epoch 255/400, Train Loss: 0.0135, Test Loss: 0.5929\n",
      "Epoch 256/400, Train Loss: 0.0077, Test Loss: 0.5089\n",
      "Epoch 257/400, Train Loss: 0.0066, Test Loss: 0.5369\n",
      "Epoch 258/400, Train Loss: 0.0080, Test Loss: 0.5436\n",
      "Epoch 259/400, Train Loss: 0.0128, Test Loss: 0.5361\n",
      "Epoch 260/400, Train Loss: 0.0053, Test Loss: 0.5214\n",
      "Epoch 261/400, Train Loss: 0.0076, Test Loss: 0.5929\n",
      "Epoch 262/400, Train Loss: 0.0115, Test Loss: 0.5794\n",
      "Epoch 263/400, Train Loss: 0.0101, Test Loss: 0.4827\n",
      "Epoch 264/400, Train Loss: 0.0059, Test Loss: 0.5161\n",
      "Epoch 265/400, Train Loss: 0.0028, Test Loss: 0.4459\n",
      "Epoch 266/400, Train Loss: 0.0001, Test Loss: 0.4530\n",
      "Epoch 267/400, Train Loss: 0.0170, Test Loss: 0.6084\n",
      "Epoch 268/400, Train Loss: 0.0253, Test Loss: 0.5373\n",
      "Epoch 269/400, Train Loss: 0.0036, Test Loss: 0.5123\n",
      "Epoch 270/400, Train Loss: 0.0042, Test Loss: 0.5547\n",
      "Epoch 271/400, Train Loss: 0.0102, Test Loss: 0.6276\n",
      "Epoch 272/400, Train Loss: 0.0171, Test Loss: 0.5233\n",
      "Epoch 273/400, Train Loss: 0.0040, Test Loss: 0.5178\n",
      "Epoch 274/400, Train Loss: 0.0035, Test Loss: 0.5194\n",
      "Epoch 275/400, Train Loss: 0.0082, Test Loss: 0.5481\n",
      "Epoch 276/400, Train Loss: 0.0087, Test Loss: 0.5842\n",
      "Epoch 277/400, Train Loss: 0.0068, Test Loss: 0.5756\n",
      "Epoch 278/400, Train Loss: 0.0030, Test Loss: 0.5337\n",
      "Epoch 279/400, Train Loss: 0.0322, Test Loss: 0.6818\n",
      "Epoch 280/400, Train Loss: 0.0137, Test Loss: 0.5408\n",
      "Epoch 281/400, Train Loss: 0.0052, Test Loss: 0.5172\n",
      "Epoch 282/400, Train Loss: 0.0025, Test Loss: 0.5360\n",
      "Epoch 283/400, Train Loss: 0.0102, Test Loss: 0.6340\n",
      "Epoch 284/400, Train Loss: 0.0116, Test Loss: 0.5469\n",
      "Epoch 285/400, Train Loss: 0.0085, Test Loss: 0.6054\n",
      "Epoch 286/400, Train Loss: 0.0033, Test Loss: 0.5620\n",
      "Epoch 287/400, Train Loss: 0.0081, Test Loss: 0.7050\n",
      "Epoch 288/400, Train Loss: 0.0101, Test Loss: 0.6123\n",
      "Epoch 289/400, Train Loss: 0.0047, Test Loss: 0.5594\n",
      "Epoch 290/400, Train Loss: 0.0109, Test Loss: 0.5853\n",
      "Epoch 291/400, Train Loss: 0.0142, Test Loss: 0.7520\n",
      "Epoch 292/400, Train Loss: 0.0110, Test Loss: 0.5516\n",
      "Epoch 293/400, Train Loss: 0.0086, Test Loss: 0.6259\n",
      "Epoch 294/400, Train Loss: 0.0099, Test Loss: 0.6151\n",
      "Epoch 295/400, Train Loss: 0.0072, Test Loss: 0.5918\n",
      "Epoch 296/400, Train Loss: 0.0026, Test Loss: 0.5904\n",
      "Epoch 297/400, Train Loss: 0.0053, Test Loss: 0.6004\n",
      "Epoch 298/400, Train Loss: 0.0136, Test Loss: 0.5925\n",
      "Epoch 299/400, Train Loss: 0.0107, Test Loss: 0.6463\n",
      "Epoch 300/400, Train Loss: 0.0082, Test Loss: 0.5970\n",
      "Epoch 301/400, Train Loss: 0.0137, Test Loss: 0.6101\n",
      "Epoch 302/400, Train Loss: 0.0108, Test Loss: 0.6535\n",
      "Epoch 303/400, Train Loss: 0.0037, Test Loss: 0.5570\n",
      "Epoch 304/400, Train Loss: 0.0015, Test Loss: 0.6106\n",
      "Epoch 305/400, Train Loss: 0.0138, Test Loss: 0.6156\n",
      "Epoch 306/400, Train Loss: 0.0172, Test Loss: 0.6672\n",
      "Epoch 307/400, Train Loss: 0.0070, Test Loss: 0.5996\n",
      "Epoch 308/400, Train Loss: 0.0077, Test Loss: 0.6387\n",
      "Epoch 309/400, Train Loss: 0.0143, Test Loss: 0.5744\n",
      "Epoch 310/400, Train Loss: 0.0143, Test Loss: 0.6420\n",
      "Epoch 311/400, Train Loss: 0.0039, Test Loss: 0.6052\n",
      "Epoch 312/400, Train Loss: 0.0076, Test Loss: 0.6274\n",
      "Epoch 313/400, Train Loss: 0.0093, Test Loss: 0.6574\n",
      "Epoch 314/400, Train Loss: 0.0064, Test Loss: 0.6668\n",
      "Epoch 315/400, Train Loss: 0.0023, Test Loss: 0.5785\n",
      "Epoch 316/400, Train Loss: 0.0061, Test Loss: 0.6852\n",
      "Epoch 317/400, Train Loss: 0.0208, Test Loss: 0.5990\n",
      "Epoch 318/400, Train Loss: 0.0078, Test Loss: 0.6542\n",
      "Epoch 319/400, Train Loss: 0.0056, Test Loss: 0.6691\n",
      "Epoch 320/400, Train Loss: 0.0100, Test Loss: 0.6610\n",
      "Epoch 321/400, Train Loss: 0.0096, Test Loss: 0.7661\n",
      "Epoch 322/400, Train Loss: 0.0181, Test Loss: 0.7049\n",
      "Epoch 323/400, Train Loss: 0.0109, Test Loss: 0.5851\n",
      "Epoch 324/400, Train Loss: 0.0038, Test Loss: 0.6271\n",
      "Epoch 325/400, Train Loss: 0.0013, Test Loss: 0.5866\n",
      "Epoch 326/400, Train Loss: 0.0002, Test Loss: 0.5636\n",
      "Epoch 327/400, Train Loss: 0.0000, Test Loss: 0.5625\n",
      "Epoch 328/400, Train Loss: 0.0000, Test Loss: 0.5620\n",
      "Epoch 329/400, Train Loss: 0.0000, Test Loss: 0.5617\n",
      "Epoch 330/400, Train Loss: 0.0000, Test Loss: 0.5613\n",
      "Epoch 331/400, Train Loss: 0.0000, Test Loss: 0.5638\n",
      "Epoch 332/400, Train Loss: 0.0000, Test Loss: 0.5608\n",
      "Epoch 333/400, Train Loss: 0.0000, Test Loss: 0.5605\n",
      "Epoch 334/400, Train Loss: 0.0000, Test Loss: 0.5602\n",
      "Epoch 335/400, Train Loss: 0.0000, Test Loss: 0.5600\n",
      "Epoch 336/400, Train Loss: 0.0000, Test Loss: 0.5597\n",
      "Epoch 337/400, Train Loss: 0.0000, Test Loss: 0.5595\n",
      "Epoch 338/400, Train Loss: 0.0000, Test Loss: 0.5593\n",
      "Epoch 339/400, Train Loss: 0.0000, Test Loss: 0.5590\n",
      "Epoch 340/400, Train Loss: 0.0000, Test Loss: 0.5588\n",
      "Epoch 341/400, Train Loss: 0.0000, Test Loss: 0.5586\n",
      "Epoch 342/400, Train Loss: 0.0000, Test Loss: 0.5583\n",
      "Epoch 343/400, Train Loss: 0.0000, Test Loss: 0.5584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/400, Train Loss: 0.0000, Test Loss: 0.5579\n",
      "Epoch 345/400, Train Loss: 0.0000, Test Loss: 0.5576\n",
      "Epoch 346/400, Train Loss: 0.0000, Test Loss: 0.5574\n",
      "Epoch 347/400, Train Loss: 0.0000, Test Loss: 0.5571\n",
      "Epoch 348/400, Train Loss: 0.0000, Test Loss: 0.5569\n",
      "Epoch 349/400, Train Loss: 0.0000, Test Loss: 0.5567\n",
      "Epoch 350/400, Train Loss: 0.0000, Test Loss: 0.5564\n",
      "Epoch 351/400, Train Loss: 0.0000, Test Loss: 0.5731\n",
      "Epoch 352/400, Train Loss: 0.0000, Test Loss: 0.5559\n",
      "Epoch 353/400, Train Loss: 0.0000, Test Loss: 0.5557\n",
      "Epoch 354/400, Train Loss: 0.0000, Test Loss: 0.5554\n",
      "Epoch 355/400, Train Loss: 0.0000, Test Loss: 0.5552\n",
      "Epoch 356/400, Train Loss: 0.0000, Test Loss: 0.5550\n",
      "Epoch 357/400, Train Loss: 0.0000, Test Loss: 0.5547\n",
      "Epoch 358/400, Train Loss: 0.0000, Test Loss: 0.5545\n",
      "Epoch 359/400, Train Loss: 0.0000, Test Loss: 0.5542\n",
      "Epoch 360/400, Train Loss: 0.0000, Test Loss: 0.5569\n",
      "Epoch 361/400, Train Loss: 0.0000, Test Loss: 0.5537\n",
      "Epoch 362/400, Train Loss: 0.0000, Test Loss: 0.5535\n",
      "Epoch 363/400, Train Loss: 0.0000, Test Loss: 0.5532\n",
      "Epoch 364/400, Train Loss: 0.0000, Test Loss: 0.5804\n",
      "Epoch 365/400, Train Loss: 0.0000, Test Loss: 0.5527\n",
      "Epoch 366/400, Train Loss: 0.0000, Test Loss: 0.5525\n",
      "Epoch 367/400, Train Loss: 0.0000, Test Loss: 0.5523\n",
      "Epoch 368/400, Train Loss: 0.0000, Test Loss: 0.5521\n",
      "Epoch 369/400, Train Loss: 0.0000, Test Loss: 0.5518\n",
      "Epoch 370/400, Train Loss: 0.0000, Test Loss: 0.5828\n",
      "Epoch 371/400, Train Loss: 0.0000, Test Loss: 0.5514\n",
      "Epoch 372/400, Train Loss: 0.0000, Test Loss: 0.5512\n",
      "Epoch 373/400, Train Loss: 0.0000, Test Loss: 0.5510\n",
      "Epoch 374/400, Train Loss: 0.0000, Test Loss: 0.5536\n",
      "Epoch 375/400, Train Loss: 0.0000, Test Loss: 0.5538\n",
      "Epoch 376/400, Train Loss: 0.0000, Test Loss: 0.5505\n",
      "Epoch 377/400, Train Loss: 0.0000, Test Loss: 0.5503\n",
      "Epoch 378/400, Train Loss: 0.0000, Test Loss: 0.5613\n",
      "Epoch 379/400, Train Loss: 0.0000, Test Loss: 0.5703\n",
      "Epoch 380/400, Train Loss: 0.0000, Test Loss: 0.5501\n",
      "Epoch 381/400, Train Loss: 0.0000, Test Loss: 0.5527\n",
      "Epoch 382/400, Train Loss: 0.0000, Test Loss: 0.5833\n",
      "Epoch 383/400, Train Loss: 0.0000, Test Loss: 0.5732\n",
      "Epoch 384/400, Train Loss: 0.0000, Test Loss: 0.5499\n",
      "Epoch 385/400, Train Loss: 0.0000, Test Loss: 0.5499\n",
      "Epoch 386/400, Train Loss: 0.0000, Test Loss: 0.5499\n",
      "Epoch 387/400, Train Loss: 0.0000, Test Loss: 0.5500\n",
      "Epoch 388/400, Train Loss: 0.0000, Test Loss: 0.5525\n",
      "Epoch 389/400, Train Loss: 0.0000, Test Loss: 0.5501\n",
      "Epoch 390/400, Train Loss: 0.0000, Test Loss: 0.5794\n",
      "Epoch 391/400, Train Loss: 0.0000, Test Loss: 0.5908\n",
      "Epoch 392/400, Train Loss: 0.0000, Test Loss: 0.5506\n",
      "Epoch 393/400, Train Loss: 0.0000, Test Loss: 0.5506\n",
      "Epoch 394/400, Train Loss: 0.0000, Test Loss: 0.5507\n",
      "Epoch 395/400, Train Loss: 0.0000, Test Loss: 0.5508\n",
      "Epoch 396/400, Train Loss: 0.0000, Test Loss: 0.5508\n",
      "Epoch 397/400, Train Loss: 0.0000, Test Loss: 0.5509\n",
      "Epoch 398/400, Train Loss: 0.0000, Test Loss: 0.5560\n",
      "Epoch 399/400, Train Loss: 0.0000, Test Loss: 0.5509\n",
      "Epoch 400/400, Train Loss: 0.0000, Test Loss: 0.5509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td></td></tr><tr><td>accuracy/train</td><td></td></tr><tr><td>batch_loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss/test</td><td></td></tr><tr><td>loss/train</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.982</td></tr><tr><td>accuracy/train</td><td>1.0</td></tr><tr><td>batch_loss</td><td>0.0</td></tr><tr><td>epoch</td><td>399</td></tr><tr><td>loss/test</td><td>0.55091</td></tr><tr><td>loss/train</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apple-cobbler-284</strong> at: <a href='https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/azj803hf' target=\"_blank\">https://wandb.ai/sienka/SLT%20of%20Double%20Descent/runs/azj803hf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240314_124041-azj803hf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for hidden size: 512\n"
     ]
    }
   ],
   "source": [
    "input_size = 28 * 28  # MNIST images are 28x28\n",
    "output_size = 10  # 10 classes\n",
    "hidden_sizes = [2, 4, 8, 16, 32 ,64, 128, 512]  # Example sizes\n",
    "\n",
    "previous_model = None\n",
    "for k in range (len(hidden_sizes)):\n",
    "    hidden_size = hidden_sizes[k]\n",
    "    torch.manual_seed(42)\n",
    "    model = FCNN(input_size, hidden_size, output_size).to(device)\n",
    "    '''if previous_model:\n",
    "        initialize_with_weight_reuse(model, previous_model, hidden_size)\n",
    "    print('Started traing for model')\n",
    "    train_network(model, train_loader, input_size, hidden_size, output_size)\n",
    "    previous_model = model'''\n",
    "    train_network(model, train_loader, input_size, hidden_size, output_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
